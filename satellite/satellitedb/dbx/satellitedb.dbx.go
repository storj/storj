//lint:file-ignore U1000,ST1012 generated file
// AUTOGENERATED BY storj.io/dbx
// DO NOT EDIT.

package dbx

import (
	"bytes"
	"context"
	"database/sql"
	"errors"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"
	"unicode"

	"storj.io/storj/shared/flightrecorder"
	"storj.io/storj/shared/dbutil/txutil"

	"cloud.google.com/go/spanner"
	"encoding/base64"
	"encoding/json"
	sqlspanner "github.com/googleapis/go-sql-spanner"
	"github.com/jackc/pgx/v5/pgconn"
	"storj.io/storj/shared/tagsql"
	"google.golang.org/api/option"
	"google.golang.org/grpc/codes"
)

// Prevent conditional imports from causing build failures.
var _ = strconv.Itoa
var _ = strings.LastIndex
var _ = fmt.Sprint
var _ sync.Mutex

var (
	WrapErr     = func(err *Error) error { return err }
	Logger      func(format string, args ...any)
	ShouldRetry func(driver string, err error) bool

	errTooManyRows       = errors.New("too many rows")
	errUnsupportedDriver = errors.New("unsupported driver")
	errEmptyUpdate       = errors.New("empty update")
)

func logError(format string, args ...any) {
	if Logger != nil {
		Logger(format, args...)
	}
}

type ErrorCode int

const (
	ErrorCode_Unknown ErrorCode = iota
	ErrorCode_UnsupportedDriver
	ErrorCode_NoRows
	ErrorCode_TxDone
	ErrorCode_TooManyRows
	ErrorCode_ConstraintViolation
	ErrorCode_EmptyUpdate
)

type Error struct {
	Err         error
	Code        ErrorCode
	Driver      string
	Constraint  string
	QuerySuffix string
}

func (e *Error) Error() string {
	return e.Err.Error()
}

func (e *Error) Unwrap() error {
	return e.Err
}

func wrapErr(e *Error) error {
	if WrapErr == nil {
		return e
	}
	return WrapErr(e)
}

func makeErr(err error) error {
	if err == nil {
		return nil
	}
	var e *Error
	if errors.As(err, &e) {
		return wrapErr(e)
	}
	e = &Error{Err: err}
	switch {
	case errors.Is(err, sql.ErrNoRows):
		e.Code = ErrorCode_NoRows
	case errors.Is(err, sql.ErrTxDone):
		e.Code = ErrorCode_TxDone
	}
	return wrapErr(e)
}

func shouldRetry(driver string, err error) bool {
	if ShouldRetry == nil {
		return false
	}
	return ShouldRetry(driver, err)
}

func unsupportedDriver(driver string) error {
	return wrapErr(&Error{
		Err:    errUnsupportedDriver,
		Code:   ErrorCode_UnsupportedDriver,
		Driver: driver,
	})
}

func emptyUpdate() error {
	return wrapErr(&Error{
		Err:  errEmptyUpdate,
		Code: ErrorCode_EmptyUpdate,
	})
}

func tooManyRows(query_suffix string) error {
	return wrapErr(&Error{
		Err:         errTooManyRows,
		Code:        ErrorCode_TooManyRows,
		QuerySuffix: query_suffix,
	})
}

func constraintViolation(err error, constraint string) error {
	return wrapErr(&Error{
		Err:        err,
		Code:       ErrorCode_ConstraintViolation,
		Constraint: constraint,
	})
}

func closeRows(rows tagsql.Rows, err *error) {
	rowsErr := rows.Err()
	closeErr := rows.Close()
	if *err != nil {
		// throw away errors from .Err() and .Close(), if any; they are almost certainly less important
		// than the error we already have
		return
	}
	if rowsErr != nil {
		// throw away error from .Close(), if any; it is probably less important
		*err = rowsErr
		return
	}
	*err = closeErr
}

type driver interface {
	ExecContext(ctx context.Context, query string, args ...any) (sql.Result, error)
	QueryContext(ctx context.Context, query string, args ...any) (tagsql.Rows, error)
	QueryRowContext(ctx context.Context, query string, args ...any) *sql.Row
}

type DB struct {
	tagsql.DB
	dbMethods

	Hooks struct {
		Now func() time.Time
	}

	driver string
}

func Open(driver, source string, recorder *flightrecorder.Box) (db *DB, err error) {
	var sql_db *sql.DB
	switch driver {
	case "pgx":
		sql_db, err = openpgx(source)
	case "pgxcockroach":
		sql_db, err = openpgxcockroach(source)
	case "spanner":
		sql_db, err = openspanner(source)
	default:
		return nil, unsupportedDriver(driver)
	}
	if err != nil {
		return nil, makeErr(err)
	}
	defer func(sql_db *sql.DB) {
		if err != nil {
			_ = sql_db.Close()
		}
	}(sql_db)

	if err := sql_db.Ping(); err != nil {
		return nil, makeErr(err)
	}

	db = &DB{
		DB: tagsql.WrapWithRecorder(sql_db, recorder),

		driver: driver,
	}
	db.Hooks.Now = time.Now

	switch driver {
	case "pgx":
		db.dbMethods = newpgx(db)
	case "pgxcockroach":
		db.dbMethods = newpgxcockroach(db)
	case "spanner":
		db.dbMethods = newspanner(db)
	default:
		return nil, unsupportedDriver(driver)
	}

	return db, nil
}

func (obj *DB) Close() (err error) {
	return obj.makeErr(obj.DB.Close())
}

func (obj *DB) Open(ctx context.Context) (*Tx, error) {
	tx, err := obj.DB.BeginTx(ctx, nil)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	return &Tx{
		Tx:        tx,
		txMethods: obj.wrapTx(tx),
	}, nil
}

func DeleteAll(ctx context.Context, db *DB) (int64, error) {
	tx, err := db.Open(ctx)
	if err != nil {
		return 0, err
	}
	defer func() {
		if err == nil {
			err = db.makeErr(tx.Commit())
			return
		}

		if err_rollback := tx.Rollback(); err_rollback != nil {
			logError("delete-all: rollback failed: %v", db.makeErr(err_rollback))
		}
	}()
	return tx.deleteAll(ctx)
}

type Tx struct {
	Tx tagsql.Tx
	txMethods
}

func (tx *Tx) ExecContext(ctx context.Context, query string, args ...any) (sql.Result, error) {
	return tx.Tx.ExecContext(ctx, query, args...)
}
func (tx *Tx) QueryContext(ctx context.Context, query string, args ...any) (tagsql.Rows, error) {
	return tx.Tx.QueryContext(ctx, query, args...)
}
func (tx *Tx) QueryRowContext(ctx context.Context, query string, args ...any) *sql.Row {
	return tx.Tx.QueryRowContext(ctx, query, args...)
}

type dialectTx struct {
	tx tagsql.Tx
}

func (tx *dialectTx) Commit() (err error) {
	return makeErr(tx.tx.Commit())
}

func (tx *dialectTx) Rollback() (err error) {
	return makeErr(tx.tx.Rollback())
}

type pgxImpl struct {
	db      *DB
	dialect __sqlbundle_pgx
	driver
	txn bool
}

func (obj *pgxImpl) Rebind(s string) string {
	return obj.dialect.Rebind(s)
}

func (obj *pgxImpl) logStmt(stmt string, args ...any) {
	pgxLogStmt(stmt, args...)
}

func (obj *pgxImpl) makeErr(err error) error {
	constraint, ok := obj.isConstraintError(err)
	if ok {
		return constraintViolation(err, constraint)
	}
	return makeErr(err)
}

func (obj *pgxImpl) shouldRetry(err error) bool {
	return !obj.txn && shouldRetry(obj.db.driver, err)
}

type pgxImpl_retryingRow struct {
	obj   *pgxImpl
	ctx   context.Context
	query string
	args  []any
}

func (obj *pgxImpl) queryRowContext(ctx context.Context, query string, args ...any) *pgxImpl_retryingRow {
	return &pgxImpl_retryingRow{
		obj:   obj,
		ctx:   ctx,
		query: query,
		args:  args,
	}
}

func (rows *pgxImpl_retryingRow) Scan(dest ...any) error {
	for {
		err := rows.obj.driver.QueryRowContext(rows.ctx, rows.query, rows.args...).Scan(dest...)
		if err != nil {
			if rows.obj.shouldRetry(err) {
				continue
			}
			// caller will wrap this error
			return err
		}
		return nil
	}
}

type pgxDB struct {
	db *DB
	*pgxImpl
}

func newpgx(db *DB) *pgxDB {
	return &pgxDB{
		db: db,
		pgxImpl: &pgxImpl{
			db:     db,
			driver: db.DB,
		},
	}
}

func (obj *pgxDB) Schema() []string {
	return []string{

		`CREATE TABLE account_freeze_events (
	user_id bytea NOT NULL,
	event integer NOT NULL,
	limits jsonb,
	days_till_escalation integer,
	notifications_count integer NOT NULL DEFAULT 0,
	created_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	PRIMARY KEY ( user_id, event )
)`,

		`CREATE TABLE accounting_rollups (
	node_id bytea NOT NULL,
	start_time timestamp with time zone NOT NULL,
	put_total bigint NOT NULL,
	get_total bigint NOT NULL,
	get_audit_total bigint NOT NULL,
	get_repair_total bigint NOT NULL,
	put_repair_total bigint NOT NULL,
	at_rest_total double precision NOT NULL,
	interval_end_time timestamp with time zone,
	PRIMARY KEY ( node_id, start_time )
)`,

		`CREATE TABLE accounting_timestamps (
	name text NOT NULL,
	value timestamp with time zone NOT NULL,
	PRIMARY KEY ( name )
)`,

		`CREATE TABLE billing_balances (
	user_id bytea NOT NULL,
	balance bigint NOT NULL,
	last_updated timestamp with time zone NOT NULL,
	PRIMARY KEY ( user_id )
)`,

		`CREATE TABLE billing_transactions (
	id bigserial NOT NULL,
	user_id bytea NOT NULL,
	amount bigint NOT NULL,
	currency text NOT NULL,
	description text NOT NULL,
	source text NOT NULL,
	status text NOT NULL,
	type text NOT NULL,
	metadata jsonb NOT NULL,
	tx_timestamp timestamp with time zone NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE bucket_bandwidth_rollups (
	bucket_name bytea NOT NULL,
	project_id bytea NOT NULL,
	interval_start timestamp with time zone NOT NULL,
	interval_seconds integer NOT NULL,
	action integer NOT NULL,
	product_id integer,
	inline bigint NOT NULL,
	allocated bigint NOT NULL,
	settled bigint NOT NULL,
	PRIMARY KEY ( project_id, bucket_name, interval_start, action )
)`,

		`CREATE TABLE bucket_bandwidth_rollup_archives (
	bucket_name bytea NOT NULL,
	project_id bytea NOT NULL,
	product_id integer,
	interval_start timestamp with time zone NOT NULL,
	interval_seconds integer NOT NULL,
	action integer NOT NULL,
	inline bigint NOT NULL,
	allocated bigint NOT NULL,
	settled bigint NOT NULL,
	PRIMARY KEY ( bucket_name, project_id, interval_start, action )
)`,

		`CREATE TABLE bucket_storage_tallies (
	bucket_name bytea NOT NULL,
	project_id bytea NOT NULL,
	interval_start timestamp with time zone NOT NULL,
	product_id integer,
	total_bytes bigint NOT NULL DEFAULT 0,
	inline bigint NOT NULL,
	remote bigint NOT NULL,
	total_segments_count integer NOT NULL DEFAULT 0,
	remote_segments_count integer NOT NULL,
	inline_segments_count integer NOT NULL,
	object_count integer NOT NULL,
	metadata_size bigint NOT NULL,
	PRIMARY KEY ( bucket_name, project_id, interval_start )
)`,

		`CREATE TABLE change_histories (
	id bytea NOT NULL,
	admin_email text NOT NULL,
	user_id bytea NOT NULL,
	project_id bytea,
	bucket_name bytea,
	item_type text NOT NULL,
	operation text NOT NULL,
	reason text NOT NULL,
	changes jsonb NOT NULL,
	timestamp timestamp with time zone NOT NULL DEFAULT current_timestamp,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE coinpayments_transactions (
	id text NOT NULL,
	user_id bytea NOT NULL,
	address text NOT NULL,
	amount_numeric bigint NOT NULL,
	received_numeric bigint NOT NULL,
	status integer NOT NULL,
	key text NOT NULL,
	timeout integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE entitlements (
	scope bytea NOT NULL,
	features jsonb NOT NULL DEFAULT '{}',
	updated_at timestamp with time zone NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( scope )
)`,

		`CREATE TABLE nodes (
	id bytea NOT NULL,
	address text NOT NULL DEFAULT '',
	last_net text NOT NULL,
	last_ip_port text,
	country_code text,
	protocol integer NOT NULL DEFAULT 0,
	email text NOT NULL,
	wallet text NOT NULL,
	wallet_features text NOT NULL DEFAULT '',
	free_disk bigint NOT NULL DEFAULT -1,
	piece_count bigint NOT NULL DEFAULT 0,
	major bigint NOT NULL DEFAULT 0,
	minor bigint NOT NULL DEFAULT 0,
	patch bigint NOT NULL DEFAULT 0,
	commit_hash text NOT NULL DEFAULT '',
	release_timestamp timestamp with time zone NOT NULL DEFAULT '0001-01-01 00:00:00+00',
	release boolean NOT NULL DEFAULT false,
	latency_90 bigint NOT NULL DEFAULT 0,
	vetted_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	updated_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	last_contact_success timestamp with time zone NOT NULL DEFAULT 'epoch',
	last_contact_failure timestamp with time zone NOT NULL DEFAULT 'epoch',
	disqualified timestamp with time zone,
	disqualification_reason integer,
	unknown_audit_suspended timestamp with time zone,
	offline_suspended timestamp with time zone,
	under_review timestamp with time zone,
	exit_initiated_at timestamp with time zone,
	exit_loop_completed_at timestamp with time zone,
	exit_finished_at timestamp with time zone,
	exit_success boolean NOT NULL DEFAULT false,
	contained timestamp with time zone,
	last_offline_email timestamp with time zone,
	last_software_update_email timestamp with time zone,
	noise_proto integer,
	noise_public_key bytea,
	debounce_limit integer NOT NULL DEFAULT 0,
	features integer NOT NULL DEFAULT 0,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE node_api_versions (
	id bytea NOT NULL,
	api_version integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	updated_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE node_events (
	id bytea NOT NULL,
	email text NOT NULL,
	last_ip_port text,
	node_id bytea NOT NULL,
	event integer NOT NULL,
	created_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	last_attempted timestamp with time zone,
	email_sent timestamp with time zone,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE node_tags (
	node_id bytea NOT NULL,
	name text NOT NULL,
	value bytea NOT NULL,
	signed_at timestamp with time zone NOT NULL,
	signer bytea NOT NULL,
	PRIMARY KEY ( node_id, name, signer )
)`,

		`CREATE TABLE oauth_clients (
	id bytea NOT NULL,
	encrypted_secret bytea NOT NULL,
	redirect_url text NOT NULL,
	user_id bytea NOT NULL,
	app_name text NOT NULL,
	app_logo_url text NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE oauth_codes (
	client_id bytea NOT NULL,
	user_id bytea NOT NULL,
	scope text NOT NULL,
	redirect_url text NOT NULL,
	challenge text NOT NULL,
	challenge_method text NOT NULL,
	code text NOT NULL,
	created_at timestamp with time zone NOT NULL,
	expires_at timestamp with time zone NOT NULL,
	claimed_at timestamp with time zone,
	PRIMARY KEY ( code )
)`,

		`CREATE TABLE oauth_tokens (
	client_id bytea NOT NULL,
	user_id bytea NOT NULL,
	scope text NOT NULL,
	kind integer NOT NULL,
	token bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	expires_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( token )
)`,

		`CREATE TABLE peer_identities (
	node_id bytea NOT NULL,
	leaf_serial_number bytea NOT NULL,
	chain bytea NOT NULL,
	updated_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( node_id )
)`,

		`CREATE TABLE projects (
	id bytea NOT NULL,
	public_id bytea,
	name text NOT NULL,
	description text NOT NULL,
	usage_limit bigint,
	bandwidth_limit bigint,
	user_specified_usage_limit bigint,
	user_specified_bandwidth_limit bigint,
	segment_limit bigint DEFAULT 1000000,
	rate_limit integer,
	burst_limit integer,
	rate_limit_head integer,
	burst_limit_head integer,
	rate_limit_get integer,
	burst_limit_get integer,
	rate_limit_put integer,
	burst_limit_put integer,
	rate_limit_list integer,
	burst_limit_list integer,
	rate_limit_del integer,
	burst_limit_del integer,
	max_buckets integer,
	user_agent bytea,
	owner_id bytea NOT NULL,
	salt bytea,
	status integer DEFAULT 1,
	status_updated_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL,
	default_placement integer,
	default_versioning integer NOT NULL DEFAULT 1,
	prompted_for_versioning_beta boolean NOT NULL DEFAULT false,
	passphrase_enc bytea,
	passphrase_enc_key_id integer,
	path_encryption boolean NOT NULL DEFAULT true,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE project_bandwidth_daily_rollups (
	project_id bytea NOT NULL,
	product_id integer,
	interval_day date NOT NULL,
	egress_allocated bigint NOT NULL,
	egress_settled bigint NOT NULL,
	egress_dead bigint NOT NULL DEFAULT 0,
	PRIMARY KEY ( project_id, interval_day )
)`,

		`CREATE TABLE registration_tokens (
	secret bytea NOT NULL,
	owner_id bytea,
	project_limit integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( secret ),
	UNIQUE ( owner_id )
)`,

		`CREATE TABLE repair_queue (
	stream_id bytea NOT NULL,
	position bigint NOT NULL,
	attempted_at timestamp with time zone,
	updated_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	inserted_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	segment_health double precision NOT NULL DEFAULT 1,
	placement integer,
	PRIMARY KEY ( stream_id, position )
)`,

		`CREATE TABLE reputations (
	id bytea NOT NULL,
	audit_success_count bigint NOT NULL DEFAULT 0,
	total_audit_count bigint NOT NULL DEFAULT 0,
	vetted_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	updated_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	disqualified timestamp with time zone,
	disqualification_reason integer,
	unknown_audit_suspended timestamp with time zone,
	offline_suspended timestamp with time zone,
	under_review timestamp with time zone,
	online_score double precision NOT NULL DEFAULT 1,
	audit_history bytea NOT NULL,
	audit_reputation_alpha double precision NOT NULL DEFAULT 1,
	audit_reputation_beta double precision NOT NULL DEFAULT 0,
	unknown_audit_reputation_alpha double precision NOT NULL DEFAULT 1,
	unknown_audit_reputation_beta double precision NOT NULL DEFAULT 0,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE reset_password_tokens (
	secret bytea NOT NULL,
	owner_id bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( secret ),
	UNIQUE ( owner_id )
)`,

		`CREATE TABLE reverification_audits (
	node_id bytea NOT NULL,
	stream_id bytea NOT NULL,
	position bigint NOT NULL,
	piece_num integer NOT NULL,
	inserted_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	last_attempt timestamp with time zone,
	reverify_count bigint NOT NULL DEFAULT 0,
	PRIMARY KEY ( node_id, stream_id, position )
)`,

		`CREATE TABLE revocations (
	revoked bytea NOT NULL,
	api_key_id bytea NOT NULL,
	PRIMARY KEY ( revoked )
)`,

		`CREATE TABLE segment_pending_audits (
	node_id bytea NOT NULL,
	stream_id bytea NOT NULL,
	position bigint NOT NULL,
	piece_id bytea NOT NULL,
	stripe_index bigint NOT NULL,
	share_size bigint NOT NULL,
	expected_share_hash bytea NOT NULL,
	reverify_count bigint NOT NULL,
	PRIMARY KEY ( node_id )
)`,

		`CREATE TABLE storagenode_bandwidth_rollups (
	storagenode_id bytea NOT NULL,
	interval_start timestamp with time zone NOT NULL,
	interval_seconds integer NOT NULL,
	action integer NOT NULL,
	allocated bigint DEFAULT 0,
	settled bigint NOT NULL,
	PRIMARY KEY ( storagenode_id, interval_start, action )
)`,

		`CREATE TABLE storagenode_bandwidth_rollup_archives (
	storagenode_id bytea NOT NULL,
	interval_start timestamp with time zone NOT NULL,
	interval_seconds integer NOT NULL,
	action integer NOT NULL,
	allocated bigint DEFAULT 0,
	settled bigint NOT NULL,
	PRIMARY KEY ( storagenode_id, interval_start, action )
)`,

		`CREATE TABLE storagenode_payments (
	id bigserial NOT NULL,
	created_at timestamp with time zone NOT NULL,
	node_id bytea NOT NULL,
	period text NOT NULL,
	amount bigint NOT NULL,
	receipt text,
	notes text,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE storagenode_paystubs (
	period text NOT NULL,
	node_id bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	codes text NOT NULL,
	usage_at_rest double precision NOT NULL,
	usage_get bigint NOT NULL,
	usage_put bigint NOT NULL,
	usage_get_repair bigint NOT NULL,
	usage_put_repair bigint NOT NULL,
	usage_get_audit bigint NOT NULL,
	comp_at_rest bigint NOT NULL,
	comp_get bigint NOT NULL,
	comp_put bigint NOT NULL,
	comp_get_repair bigint NOT NULL,
	comp_put_repair bigint NOT NULL,
	comp_get_audit bigint NOT NULL,
	surge_percent bigint NOT NULL,
	held bigint NOT NULL,
	owed bigint NOT NULL,
	disposed bigint NOT NULL,
	paid bigint NOT NULL,
	distributed bigint NOT NULL,
	PRIMARY KEY ( period, node_id )
)`,

		`CREATE TABLE storagenode_storage_tallies (
	node_id bytea NOT NULL,
	interval_end_time timestamp with time zone NOT NULL,
	data_total double precision NOT NULL,
	PRIMARY KEY ( interval_end_time, node_id )
)`,

		`CREATE TABLE storjscan_payments (
	chain_id bigint NOT NULL DEFAULT 0,
	block_hash bytea NOT NULL,
	block_number bigint NOT NULL,
	transaction bytea NOT NULL,
	log_index integer NOT NULL,
	from_address bytea NOT NULL,
	to_address bytea NOT NULL,
	token_value bigint NOT NULL,
	usd_value bigint NOT NULL,
	status text NOT NULL,
	block_timestamp timestamp with time zone NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( block_hash, log_index )
)`,

		`CREATE TABLE storjscan_wallets (
	user_id bytea NOT NULL,
	wallet_address bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( user_id, wallet_address )
)`,

		`CREATE TABLE stripe_customers (
	user_id bytea NOT NULL,
	customer_id text NOT NULL,
	billing_customer_id text,
	package_plan text,
	purchased_package_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( user_id ),
	UNIQUE ( customer_id )
)`,

		`CREATE TABLE stripecoinpayments_invoice_project_records (
	id bytea NOT NULL,
	project_id bytea NOT NULL,
	storage double precision NOT NULL,
	egress bigint NOT NULL,
	objects bigint,
	segments bigint,
	period_start timestamp with time zone NOT NULL,
	period_end timestamp with time zone NOT NULL,
	state integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id ),
	UNIQUE ( project_id, period_start, period_end )
)`,

		`CREATE TABLE stripecoinpayments_tx_conversion_rates (
	tx_id text NOT NULL,
	rate_numeric double precision NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( tx_id )
)`,

		`CREATE TABLE users (
	id bytea NOT NULL,
	external_id text,
	tenant_id text,
	email text NOT NULL,
	normalized_email text NOT NULL,
	full_name text NOT NULL,
	short_name text,
	password_hash bytea NOT NULL,
	new_unverified_email text,
	email_change_verification_step integer NOT NULL DEFAULT 0,
	status integer NOT NULL,
	status_updated_at timestamp with time zone,
	final_invoice_generated boolean NOT NULL DEFAULT false,
	user_agent bytea,
	created_at timestamp with time zone NOT NULL,
	project_limit integer NOT NULL DEFAULT 0,
	project_bandwidth_limit bigint NOT NULL DEFAULT 0,
	project_storage_limit bigint NOT NULL DEFAULT 0,
	project_segment_limit bigint NOT NULL DEFAULT 0,
	kind integer NOT NULL DEFAULT 0,
	position text,
	company_name text,
	company_size integer,
	working_on text,
	is_professional boolean NOT NULL DEFAULT false,
	employee_count text,
	have_sales_contact boolean NOT NULL DEFAULT false,
	mfa_enabled boolean NOT NULL DEFAULT false,
	mfa_secret_key text,
	mfa_recovery_codes text,
	signup_promo_code text,
	verification_reminders integer NOT NULL DEFAULT 0,
	trial_notifications integer NOT NULL DEFAULT 0,
	failed_login_count integer,
	login_lockout_expiration timestamp with time zone,
	signup_captcha double precision,
	default_placement integer,
	activation_code text,
	signup_id text,
	trial_expiration timestamp with time zone,
	upgrade_time timestamp with time zone,
	hubspot_object_id text,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE user_settings (
	user_id bytea NOT NULL,
	session_minutes integer,
	passphrase_prompt boolean,
	onboarding_start boolean NOT NULL DEFAULT true,
	onboarding_end boolean NOT NULL DEFAULT true,
	onboarding_step text,
	notice_dismissal jsonb NOT NULL DEFAULT '{}',
	PRIMARY KEY ( user_id )
)`,

		`CREATE TABLE value_attributions (
	project_id bytea NOT NULL,
	bucket_name bytea NOT NULL,
	user_agent bytea,
	placement integer,
	last_updated timestamp with time zone NOT NULL,
	PRIMARY KEY ( project_id, bucket_name )
)`,

		`CREATE TABLE verification_audits (
	inserted_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	stream_id bytea NOT NULL,
	position bigint NOT NULL,
	expires_at timestamp with time zone,
	encrypted_size integer NOT NULL,
	PRIMARY KEY ( inserted_at, stream_id, position )
)`,

		`CREATE TABLE webapp_sessions (
	id bytea NOT NULL,
	user_id bytea NOT NULL,
	ip_address text NOT NULL,
	user_agent text NOT NULL,
	status integer NOT NULL,
	expires_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE api_keys (
	id bytea NOT NULL,
	project_id bytea NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	head bytea NOT NULL,
	name text NOT NULL,
	secret bytea NOT NULL,
	user_agent bytea,
	created_at timestamp with time zone NOT NULL,
	created_by bytea REFERENCES users( id ),
	version integer NOT NULL DEFAULT 0,
	PRIMARY KEY ( id ),
	UNIQUE ( head ),
	UNIQUE ( name, project_id )
)`,

		`CREATE TABLE bucket_metainfos (
	id bytea NOT NULL,
	project_id bytea NOT NULL REFERENCES projects( id ),
	name bytea NOT NULL,
	tags bytea,
	user_agent bytea,
	versioning integer NOT NULL DEFAULT 0,
	object_lock_enabled boolean NOT NULL DEFAULT false,
	default_retention_mode integer,
	default_retention_days integer,
	default_retention_years integer,
	path_cipher integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	default_segment_size integer NOT NULL,
	default_encryption_cipher_suite integer NOT NULL,
	default_encryption_block_size integer NOT NULL,
	default_redundancy_algorithm integer NOT NULL,
	default_redundancy_share_size integer NOT NULL,
	default_redundancy_required_shares integer NOT NULL,
	default_redundancy_repair_shares integer NOT NULL,
	default_redundancy_optimal_shares integer NOT NULL,
	default_redundancy_total_shares integer NOT NULL,
	placement integer,
	created_by bytea REFERENCES users( id ),
	PRIMARY KEY ( project_id, name )
)`,

		`CREATE TABLE bucket_migrations (
	id bytea NOT NULL,
	project_id bytea NOT NULL REFERENCES projects( id ),
	bucket_name bytea NOT NULL,
	from_placement integer NOT NULL,
	to_placement integer NOT NULL,
	migration_type integer NOT NULL,
	state text NOT NULL,
	bytes_processed bigint NOT NULL DEFAULT 0,
	error_message text,
	created_at timestamp with time zone NOT NULL,
	updated_at timestamp with time zone NOT NULL,
	completed_at timestamp with time zone,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE domains (
	subdomain text NOT NULL,
	project_id bytea NOT NULL REFERENCES projects( id ),
	prefix text NOT NULL,
	access_id text NOT NULL,
	created_by bytea NOT NULL REFERENCES users( id ),
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( project_id, subdomain )
)`,

		`CREATE TABLE project_invitations (
	project_id bytea NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	email text NOT NULL,
	inviter_id bytea REFERENCES users( id ) ON DELETE CASCADE,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( project_id, email )
)`,

		`CREATE TABLE project_members (
	member_id bytea NOT NULL REFERENCES users( id ) ON DELETE CASCADE,
	project_id bytea NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	role integer NOT NULL DEFAULT 0,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( member_id, project_id )
)`,

		`CREATE TABLE rest_api_keys (
	id bytea NOT NULL,
	user_id bytea NOT NULL REFERENCES users( id ) ON DELETE CASCADE,
	token bytea NOT NULL,
	name text NOT NULL,
	expires_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id ),
	UNIQUE ( token )
)`,

		`CREATE TABLE stripecoinpayments_apply_balance_intents (
	tx_id text NOT NULL REFERENCES coinpayments_transactions( id ) ON DELETE CASCADE,
	state integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( tx_id )
)`,

		`CREATE TABLE api_key_tails (
	root_key_id bytea REFERENCES api_keys( id ) ON DELETE CASCADE,
	tail bytea NOT NULL,
	parent_tail bytea NOT NULL,
	caveat bytea NOT NULL,
	last_used timestamp with time zone NOT NULL,
	PRIMARY KEY ( tail )
)`,

		`CREATE INDEX accounting_rollups_start_time_index ON accounting_rollups ( start_time )`,

		`CREATE INDEX billing_transactions_tx_timestamp_index ON billing_transactions ( tx_timestamp )`,

		`CREATE INDEX bucket_bandwidth_rollups_project_id_action_interval_index ON bucket_bandwidth_rollups ( project_id, action, interval_start )`,

		`CREATE INDEX bucket_bandwidth_rollups_action_interval_project_id_index ON bucket_bandwidth_rollups ( action, interval_start, project_id )`,

		`CREATE INDEX bucket_bandwidth_rollups_archive_project_id_action_interval_index ON bucket_bandwidth_rollup_archives ( project_id, action, interval_start )`,

		`CREATE INDEX bucket_bandwidth_rollups_archive_action_interval_project_id_index ON bucket_bandwidth_rollup_archives ( action, interval_start, project_id )`,

		`CREATE INDEX bucket_storage_tallies_project_id_interval_start_index ON bucket_storage_tallies ( project_id, interval_start )`,

		`CREATE INDEX bucket_storage_tallies_interval_start_index ON bucket_storage_tallies ( interval_start )`,

		`CREATE INDEX change_history_user_id_timestamp_idx ON change_histories ( user_id, timestamp )`,

		`CREATE INDEX change_history_user_id_item_type_timestamp_idx ON change_histories ( user_id, item_type, timestamp )`,

		`CREATE INDEX change_history_project_id_item_type_timestamp_idx ON change_histories ( project_id, item_type, timestamp )`,

		`CREATE INDEX change_history_bucket_name_timestamp_idx ON change_histories ( bucket_name, timestamp )`,

		`CREATE INDEX node_events_email_event_created_at_index ON node_events ( email, event, created_at ) WHERE node_events.email_sent is NULL`,

		`CREATE INDEX oauth_clients_user_id_index ON oauth_clients ( user_id )`,

		`CREATE INDEX oauth_codes_user_id_index ON oauth_codes ( user_id )`,

		`CREATE INDEX oauth_codes_client_id_index ON oauth_codes ( client_id )`,

		`CREATE INDEX oauth_tokens_user_id_index ON oauth_tokens ( user_id )`,

		`CREATE INDEX oauth_tokens_client_id_index ON oauth_tokens ( client_id )`,

		`CREATE INDEX projects_public_id_index ON projects ( public_id )`,

		`CREATE INDEX projects_owner_id_index ON projects ( owner_id )`,

		`CREATE INDEX projects_status_status_updated_at_index ON projects ( status, status_updated_at ) WHERE projects.status_updated_at is not NULL`,

		`CREATE INDEX project_bandwidth_daily_rollup_interval_day_index ON project_bandwidth_daily_rollups ( interval_day )`,

		`CREATE INDEX repair_queue_updated_at_index ON repair_queue ( updated_at )`,

		`CREATE INDEX repair_queue_num_healthy_pieces_attempted_at_index ON repair_queue ( segment_health, attempted_at )`,

		`CREATE INDEX repair_queue_placement_index ON repair_queue ( placement )`,

		`CREATE INDEX reverification_audits_inserted_at_index ON reverification_audits ( inserted_at )`,

		`CREATE INDEX storagenode_bandwidth_rollups_interval_start_index ON storagenode_bandwidth_rollups ( interval_start )`,

		`CREATE INDEX storagenode_bandwidth_rollup_archives_interval_start_index ON storagenode_bandwidth_rollup_archives ( interval_start )`,

		`CREATE INDEX storagenode_payments_node_id_period_index ON storagenode_payments ( node_id, period )`,

		`CREATE INDEX storagenode_paystubs_node_id_index ON storagenode_paystubs ( node_id )`,

		`CREATE INDEX storagenode_storage_tallies_node_id_index ON storagenode_storage_tallies ( node_id )`,

		`CREATE INDEX storjscan_payments_chain_id_block_number_log_index_index ON storjscan_payments ( chain_id, block_number, log_index )`,

		`CREATE INDEX storjscan_wallets_wallet_address_index ON storjscan_wallets ( wallet_address )`,

		`CREATE INDEX stripecoinpayments_invoice_project_records_unbilled_project_id_index ON stripecoinpayments_invoice_project_records ( project_id ) WHERE stripecoinpayments_invoice_project_records.state = 0`,

		`CREATE INDEX users_email_status_index ON users ( normalized_email, status )`,

		`CREATE INDEX trial_expiration_index ON users ( trial_expiration )`,

		`CREATE INDEX users_external_id_index ON users ( external_id ) WHERE users.external_id is not NULL`,

		`CREATE INDEX users_status_status_updated_at_index ON users ( status, status_updated_at ) WHERE users.status_updated_at is not NULL`,

		`CREATE INDEX users_tenant_id_index ON users ( tenant_id ) WHERE users.tenant_id is not NULL`,

		`CREATE INDEX users_normalized_email_tenant_id_status_index ON users ( normalized_email, tenant_id, status ) WHERE users.tenant_id is not NULL`,

		`CREATE INDEX webapp_sessions_user_id_index ON webapp_sessions ( user_id )`,

		`CREATE INDEX bucket_migrations_state_created_at_index ON bucket_migrations ( state, created_at )`,

		`CREATE INDEX project_invitations_project_id_index ON project_invitations ( project_id )`,

		`CREATE INDEX project_invitations_email_index ON project_invitations ( email )`,

		`CREATE INDEX project_members_project_id_index ON project_members ( project_id )`,

		`CREATE INDEX rest_api_keys_user_id_index ON rest_api_keys ( user_id )`,

		`CREATE INDEX rest_api_keys_name_index ON rest_api_keys ( name )`,
	}
}

func (obj *pgxDB) DropSchema() []string {
	return []string{

		`DROP TABLE IF EXISTS api_key_tails`,

		`DROP TABLE IF EXISTS stripecoinpayments_apply_balance_intents`,

		`DROP TABLE IF EXISTS rest_api_keys`,

		`DROP TABLE IF EXISTS project_members`,

		`DROP TABLE IF EXISTS project_invitations`,

		`DROP TABLE IF EXISTS domains`,

		`DROP TABLE IF EXISTS bucket_migrations`,

		`DROP TABLE IF EXISTS bucket_metainfos`,

		`DROP TABLE IF EXISTS api_keys`,

		`DROP TABLE IF EXISTS webapp_sessions`,

		`DROP TABLE IF EXISTS verification_audits`,

		`DROP TABLE IF EXISTS value_attributions`,

		`DROP TABLE IF EXISTS user_settings`,

		`DROP TABLE IF EXISTS users`,

		`DROP TABLE IF EXISTS stripecoinpayments_tx_conversion_rates`,

		`DROP TABLE IF EXISTS stripecoinpayments_invoice_project_records`,

		`DROP TABLE IF EXISTS stripe_customers`,

		`DROP TABLE IF EXISTS storjscan_wallets`,

		`DROP TABLE IF EXISTS storjscan_payments`,

		`DROP TABLE IF EXISTS storagenode_storage_tallies`,

		`DROP TABLE IF EXISTS storagenode_paystubs`,

		`DROP TABLE IF EXISTS storagenode_payments`,

		`DROP TABLE IF EXISTS storagenode_bandwidth_rollup_archives`,

		`DROP TABLE IF EXISTS storagenode_bandwidth_rollups`,

		`DROP TABLE IF EXISTS segment_pending_audits`,

		`DROP TABLE IF EXISTS revocations`,

		`DROP TABLE IF EXISTS reverification_audits`,

		`DROP TABLE IF EXISTS reset_password_tokens`,

		`DROP TABLE IF EXISTS reputations`,

		`DROP TABLE IF EXISTS repair_queue`,

		`DROP TABLE IF EXISTS registration_tokens`,

		`DROP TABLE IF EXISTS project_bandwidth_daily_rollups`,

		`DROP TABLE IF EXISTS projects`,

		`DROP TABLE IF EXISTS peer_identities`,

		`DROP TABLE IF EXISTS oauth_tokens`,

		`DROP TABLE IF EXISTS oauth_codes`,

		`DROP TABLE IF EXISTS oauth_clients`,

		`DROP TABLE IF EXISTS node_tags`,

		`DROP TABLE IF EXISTS node_events`,

		`DROP TABLE IF EXISTS node_api_versions`,

		`DROP TABLE IF EXISTS nodes`,

		`DROP TABLE IF EXISTS entitlements`,

		`DROP TABLE IF EXISTS coinpayments_transactions`,

		`DROP TABLE IF EXISTS change_histories`,

		`DROP TABLE IF EXISTS bucket_storage_tallies`,

		`DROP TABLE IF EXISTS bucket_bandwidth_rollup_archives`,

		`DROP TABLE IF EXISTS bucket_bandwidth_rollups`,

		`DROP TABLE IF EXISTS billing_transactions`,

		`DROP TABLE IF EXISTS billing_balances`,

		`DROP TABLE IF EXISTS accounting_timestamps`,

		`DROP TABLE IF EXISTS accounting_rollups`,

		`DROP TABLE IF EXISTS account_freeze_events`,
	}
}

func (obj *pgxDB) wrapTx(tx tagsql.Tx) txMethods {
	return &pgxTx{
		dialectTx: dialectTx{tx: tx},
		pgxImpl: &pgxImpl{
			db:     obj.db,
			driver: tx,
			txn:    true,
		},
	}
}

type pgxTx struct {
	dialectTx
	*pgxImpl
}

func pgxLogStmt(stmt string, args ...any) {
	// TODO: render placeholders
	if Logger != nil {
		out := fmt.Sprintf("stmt: %s\nargs: %v\n", stmt, pretty(args))
		Logger(out)
	}
}

type pgxcockroachImpl struct {
	db      *DB
	dialect __sqlbundle_pgxcockroach
	driver
	txn bool
}

func (obj *pgxcockroachImpl) Rebind(s string) string {
	return obj.dialect.Rebind(s)
}

func (obj *pgxcockroachImpl) logStmt(stmt string, args ...any) {
	pgxcockroachLogStmt(stmt, args...)
}

func (obj *pgxcockroachImpl) makeErr(err error) error {
	constraint, ok := obj.isConstraintError(err)
	if ok {
		return constraintViolation(err, constraint)
	}
	return makeErr(err)
}

func (obj *pgxcockroachImpl) shouldRetry(err error) bool {
	return !obj.txn && shouldRetry(obj.db.driver, err)
}

type pgxcockroachImpl_retryingRow struct {
	obj   *pgxcockroachImpl
	ctx   context.Context
	query string
	args  []any
}

func (obj *pgxcockroachImpl) queryRowContext(ctx context.Context, query string, args ...any) *pgxcockroachImpl_retryingRow {
	return &pgxcockroachImpl_retryingRow{
		obj:   obj,
		ctx:   ctx,
		query: query,
		args:  args,
	}
}

func (rows *pgxcockroachImpl_retryingRow) Scan(dest ...any) error {
	for {
		err := rows.obj.driver.QueryRowContext(rows.ctx, rows.query, rows.args...).Scan(dest...)
		if err != nil {
			if rows.obj.shouldRetry(err) {
				continue
			}
			// caller will wrap this error
			return err
		}
		return nil
	}
}

type pgxcockroachDB struct {
	db *DB
	*pgxcockroachImpl
}

func newpgxcockroach(db *DB) *pgxcockroachDB {
	return &pgxcockroachDB{
		db: db,
		pgxcockroachImpl: &pgxcockroachImpl{
			db:     db,
			driver: db.DB,
		},
	}
}

func (obj *pgxcockroachDB) Schema() []string {
	return []string{

		`CREATE TABLE account_freeze_events (
	user_id bytea NOT NULL,
	event integer NOT NULL,
	limits jsonb,
	days_till_escalation integer,
	notifications_count integer NOT NULL DEFAULT 0,
	created_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	PRIMARY KEY ( user_id, event )
)`,

		`CREATE TABLE accounting_rollups (
	node_id bytea NOT NULL,
	start_time timestamp with time zone NOT NULL,
	put_total bigint NOT NULL,
	get_total bigint NOT NULL,
	get_audit_total bigint NOT NULL,
	get_repair_total bigint NOT NULL,
	put_repair_total bigint NOT NULL,
	at_rest_total double precision NOT NULL,
	interval_end_time timestamp with time zone,
	PRIMARY KEY ( node_id, start_time )
)`,

		`CREATE TABLE accounting_timestamps (
	name text NOT NULL,
	value timestamp with time zone NOT NULL,
	PRIMARY KEY ( name )
)`,

		`CREATE TABLE billing_balances (
	user_id bytea NOT NULL,
	balance bigint NOT NULL,
	last_updated timestamp with time zone NOT NULL,
	PRIMARY KEY ( user_id )
)`,

		`CREATE TABLE billing_transactions (
	id bigserial NOT NULL,
	user_id bytea NOT NULL,
	amount bigint NOT NULL,
	currency text NOT NULL,
	description text NOT NULL,
	source text NOT NULL,
	status text NOT NULL,
	type text NOT NULL,
	metadata jsonb NOT NULL,
	tx_timestamp timestamp with time zone NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE bucket_bandwidth_rollups (
	bucket_name bytea NOT NULL,
	project_id bytea NOT NULL,
	interval_start timestamp with time zone NOT NULL,
	interval_seconds integer NOT NULL,
	action integer NOT NULL,
	product_id integer,
	inline bigint NOT NULL,
	allocated bigint NOT NULL,
	settled bigint NOT NULL,
	PRIMARY KEY ( project_id, bucket_name, interval_start, action )
)`,

		`CREATE TABLE bucket_bandwidth_rollup_archives (
	bucket_name bytea NOT NULL,
	project_id bytea NOT NULL,
	product_id integer,
	interval_start timestamp with time zone NOT NULL,
	interval_seconds integer NOT NULL,
	action integer NOT NULL,
	inline bigint NOT NULL,
	allocated bigint NOT NULL,
	settled bigint NOT NULL,
	PRIMARY KEY ( bucket_name, project_id, interval_start, action )
)`,

		`CREATE TABLE bucket_storage_tallies (
	bucket_name bytea NOT NULL,
	project_id bytea NOT NULL,
	interval_start timestamp with time zone NOT NULL,
	product_id integer,
	total_bytes bigint NOT NULL DEFAULT 0,
	inline bigint NOT NULL,
	remote bigint NOT NULL,
	total_segments_count integer NOT NULL DEFAULT 0,
	remote_segments_count integer NOT NULL,
	inline_segments_count integer NOT NULL,
	object_count integer NOT NULL,
	metadata_size bigint NOT NULL,
	PRIMARY KEY ( bucket_name, project_id, interval_start )
)`,

		`CREATE TABLE change_histories (
	id bytea NOT NULL,
	admin_email text NOT NULL,
	user_id bytea NOT NULL,
	project_id bytea,
	bucket_name bytea,
	item_type text NOT NULL,
	operation text NOT NULL,
	reason text NOT NULL,
	changes jsonb NOT NULL,
	timestamp timestamp with time zone NOT NULL DEFAULT current_timestamp,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE coinpayments_transactions (
	id text NOT NULL,
	user_id bytea NOT NULL,
	address text NOT NULL,
	amount_numeric bigint NOT NULL,
	received_numeric bigint NOT NULL,
	status integer NOT NULL,
	key text NOT NULL,
	timeout integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE entitlements (
	scope bytea NOT NULL,
	features jsonb NOT NULL DEFAULT '{}',
	updated_at timestamp with time zone NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( scope )
)`,

		`CREATE TABLE nodes (
	id bytea NOT NULL,
	address text NOT NULL DEFAULT '',
	last_net text NOT NULL,
	last_ip_port text,
	country_code text,
	protocol integer NOT NULL DEFAULT 0,
	email text NOT NULL,
	wallet text NOT NULL,
	wallet_features text NOT NULL DEFAULT '',
	free_disk bigint NOT NULL DEFAULT -1,
	piece_count bigint NOT NULL DEFAULT 0,
	major bigint NOT NULL DEFAULT 0,
	minor bigint NOT NULL DEFAULT 0,
	patch bigint NOT NULL DEFAULT 0,
	commit_hash text NOT NULL DEFAULT '',
	release_timestamp timestamp with time zone NOT NULL DEFAULT '0001-01-01 00:00:00+00',
	release boolean NOT NULL DEFAULT false,
	latency_90 bigint NOT NULL DEFAULT 0,
	vetted_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	updated_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	last_contact_success timestamp with time zone NOT NULL DEFAULT 'epoch',
	last_contact_failure timestamp with time zone NOT NULL DEFAULT 'epoch',
	disqualified timestamp with time zone,
	disqualification_reason integer,
	unknown_audit_suspended timestamp with time zone,
	offline_suspended timestamp with time zone,
	under_review timestamp with time zone,
	exit_initiated_at timestamp with time zone,
	exit_loop_completed_at timestamp with time zone,
	exit_finished_at timestamp with time zone,
	exit_success boolean NOT NULL DEFAULT false,
	contained timestamp with time zone,
	last_offline_email timestamp with time zone,
	last_software_update_email timestamp with time zone,
	noise_proto integer,
	noise_public_key bytea,
	debounce_limit integer NOT NULL DEFAULT 0,
	features integer NOT NULL DEFAULT 0,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE node_api_versions (
	id bytea NOT NULL,
	api_version integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	updated_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE node_events (
	id bytea NOT NULL,
	email text NOT NULL,
	last_ip_port text,
	node_id bytea NOT NULL,
	event integer NOT NULL,
	created_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	last_attempted timestamp with time zone,
	email_sent timestamp with time zone,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE node_tags (
	node_id bytea NOT NULL,
	name text NOT NULL,
	value bytea NOT NULL,
	signed_at timestamp with time zone NOT NULL,
	signer bytea NOT NULL,
	PRIMARY KEY ( node_id, name, signer )
)`,

		`CREATE TABLE oauth_clients (
	id bytea NOT NULL,
	encrypted_secret bytea NOT NULL,
	redirect_url text NOT NULL,
	user_id bytea NOT NULL,
	app_name text NOT NULL,
	app_logo_url text NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE oauth_codes (
	client_id bytea NOT NULL,
	user_id bytea NOT NULL,
	scope text NOT NULL,
	redirect_url text NOT NULL,
	challenge text NOT NULL,
	challenge_method text NOT NULL,
	code text NOT NULL,
	created_at timestamp with time zone NOT NULL,
	expires_at timestamp with time zone NOT NULL,
	claimed_at timestamp with time zone,
	PRIMARY KEY ( code )
)`,

		`CREATE TABLE oauth_tokens (
	client_id bytea NOT NULL,
	user_id bytea NOT NULL,
	scope text NOT NULL,
	kind integer NOT NULL,
	token bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	expires_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( token )
)`,

		`CREATE TABLE peer_identities (
	node_id bytea NOT NULL,
	leaf_serial_number bytea NOT NULL,
	chain bytea NOT NULL,
	updated_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( node_id )
)`,

		`CREATE TABLE projects (
	id bytea NOT NULL,
	public_id bytea,
	name text NOT NULL,
	description text NOT NULL,
	usage_limit bigint,
	bandwidth_limit bigint,
	user_specified_usage_limit bigint,
	user_specified_bandwidth_limit bigint,
	segment_limit bigint DEFAULT 1000000,
	rate_limit integer,
	burst_limit integer,
	rate_limit_head integer,
	burst_limit_head integer,
	rate_limit_get integer,
	burst_limit_get integer,
	rate_limit_put integer,
	burst_limit_put integer,
	rate_limit_list integer,
	burst_limit_list integer,
	rate_limit_del integer,
	burst_limit_del integer,
	max_buckets integer,
	user_agent bytea,
	owner_id bytea NOT NULL,
	salt bytea,
	status integer DEFAULT 1,
	status_updated_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL,
	default_placement integer,
	default_versioning integer NOT NULL DEFAULT 1,
	prompted_for_versioning_beta boolean NOT NULL DEFAULT false,
	passphrase_enc bytea,
	passphrase_enc_key_id integer,
	path_encryption boolean NOT NULL DEFAULT true,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE project_bandwidth_daily_rollups (
	project_id bytea NOT NULL,
	product_id integer,
	interval_day date NOT NULL,
	egress_allocated bigint NOT NULL,
	egress_settled bigint NOT NULL,
	egress_dead bigint NOT NULL DEFAULT 0,
	PRIMARY KEY ( project_id, interval_day )
)`,

		`CREATE TABLE registration_tokens (
	secret bytea NOT NULL,
	owner_id bytea,
	project_limit integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( secret ),
	UNIQUE ( owner_id )
)`,

		`CREATE TABLE repair_queue (
	stream_id bytea NOT NULL,
	position bigint NOT NULL,
	attempted_at timestamp with time zone,
	updated_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	inserted_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	segment_health double precision NOT NULL DEFAULT 1,
	placement integer,
	PRIMARY KEY ( stream_id, position )
)`,

		`CREATE TABLE reputations (
	id bytea NOT NULL,
	audit_success_count bigint NOT NULL DEFAULT 0,
	total_audit_count bigint NOT NULL DEFAULT 0,
	vetted_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	updated_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	disqualified timestamp with time zone,
	disqualification_reason integer,
	unknown_audit_suspended timestamp with time zone,
	offline_suspended timestamp with time zone,
	under_review timestamp with time zone,
	online_score double precision NOT NULL DEFAULT 1,
	audit_history bytea NOT NULL,
	audit_reputation_alpha double precision NOT NULL DEFAULT 1,
	audit_reputation_beta double precision NOT NULL DEFAULT 0,
	unknown_audit_reputation_alpha double precision NOT NULL DEFAULT 1,
	unknown_audit_reputation_beta double precision NOT NULL DEFAULT 0,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE reset_password_tokens (
	secret bytea NOT NULL,
	owner_id bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( secret ),
	UNIQUE ( owner_id )
)`,

		`CREATE TABLE reverification_audits (
	node_id bytea NOT NULL,
	stream_id bytea NOT NULL,
	position bigint NOT NULL,
	piece_num integer NOT NULL,
	inserted_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	last_attempt timestamp with time zone,
	reverify_count bigint NOT NULL DEFAULT 0,
	PRIMARY KEY ( node_id, stream_id, position )
)`,

		`CREATE TABLE revocations (
	revoked bytea NOT NULL,
	api_key_id bytea NOT NULL,
	PRIMARY KEY ( revoked )
)`,

		`CREATE TABLE segment_pending_audits (
	node_id bytea NOT NULL,
	stream_id bytea NOT NULL,
	position bigint NOT NULL,
	piece_id bytea NOT NULL,
	stripe_index bigint NOT NULL,
	share_size bigint NOT NULL,
	expected_share_hash bytea NOT NULL,
	reverify_count bigint NOT NULL,
	PRIMARY KEY ( node_id )
)`,

		`CREATE TABLE storagenode_bandwidth_rollups (
	storagenode_id bytea NOT NULL,
	interval_start timestamp with time zone NOT NULL,
	interval_seconds integer NOT NULL,
	action integer NOT NULL,
	allocated bigint DEFAULT 0,
	settled bigint NOT NULL,
	PRIMARY KEY ( storagenode_id, interval_start, action )
)`,

		`CREATE TABLE storagenode_bandwidth_rollup_archives (
	storagenode_id bytea NOT NULL,
	interval_start timestamp with time zone NOT NULL,
	interval_seconds integer NOT NULL,
	action integer NOT NULL,
	allocated bigint DEFAULT 0,
	settled bigint NOT NULL,
	PRIMARY KEY ( storagenode_id, interval_start, action )
)`,

		`CREATE TABLE storagenode_payments (
	id bigserial NOT NULL,
	created_at timestamp with time zone NOT NULL,
	node_id bytea NOT NULL,
	period text NOT NULL,
	amount bigint NOT NULL,
	receipt text,
	notes text,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE storagenode_paystubs (
	period text NOT NULL,
	node_id bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	codes text NOT NULL,
	usage_at_rest double precision NOT NULL,
	usage_get bigint NOT NULL,
	usage_put bigint NOT NULL,
	usage_get_repair bigint NOT NULL,
	usage_put_repair bigint NOT NULL,
	usage_get_audit bigint NOT NULL,
	comp_at_rest bigint NOT NULL,
	comp_get bigint NOT NULL,
	comp_put bigint NOT NULL,
	comp_get_repair bigint NOT NULL,
	comp_put_repair bigint NOT NULL,
	comp_get_audit bigint NOT NULL,
	surge_percent bigint NOT NULL,
	held bigint NOT NULL,
	owed bigint NOT NULL,
	disposed bigint NOT NULL,
	paid bigint NOT NULL,
	distributed bigint NOT NULL,
	PRIMARY KEY ( period, node_id )
)`,

		`CREATE TABLE storagenode_storage_tallies (
	node_id bytea NOT NULL,
	interval_end_time timestamp with time zone NOT NULL,
	data_total double precision NOT NULL,
	PRIMARY KEY ( interval_end_time, node_id )
)`,

		`CREATE TABLE storjscan_payments (
	chain_id bigint NOT NULL DEFAULT 0,
	block_hash bytea NOT NULL,
	block_number bigint NOT NULL,
	transaction bytea NOT NULL,
	log_index integer NOT NULL,
	from_address bytea NOT NULL,
	to_address bytea NOT NULL,
	token_value bigint NOT NULL,
	usd_value bigint NOT NULL,
	status text NOT NULL,
	block_timestamp timestamp with time zone NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( block_hash, log_index )
)`,

		`CREATE TABLE storjscan_wallets (
	user_id bytea NOT NULL,
	wallet_address bytea NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( user_id, wallet_address )
)`,

		`CREATE TABLE stripe_customers (
	user_id bytea NOT NULL,
	customer_id text NOT NULL,
	billing_customer_id text,
	package_plan text,
	purchased_package_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( user_id ),
	UNIQUE ( customer_id )
)`,

		`CREATE TABLE stripecoinpayments_invoice_project_records (
	id bytea NOT NULL,
	project_id bytea NOT NULL,
	storage double precision NOT NULL,
	egress bigint NOT NULL,
	objects bigint,
	segments bigint,
	period_start timestamp with time zone NOT NULL,
	period_end timestamp with time zone NOT NULL,
	state integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id ),
	UNIQUE ( project_id, period_start, period_end )
)`,

		`CREATE TABLE stripecoinpayments_tx_conversion_rates (
	tx_id text NOT NULL,
	rate_numeric double precision NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( tx_id )
)`,

		`CREATE TABLE users (
	id bytea NOT NULL,
	external_id text,
	tenant_id text,
	email text NOT NULL,
	normalized_email text NOT NULL,
	full_name text NOT NULL,
	short_name text,
	password_hash bytea NOT NULL,
	new_unverified_email text,
	email_change_verification_step integer NOT NULL DEFAULT 0,
	status integer NOT NULL,
	status_updated_at timestamp with time zone,
	final_invoice_generated boolean NOT NULL DEFAULT false,
	user_agent bytea,
	created_at timestamp with time zone NOT NULL,
	project_limit integer NOT NULL DEFAULT 0,
	project_bandwidth_limit bigint NOT NULL DEFAULT 0,
	project_storage_limit bigint NOT NULL DEFAULT 0,
	project_segment_limit bigint NOT NULL DEFAULT 0,
	kind integer NOT NULL DEFAULT 0,
	position text,
	company_name text,
	company_size integer,
	working_on text,
	is_professional boolean NOT NULL DEFAULT false,
	employee_count text,
	have_sales_contact boolean NOT NULL DEFAULT false,
	mfa_enabled boolean NOT NULL DEFAULT false,
	mfa_secret_key text,
	mfa_recovery_codes text,
	signup_promo_code text,
	verification_reminders integer NOT NULL DEFAULT 0,
	trial_notifications integer NOT NULL DEFAULT 0,
	failed_login_count integer,
	login_lockout_expiration timestamp with time zone,
	signup_captcha double precision,
	default_placement integer,
	activation_code text,
	signup_id text,
	trial_expiration timestamp with time zone,
	upgrade_time timestamp with time zone,
	hubspot_object_id text,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE user_settings (
	user_id bytea NOT NULL,
	session_minutes integer,
	passphrase_prompt boolean,
	onboarding_start boolean NOT NULL DEFAULT true,
	onboarding_end boolean NOT NULL DEFAULT true,
	onboarding_step text,
	notice_dismissal jsonb NOT NULL DEFAULT '{}',
	PRIMARY KEY ( user_id )
)`,

		`CREATE TABLE value_attributions (
	project_id bytea NOT NULL,
	bucket_name bytea NOT NULL,
	user_agent bytea,
	placement integer,
	last_updated timestamp with time zone NOT NULL,
	PRIMARY KEY ( project_id, bucket_name )
)`,

		`CREATE TABLE verification_audits (
	inserted_at timestamp with time zone NOT NULL DEFAULT current_timestamp,
	stream_id bytea NOT NULL,
	position bigint NOT NULL,
	expires_at timestamp with time zone,
	encrypted_size integer NOT NULL,
	PRIMARY KEY ( inserted_at, stream_id, position )
)`,

		`CREATE TABLE webapp_sessions (
	id bytea NOT NULL,
	user_id bytea NOT NULL,
	ip_address text NOT NULL,
	user_agent text NOT NULL,
	status integer NOT NULL,
	expires_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE api_keys (
	id bytea NOT NULL,
	project_id bytea NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	head bytea NOT NULL,
	name text NOT NULL,
	secret bytea NOT NULL,
	user_agent bytea,
	created_at timestamp with time zone NOT NULL,
	created_by bytea REFERENCES users( id ),
	version integer NOT NULL DEFAULT 0,
	PRIMARY KEY ( id ),
	UNIQUE ( head ),
	UNIQUE ( name, project_id )
)`,

		`CREATE TABLE bucket_metainfos (
	id bytea NOT NULL,
	project_id bytea NOT NULL REFERENCES projects( id ),
	name bytea NOT NULL,
	tags bytea,
	user_agent bytea,
	versioning integer NOT NULL DEFAULT 0,
	object_lock_enabled boolean NOT NULL DEFAULT false,
	default_retention_mode integer,
	default_retention_days integer,
	default_retention_years integer,
	path_cipher integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	default_segment_size integer NOT NULL,
	default_encryption_cipher_suite integer NOT NULL,
	default_encryption_block_size integer NOT NULL,
	default_redundancy_algorithm integer NOT NULL,
	default_redundancy_share_size integer NOT NULL,
	default_redundancy_required_shares integer NOT NULL,
	default_redundancy_repair_shares integer NOT NULL,
	default_redundancy_optimal_shares integer NOT NULL,
	default_redundancy_total_shares integer NOT NULL,
	placement integer,
	created_by bytea REFERENCES users( id ),
	PRIMARY KEY ( project_id, name )
)`,

		`CREATE TABLE bucket_migrations (
	id bytea NOT NULL,
	project_id bytea NOT NULL REFERENCES projects( id ),
	bucket_name bytea NOT NULL,
	from_placement integer NOT NULL,
	to_placement integer NOT NULL,
	migration_type integer NOT NULL,
	state text NOT NULL,
	bytes_processed bigint NOT NULL DEFAULT 0,
	error_message text,
	created_at timestamp with time zone NOT NULL,
	updated_at timestamp with time zone NOT NULL,
	completed_at timestamp with time zone,
	PRIMARY KEY ( id )
)`,

		`CREATE TABLE domains (
	subdomain text NOT NULL,
	project_id bytea NOT NULL REFERENCES projects( id ),
	prefix text NOT NULL,
	access_id text NOT NULL,
	created_by bytea NOT NULL REFERENCES users( id ),
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( project_id, subdomain )
)`,

		`CREATE TABLE project_invitations (
	project_id bytea NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	email text NOT NULL,
	inviter_id bytea REFERENCES users( id ) ON DELETE CASCADE,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( project_id, email )
)`,

		`CREATE TABLE project_members (
	member_id bytea NOT NULL REFERENCES users( id ) ON DELETE CASCADE,
	project_id bytea NOT NULL REFERENCES projects( id ) ON DELETE CASCADE,
	role integer NOT NULL DEFAULT 0,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( member_id, project_id )
)`,

		`CREATE TABLE rest_api_keys (
	id bytea NOT NULL,
	user_id bytea NOT NULL REFERENCES users( id ) ON DELETE CASCADE,
	token bytea NOT NULL,
	name text NOT NULL,
	expires_at timestamp with time zone,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( id ),
	UNIQUE ( token )
)`,

		`CREATE TABLE stripecoinpayments_apply_balance_intents (
	tx_id text NOT NULL REFERENCES coinpayments_transactions( id ) ON DELETE CASCADE,
	state integer NOT NULL,
	created_at timestamp with time zone NOT NULL,
	PRIMARY KEY ( tx_id )
)`,

		`CREATE TABLE api_key_tails (
	root_key_id bytea REFERENCES api_keys( id ) ON DELETE CASCADE,
	tail bytea NOT NULL,
	parent_tail bytea NOT NULL,
	caveat bytea NOT NULL,
	last_used timestamp with time zone NOT NULL,
	PRIMARY KEY ( tail )
)`,

		`CREATE INDEX accounting_rollups_start_time_index ON accounting_rollups ( start_time )`,

		`CREATE INDEX billing_transactions_tx_timestamp_index ON billing_transactions ( tx_timestamp )`,

		`CREATE INDEX bucket_bandwidth_rollups_project_id_action_interval_index ON bucket_bandwidth_rollups ( project_id, action, interval_start )`,

		`CREATE INDEX bucket_bandwidth_rollups_action_interval_project_id_index ON bucket_bandwidth_rollups ( action, interval_start, project_id )`,

		`CREATE INDEX bucket_bandwidth_rollups_archive_project_id_action_interval_index ON bucket_bandwidth_rollup_archives ( project_id, action, interval_start )`,

		`CREATE INDEX bucket_bandwidth_rollups_archive_action_interval_project_id_index ON bucket_bandwidth_rollup_archives ( action, interval_start, project_id )`,

		`CREATE INDEX bucket_storage_tallies_project_id_interval_start_index ON bucket_storage_tallies ( project_id, interval_start )`,

		`CREATE INDEX bucket_storage_tallies_interval_start_index ON bucket_storage_tallies ( interval_start )`,

		`CREATE INDEX change_history_user_id_timestamp_idx ON change_histories ( user_id, timestamp )`,

		`CREATE INDEX change_history_user_id_item_type_timestamp_idx ON change_histories ( user_id, item_type, timestamp )`,

		`CREATE INDEX change_history_project_id_item_type_timestamp_idx ON change_histories ( project_id, item_type, timestamp )`,

		`CREATE INDEX change_history_bucket_name_timestamp_idx ON change_histories ( bucket_name, timestamp )`,

		`CREATE INDEX node_events_email_event_created_at_index ON node_events ( email, event, created_at ) WHERE node_events.email_sent is NULL`,

		`CREATE INDEX oauth_clients_user_id_index ON oauth_clients ( user_id )`,

		`CREATE INDEX oauth_codes_user_id_index ON oauth_codes ( user_id )`,

		`CREATE INDEX oauth_codes_client_id_index ON oauth_codes ( client_id )`,

		`CREATE INDEX oauth_tokens_user_id_index ON oauth_tokens ( user_id )`,

		`CREATE INDEX oauth_tokens_client_id_index ON oauth_tokens ( client_id )`,

		`CREATE INDEX projects_public_id_index ON projects ( public_id )`,

		`CREATE INDEX projects_owner_id_index ON projects ( owner_id )`,

		`CREATE INDEX projects_status_status_updated_at_index ON projects ( status, status_updated_at ) WHERE projects.status_updated_at is not NULL`,

		`CREATE INDEX project_bandwidth_daily_rollup_interval_day_index ON project_bandwidth_daily_rollups ( interval_day )`,

		`CREATE INDEX repair_queue_updated_at_index ON repair_queue ( updated_at )`,

		`CREATE INDEX repair_queue_num_healthy_pieces_attempted_at_index ON repair_queue ( segment_health, attempted_at )`,

		`CREATE INDEX repair_queue_placement_index ON repair_queue ( placement )`,

		`CREATE INDEX reverification_audits_inserted_at_index ON reverification_audits ( inserted_at )`,

		`CREATE INDEX storagenode_bandwidth_rollups_interval_start_index ON storagenode_bandwidth_rollups ( interval_start )`,

		`CREATE INDEX storagenode_bandwidth_rollup_archives_interval_start_index ON storagenode_bandwidth_rollup_archives ( interval_start )`,

		`CREATE INDEX storagenode_payments_node_id_period_index ON storagenode_payments ( node_id, period )`,

		`CREATE INDEX storagenode_paystubs_node_id_index ON storagenode_paystubs ( node_id )`,

		`CREATE INDEX storagenode_storage_tallies_node_id_index ON storagenode_storage_tallies ( node_id )`,

		`CREATE INDEX storjscan_payments_chain_id_block_number_log_index_index ON storjscan_payments ( chain_id, block_number, log_index )`,

		`CREATE INDEX storjscan_wallets_wallet_address_index ON storjscan_wallets ( wallet_address )`,

		`CREATE INDEX stripecoinpayments_invoice_project_records_unbilled_project_id_index ON stripecoinpayments_invoice_project_records ( project_id ) WHERE stripecoinpayments_invoice_project_records.state = 0`,

		`CREATE INDEX users_email_status_index ON users ( normalized_email, status )`,

		`CREATE INDEX trial_expiration_index ON users ( trial_expiration )`,

		`CREATE INDEX users_external_id_index ON users ( external_id ) WHERE users.external_id is not NULL`,

		`CREATE INDEX users_status_status_updated_at_index ON users ( status, status_updated_at ) WHERE users.status_updated_at is not NULL`,

		`CREATE INDEX users_tenant_id_index ON users ( tenant_id ) WHERE users.tenant_id is not NULL`,

		`CREATE INDEX users_normalized_email_tenant_id_status_index ON users ( normalized_email, tenant_id, status ) WHERE users.tenant_id is not NULL`,

		`CREATE INDEX webapp_sessions_user_id_index ON webapp_sessions ( user_id )`,

		`CREATE INDEX bucket_migrations_state_created_at_index ON bucket_migrations ( state, created_at )`,

		`CREATE INDEX project_invitations_project_id_index ON project_invitations ( project_id )`,

		`CREATE INDEX project_invitations_email_index ON project_invitations ( email )`,

		`CREATE INDEX project_members_project_id_index ON project_members ( project_id )`,

		`CREATE INDEX rest_api_keys_user_id_index ON rest_api_keys ( user_id )`,

		`CREATE INDEX rest_api_keys_name_index ON rest_api_keys ( name )`,
	}
}

func (obj *pgxcockroachDB) DropSchema() []string {
	return []string{

		`DROP TABLE IF EXISTS api_key_tails`,

		`DROP TABLE IF EXISTS stripecoinpayments_apply_balance_intents`,

		`DROP TABLE IF EXISTS rest_api_keys`,

		`DROP TABLE IF EXISTS project_members`,

		`DROP TABLE IF EXISTS project_invitations`,

		`DROP TABLE IF EXISTS domains`,

		`DROP TABLE IF EXISTS bucket_migrations`,

		`DROP TABLE IF EXISTS bucket_metainfos`,

		`DROP TABLE IF EXISTS api_keys`,

		`DROP TABLE IF EXISTS webapp_sessions`,

		`DROP TABLE IF EXISTS verification_audits`,

		`DROP TABLE IF EXISTS value_attributions`,

		`DROP TABLE IF EXISTS user_settings`,

		`DROP TABLE IF EXISTS users`,

		`DROP TABLE IF EXISTS stripecoinpayments_tx_conversion_rates`,

		`DROP TABLE IF EXISTS stripecoinpayments_invoice_project_records`,

		`DROP TABLE IF EXISTS stripe_customers`,

		`DROP TABLE IF EXISTS storjscan_wallets`,

		`DROP TABLE IF EXISTS storjscan_payments`,

		`DROP TABLE IF EXISTS storagenode_storage_tallies`,

		`DROP TABLE IF EXISTS storagenode_paystubs`,

		`DROP TABLE IF EXISTS storagenode_payments`,

		`DROP TABLE IF EXISTS storagenode_bandwidth_rollup_archives`,

		`DROP TABLE IF EXISTS storagenode_bandwidth_rollups`,

		`DROP TABLE IF EXISTS segment_pending_audits`,

		`DROP TABLE IF EXISTS revocations`,

		`DROP TABLE IF EXISTS reverification_audits`,

		`DROP TABLE IF EXISTS reset_password_tokens`,

		`DROP TABLE IF EXISTS reputations`,

		`DROP TABLE IF EXISTS repair_queue`,

		`DROP TABLE IF EXISTS registration_tokens`,

		`DROP TABLE IF EXISTS project_bandwidth_daily_rollups`,

		`DROP TABLE IF EXISTS projects`,

		`DROP TABLE IF EXISTS peer_identities`,

		`DROP TABLE IF EXISTS oauth_tokens`,

		`DROP TABLE IF EXISTS oauth_codes`,

		`DROP TABLE IF EXISTS oauth_clients`,

		`DROP TABLE IF EXISTS node_tags`,

		`DROP TABLE IF EXISTS node_events`,

		`DROP TABLE IF EXISTS node_api_versions`,

		`DROP TABLE IF EXISTS nodes`,

		`DROP TABLE IF EXISTS entitlements`,

		`DROP TABLE IF EXISTS coinpayments_transactions`,

		`DROP TABLE IF EXISTS change_histories`,

		`DROP TABLE IF EXISTS bucket_storage_tallies`,

		`DROP TABLE IF EXISTS bucket_bandwidth_rollup_archives`,

		`DROP TABLE IF EXISTS bucket_bandwidth_rollups`,

		`DROP TABLE IF EXISTS billing_transactions`,

		`DROP TABLE IF EXISTS billing_balances`,

		`DROP TABLE IF EXISTS accounting_timestamps`,

		`DROP TABLE IF EXISTS accounting_rollups`,

		`DROP TABLE IF EXISTS account_freeze_events`,
	}
}

func (obj *pgxcockroachDB) wrapTx(tx tagsql.Tx) txMethods {
	return &pgxcockroachTx{
		dialectTx: dialectTx{tx: tx},
		pgxcockroachImpl: &pgxcockroachImpl{
			db:     obj.db,
			driver: tx,
			txn:    true,
		},
	}
}

type pgxcockroachTx struct {
	dialectTx
	*pgxcockroachImpl
}

func pgxcockroachLogStmt(stmt string, args ...any) {
	// TODO: render placeholders
	if Logger != nil {
		out := fmt.Sprintf("stmt: %s\nargs: %v\n", stmt, pretty(args))
		Logger(out)
	}
}

type spannerImpl struct {
	db      *DB
	dialect __sqlbundle_spanner
	driver
	txn bool
}

func (obj *spannerImpl) Rebind(s string) string {
	return obj.dialect.Rebind(s)
}

func (obj *spannerImpl) logStmt(stmt string, args ...any) {
	spannerLogStmt(stmt, args...)
}

func (obj *spannerImpl) makeErr(err error) error {
	constraint, ok := obj.isConstraintError(err)
	if ok {
		return constraintViolation(err, constraint)
	}
	return makeErr(err)
}

func (obj *spannerImpl) shouldRetry(err error) bool {
	return !obj.txn && shouldRetry(obj.db.driver, err)
}

type spannerImpl_retryingRow struct {
	obj   *spannerImpl
	ctx   context.Context
	query string
	args  []any
}

func (obj *spannerImpl) queryRowContext(ctx context.Context, query string, args ...any) *spannerImpl_retryingRow {
	return &spannerImpl_retryingRow{
		obj:   obj,
		ctx:   ctx,
		query: query,
		args:  args,
	}
}

func (rows *spannerImpl_retryingRow) Scan(dest ...any) error {
	for {
		err := rows.obj.driver.QueryRowContext(rows.ctx, rows.query, rows.args...).Scan(dest...)
		if err != nil {
			if rows.obj.shouldRetry(err) {
				continue
			}
			// caller will wrap this error
			return err
		}
		return nil
	}
}

type spannerDB struct {
	db *DB
	*spannerImpl
}

func newspanner(db *DB) *spannerDB {
	return &spannerDB{
		db: db,
		spannerImpl: &spannerImpl{
			db:     db,
			driver: db.DB,
		},
	}
}

func (obj *spannerDB) Schema() []string {
	return []string{

		`CREATE TABLE account_freeze_events (
	user_id BYTES(MAX) NOT NULL,
	event INT64 NOT NULL,
	limits JSON,
	days_till_escalation INT64,
	notifications_count INT64 NOT NULL DEFAULT (0),
	created_at TIMESTAMP NOT NULL DEFAULT (current_timestamp)
) PRIMARY KEY ( user_id, event )`,

		`CREATE TABLE accounting_rollups (
	node_id BYTES(MAX) NOT NULL,
	start_time TIMESTAMP NOT NULL,
	put_total INT64 NOT NULL,
	get_total INT64 NOT NULL,
	get_audit_total INT64 NOT NULL,
	get_repair_total INT64 NOT NULL,
	put_repair_total INT64 NOT NULL,
	at_rest_total FLOAT64 NOT NULL,
	interval_end_time TIMESTAMP
) PRIMARY KEY ( node_id, start_time )`,

		`CREATE TABLE accounting_timestamps (
	name STRING(MAX) NOT NULL,
	value TIMESTAMP NOT NULL
) PRIMARY KEY ( name )`,

		`CREATE TABLE billing_balances (
	user_id BYTES(MAX) NOT NULL,
	balance INT64 NOT NULL,
	last_updated TIMESTAMP NOT NULL
) PRIMARY KEY ( user_id )`,

		`CREATE SEQUENCE billing_transactions_id OPTIONS (sequence_kind='bit_reversed_positive')`,

		`CREATE TABLE billing_transactions (
	id INT64 NOT NULL DEFAULT (GET_NEXT_SEQUENCE_VALUE(SEQUENCE billing_transactions_id)),
	user_id BYTES(MAX) NOT NULL,
	amount INT64 NOT NULL,
	currency STRING(MAX) NOT NULL,
	description STRING(MAX) NOT NULL,
	source STRING(MAX) NOT NULL,
	status STRING(MAX) NOT NULL,
	type STRING(MAX) NOT NULL,
	metadata JSON NOT NULL,
	tx_timestamp TIMESTAMP NOT NULL,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( id )`,

		`CREATE TABLE bucket_bandwidth_rollups (
	bucket_name BYTES(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	interval_start TIMESTAMP NOT NULL,
	interval_seconds INT64 NOT NULL,
	action INT64 NOT NULL,
	product_id INT64,
	inline INT64 NOT NULL,
	allocated INT64 NOT NULL,
	settled INT64 NOT NULL
) PRIMARY KEY ( project_id, bucket_name, interval_start, action )`,

		`CREATE TABLE bucket_bandwidth_rollup_archives (
	bucket_name BYTES(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	product_id INT64,
	interval_start TIMESTAMP NOT NULL,
	interval_seconds INT64 NOT NULL,
	action INT64 NOT NULL,
	inline INT64 NOT NULL,
	allocated INT64 NOT NULL,
	settled INT64 NOT NULL
) PRIMARY KEY ( bucket_name, project_id, interval_start, action )`,

		`CREATE TABLE bucket_storage_tallies (
	bucket_name BYTES(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	interval_start TIMESTAMP NOT NULL,
	product_id INT64,
	total_bytes INT64 NOT NULL DEFAULT (0),
	inline INT64 NOT NULL,
	remote INT64 NOT NULL,
	total_segments_count INT64 NOT NULL DEFAULT (0),
	remote_segments_count INT64 NOT NULL,
	inline_segments_count INT64 NOT NULL,
	object_count INT64 NOT NULL,
	metadata_size INT64 NOT NULL
) PRIMARY KEY ( bucket_name, project_id, interval_start )`,

		`CREATE TABLE change_histories (
	id BYTES(MAX) NOT NULL,
	admin_email STRING(MAX) NOT NULL,
	user_id BYTES(MAX) NOT NULL,
	project_id BYTES(MAX),
	bucket_name BYTES(MAX),
	item_type STRING(MAX) NOT NULL,
	operation STRING(MAX) NOT NULL,
	reason STRING(MAX) NOT NULL,
	changes JSON NOT NULL,
	timestamp TIMESTAMP NOT NULL DEFAULT (current_timestamp)
) PRIMARY KEY ( id )`,

		`CREATE TABLE coinpayments_transactions (
	id STRING(MAX) NOT NULL,
	user_id BYTES(MAX) NOT NULL,
	address STRING(MAX) NOT NULL,
	amount_numeric INT64 NOT NULL,
	received_numeric INT64 NOT NULL,
	status INT64 NOT NULL,
	key STRING(MAX) NOT NULL,
	timeout INT64 NOT NULL,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( id )`,

		`CREATE TABLE entitlements (
	scope BYTES(MAX) NOT NULL,
	features JSON NOT NULL DEFAULT (JSON "{}"),
	updated_at TIMESTAMP NOT NULL,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( scope )`,

		`CREATE TABLE nodes (
	id BYTES(MAX) NOT NULL,
	address STRING(MAX) NOT NULL DEFAULT (""),
	last_net STRING(MAX) NOT NULL,
	last_ip_port STRING(MAX),
	country_code STRING(MAX),
	protocol INT64 NOT NULL DEFAULT (0),
	email STRING(MAX) NOT NULL,
	wallet STRING(MAX) NOT NULL,
	wallet_features STRING(MAX) NOT NULL DEFAULT (""),
	free_disk INT64 NOT NULL DEFAULT (-1),
	piece_count INT64 NOT NULL DEFAULT (0),
	major INT64 NOT NULL DEFAULT (0),
	minor INT64 NOT NULL DEFAULT (0),
	patch INT64 NOT NULL DEFAULT (0),
	commit_hash STRING(MAX) NOT NULL DEFAULT (""),
	release_timestamp TIMESTAMP NOT NULL DEFAULT ("0001-01-01 00:00:00+00"),
	release BOOL NOT NULL DEFAULT (false),
	latency_90 INT64 NOT NULL DEFAULT (0),
	vetted_at TIMESTAMP,
	created_at TIMESTAMP NOT NULL DEFAULT (current_timestamp),
	updated_at TIMESTAMP NOT NULL DEFAULT (current_timestamp),
	last_contact_success TIMESTAMP NOT NULL DEFAULT (timestamp_seconds(0)),
	last_contact_failure TIMESTAMP NOT NULL DEFAULT (timestamp_seconds(0)),
	disqualified TIMESTAMP,
	disqualification_reason INT64,
	unknown_audit_suspended TIMESTAMP,
	offline_suspended TIMESTAMP,
	under_review TIMESTAMP,
	exit_initiated_at TIMESTAMP,
	exit_loop_completed_at TIMESTAMP,
	exit_finished_at TIMESTAMP,
	exit_success BOOL NOT NULL DEFAULT (false),
	contained TIMESTAMP,
	last_offline_email TIMESTAMP,
	last_software_update_email TIMESTAMP,
	noise_proto INT64,
	noise_public_key BYTES(MAX),
	debounce_limit INT64 NOT NULL DEFAULT (0),
	features INT64 NOT NULL DEFAULT (0)
) PRIMARY KEY ( id )`,

		`CREATE TABLE node_api_versions (
	id BYTES(MAX) NOT NULL,
	api_version INT64 NOT NULL,
	created_at TIMESTAMP NOT NULL,
	updated_at TIMESTAMP NOT NULL
) PRIMARY KEY ( id )`,

		`CREATE TABLE node_events (
	id BYTES(MAX) NOT NULL,
	email STRING(MAX) NOT NULL,
	last_ip_port STRING(MAX),
	node_id BYTES(MAX) NOT NULL,
	event INT64 NOT NULL,
	created_at TIMESTAMP NOT NULL DEFAULT (current_timestamp),
	last_attempted TIMESTAMP,
	email_sent TIMESTAMP
) PRIMARY KEY ( id )`,

		`CREATE TABLE node_tags (
	node_id BYTES(MAX) NOT NULL,
	name STRING(MAX) NOT NULL,
	value BYTES(MAX) NOT NULL,
	signed_at TIMESTAMP NOT NULL,
	signer BYTES(MAX) NOT NULL
) PRIMARY KEY ( node_id, name, signer )`,

		`CREATE TABLE oauth_clients (
	id BYTES(MAX) NOT NULL,
	encrypted_secret BYTES(MAX) NOT NULL,
	redirect_url STRING(MAX) NOT NULL,
	user_id BYTES(MAX) NOT NULL,
	app_name STRING(MAX) NOT NULL,
	app_logo_url STRING(MAX) NOT NULL
) PRIMARY KEY ( id )`,

		`CREATE TABLE oauth_codes (
	client_id BYTES(MAX) NOT NULL,
	user_id BYTES(MAX) NOT NULL,
	scope STRING(MAX) NOT NULL,
	redirect_url STRING(MAX) NOT NULL,
	challenge STRING(MAX) NOT NULL,
	challenge_method STRING(MAX) NOT NULL,
	code STRING(MAX) NOT NULL,
	created_at TIMESTAMP NOT NULL,
	expires_at TIMESTAMP NOT NULL,
	claimed_at TIMESTAMP
) PRIMARY KEY ( code )`,

		`CREATE TABLE oauth_tokens (
	client_id BYTES(MAX) NOT NULL,
	user_id BYTES(MAX) NOT NULL,
	scope STRING(MAX) NOT NULL,
	kind INT64 NOT NULL,
	token BYTES(MAX) NOT NULL,
	created_at TIMESTAMP NOT NULL,
	expires_at TIMESTAMP NOT NULL
) PRIMARY KEY ( token )`,

		`CREATE TABLE peer_identities (
	node_id BYTES(MAX) NOT NULL,
	leaf_serial_number BYTES(MAX) NOT NULL,
	chain BYTES(MAX) NOT NULL,
	updated_at TIMESTAMP NOT NULL
) PRIMARY KEY ( node_id )`,

		`CREATE TABLE projects (
	id BYTES(MAX) NOT NULL,
	public_id BYTES(MAX),
	name STRING(MAX) NOT NULL,
	description STRING(MAX) NOT NULL,
	usage_limit INT64,
	bandwidth_limit INT64,
	user_specified_usage_limit INT64,
	user_specified_bandwidth_limit INT64,
	segment_limit INT64 DEFAULT (1000000),
	rate_limit INT64,
	burst_limit INT64,
	rate_limit_head INT64,
	burst_limit_head INT64,
	rate_limit_get INT64,
	burst_limit_get INT64,
	rate_limit_put INT64,
	burst_limit_put INT64,
	rate_limit_list INT64,
	burst_limit_list INT64,
	rate_limit_del INT64,
	burst_limit_del INT64,
	max_buckets INT64,
	user_agent BYTES(MAX),
	owner_id BYTES(MAX) NOT NULL,
	salt BYTES(MAX),
	status INT64 DEFAULT (1),
	status_updated_at TIMESTAMP,
	created_at TIMESTAMP NOT NULL,
	default_placement INT64,
	default_versioning INT64 NOT NULL DEFAULT (1),
	prompted_for_versioning_beta BOOL NOT NULL DEFAULT (false),
	passphrase_enc BYTES(MAX),
	passphrase_enc_key_id INT64,
	path_encryption BOOL NOT NULL DEFAULT (true)
) PRIMARY KEY ( id )`,

		`CREATE TABLE project_bandwidth_daily_rollups (
	project_id BYTES(MAX) NOT NULL,
	product_id INT64,
	interval_day DATE NOT NULL,
	egress_allocated INT64 NOT NULL,
	egress_settled INT64 NOT NULL,
	egress_dead INT64 NOT NULL DEFAULT (0)
) PRIMARY KEY ( project_id, interval_day )`,

		`CREATE TABLE registration_tokens (
	secret BYTES(MAX) NOT NULL,
	owner_id BYTES(MAX),
	project_limit INT64 NOT NULL,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( secret )`,

		`CREATE UNIQUE INDEX index_registration_tokens_owner_id ON registration_tokens ( owner_id )`,

		`CREATE TABLE repair_queue (
	stream_id BYTES(MAX) NOT NULL,
	position INT64 NOT NULL,
	attempted_at TIMESTAMP,
	updated_at TIMESTAMP NOT NULL DEFAULT (current_timestamp),
	inserted_at TIMESTAMP NOT NULL DEFAULT (current_timestamp),
	segment_health FLOAT64 NOT NULL DEFAULT (1),
	placement INT64
) PRIMARY KEY ( stream_id, position )`,

		`CREATE TABLE reputations (
	id BYTES(MAX) NOT NULL,
	audit_success_count INT64 NOT NULL DEFAULT (0),
	total_audit_count INT64 NOT NULL DEFAULT (0),
	vetted_at TIMESTAMP,
	created_at TIMESTAMP NOT NULL DEFAULT (current_timestamp),
	updated_at TIMESTAMP NOT NULL DEFAULT (current_timestamp),
	disqualified TIMESTAMP,
	disqualification_reason INT64,
	unknown_audit_suspended TIMESTAMP,
	offline_suspended TIMESTAMP,
	under_review TIMESTAMP,
	online_score FLOAT64 NOT NULL DEFAULT (1),
	audit_history BYTES(MAX) NOT NULL,
	audit_reputation_alpha FLOAT64 NOT NULL DEFAULT (1),
	audit_reputation_beta FLOAT64 NOT NULL DEFAULT (0),
	unknown_audit_reputation_alpha FLOAT64 NOT NULL DEFAULT (1),
	unknown_audit_reputation_beta FLOAT64 NOT NULL DEFAULT (0)
) PRIMARY KEY ( id )`,

		`CREATE TABLE reset_password_tokens (
	secret BYTES(MAX) NOT NULL,
	owner_id BYTES(MAX) NOT NULL,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( secret )`,

		`CREATE UNIQUE INDEX index_reset_password_tokens_owner_id ON reset_password_tokens ( owner_id )`,

		`CREATE TABLE reverification_audits (
	node_id BYTES(MAX) NOT NULL,
	stream_id BYTES(MAX) NOT NULL,
	position INT64 NOT NULL,
	piece_num INT64 NOT NULL,
	inserted_at TIMESTAMP NOT NULL DEFAULT (current_timestamp),
	last_attempt TIMESTAMP,
	reverify_count INT64 NOT NULL DEFAULT (0)
) PRIMARY KEY ( node_id, stream_id, position )`,

		`CREATE TABLE revocations (
	revoked BYTES(MAX) NOT NULL,
	api_key_id BYTES(MAX) NOT NULL
) PRIMARY KEY ( revoked )`,

		`CREATE TABLE segment_pending_audits (
	node_id BYTES(MAX) NOT NULL,
	stream_id BYTES(MAX) NOT NULL,
	position INT64 NOT NULL,
	piece_id BYTES(MAX) NOT NULL,
	stripe_index INT64 NOT NULL,
	share_size INT64 NOT NULL,
	expected_share_hash BYTES(MAX) NOT NULL,
	reverify_count INT64 NOT NULL
) PRIMARY KEY ( node_id )`,

		`CREATE TABLE storagenode_bandwidth_rollups (
	storagenode_id BYTES(MAX) NOT NULL,
	interval_start TIMESTAMP NOT NULL,
	interval_seconds INT64 NOT NULL,
	action INT64 NOT NULL,
	allocated INT64 DEFAULT (0),
	settled INT64 NOT NULL
) PRIMARY KEY ( storagenode_id, interval_start, action )`,

		`CREATE TABLE storagenode_bandwidth_rollup_archives (
	storagenode_id BYTES(MAX) NOT NULL,
	interval_start TIMESTAMP NOT NULL,
	interval_seconds INT64 NOT NULL,
	action INT64 NOT NULL,
	allocated INT64 DEFAULT (0),
	settled INT64 NOT NULL
) PRIMARY KEY ( storagenode_id, interval_start, action )`,

		`CREATE SEQUENCE storagenode_payments_id OPTIONS (sequence_kind='bit_reversed_positive')`,

		`CREATE TABLE storagenode_payments (
	id INT64 NOT NULL DEFAULT (GET_NEXT_SEQUENCE_VALUE(SEQUENCE storagenode_payments_id)),
	created_at TIMESTAMP NOT NULL,
	node_id BYTES(MAX) NOT NULL,
	period STRING(MAX) NOT NULL,
	amount INT64 NOT NULL,
	receipt STRING(MAX),
	notes STRING(MAX)
) PRIMARY KEY ( id )`,

		`CREATE TABLE storagenode_paystubs (
	period STRING(MAX) NOT NULL,
	node_id BYTES(MAX) NOT NULL,
	created_at TIMESTAMP NOT NULL,
	codes STRING(MAX) NOT NULL,
	usage_at_rest FLOAT64 NOT NULL,
	usage_get INT64 NOT NULL,
	usage_put INT64 NOT NULL,
	usage_get_repair INT64 NOT NULL,
	usage_put_repair INT64 NOT NULL,
	usage_get_audit INT64 NOT NULL,
	comp_at_rest INT64 NOT NULL,
	comp_get INT64 NOT NULL,
	comp_put INT64 NOT NULL,
	comp_get_repair INT64 NOT NULL,
	comp_put_repair INT64 NOT NULL,
	comp_get_audit INT64 NOT NULL,
	surge_percent INT64 NOT NULL,
	held INT64 NOT NULL,
	owed INT64 NOT NULL,
	disposed INT64 NOT NULL,
	paid INT64 NOT NULL,
	distributed INT64 NOT NULL
) PRIMARY KEY ( period, node_id )`,

		`CREATE TABLE storagenode_storage_tallies (
	node_id BYTES(MAX) NOT NULL,
	interval_end_time TIMESTAMP NOT NULL,
	data_total FLOAT64 NOT NULL
) PRIMARY KEY ( interval_end_time, node_id )`,

		`CREATE TABLE storjscan_payments (
	chain_id INT64 NOT NULL DEFAULT (0),
	block_hash BYTES(MAX) NOT NULL,
	block_number INT64 NOT NULL,
	transaction BYTES(MAX) NOT NULL,
	log_index INT64 NOT NULL,
	from_address BYTES(MAX) NOT NULL,
	to_address BYTES(MAX) NOT NULL,
	token_value INT64 NOT NULL,
	usd_value INT64 NOT NULL,
	status STRING(MAX) NOT NULL,
	block_timestamp TIMESTAMP NOT NULL,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( block_hash, log_index )`,

		`CREATE TABLE storjscan_wallets (
	user_id BYTES(MAX) NOT NULL,
	wallet_address BYTES(MAX) NOT NULL,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( user_id, wallet_address )`,

		`CREATE TABLE stripe_customers (
	user_id BYTES(MAX) NOT NULL,
	customer_id STRING(MAX) NOT NULL,
	billing_customer_id STRING(MAX),
	package_plan STRING(MAX),
	purchased_package_at TIMESTAMP,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( user_id )`,

		`CREATE UNIQUE INDEX index_stripe_customers_customer_id ON stripe_customers ( customer_id )`,

		`CREATE TABLE stripecoinpayments_invoice_project_records (
	id BYTES(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	storage FLOAT64 NOT NULL,
	egress INT64 NOT NULL,
	objects INT64,
	segments INT64,
	period_start TIMESTAMP NOT NULL,
	period_end TIMESTAMP NOT NULL,
	state INT64 NOT NULL,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( id )`,

		`CREATE UNIQUE INDEX index_stripecoinpayments_invoice_project_records_project_id_period_start_period_end ON stripecoinpayments_invoice_project_records ( project_id, period_start, period_end )`,

		`CREATE TABLE stripecoinpayments_tx_conversion_rates (
	tx_id STRING(MAX) NOT NULL,
	rate_numeric FLOAT64 NOT NULL,
	created_at TIMESTAMP NOT NULL
) PRIMARY KEY ( tx_id )`,

		`CREATE TABLE users (
	id BYTES(MAX) NOT NULL,
	external_id STRING(MAX),
	tenant_id STRING(MAX),
	email STRING(MAX) NOT NULL,
	normalized_email STRING(MAX) NOT NULL,
	full_name STRING(MAX) NOT NULL,
	short_name STRING(MAX),
	password_hash BYTES(MAX) NOT NULL,
	new_unverified_email STRING(MAX),
	email_change_verification_step INT64 NOT NULL DEFAULT (0),
	status INT64 NOT NULL,
	status_updated_at TIMESTAMP,
	final_invoice_generated BOOL NOT NULL DEFAULT (false),
	user_agent BYTES(MAX),
	created_at TIMESTAMP NOT NULL,
	project_limit INT64 NOT NULL DEFAULT (0),
	project_bandwidth_limit INT64 NOT NULL DEFAULT (0),
	project_storage_limit INT64 NOT NULL DEFAULT (0),
	project_segment_limit INT64 NOT NULL DEFAULT (0),
	kind INT64 NOT NULL DEFAULT (0),
	position STRING(MAX),
	company_name STRING(MAX),
	company_size INT64,
	working_on STRING(MAX),
	is_professional BOOL NOT NULL DEFAULT (false),
	employee_count STRING(MAX),
	have_sales_contact BOOL NOT NULL DEFAULT (false),
	mfa_enabled BOOL NOT NULL DEFAULT (false),
	mfa_secret_key STRING(MAX),
	mfa_recovery_codes STRING(MAX),
	signup_promo_code STRING(MAX),
	verification_reminders INT64 NOT NULL DEFAULT (0),
	trial_notifications INT64 NOT NULL DEFAULT (0),
	failed_login_count INT64,
	login_lockout_expiration TIMESTAMP,
	signup_captcha FLOAT64,
	default_placement INT64,
	activation_code STRING(MAX),
	signup_id STRING(MAX),
	trial_expiration TIMESTAMP,
	upgrade_time TIMESTAMP,
	hubspot_object_id STRING(MAX)
) PRIMARY KEY ( id )`,

		`CREATE TABLE user_settings (
	user_id BYTES(MAX) NOT NULL,
	session_minutes INT64,
	passphrase_prompt BOOL,
	onboarding_start BOOL NOT NULL DEFAULT (true),
	onboarding_end BOOL NOT NULL DEFAULT (true),
	onboarding_step STRING(MAX),
	notice_dismissal JSON NOT NULL DEFAULT (JSON "{}")
) PRIMARY KEY ( user_id )`,

		`CREATE TABLE value_attributions (
	project_id BYTES(MAX) NOT NULL,
	bucket_name BYTES(MAX) NOT NULL,
	user_agent BYTES(MAX),
	placement INT64,
	last_updated TIMESTAMP NOT NULL
) PRIMARY KEY ( project_id, bucket_name )`,

		`CREATE TABLE verification_audits (
	inserted_at TIMESTAMP NOT NULL DEFAULT (current_timestamp),
	stream_id BYTES(MAX) NOT NULL,
	position INT64 NOT NULL,
	expires_at TIMESTAMP,
	encrypted_size INT64 NOT NULL
) PRIMARY KEY ( inserted_at, stream_id, position )`,

		`CREATE TABLE webapp_sessions (
	id BYTES(MAX) NOT NULL,
	user_id BYTES(MAX) NOT NULL,
	ip_address STRING(MAX) NOT NULL,
	user_agent STRING(MAX) NOT NULL,
	status INT64 NOT NULL,
	expires_at TIMESTAMP NOT NULL
) PRIMARY KEY ( id )`,

		`CREATE TABLE api_keys (
	id BYTES(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	head BYTES(MAX) NOT NULL,
	name STRING(MAX) NOT NULL,
	secret BYTES(MAX) NOT NULL,
	user_agent BYTES(MAX),
	created_at TIMESTAMP NOT NULL,
	created_by BYTES(MAX),
	version INT64 NOT NULL DEFAULT (0),
	CONSTRAINT api_keys_project_id_fkey FOREIGN KEY (project_id) REFERENCES projects (id) ON DELETE CASCADE ,
	CONSTRAINT api_keys_created_by_fkey FOREIGN KEY (created_by) REFERENCES users (id)
) PRIMARY KEY ( id )`,

		`CREATE UNIQUE INDEX index_api_keys_head ON api_keys ( head )`,

		`CREATE UNIQUE INDEX index_api_keys_name_project_id ON api_keys ( name, project_id )`,

		`CREATE TABLE bucket_metainfos (
	id BYTES(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	name BYTES(MAX) NOT NULL,
	tags BYTES(MAX),
	user_agent BYTES(MAX),
	versioning INT64 NOT NULL DEFAULT (0),
	object_lock_enabled BOOL NOT NULL DEFAULT (false),
	default_retention_mode INT64,
	default_retention_days INT64,
	default_retention_years INT64,
	path_cipher INT64 NOT NULL,
	created_at TIMESTAMP NOT NULL,
	default_segment_size INT64 NOT NULL,
	default_encryption_cipher_suite INT64 NOT NULL,
	default_encryption_block_size INT64 NOT NULL,
	default_redundancy_algorithm INT64 NOT NULL,
	default_redundancy_share_size INT64 NOT NULL,
	default_redundancy_required_shares INT64 NOT NULL,
	default_redundancy_repair_shares INT64 NOT NULL,
	default_redundancy_optimal_shares INT64 NOT NULL,
	default_redundancy_total_shares INT64 NOT NULL,
	placement INT64,
	created_by BYTES(MAX),
	CONSTRAINT bucket_metainfos_project_id_fkey FOREIGN KEY (project_id) REFERENCES projects (id),
	CONSTRAINT bucket_metainfos_created_by_fkey FOREIGN KEY (created_by) REFERENCES users (id)
) PRIMARY KEY ( project_id, name )`,

		`CREATE TABLE bucket_migrations (
	id BYTES(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	bucket_name BYTES(MAX) NOT NULL,
	from_placement INT64 NOT NULL,
	to_placement INT64 NOT NULL,
	migration_type INT64 NOT NULL,
	state STRING(MAX) NOT NULL,
	bytes_processed INT64 NOT NULL DEFAULT (0),
	error_message STRING(MAX),
	created_at TIMESTAMP NOT NULL,
	updated_at TIMESTAMP NOT NULL,
	completed_at TIMESTAMP,
	CONSTRAINT bucket_migrations_project_id_fkey FOREIGN KEY (project_id) REFERENCES projects (id)
) PRIMARY KEY ( id )`,

		`CREATE TABLE domains (
	subdomain STRING(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	prefix STRING(MAX) NOT NULL,
	access_id STRING(MAX) NOT NULL,
	created_by BYTES(MAX) NOT NULL,
	created_at TIMESTAMP NOT NULL,
	CONSTRAINT domains_project_id_fkey FOREIGN KEY (project_id) REFERENCES projects (id),
	CONSTRAINT domains_created_by_fkey FOREIGN KEY (created_by) REFERENCES users (id)
) PRIMARY KEY ( project_id, subdomain )`,

		`CREATE TABLE project_invitations (
	project_id BYTES(MAX) NOT NULL,
	email STRING(MAX) NOT NULL,
	inviter_id BYTES(MAX),
	created_at TIMESTAMP NOT NULL,
	CONSTRAINT project_invitations_project_id_fkey FOREIGN KEY (project_id) REFERENCES projects (id) ON DELETE CASCADE ,
	CONSTRAINT project_invitations_inviter_id_fkey FOREIGN KEY (inviter_id) REFERENCES users (id) ON DELETE CASCADE 
) PRIMARY KEY ( project_id, email )`,

		`CREATE TABLE project_members (
	member_id BYTES(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	role INT64 NOT NULL DEFAULT (0),
	created_at TIMESTAMP NOT NULL,
	CONSTRAINT project_members_member_id_fkey FOREIGN KEY (member_id) REFERENCES users (id) ON DELETE CASCADE ,
	CONSTRAINT project_members_project_id_fkey FOREIGN KEY (project_id) REFERENCES projects (id) ON DELETE CASCADE 
) PRIMARY KEY ( member_id, project_id )`,

		`CREATE TABLE rest_api_keys (
	id BYTES(MAX) NOT NULL,
	user_id BYTES(MAX) NOT NULL,
	token BYTES(MAX) NOT NULL,
	name STRING(MAX) NOT NULL,
	expires_at TIMESTAMP,
	created_at TIMESTAMP NOT NULL,
	CONSTRAINT rest_api_keys_user_id_fkey FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE 
) PRIMARY KEY ( id )`,

		`CREATE UNIQUE INDEX index_rest_api_keys_token ON rest_api_keys ( token )`,

		`CREATE TABLE stripecoinpayments_apply_balance_intents (
	tx_id STRING(MAX) NOT NULL,
	state INT64 NOT NULL,
	created_at TIMESTAMP NOT NULL,
	CONSTRAINT stripecoinpayments_apply_balance_intents_tx_id_fkey FOREIGN KEY (tx_id) REFERENCES coinpayments_transactions (id) ON DELETE CASCADE 
) PRIMARY KEY ( tx_id )`,

		`CREATE TABLE api_key_tails (
	root_key_id BYTES(MAX),
	tail BYTES(MAX) NOT NULL,
	parent_tail BYTES(MAX) NOT NULL,
	caveat BYTES(MAX) NOT NULL,
	last_used TIMESTAMP NOT NULL,
	CONSTRAINT api_key_tails_root_key_id_fkey FOREIGN KEY (root_key_id) REFERENCES api_keys (id) ON DELETE CASCADE 
) PRIMARY KEY ( tail )`,

		`CREATE INDEX accounting_rollups_start_time_index ON accounting_rollups ( start_time )`,

		`CREATE INDEX billing_transactions_tx_timestamp_index ON billing_transactions ( tx_timestamp )`,

		`CREATE INDEX bucket_bandwidth_rollups_project_id_action_interval_index ON bucket_bandwidth_rollups ( project_id, action, interval_start )`,

		`CREATE INDEX bucket_bandwidth_rollups_action_interval_project_id_index ON bucket_bandwidth_rollups ( action, interval_start, project_id )`,

		`CREATE INDEX bucket_bandwidth_rollups_archive_project_id_action_interval_index ON bucket_bandwidth_rollup_archives ( project_id, action, interval_start )`,

		`CREATE INDEX bucket_bandwidth_rollups_archive_action_interval_project_id_index ON bucket_bandwidth_rollup_archives ( action, interval_start, project_id )`,

		`CREATE INDEX bucket_storage_tallies_project_id_interval_start_index ON bucket_storage_tallies ( project_id, interval_start )`,

		`CREATE INDEX bucket_storage_tallies_interval_start_index ON bucket_storage_tallies ( interval_start )`,

		`CREATE INDEX change_history_user_id_timestamp_idx ON change_histories ( user_id, timestamp )`,

		`CREATE INDEX change_history_user_id_item_type_timestamp_idx ON change_histories ( user_id, item_type, timestamp )`,

		`CREATE INDEX change_history_project_id_item_type_timestamp_idx ON change_histories ( project_id, item_type, timestamp )`,

		`CREATE INDEX change_history_bucket_name_timestamp_idx ON change_histories ( bucket_name, timestamp )`,

		`CREATE INDEX node_events_email_event_created_at_index ON node_events ( email, event, created_at )`,

		`CREATE INDEX oauth_clients_user_id_index ON oauth_clients ( user_id )`,

		`CREATE INDEX oauth_codes_user_id_index ON oauth_codes ( user_id )`,

		`CREATE INDEX oauth_codes_client_id_index ON oauth_codes ( client_id )`,

		`CREATE INDEX oauth_tokens_user_id_index ON oauth_tokens ( user_id )`,

		`CREATE INDEX oauth_tokens_client_id_index ON oauth_tokens ( client_id )`,

		`CREATE INDEX projects_public_id_index ON projects ( public_id )`,

		`CREATE INDEX projects_owner_id_index ON projects ( owner_id )`,

		`CREATE INDEX projects_status_status_updated_at_index ON projects ( status, status_updated_at )`,

		`CREATE INDEX project_bandwidth_daily_rollup_interval_day_index ON project_bandwidth_daily_rollups ( interval_day )`,

		`CREATE INDEX repair_queue_updated_at_index ON repair_queue ( updated_at )`,

		`CREATE INDEX repair_queue_num_healthy_pieces_attempted_at_index ON repair_queue ( segment_health, attempted_at )`,

		`CREATE INDEX repair_queue_placement_index ON repair_queue ( placement )`,

		`CREATE INDEX reverification_audits_inserted_at_index ON reverification_audits ( inserted_at )`,

		`CREATE INDEX storagenode_bandwidth_rollups_interval_start_index ON storagenode_bandwidth_rollups ( interval_start )`,

		`CREATE INDEX storagenode_bandwidth_rollup_archives_interval_start_index ON storagenode_bandwidth_rollup_archives ( interval_start )`,

		`CREATE INDEX storagenode_payments_node_id_period_index ON storagenode_payments ( node_id, period )`,

		`CREATE INDEX storagenode_paystubs_node_id_index ON storagenode_paystubs ( node_id )`,

		`CREATE INDEX storagenode_storage_tallies_node_id_index ON storagenode_storage_tallies ( node_id )`,

		`CREATE INDEX storjscan_payments_chain_id_block_number_log_index_index ON storjscan_payments ( chain_id, block_number, log_index )`,

		`CREATE INDEX storjscan_wallets_wallet_address_index ON storjscan_wallets ( wallet_address )`,

		`CREATE INDEX stripecoinpayments_invoice_project_records_unbilled_project_id_index ON stripecoinpayments_invoice_project_records ( project_id )`,

		`CREATE INDEX users_email_status_index ON users ( normalized_email, status )`,

		`CREATE INDEX trial_expiration_index ON users ( trial_expiration )`,

		`CREATE INDEX users_external_id_index ON users ( external_id )`,

		`CREATE INDEX users_status_status_updated_at_index ON users ( status, status_updated_at )`,

		`CREATE INDEX users_tenant_id_index ON users ( tenant_id )`,

		`CREATE INDEX users_normalized_email_tenant_id_status_index ON users ( normalized_email, tenant_id, status )`,

		`CREATE INDEX webapp_sessions_user_id_index ON webapp_sessions ( user_id )`,

		`CREATE INDEX bucket_migrations_state_created_at_index ON bucket_migrations ( state, created_at )`,

		`CREATE INDEX project_invitations_project_id_index ON project_invitations ( project_id )`,

		`CREATE INDEX project_invitations_email_index ON project_invitations ( email )`,

		`CREATE INDEX project_members_project_id_index ON project_members ( project_id )`,

		`CREATE INDEX rest_api_keys_user_id_index ON rest_api_keys ( user_id )`,

		`CREATE INDEX rest_api_keys_name_index ON rest_api_keys ( name )`,
	}
}

func (obj *spannerDB) DropSchema() []string {
	return []string{

		`ALTER TABLE api_key_tails DROP CONSTRAINT api_key_tails_root_key_id_fkey`,

		`ALTER TABLE stripecoinpayments_apply_balance_intents DROP CONSTRAINT stripecoinpayments_apply_balance_intents_tx_id_fkey`,

		`ALTER TABLE rest_api_keys DROP CONSTRAINT rest_api_keys_user_id_fkey`,

		`DROP INDEX IF EXISTS index_rest_api_keys_token`,

		`ALTER TABLE project_members DROP CONSTRAINT project_members_member_id_fkey`,

		`ALTER TABLE project_members DROP CONSTRAINT project_members_project_id_fkey`,

		`ALTER TABLE project_invitations DROP CONSTRAINT project_invitations_project_id_fkey`,

		`ALTER TABLE project_invitations DROP CONSTRAINT project_invitations_inviter_id_fkey`,

		`ALTER TABLE domains DROP CONSTRAINT domains_project_id_fkey`,

		`ALTER TABLE domains DROP CONSTRAINT domains_created_by_fkey`,

		`ALTER TABLE bucket_migrations DROP CONSTRAINT bucket_migrations_project_id_fkey`,

		`ALTER TABLE bucket_metainfos DROP CONSTRAINT bucket_metainfos_project_id_fkey`,

		`ALTER TABLE bucket_metainfos DROP CONSTRAINT bucket_metainfos_created_by_fkey`,

		`ALTER TABLE api_keys DROP CONSTRAINT api_keys_project_id_fkey`,

		`ALTER TABLE api_keys DROP CONSTRAINT api_keys_created_by_fkey`,

		`DROP INDEX IF EXISTS index_api_keys_head`,

		`DROP INDEX IF EXISTS index_api_keys_name_project_id`,

		`DROP INDEX IF EXISTS index_stripecoinpayments_invoice_project_records_project_id_period_start_period_end`,

		`DROP INDEX IF EXISTS index_stripe_customers_customer_id`,

		`DROP INDEX IF EXISTS index_reset_password_tokens_owner_id`,

		`DROP INDEX IF EXISTS index_registration_tokens_owner_id`,

		`DROP INDEX IF EXISTS accounting_rollups_start_time_index`,

		`DROP INDEX IF EXISTS billing_transactions_tx_timestamp_index`,

		`DROP INDEX IF EXISTS bucket_bandwidth_rollups_project_id_action_interval_index`,

		`DROP INDEX IF EXISTS bucket_bandwidth_rollups_action_interval_project_id_index`,

		`DROP INDEX IF EXISTS bucket_bandwidth_rollups_archive_project_id_action_interval_index`,

		`DROP INDEX IF EXISTS bucket_bandwidth_rollups_archive_action_interval_project_id_index`,

		`DROP INDEX IF EXISTS bucket_storage_tallies_project_id_interval_start_index`,

		`DROP INDEX IF EXISTS bucket_storage_tallies_interval_start_index`,

		`DROP INDEX IF EXISTS change_history_user_id_timestamp_idx`,

		`DROP INDEX IF EXISTS change_history_user_id_item_type_timestamp_idx`,

		`DROP INDEX IF EXISTS change_history_project_id_item_type_timestamp_idx`,

		`DROP INDEX IF EXISTS change_history_bucket_name_timestamp_idx`,

		`DROP INDEX IF EXISTS node_events_email_event_created_at_index`,

		`DROP INDEX IF EXISTS oauth_clients_user_id_index`,

		`DROP INDEX IF EXISTS oauth_codes_user_id_index`,

		`DROP INDEX IF EXISTS oauth_codes_client_id_index`,

		`DROP INDEX IF EXISTS oauth_tokens_user_id_index`,

		`DROP INDEX IF EXISTS oauth_tokens_client_id_index`,

		`DROP INDEX IF EXISTS projects_public_id_index`,

		`DROP INDEX IF EXISTS projects_owner_id_index`,

		`DROP INDEX IF EXISTS projects_status_status_updated_at_index`,

		`DROP INDEX IF EXISTS project_bandwidth_daily_rollup_interval_day_index`,

		`DROP INDEX IF EXISTS repair_queue_updated_at_index`,

		`DROP INDEX IF EXISTS repair_queue_num_healthy_pieces_attempted_at_index`,

		`DROP INDEX IF EXISTS repair_queue_placement_index`,

		`DROP INDEX IF EXISTS reverification_audits_inserted_at_index`,

		`DROP INDEX IF EXISTS storagenode_bandwidth_rollups_interval_start_index`,

		`DROP INDEX IF EXISTS storagenode_bandwidth_rollup_archives_interval_start_index`,

		`DROP INDEX IF EXISTS storagenode_payments_node_id_period_index`,

		`DROP INDEX IF EXISTS storagenode_paystubs_node_id_index`,

		`DROP INDEX IF EXISTS storagenode_storage_tallies_node_id_index`,

		`DROP INDEX IF EXISTS storjscan_payments_chain_id_block_number_log_index_index`,

		`DROP INDEX IF EXISTS storjscan_wallets_wallet_address_index`,

		`DROP INDEX IF EXISTS stripecoinpayments_invoice_project_records_unbilled_project_id_index`,

		`DROP INDEX IF EXISTS users_email_status_index`,

		`DROP INDEX IF EXISTS trial_expiration_index`,

		`DROP INDEX IF EXISTS users_external_id_index`,

		`DROP INDEX IF EXISTS users_status_status_updated_at_index`,

		`DROP INDEX IF EXISTS users_tenant_id_index`,

		`DROP INDEX IF EXISTS users_normalized_email_tenant_id_status_index`,

		`DROP INDEX IF EXISTS webapp_sessions_user_id_index`,

		`DROP INDEX IF EXISTS bucket_migrations_state_created_at_index`,

		`DROP INDEX IF EXISTS project_invitations_project_id_index`,

		`DROP INDEX IF EXISTS project_invitations_email_index`,

		`DROP INDEX IF EXISTS project_members_project_id_index`,

		`DROP INDEX IF EXISTS rest_api_keys_user_id_index`,

		`DROP INDEX IF EXISTS rest_api_keys_name_index`,

		`ALTER TABLE  api_key_tails ALTER tail SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS api_key_tails_tail`,

		`DROP TABLE IF EXISTS api_key_tails`,

		`ALTER TABLE  stripecoinpayments_apply_balance_intents ALTER tx_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS stripecoinpayments_apply_balance_intents_tx_id`,

		`DROP TABLE IF EXISTS stripecoinpayments_apply_balance_intents`,

		`ALTER TABLE  rest_api_keys ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS rest_api_keys_id`,

		`DROP TABLE IF EXISTS rest_api_keys`,

		`ALTER TABLE  project_members ALTER member_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS project_members_member_id`,

		`ALTER TABLE  project_members ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS project_members_project_id`,

		`DROP TABLE IF EXISTS project_members`,

		`ALTER TABLE  project_invitations ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS project_invitations_project_id`,

		`ALTER TABLE  project_invitations ALTER email SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS project_invitations_email`,

		`DROP TABLE IF EXISTS project_invitations`,

		`ALTER TABLE  domains ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS domains_project_id`,

		`ALTER TABLE  domains ALTER subdomain SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS domains_subdomain`,

		`DROP TABLE IF EXISTS domains`,

		`ALTER TABLE  bucket_migrations ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_migrations_id`,

		`DROP TABLE IF EXISTS bucket_migrations`,

		`ALTER TABLE  bucket_metainfos ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_metainfos_project_id`,

		`ALTER TABLE  bucket_metainfos ALTER name SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_metainfos_name`,

		`DROP TABLE IF EXISTS bucket_metainfos`,

		`ALTER TABLE  api_keys ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS api_keys_id`,

		`DROP TABLE IF EXISTS api_keys`,

		`ALTER TABLE  webapp_sessions ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS webapp_sessions_id`,

		`DROP TABLE IF EXISTS webapp_sessions`,

		`ALTER TABLE  verification_audits ALTER inserted_at SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS verification_audits_inserted_at`,

		`ALTER TABLE  verification_audits ALTER stream_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS verification_audits_stream_id`,

		`ALTER TABLE  verification_audits ALTER position SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS verification_audits_position`,

		`DROP TABLE IF EXISTS verification_audits`,

		`ALTER TABLE  value_attributions ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS value_attributions_project_id`,

		`ALTER TABLE  value_attributions ALTER bucket_name SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS value_attributions_bucket_name`,

		`DROP TABLE IF EXISTS value_attributions`,

		`ALTER TABLE  user_settings ALTER user_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS user_settings_user_id`,

		`DROP TABLE IF EXISTS user_settings`,

		`ALTER TABLE  users ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS users_id`,

		`DROP TABLE IF EXISTS users`,

		`ALTER TABLE  stripecoinpayments_tx_conversion_rates ALTER tx_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS stripecoinpayments_tx_conversion_rates_tx_id`,

		`DROP TABLE IF EXISTS stripecoinpayments_tx_conversion_rates`,

		`ALTER TABLE  stripecoinpayments_invoice_project_records ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS stripecoinpayments_invoice_project_records_id`,

		`DROP TABLE IF EXISTS stripecoinpayments_invoice_project_records`,

		`ALTER TABLE  stripe_customers ALTER user_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS stripe_customers_user_id`,

		`DROP TABLE IF EXISTS stripe_customers`,

		`ALTER TABLE  storjscan_wallets ALTER user_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storjscan_wallets_user_id`,

		`ALTER TABLE  storjscan_wallets ALTER wallet_address SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storjscan_wallets_wallet_address`,

		`DROP TABLE IF EXISTS storjscan_wallets`,

		`ALTER TABLE  storjscan_payments ALTER block_hash SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storjscan_payments_block_hash`,

		`ALTER TABLE  storjscan_payments ALTER log_index SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storjscan_payments_log_index`,

		`DROP TABLE IF EXISTS storjscan_payments`,

		`ALTER TABLE  storagenode_storage_tallies ALTER interval_end_time SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_storage_tallies_interval_end_time`,

		`ALTER TABLE  storagenode_storage_tallies ALTER node_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_storage_tallies_node_id`,

		`DROP TABLE IF EXISTS storagenode_storage_tallies`,

		`ALTER TABLE  storagenode_paystubs ALTER period SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_paystubs_period`,

		`ALTER TABLE  storagenode_paystubs ALTER node_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_paystubs_node_id`,

		`DROP TABLE IF EXISTS storagenode_paystubs`,

		`ALTER TABLE  storagenode_payments ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_payments_id`,

		`DROP TABLE IF EXISTS storagenode_payments`,

		`ALTER TABLE  storagenode_bandwidth_rollup_archives ALTER storagenode_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_bandwidth_rollup_archives_storagenode_id`,

		`ALTER TABLE  storagenode_bandwidth_rollup_archives ALTER interval_start SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_bandwidth_rollup_archives_interval_start`,

		`ALTER TABLE  storagenode_bandwidth_rollup_archives ALTER action SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_bandwidth_rollup_archives_action`,

		`DROP TABLE IF EXISTS storagenode_bandwidth_rollup_archives`,

		`ALTER TABLE  storagenode_bandwidth_rollups ALTER storagenode_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_bandwidth_rollups_storagenode_id`,

		`ALTER TABLE  storagenode_bandwidth_rollups ALTER interval_start SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_bandwidth_rollups_interval_start`,

		`ALTER TABLE  storagenode_bandwidth_rollups ALTER action SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS storagenode_bandwidth_rollups_action`,

		`DROP TABLE IF EXISTS storagenode_bandwidth_rollups`,

		`ALTER TABLE  segment_pending_audits ALTER node_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS segment_pending_audits_node_id`,

		`DROP TABLE IF EXISTS segment_pending_audits`,

		`ALTER TABLE  revocations ALTER revoked SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS revocations_revoked`,

		`DROP TABLE IF EXISTS revocations`,

		`ALTER TABLE  reverification_audits ALTER node_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS reverification_audits_node_id`,

		`ALTER TABLE  reverification_audits ALTER stream_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS reverification_audits_stream_id`,

		`ALTER TABLE  reverification_audits ALTER position SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS reverification_audits_position`,

		`DROP TABLE IF EXISTS reverification_audits`,

		`ALTER TABLE  reset_password_tokens ALTER secret SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS reset_password_tokens_secret`,

		`DROP TABLE IF EXISTS reset_password_tokens`,

		`ALTER TABLE  reputations ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS reputations_id`,

		`DROP TABLE IF EXISTS reputations`,

		`ALTER TABLE  repair_queue ALTER stream_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS repair_queue_stream_id`,

		`ALTER TABLE  repair_queue ALTER position SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS repair_queue_position`,

		`DROP TABLE IF EXISTS repair_queue`,

		`ALTER TABLE  registration_tokens ALTER secret SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS registration_tokens_secret`,

		`DROP TABLE IF EXISTS registration_tokens`,

		`ALTER TABLE  project_bandwidth_daily_rollups ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS project_bandwidth_daily_rollups_project_id`,

		`ALTER TABLE  project_bandwidth_daily_rollups ALTER interval_day SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS project_bandwidth_daily_rollups_interval_day`,

		`DROP TABLE IF EXISTS project_bandwidth_daily_rollups`,

		`ALTER TABLE  projects ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS projects_id`,

		`DROP TABLE IF EXISTS projects`,

		`ALTER TABLE  peer_identities ALTER node_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS peer_identities_node_id`,

		`DROP TABLE IF EXISTS peer_identities`,

		`ALTER TABLE  oauth_tokens ALTER token SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS oauth_tokens_token`,

		`DROP TABLE IF EXISTS oauth_tokens`,

		`ALTER TABLE  oauth_codes ALTER code SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS oauth_codes_code`,

		`DROP TABLE IF EXISTS oauth_codes`,

		`ALTER TABLE  oauth_clients ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS oauth_clients_id`,

		`DROP TABLE IF EXISTS oauth_clients`,

		`ALTER TABLE  node_tags ALTER node_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS node_tags_node_id`,

		`ALTER TABLE  node_tags ALTER name SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS node_tags_name`,

		`ALTER TABLE  node_tags ALTER signer SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS node_tags_signer`,

		`DROP TABLE IF EXISTS node_tags`,

		`ALTER TABLE  node_events ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS node_events_id`,

		`DROP TABLE IF EXISTS node_events`,

		`ALTER TABLE  node_api_versions ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS node_api_versions_id`,

		`DROP TABLE IF EXISTS node_api_versions`,

		`ALTER TABLE  nodes ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS nodes_id`,

		`DROP TABLE IF EXISTS nodes`,

		`ALTER TABLE  entitlements ALTER scope SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS entitlements_scope`,

		`DROP TABLE IF EXISTS entitlements`,

		`ALTER TABLE  coinpayments_transactions ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS coinpayments_transactions_id`,

		`DROP TABLE IF EXISTS coinpayments_transactions`,

		`ALTER TABLE  change_histories ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS change_histories_id`,

		`DROP TABLE IF EXISTS change_histories`,

		`ALTER TABLE  bucket_storage_tallies ALTER bucket_name SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_storage_tallies_bucket_name`,

		`ALTER TABLE  bucket_storage_tallies ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_storage_tallies_project_id`,

		`ALTER TABLE  bucket_storage_tallies ALTER interval_start SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_storage_tallies_interval_start`,

		`DROP TABLE IF EXISTS bucket_storage_tallies`,

		`ALTER TABLE  bucket_bandwidth_rollup_archives ALTER bucket_name SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_bandwidth_rollup_archives_bucket_name`,

		`ALTER TABLE  bucket_bandwidth_rollup_archives ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_bandwidth_rollup_archives_project_id`,

		`ALTER TABLE  bucket_bandwidth_rollup_archives ALTER interval_start SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_bandwidth_rollup_archives_interval_start`,

		`ALTER TABLE  bucket_bandwidth_rollup_archives ALTER action SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_bandwidth_rollup_archives_action`,

		`DROP TABLE IF EXISTS bucket_bandwidth_rollup_archives`,

		`ALTER TABLE  bucket_bandwidth_rollups ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_bandwidth_rollups_project_id`,

		`ALTER TABLE  bucket_bandwidth_rollups ALTER bucket_name SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_bandwidth_rollups_bucket_name`,

		`ALTER TABLE  bucket_bandwidth_rollups ALTER interval_start SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_bandwidth_rollups_interval_start`,

		`ALTER TABLE  bucket_bandwidth_rollups ALTER action SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS bucket_bandwidth_rollups_action`,

		`DROP TABLE IF EXISTS bucket_bandwidth_rollups`,

		`ALTER TABLE  billing_transactions ALTER id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS billing_transactions_id`,

		`DROP TABLE IF EXISTS billing_transactions`,

		`ALTER TABLE  billing_balances ALTER user_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS billing_balances_user_id`,

		`DROP TABLE IF EXISTS billing_balances`,

		`ALTER TABLE  accounting_timestamps ALTER name SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS accounting_timestamps_name`,

		`DROP TABLE IF EXISTS accounting_timestamps`,

		`ALTER TABLE  accounting_rollups ALTER node_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS accounting_rollups_node_id`,

		`ALTER TABLE  accounting_rollups ALTER start_time SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS accounting_rollups_start_time`,

		`DROP TABLE IF EXISTS accounting_rollups`,

		`ALTER TABLE  account_freeze_events ALTER user_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS account_freeze_events_user_id`,

		`ALTER TABLE  account_freeze_events ALTER event SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS account_freeze_events_event`,

		`DROP TABLE IF EXISTS account_freeze_events`,
	}
}

func (obj *spannerDB) wrapTx(tx tagsql.Tx) txMethods {
	return &spannerTx{
		dialectTx: dialectTx{tx: tx},
		spannerImpl: &spannerImpl{
			db:     obj.db,
			driver: tx,
			txn:    true,
		},
	}
}

type spannerTx struct {
	dialectTx
	*spannerImpl
}

func spannerLogStmt(stmt string, args ...any) {
	// TODO: render placeholders
	if Logger != nil {
		out := fmt.Sprintf("stmt: %s\nargs: %v\n", stmt, pretty(args))
		Logger(out)
	}
}

type pretty []any

func (p pretty) Format(f fmt.State, c rune) {
	_, _ = fmt.Fprint(f, "[")
nextval:
	for i, val := range p {
		if i > 0 {
			_, _ = fmt.Fprint(f, ", ")
		}
		rv := reflect.ValueOf(val)
		if rv.Kind() == reflect.Ptr {
			if rv.IsNil() {
				_, _ = fmt.Fprint(f, "NULL")
				continue
			}
			val = rv.Elem().Interface()
		}
		switch v := val.(type) {
		case string:
			_, _ = fmt.Fprintf(f, "%q", v)
		case time.Time:
			_, _ = fmt.Fprintf(f, "%s", v.Format(time.RFC3339Nano))
		case []byte:
			for _, b := range v {
				if !unicode.IsPrint(rune(b)) {
					_, _ = fmt.Fprintf(f, "%#x", v)
					continue nextval
				}
			}
			_, _ = fmt.Fprintf(f, "%q", v)
		default:
			_, _ = fmt.Fprintf(f, "%v", v)
		}
	}
	_, _ = fmt.Fprint(f, "]")
}

type AccountFreezeEvent struct {
	UserId             []byte
	Event              int
	Limits             []byte
	DaysTillEscalation *int
	NotificationsCount int
	CreatedAt          time.Time
}

func (AccountFreezeEvent) _Table() string { return "account_freeze_events" }

type AccountFreezeEvent_Create_Fields struct {
	Limits             AccountFreezeEvent_Limits_Field
	DaysTillEscalation AccountFreezeEvent_DaysTillEscalation_Field
	NotificationsCount AccountFreezeEvent_NotificationsCount_Field
	CreatedAt          AccountFreezeEvent_CreatedAt_Field
}

type AccountFreezeEvent_Update_Fields struct {
	Limits             AccountFreezeEvent_Limits_Field
	DaysTillEscalation AccountFreezeEvent_DaysTillEscalation_Field
	NotificationsCount AccountFreezeEvent_NotificationsCount_Field
}

type AccountFreezeEvent_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func AccountFreezeEvent_UserId(v []byte) AccountFreezeEvent_UserId_Field {
	return AccountFreezeEvent_UserId_Field{_set: true, _value: v}
}

func (f AccountFreezeEvent_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountFreezeEvent_Event_Field struct {
	_set   bool
	_null  bool
	_value int
}

func AccountFreezeEvent_Event(v int) AccountFreezeEvent_Event_Field {
	return AccountFreezeEvent_Event_Field{_set: true, _value: v}
}

func (f AccountFreezeEvent_Event_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountFreezeEvent_Limits_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func AccountFreezeEvent_Limits(v []byte) AccountFreezeEvent_Limits_Field {
	return AccountFreezeEvent_Limits_Field{_set: true, _value: v}
}

func AccountFreezeEvent_Limits_Raw(v []byte) AccountFreezeEvent_Limits_Field {
	if v == nil {
		return AccountFreezeEvent_Limits_Null()
	}
	return AccountFreezeEvent_Limits(v)
}

func AccountFreezeEvent_Limits_Null() AccountFreezeEvent_Limits_Field {
	return AccountFreezeEvent_Limits_Field{_set: true, _null: true}
}

func (f AccountFreezeEvent_Limits_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f AccountFreezeEvent_Limits_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountFreezeEvent_DaysTillEscalation_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func AccountFreezeEvent_DaysTillEscalation(v int) AccountFreezeEvent_DaysTillEscalation_Field {
	return AccountFreezeEvent_DaysTillEscalation_Field{_set: true, _value: &v}
}

func AccountFreezeEvent_DaysTillEscalation_Raw(v *int) AccountFreezeEvent_DaysTillEscalation_Field {
	if v == nil {
		return AccountFreezeEvent_DaysTillEscalation_Null()
	}
	return AccountFreezeEvent_DaysTillEscalation(*v)
}

func AccountFreezeEvent_DaysTillEscalation_Null() AccountFreezeEvent_DaysTillEscalation_Field {
	return AccountFreezeEvent_DaysTillEscalation_Field{_set: true, _null: true}
}

func (f AccountFreezeEvent_DaysTillEscalation_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f AccountFreezeEvent_DaysTillEscalation_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountFreezeEvent_NotificationsCount_Field struct {
	_set   bool
	_null  bool
	_value int
}

func AccountFreezeEvent_NotificationsCount(v int) AccountFreezeEvent_NotificationsCount_Field {
	return AccountFreezeEvent_NotificationsCount_Field{_set: true, _value: v}
}

func (f AccountFreezeEvent_NotificationsCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountFreezeEvent_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func AccountFreezeEvent_CreatedAt(v time.Time) AccountFreezeEvent_CreatedAt_Field {
	return AccountFreezeEvent_CreatedAt_Field{_set: true, _value: v}
}

func (f AccountFreezeEvent_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingRollup struct {
	NodeId          []byte
	StartTime       time.Time
	PutTotal        int64
	GetTotal        int64
	GetAuditTotal   int64
	GetRepairTotal  int64
	PutRepairTotal  int64
	AtRestTotal     float64
	IntervalEndTime *time.Time
}

func (AccountingRollup) _Table() string { return "accounting_rollups" }

type AccountingRollup_Create_Fields struct {
	IntervalEndTime AccountingRollup_IntervalEndTime_Field
}

type AccountingRollup_Update_Fields struct {
	IntervalEndTime AccountingRollup_IntervalEndTime_Field
}

type AccountingRollup_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func AccountingRollup_NodeId(v []byte) AccountingRollup_NodeId_Field {
	return AccountingRollup_NodeId_Field{_set: true, _value: v}
}

func (f AccountingRollup_NodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingRollup_StartTime_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func AccountingRollup_StartTime(v time.Time) AccountingRollup_StartTime_Field {
	return AccountingRollup_StartTime_Field{_set: true, _value: v}
}

func (f AccountingRollup_StartTime_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingRollup_PutTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_PutTotal(v int64) AccountingRollup_PutTotal_Field {
	return AccountingRollup_PutTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_PutTotal_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingRollup_GetTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_GetTotal(v int64) AccountingRollup_GetTotal_Field {
	return AccountingRollup_GetTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_GetTotal_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingRollup_GetAuditTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_GetAuditTotal(v int64) AccountingRollup_GetAuditTotal_Field {
	return AccountingRollup_GetAuditTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_GetAuditTotal_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingRollup_GetRepairTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_GetRepairTotal(v int64) AccountingRollup_GetRepairTotal_Field {
	return AccountingRollup_GetRepairTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_GetRepairTotal_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingRollup_PutRepairTotal_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func AccountingRollup_PutRepairTotal(v int64) AccountingRollup_PutRepairTotal_Field {
	return AccountingRollup_PutRepairTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_PutRepairTotal_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingRollup_AtRestTotal_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func AccountingRollup_AtRestTotal(v float64) AccountingRollup_AtRestTotal_Field {
	return AccountingRollup_AtRestTotal_Field{_set: true, _value: v}
}

func (f AccountingRollup_AtRestTotal_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingRollup_IntervalEndTime_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func AccountingRollup_IntervalEndTime(v time.Time) AccountingRollup_IntervalEndTime_Field {
	return AccountingRollup_IntervalEndTime_Field{_set: true, _value: &v}
}

func AccountingRollup_IntervalEndTime_Raw(v *time.Time) AccountingRollup_IntervalEndTime_Field {
	if v == nil {
		return AccountingRollup_IntervalEndTime_Null()
	}
	return AccountingRollup_IntervalEndTime(*v)
}

func AccountingRollup_IntervalEndTime_Null() AccountingRollup_IntervalEndTime_Field {
	return AccountingRollup_IntervalEndTime_Field{_set: true, _null: true}
}

func (f AccountingRollup_IntervalEndTime_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f AccountingRollup_IntervalEndTime_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingTimestamps struct {
	Name  string
	Value time.Time
}

func (AccountingTimestamps) _Table() string { return "accounting_timestamps" }

type AccountingTimestamps_Update_Fields struct {
	Value AccountingTimestamps_Value_Field
}

type AccountingTimestamps_Name_Field struct {
	_set   bool
	_null  bool
	_value string
}

func AccountingTimestamps_Name(v string) AccountingTimestamps_Name_Field {
	return AccountingTimestamps_Name_Field{_set: true, _value: v}
}

func (f AccountingTimestamps_Name_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type AccountingTimestamps_Value_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func AccountingTimestamps_Value(v time.Time) AccountingTimestamps_Value_Field {
	return AccountingTimestamps_Value_Field{_set: true, _value: v}
}

func (f AccountingTimestamps_Value_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingBalance struct {
	UserId      []byte
	Balance     int64
	LastUpdated time.Time
}

func (BillingBalance) _Table() string { return "billing_balances" }

type BillingBalance_Update_Fields struct {
	Balance BillingBalance_Balance_Field
}

type BillingBalance_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BillingBalance_UserId(v []byte) BillingBalance_UserId_Field {
	return BillingBalance_UserId_Field{_set: true, _value: v}
}

func (f BillingBalance_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingBalance_Balance_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func BillingBalance_Balance(v int64) BillingBalance_Balance_Field {
	return BillingBalance_Balance_Field{_set: true, _value: v}
}

func (f BillingBalance_Balance_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingBalance_LastUpdated_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func BillingBalance_LastUpdated(v time.Time) BillingBalance_LastUpdated_Field {
	return BillingBalance_LastUpdated_Field{_set: true, _value: v}
}

func (f BillingBalance_LastUpdated_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction struct {
	Id          int64
	UserId      []byte
	Amount      int64
	Currency    string
	Description string
	Source      string
	Status      string
	Type        string
	Metadata    []byte
	TxTimestamp time.Time
	CreatedAt   time.Time
}

func (BillingTransaction) _Table() string { return "billing_transactions" }

type BillingTransaction_Update_Fields struct {
	Status   BillingTransaction_Status_Field
	Metadata BillingTransaction_Metadata_Field
}

type BillingTransaction_Id_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func BillingTransaction_Id(v int64) BillingTransaction_Id_Field {
	return BillingTransaction_Id_Field{_set: true, _value: v}
}

func (f BillingTransaction_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BillingTransaction_UserId(v []byte) BillingTransaction_UserId_Field {
	return BillingTransaction_UserId_Field{_set: true, _value: v}
}

func (f BillingTransaction_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_Amount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func BillingTransaction_Amount(v int64) BillingTransaction_Amount_Field {
	return BillingTransaction_Amount_Field{_set: true, _value: v}
}

func (f BillingTransaction_Amount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_Currency_Field struct {
	_set   bool
	_null  bool
	_value string
}

func BillingTransaction_Currency(v string) BillingTransaction_Currency_Field {
	return BillingTransaction_Currency_Field{_set: true, _value: v}
}

func (f BillingTransaction_Currency_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_Description_Field struct {
	_set   bool
	_null  bool
	_value string
}

func BillingTransaction_Description(v string) BillingTransaction_Description_Field {
	return BillingTransaction_Description_Field{_set: true, _value: v}
}

func (f BillingTransaction_Description_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_Source_Field struct {
	_set   bool
	_null  bool
	_value string
}

func BillingTransaction_Source(v string) BillingTransaction_Source_Field {
	return BillingTransaction_Source_Field{_set: true, _value: v}
}

func (f BillingTransaction_Source_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_Status_Field struct {
	_set   bool
	_null  bool
	_value string
}

func BillingTransaction_Status(v string) BillingTransaction_Status_Field {
	return BillingTransaction_Status_Field{_set: true, _value: v}
}

func (f BillingTransaction_Status_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_Type_Field struct {
	_set   bool
	_null  bool
	_value string
}

func BillingTransaction_Type(v string) BillingTransaction_Type_Field {
	return BillingTransaction_Type_Field{_set: true, _value: v}
}

func (f BillingTransaction_Type_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_Metadata_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BillingTransaction_Metadata(v []byte) BillingTransaction_Metadata_Field {
	return BillingTransaction_Metadata_Field{_set: true, _value: v}
}

func (f BillingTransaction_Metadata_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_TxTimestamp_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func BillingTransaction_TxTimestamp(v time.Time) BillingTransaction_TxTimestamp_Field {
	return BillingTransaction_TxTimestamp_Field{_set: true, _value: v}
}

func (f BillingTransaction_TxTimestamp_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BillingTransaction_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func BillingTransaction_CreatedAt(v time.Time) BillingTransaction_CreatedAt_Field {
	return BillingTransaction_CreatedAt_Field{_set: true, _value: v}
}

func (f BillingTransaction_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollup struct {
	BucketName      []byte
	ProjectId       []byte
	IntervalStart   time.Time
	IntervalSeconds uint
	Action          uint
	ProductId       *int
	Inline          uint64
	Allocated       uint64
	Settled         uint64
}

func (BucketBandwidthRollup) _Table() string { return "bucket_bandwidth_rollups" }

type BucketBandwidthRollup_Create_Fields struct {
	ProductId BucketBandwidthRollup_ProductId_Field
}

type BucketBandwidthRollup_Update_Fields struct {
	Inline    BucketBandwidthRollup_Inline_Field
	Allocated BucketBandwidthRollup_Allocated_Field
	Settled   BucketBandwidthRollup_Settled_Field
}

type BucketBandwidthRollup_BucketName_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketBandwidthRollup_BucketName(v []byte) BucketBandwidthRollup_BucketName_Field {
	return BucketBandwidthRollup_BucketName_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollup_BucketName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollup_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketBandwidthRollup_ProjectId(v []byte) BucketBandwidthRollup_ProjectId_Field {
	return BucketBandwidthRollup_ProjectId_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollup_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollup_IntervalStart_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func BucketBandwidthRollup_IntervalStart(v time.Time) BucketBandwidthRollup_IntervalStart_Field {
	return BucketBandwidthRollup_IntervalStart_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollup_IntervalStart_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollup_IntervalSeconds_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func BucketBandwidthRollup_IntervalSeconds(v uint) BucketBandwidthRollup_IntervalSeconds_Field {
	return BucketBandwidthRollup_IntervalSeconds_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollup_IntervalSeconds_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollup_Action_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func BucketBandwidthRollup_Action(v uint) BucketBandwidthRollup_Action_Field {
	return BucketBandwidthRollup_Action_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollup_Action_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollup_ProductId_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func BucketBandwidthRollup_ProductId(v int) BucketBandwidthRollup_ProductId_Field {
	return BucketBandwidthRollup_ProductId_Field{_set: true, _value: &v}
}

func BucketBandwidthRollup_ProductId_Raw(v *int) BucketBandwidthRollup_ProductId_Field {
	if v == nil {
		return BucketBandwidthRollup_ProductId_Null()
	}
	return BucketBandwidthRollup_ProductId(*v)
}

func BucketBandwidthRollup_ProductId_Null() BucketBandwidthRollup_ProductId_Field {
	return BucketBandwidthRollup_ProductId_Field{_set: true, _null: true}
}

func (f BucketBandwidthRollup_ProductId_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f BucketBandwidthRollup_ProductId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollup_Inline_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketBandwidthRollup_Inline(v uint64) BucketBandwidthRollup_Inline_Field {
	return BucketBandwidthRollup_Inline_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollup_Inline_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollup_Allocated_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketBandwidthRollup_Allocated(v uint64) BucketBandwidthRollup_Allocated_Field {
	return BucketBandwidthRollup_Allocated_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollup_Allocated_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollup_Settled_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketBandwidthRollup_Settled(v uint64) BucketBandwidthRollup_Settled_Field {
	return BucketBandwidthRollup_Settled_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollup_Settled_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollupArchive struct {
	BucketName      []byte
	ProjectId       []byte
	ProductId       *int
	IntervalStart   time.Time
	IntervalSeconds uint
	Action          uint
	Inline          uint64
	Allocated       uint64
	Settled         uint64
}

func (BucketBandwidthRollupArchive) _Table() string { return "bucket_bandwidth_rollup_archives" }

type BucketBandwidthRollupArchive_Create_Fields struct {
	ProductId BucketBandwidthRollupArchive_ProductId_Field
}

type BucketBandwidthRollupArchive_Update_Fields struct {
	Inline    BucketBandwidthRollupArchive_Inline_Field
	Allocated BucketBandwidthRollupArchive_Allocated_Field
	Settled   BucketBandwidthRollupArchive_Settled_Field
}

type BucketBandwidthRollupArchive_BucketName_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketBandwidthRollupArchive_BucketName(v []byte) BucketBandwidthRollupArchive_BucketName_Field {
	return BucketBandwidthRollupArchive_BucketName_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollupArchive_BucketName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollupArchive_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketBandwidthRollupArchive_ProjectId(v []byte) BucketBandwidthRollupArchive_ProjectId_Field {
	return BucketBandwidthRollupArchive_ProjectId_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollupArchive_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollupArchive_ProductId_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func BucketBandwidthRollupArchive_ProductId(v int) BucketBandwidthRollupArchive_ProductId_Field {
	return BucketBandwidthRollupArchive_ProductId_Field{_set: true, _value: &v}
}

func BucketBandwidthRollupArchive_ProductId_Raw(v *int) BucketBandwidthRollupArchive_ProductId_Field {
	if v == nil {
		return BucketBandwidthRollupArchive_ProductId_Null()
	}
	return BucketBandwidthRollupArchive_ProductId(*v)
}

func BucketBandwidthRollupArchive_ProductId_Null() BucketBandwidthRollupArchive_ProductId_Field {
	return BucketBandwidthRollupArchive_ProductId_Field{_set: true, _null: true}
}

func (f BucketBandwidthRollupArchive_ProductId_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f BucketBandwidthRollupArchive_ProductId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollupArchive_IntervalStart_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func BucketBandwidthRollupArchive_IntervalStart(v time.Time) BucketBandwidthRollupArchive_IntervalStart_Field {
	return BucketBandwidthRollupArchive_IntervalStart_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollupArchive_IntervalStart_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollupArchive_IntervalSeconds_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func BucketBandwidthRollupArchive_IntervalSeconds(v uint) BucketBandwidthRollupArchive_IntervalSeconds_Field {
	return BucketBandwidthRollupArchive_IntervalSeconds_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollupArchive_IntervalSeconds_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollupArchive_Action_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func BucketBandwidthRollupArchive_Action(v uint) BucketBandwidthRollupArchive_Action_Field {
	return BucketBandwidthRollupArchive_Action_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollupArchive_Action_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollupArchive_Inline_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketBandwidthRollupArchive_Inline(v uint64) BucketBandwidthRollupArchive_Inline_Field {
	return BucketBandwidthRollupArchive_Inline_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollupArchive_Inline_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollupArchive_Allocated_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketBandwidthRollupArchive_Allocated(v uint64) BucketBandwidthRollupArchive_Allocated_Field {
	return BucketBandwidthRollupArchive_Allocated_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollupArchive_Allocated_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketBandwidthRollupArchive_Settled_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketBandwidthRollupArchive_Settled(v uint64) BucketBandwidthRollupArchive_Settled_Field {
	return BucketBandwidthRollupArchive_Settled_Field{_set: true, _value: v}
}

func (f BucketBandwidthRollupArchive_Settled_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally struct {
	BucketName          []byte
	ProjectId           []byte
	IntervalStart       time.Time
	ProductId           *int
	TotalBytes          uint64
	Inline              uint64
	Remote              uint64
	TotalSegmentsCount  uint
	RemoteSegmentsCount uint
	InlineSegmentsCount uint
	ObjectCount         uint
	MetadataSize        uint64
}

func (BucketStorageTally) _Table() string { return "bucket_storage_tallies" }

type BucketStorageTally_Create_Fields struct {
	ProductId          BucketStorageTally_ProductId_Field
	TotalBytes         BucketStorageTally_TotalBytes_Field
	TotalSegmentsCount BucketStorageTally_TotalSegmentsCount_Field
}

type BucketStorageTally_Update_Fields struct {
}

type BucketStorageTally_BucketName_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketStorageTally_BucketName(v []byte) BucketStorageTally_BucketName_Field {
	return BucketStorageTally_BucketName_Field{_set: true, _value: v}
}

func (f BucketStorageTally_BucketName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketStorageTally_ProjectId(v []byte) BucketStorageTally_ProjectId_Field {
	return BucketStorageTally_ProjectId_Field{_set: true, _value: v}
}

func (f BucketStorageTally_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_IntervalStart_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func BucketStorageTally_IntervalStart(v time.Time) BucketStorageTally_IntervalStart_Field {
	return BucketStorageTally_IntervalStart_Field{_set: true, _value: v}
}

func (f BucketStorageTally_IntervalStart_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_ProductId_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func BucketStorageTally_ProductId(v int) BucketStorageTally_ProductId_Field {
	return BucketStorageTally_ProductId_Field{_set: true, _value: &v}
}

func BucketStorageTally_ProductId_Raw(v *int) BucketStorageTally_ProductId_Field {
	if v == nil {
		return BucketStorageTally_ProductId_Null()
	}
	return BucketStorageTally_ProductId(*v)
}

func BucketStorageTally_ProductId_Null() BucketStorageTally_ProductId_Field {
	return BucketStorageTally_ProductId_Field{_set: true, _null: true}
}

func (f BucketStorageTally_ProductId_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f BucketStorageTally_ProductId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_TotalBytes_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketStorageTally_TotalBytes(v uint64) BucketStorageTally_TotalBytes_Field {
	return BucketStorageTally_TotalBytes_Field{_set: true, _value: v}
}

func (f BucketStorageTally_TotalBytes_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_Inline_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketStorageTally_Inline(v uint64) BucketStorageTally_Inline_Field {
	return BucketStorageTally_Inline_Field{_set: true, _value: v}
}

func (f BucketStorageTally_Inline_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_Remote_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketStorageTally_Remote(v uint64) BucketStorageTally_Remote_Field {
	return BucketStorageTally_Remote_Field{_set: true, _value: v}
}

func (f BucketStorageTally_Remote_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_TotalSegmentsCount_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func BucketStorageTally_TotalSegmentsCount(v uint) BucketStorageTally_TotalSegmentsCount_Field {
	return BucketStorageTally_TotalSegmentsCount_Field{_set: true, _value: v}
}

func (f BucketStorageTally_TotalSegmentsCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_RemoteSegmentsCount_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func BucketStorageTally_RemoteSegmentsCount(v uint) BucketStorageTally_RemoteSegmentsCount_Field {
	return BucketStorageTally_RemoteSegmentsCount_Field{_set: true, _value: v}
}

func (f BucketStorageTally_RemoteSegmentsCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_InlineSegmentsCount_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func BucketStorageTally_InlineSegmentsCount(v uint) BucketStorageTally_InlineSegmentsCount_Field {
	return BucketStorageTally_InlineSegmentsCount_Field{_set: true, _value: v}
}

func (f BucketStorageTally_InlineSegmentsCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_ObjectCount_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func BucketStorageTally_ObjectCount(v uint) BucketStorageTally_ObjectCount_Field {
	return BucketStorageTally_ObjectCount_Field{_set: true, _value: v}
}

func (f BucketStorageTally_ObjectCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketStorageTally_MetadataSize_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketStorageTally_MetadataSize(v uint64) BucketStorageTally_MetadataSize_Field {
	return BucketStorageTally_MetadataSize_Field{_set: true, _value: v}
}

func (f BucketStorageTally_MetadataSize_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory struct {
	Id         []byte
	AdminEmail string
	UserId     []byte
	ProjectId  []byte
	BucketName []byte
	ItemType   string
	Operation  string
	Reason     string
	Changes    []byte
	Timestamp  time.Time
}

func (ChangeHistory) _Table() string { return "change_histories" }

type ChangeHistory_Create_Fields struct {
	ProjectId  ChangeHistory_ProjectId_Field
	BucketName ChangeHistory_BucketName_Field
	Timestamp  ChangeHistory_Timestamp_Field
}

type ChangeHistory_Update_Fields struct {
}

type ChangeHistory_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ChangeHistory_Id(v []byte) ChangeHistory_Id_Field {
	return ChangeHistory_Id_Field{_set: true, _value: v}
}

func (f ChangeHistory_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory_AdminEmail_Field struct {
	_set   bool
	_null  bool
	_value string
}

func ChangeHistory_AdminEmail(v string) ChangeHistory_AdminEmail_Field {
	return ChangeHistory_AdminEmail_Field{_set: true, _value: v}
}

func (f ChangeHistory_AdminEmail_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ChangeHistory_UserId(v []byte) ChangeHistory_UserId_Field {
	return ChangeHistory_UserId_Field{_set: true, _value: v}
}

func (f ChangeHistory_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ChangeHistory_ProjectId(v []byte) ChangeHistory_ProjectId_Field {
	return ChangeHistory_ProjectId_Field{_set: true, _value: v}
}

func ChangeHistory_ProjectId_Raw(v []byte) ChangeHistory_ProjectId_Field {
	if v == nil {
		return ChangeHistory_ProjectId_Null()
	}
	return ChangeHistory_ProjectId(v)
}

func ChangeHistory_ProjectId_Null() ChangeHistory_ProjectId_Field {
	return ChangeHistory_ProjectId_Field{_set: true, _null: true}
}

func (f ChangeHistory_ProjectId_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f ChangeHistory_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory_BucketName_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ChangeHistory_BucketName(v []byte) ChangeHistory_BucketName_Field {
	return ChangeHistory_BucketName_Field{_set: true, _value: v}
}

func ChangeHistory_BucketName_Raw(v []byte) ChangeHistory_BucketName_Field {
	if v == nil {
		return ChangeHistory_BucketName_Null()
	}
	return ChangeHistory_BucketName(v)
}

func ChangeHistory_BucketName_Null() ChangeHistory_BucketName_Field {
	return ChangeHistory_BucketName_Field{_set: true, _null: true}
}

func (f ChangeHistory_BucketName_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f ChangeHistory_BucketName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory_ItemType_Field struct {
	_set   bool
	_null  bool
	_value string
}

func ChangeHistory_ItemType(v string) ChangeHistory_ItemType_Field {
	return ChangeHistory_ItemType_Field{_set: true, _value: v}
}

func (f ChangeHistory_ItemType_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory_Operation_Field struct {
	_set   bool
	_null  bool
	_value string
}

func ChangeHistory_Operation(v string) ChangeHistory_Operation_Field {
	return ChangeHistory_Operation_Field{_set: true, _value: v}
}

func (f ChangeHistory_Operation_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory_Reason_Field struct {
	_set   bool
	_null  bool
	_value string
}

func ChangeHistory_Reason(v string) ChangeHistory_Reason_Field {
	return ChangeHistory_Reason_Field{_set: true, _value: v}
}

func (f ChangeHistory_Reason_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory_Changes_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ChangeHistory_Changes(v []byte) ChangeHistory_Changes_Field {
	return ChangeHistory_Changes_Field{_set: true, _value: v}
}

func (f ChangeHistory_Changes_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ChangeHistory_Timestamp_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ChangeHistory_Timestamp(v time.Time) ChangeHistory_Timestamp_Field {
	return ChangeHistory_Timestamp_Field{_set: true, _value: v}
}

func (f ChangeHistory_Timestamp_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type CoinpaymentsTransaction struct {
	Id              string
	UserId          []byte
	Address         string
	AmountNumeric   int64
	ReceivedNumeric int64
	Status          int
	Key             string
	Timeout         int
	CreatedAt       time.Time
}

func (CoinpaymentsTransaction) _Table() string { return "coinpayments_transactions" }

type CoinpaymentsTransaction_Update_Fields struct {
	ReceivedNumeric CoinpaymentsTransaction_ReceivedNumeric_Field
	Status          CoinpaymentsTransaction_Status_Field
}

type CoinpaymentsTransaction_Id_Field struct {
	_set   bool
	_null  bool
	_value string
}

func CoinpaymentsTransaction_Id(v string) CoinpaymentsTransaction_Id_Field {
	return CoinpaymentsTransaction_Id_Field{_set: true, _value: v}
}

func (f CoinpaymentsTransaction_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type CoinpaymentsTransaction_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func CoinpaymentsTransaction_UserId(v []byte) CoinpaymentsTransaction_UserId_Field {
	return CoinpaymentsTransaction_UserId_Field{_set: true, _value: v}
}

func (f CoinpaymentsTransaction_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type CoinpaymentsTransaction_Address_Field struct {
	_set   bool
	_null  bool
	_value string
}

func CoinpaymentsTransaction_Address(v string) CoinpaymentsTransaction_Address_Field {
	return CoinpaymentsTransaction_Address_Field{_set: true, _value: v}
}

func (f CoinpaymentsTransaction_Address_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type CoinpaymentsTransaction_AmountNumeric_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func CoinpaymentsTransaction_AmountNumeric(v int64) CoinpaymentsTransaction_AmountNumeric_Field {
	return CoinpaymentsTransaction_AmountNumeric_Field{_set: true, _value: v}
}

func (f CoinpaymentsTransaction_AmountNumeric_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type CoinpaymentsTransaction_ReceivedNumeric_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func CoinpaymentsTransaction_ReceivedNumeric(v int64) CoinpaymentsTransaction_ReceivedNumeric_Field {
	return CoinpaymentsTransaction_ReceivedNumeric_Field{_set: true, _value: v}
}

func (f CoinpaymentsTransaction_ReceivedNumeric_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type CoinpaymentsTransaction_Status_Field struct {
	_set   bool
	_null  bool
	_value int
}

func CoinpaymentsTransaction_Status(v int) CoinpaymentsTransaction_Status_Field {
	return CoinpaymentsTransaction_Status_Field{_set: true, _value: v}
}

func (f CoinpaymentsTransaction_Status_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type CoinpaymentsTransaction_Key_Field struct {
	_set   bool
	_null  bool
	_value string
}

func CoinpaymentsTransaction_Key(v string) CoinpaymentsTransaction_Key_Field {
	return CoinpaymentsTransaction_Key_Field{_set: true, _value: v}
}

func (f CoinpaymentsTransaction_Key_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type CoinpaymentsTransaction_Timeout_Field struct {
	_set   bool
	_null  bool
	_value int
}

func CoinpaymentsTransaction_Timeout(v int) CoinpaymentsTransaction_Timeout_Field {
	return CoinpaymentsTransaction_Timeout_Field{_set: true, _value: v}
}

func (f CoinpaymentsTransaction_Timeout_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type CoinpaymentsTransaction_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func CoinpaymentsTransaction_CreatedAt(v time.Time) CoinpaymentsTransaction_CreatedAt_Field {
	return CoinpaymentsTransaction_CreatedAt_Field{_set: true, _value: v}
}

func (f CoinpaymentsTransaction_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Entitlement struct {
	Scope     []byte
	Features  []byte
	UpdatedAt time.Time
	CreatedAt time.Time
}

func (Entitlement) _Table() string { return "entitlements" }

type Entitlement_Create_Fields struct {
	Features Entitlement_Features_Field
}

type Entitlement_Update_Fields struct {
	Features  Entitlement_Features_Field
	UpdatedAt Entitlement_UpdatedAt_Field
}

type Entitlement_Scope_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Entitlement_Scope(v []byte) Entitlement_Scope_Field {
	return Entitlement_Scope_Field{_set: true, _value: v}
}

func (f Entitlement_Scope_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Entitlement_Features_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Entitlement_Features(v []byte) Entitlement_Features_Field {
	return Entitlement_Features_Field{_set: true, _value: v}
}

func (f Entitlement_Features_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Entitlement_UpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Entitlement_UpdatedAt(v time.Time) Entitlement_UpdatedAt_Field {
	return Entitlement_UpdatedAt_Field{_set: true, _value: v}
}

func (f Entitlement_UpdatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Entitlement_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Entitlement_CreatedAt(v time.Time) Entitlement_CreatedAt_Field {
	return Entitlement_CreatedAt_Field{_set: true, _value: v}
}

func (f Entitlement_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node struct {
	Id                      []byte
	Address                 string
	LastNet                 string
	LastIpPort              *string
	CountryCode             *string
	Protocol                int
	Email                   string
	Wallet                  string
	WalletFeatures          string
	FreeDisk                int64
	PieceCount              int64
	Major                   int64
	Minor                   int64
	Patch                   int64
	CommitHash              string
	ReleaseTimestamp        time.Time
	Release                 bool
	Latency90               int64
	VettedAt                *time.Time
	CreatedAt               time.Time
	UpdatedAt               time.Time
	LastContactSuccess      time.Time
	LastContactFailure      time.Time
	Disqualified            *time.Time
	DisqualificationReason  *int
	UnknownAuditSuspended   *time.Time
	OfflineSuspended        *time.Time
	UnderReview             *time.Time
	ExitInitiatedAt         *time.Time
	ExitLoopCompletedAt     *time.Time
	ExitFinishedAt          *time.Time
	ExitSuccess             bool
	Contained               *time.Time
	LastOfflineEmail        *time.Time
	LastSoftwareUpdateEmail *time.Time
	NoiseProto              *int
	NoisePublicKey          []byte
	DebounceLimit           int
	Features                int
}

func (Node) _Table() string { return "nodes" }

type Node_Create_Fields struct {
	Address                 Node_Address_Field
	LastIpPort              Node_LastIpPort_Field
	CountryCode             Node_CountryCode_Field
	Protocol                Node_Protocol_Field
	WalletFeatures          Node_WalletFeatures_Field
	FreeDisk                Node_FreeDisk_Field
	Major                   Node_Major_Field
	Minor                   Node_Minor_Field
	Patch                   Node_Patch_Field
	CommitHash              Node_CommitHash_Field
	ReleaseTimestamp        Node_ReleaseTimestamp_Field
	Release                 Node_Release_Field
	Latency90               Node_Latency90_Field
	VettedAt                Node_VettedAt_Field
	LastContactSuccess      Node_LastContactSuccess_Field
	LastContactFailure      Node_LastContactFailure_Field
	Disqualified            Node_Disqualified_Field
	DisqualificationReason  Node_DisqualificationReason_Field
	UnknownAuditSuspended   Node_UnknownAuditSuspended_Field
	OfflineSuspended        Node_OfflineSuspended_Field
	UnderReview             Node_UnderReview_Field
	ExitInitiatedAt         Node_ExitInitiatedAt_Field
	ExitLoopCompletedAt     Node_ExitLoopCompletedAt_Field
	ExitFinishedAt          Node_ExitFinishedAt_Field
	ExitSuccess             Node_ExitSuccess_Field
	Contained               Node_Contained_Field
	LastOfflineEmail        Node_LastOfflineEmail_Field
	LastSoftwareUpdateEmail Node_LastSoftwareUpdateEmail_Field
	NoiseProto              Node_NoiseProto_Field
	NoisePublicKey          Node_NoisePublicKey_Field
	DebounceLimit           Node_DebounceLimit_Field
	Features                Node_Features_Field
}

type Node_Update_Fields struct {
	Address                 Node_Address_Field
	LastNet                 Node_LastNet_Field
	LastIpPort              Node_LastIpPort_Field
	CountryCode             Node_CountryCode_Field
	Protocol                Node_Protocol_Field
	Email                   Node_Email_Field
	Wallet                  Node_Wallet_Field
	WalletFeatures          Node_WalletFeatures_Field
	FreeDisk                Node_FreeDisk_Field
	PieceCount              Node_PieceCount_Field
	Major                   Node_Major_Field
	Minor                   Node_Minor_Field
	Patch                   Node_Patch_Field
	CommitHash              Node_CommitHash_Field
	ReleaseTimestamp        Node_ReleaseTimestamp_Field
	Release                 Node_Release_Field
	Latency90               Node_Latency90_Field
	VettedAt                Node_VettedAt_Field
	LastContactSuccess      Node_LastContactSuccess_Field
	LastContactFailure      Node_LastContactFailure_Field
	Disqualified            Node_Disqualified_Field
	DisqualificationReason  Node_DisqualificationReason_Field
	UnknownAuditSuspended   Node_UnknownAuditSuspended_Field
	OfflineSuspended        Node_OfflineSuspended_Field
	UnderReview             Node_UnderReview_Field
	ExitInitiatedAt         Node_ExitInitiatedAt_Field
	ExitLoopCompletedAt     Node_ExitLoopCompletedAt_Field
	ExitFinishedAt          Node_ExitFinishedAt_Field
	ExitSuccess             Node_ExitSuccess_Field
	Contained               Node_Contained_Field
	LastOfflineEmail        Node_LastOfflineEmail_Field
	LastSoftwareUpdateEmail Node_LastSoftwareUpdateEmail_Field
	NoiseProto              Node_NoiseProto_Field
	NoisePublicKey          Node_NoisePublicKey_Field
	DebounceLimit           Node_DebounceLimit_Field
	Features                Node_Features_Field
}

type Node_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Node_Id(v []byte) Node_Id_Field {
	return Node_Id_Field{_set: true, _value: v}
}

func (f Node_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Address_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Node_Address(v string) Node_Address_Field {
	return Node_Address_Field{_set: true, _value: v}
}

func (f Node_Address_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_LastNet_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Node_LastNet(v string) Node_LastNet_Field {
	return Node_LastNet_Field{_set: true, _value: v}
}

func (f Node_LastNet_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_LastIpPort_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func Node_LastIpPort(v string) Node_LastIpPort_Field {
	return Node_LastIpPort_Field{_set: true, _value: &v}
}

func Node_LastIpPort_Raw(v *string) Node_LastIpPort_Field {
	if v == nil {
		return Node_LastIpPort_Null()
	}
	return Node_LastIpPort(*v)
}

func Node_LastIpPort_Null() Node_LastIpPort_Field {
	return Node_LastIpPort_Field{_set: true, _null: true}
}

func (f Node_LastIpPort_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_LastIpPort_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_CountryCode_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func Node_CountryCode(v string) Node_CountryCode_Field {
	return Node_CountryCode_Field{_set: true, _value: &v}
}

func Node_CountryCode_Raw(v *string) Node_CountryCode_Field {
	if v == nil {
		return Node_CountryCode_Null()
	}
	return Node_CountryCode(*v)
}

func Node_CountryCode_Null() Node_CountryCode_Field {
	return Node_CountryCode_Field{_set: true, _null: true}
}

func (f Node_CountryCode_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_CountryCode_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Protocol_Field struct {
	_set   bool
	_null  bool
	_value int
}

func Node_Protocol(v int) Node_Protocol_Field {
	return Node_Protocol_Field{_set: true, _value: v}
}

func (f Node_Protocol_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Email_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Node_Email(v string) Node_Email_Field {
	return Node_Email_Field{_set: true, _value: v}
}

func (f Node_Email_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Wallet_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Node_Wallet(v string) Node_Wallet_Field {
	return Node_Wallet_Field{_set: true, _value: v}
}

func (f Node_Wallet_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_WalletFeatures_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Node_WalletFeatures(v string) Node_WalletFeatures_Field {
	return Node_WalletFeatures_Field{_set: true, _value: v}
}

func (f Node_WalletFeatures_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_FreeDisk_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_FreeDisk(v int64) Node_FreeDisk_Field {
	return Node_FreeDisk_Field{_set: true, _value: v}
}

func (f Node_FreeDisk_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_PieceCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_PieceCount(v int64) Node_PieceCount_Field {
	return Node_PieceCount_Field{_set: true, _value: v}
}

func (f Node_PieceCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Major_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_Major(v int64) Node_Major_Field {
	return Node_Major_Field{_set: true, _value: v}
}

func (f Node_Major_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Minor_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_Minor(v int64) Node_Minor_Field {
	return Node_Minor_Field{_set: true, _value: v}
}

func (f Node_Minor_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Patch_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_Patch(v int64) Node_Patch_Field {
	return Node_Patch_Field{_set: true, _value: v}
}

func (f Node_Patch_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_CommitHash_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Node_CommitHash(v string) Node_CommitHash_Field {
	return Node_CommitHash_Field{_set: true, _value: v}
}

func (f Node_CommitHash_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_ReleaseTimestamp_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Node_ReleaseTimestamp(v time.Time) Node_ReleaseTimestamp_Field {
	return Node_ReleaseTimestamp_Field{_set: true, _value: v}
}

func (f Node_ReleaseTimestamp_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Release_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func Node_Release(v bool) Node_Release_Field {
	return Node_Release_Field{_set: true, _value: v}
}

func (f Node_Release_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Latency90_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Node_Latency90(v int64) Node_Latency90_Field {
	return Node_Latency90_Field{_set: true, _value: v}
}

func (f Node_Latency90_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_VettedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_VettedAt(v time.Time) Node_VettedAt_Field {
	return Node_VettedAt_Field{_set: true, _value: &v}
}

func Node_VettedAt_Raw(v *time.Time) Node_VettedAt_Field {
	if v == nil {
		return Node_VettedAt_Null()
	}
	return Node_VettedAt(*v)
}

func Node_VettedAt_Null() Node_VettedAt_Field {
	return Node_VettedAt_Field{_set: true, _null: true}
}

func (f Node_VettedAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_VettedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Node_CreatedAt(v time.Time) Node_CreatedAt_Field {
	return Node_CreatedAt_Field{_set: true, _value: v}
}

func (f Node_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_UpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Node_UpdatedAt(v time.Time) Node_UpdatedAt_Field {
	return Node_UpdatedAt_Field{_set: true, _value: v}
}

func (f Node_UpdatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_LastContactSuccess_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Node_LastContactSuccess(v time.Time) Node_LastContactSuccess_Field {
	return Node_LastContactSuccess_Field{_set: true, _value: v}
}

func (f Node_LastContactSuccess_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_LastContactFailure_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Node_LastContactFailure(v time.Time) Node_LastContactFailure_Field {
	return Node_LastContactFailure_Field{_set: true, _value: v}
}

func (f Node_LastContactFailure_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Disqualified_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_Disqualified(v time.Time) Node_Disqualified_Field {
	return Node_Disqualified_Field{_set: true, _value: &v}
}

func Node_Disqualified_Raw(v *time.Time) Node_Disqualified_Field {
	if v == nil {
		return Node_Disqualified_Null()
	}
	return Node_Disqualified(*v)
}

func Node_Disqualified_Null() Node_Disqualified_Field {
	return Node_Disqualified_Field{_set: true, _null: true}
}

func (f Node_Disqualified_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_Disqualified_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_DisqualificationReason_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Node_DisqualificationReason(v int) Node_DisqualificationReason_Field {
	return Node_DisqualificationReason_Field{_set: true, _value: &v}
}

func Node_DisqualificationReason_Raw(v *int) Node_DisqualificationReason_Field {
	if v == nil {
		return Node_DisqualificationReason_Null()
	}
	return Node_DisqualificationReason(*v)
}

func Node_DisqualificationReason_Null() Node_DisqualificationReason_Field {
	return Node_DisqualificationReason_Field{_set: true, _null: true}
}

func (f Node_DisqualificationReason_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f Node_DisqualificationReason_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_UnknownAuditSuspended_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_UnknownAuditSuspended(v time.Time) Node_UnknownAuditSuspended_Field {
	return Node_UnknownAuditSuspended_Field{_set: true, _value: &v}
}

func Node_UnknownAuditSuspended_Raw(v *time.Time) Node_UnknownAuditSuspended_Field {
	if v == nil {
		return Node_UnknownAuditSuspended_Null()
	}
	return Node_UnknownAuditSuspended(*v)
}

func Node_UnknownAuditSuspended_Null() Node_UnknownAuditSuspended_Field {
	return Node_UnknownAuditSuspended_Field{_set: true, _null: true}
}

func (f Node_UnknownAuditSuspended_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_UnknownAuditSuspended_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_OfflineSuspended_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_OfflineSuspended(v time.Time) Node_OfflineSuspended_Field {
	return Node_OfflineSuspended_Field{_set: true, _value: &v}
}

func Node_OfflineSuspended_Raw(v *time.Time) Node_OfflineSuspended_Field {
	if v == nil {
		return Node_OfflineSuspended_Null()
	}
	return Node_OfflineSuspended(*v)
}

func Node_OfflineSuspended_Null() Node_OfflineSuspended_Field {
	return Node_OfflineSuspended_Field{_set: true, _null: true}
}

func (f Node_OfflineSuspended_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_OfflineSuspended_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_UnderReview_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_UnderReview(v time.Time) Node_UnderReview_Field {
	return Node_UnderReview_Field{_set: true, _value: &v}
}

func Node_UnderReview_Raw(v *time.Time) Node_UnderReview_Field {
	if v == nil {
		return Node_UnderReview_Null()
	}
	return Node_UnderReview(*v)
}

func Node_UnderReview_Null() Node_UnderReview_Field {
	return Node_UnderReview_Field{_set: true, _null: true}
}

func (f Node_UnderReview_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_UnderReview_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_ExitInitiatedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_ExitInitiatedAt(v time.Time) Node_ExitInitiatedAt_Field {
	return Node_ExitInitiatedAt_Field{_set: true, _value: &v}
}

func Node_ExitInitiatedAt_Raw(v *time.Time) Node_ExitInitiatedAt_Field {
	if v == nil {
		return Node_ExitInitiatedAt_Null()
	}
	return Node_ExitInitiatedAt(*v)
}

func Node_ExitInitiatedAt_Null() Node_ExitInitiatedAt_Field {
	return Node_ExitInitiatedAt_Field{_set: true, _null: true}
}

func (f Node_ExitInitiatedAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_ExitInitiatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_ExitLoopCompletedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_ExitLoopCompletedAt(v time.Time) Node_ExitLoopCompletedAt_Field {
	return Node_ExitLoopCompletedAt_Field{_set: true, _value: &v}
}

func Node_ExitLoopCompletedAt_Raw(v *time.Time) Node_ExitLoopCompletedAt_Field {
	if v == nil {
		return Node_ExitLoopCompletedAt_Null()
	}
	return Node_ExitLoopCompletedAt(*v)
}

func Node_ExitLoopCompletedAt_Null() Node_ExitLoopCompletedAt_Field {
	return Node_ExitLoopCompletedAt_Field{_set: true, _null: true}
}

func (f Node_ExitLoopCompletedAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_ExitLoopCompletedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_ExitFinishedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_ExitFinishedAt(v time.Time) Node_ExitFinishedAt_Field {
	return Node_ExitFinishedAt_Field{_set: true, _value: &v}
}

func Node_ExitFinishedAt_Raw(v *time.Time) Node_ExitFinishedAt_Field {
	if v == nil {
		return Node_ExitFinishedAt_Null()
	}
	return Node_ExitFinishedAt(*v)
}

func Node_ExitFinishedAt_Null() Node_ExitFinishedAt_Field {
	return Node_ExitFinishedAt_Field{_set: true, _null: true}
}

func (f Node_ExitFinishedAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_ExitFinishedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_ExitSuccess_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func Node_ExitSuccess(v bool) Node_ExitSuccess_Field {
	return Node_ExitSuccess_Field{_set: true, _value: v}
}

func (f Node_ExitSuccess_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Contained_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_Contained(v time.Time) Node_Contained_Field {
	return Node_Contained_Field{_set: true, _value: &v}
}

func Node_Contained_Raw(v *time.Time) Node_Contained_Field {
	if v == nil {
		return Node_Contained_Null()
	}
	return Node_Contained(*v)
}

func Node_Contained_Null() Node_Contained_Field {
	return Node_Contained_Field{_set: true, _null: true}
}

func (f Node_Contained_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_Contained_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_LastOfflineEmail_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_LastOfflineEmail(v time.Time) Node_LastOfflineEmail_Field {
	return Node_LastOfflineEmail_Field{_set: true, _value: &v}
}

func Node_LastOfflineEmail_Raw(v *time.Time) Node_LastOfflineEmail_Field {
	if v == nil {
		return Node_LastOfflineEmail_Null()
	}
	return Node_LastOfflineEmail(*v)
}

func Node_LastOfflineEmail_Null() Node_LastOfflineEmail_Field {
	return Node_LastOfflineEmail_Field{_set: true, _null: true}
}

func (f Node_LastOfflineEmail_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_LastOfflineEmail_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_LastSoftwareUpdateEmail_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Node_LastSoftwareUpdateEmail(v time.Time) Node_LastSoftwareUpdateEmail_Field {
	return Node_LastSoftwareUpdateEmail_Field{_set: true, _value: &v}
}

func Node_LastSoftwareUpdateEmail_Raw(v *time.Time) Node_LastSoftwareUpdateEmail_Field {
	if v == nil {
		return Node_LastSoftwareUpdateEmail_Null()
	}
	return Node_LastSoftwareUpdateEmail(*v)
}

func Node_LastSoftwareUpdateEmail_Null() Node_LastSoftwareUpdateEmail_Field {
	return Node_LastSoftwareUpdateEmail_Field{_set: true, _null: true}
}

func (f Node_LastSoftwareUpdateEmail_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f Node_LastSoftwareUpdateEmail_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_NoiseProto_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Node_NoiseProto(v int) Node_NoiseProto_Field {
	return Node_NoiseProto_Field{_set: true, _value: &v}
}

func Node_NoiseProto_Raw(v *int) Node_NoiseProto_Field {
	if v == nil {
		return Node_NoiseProto_Null()
	}
	return Node_NoiseProto(*v)
}

func Node_NoiseProto_Null() Node_NoiseProto_Field {
	return Node_NoiseProto_Field{_set: true, _null: true}
}

func (f Node_NoiseProto_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_NoiseProto_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_NoisePublicKey_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Node_NoisePublicKey(v []byte) Node_NoisePublicKey_Field {
	return Node_NoisePublicKey_Field{_set: true, _value: v}
}

func Node_NoisePublicKey_Raw(v []byte) Node_NoisePublicKey_Field {
	if v == nil {
		return Node_NoisePublicKey_Null()
	}
	return Node_NoisePublicKey(v)
}

func Node_NoisePublicKey_Null() Node_NoisePublicKey_Field {
	return Node_NoisePublicKey_Field{_set: true, _null: true}
}

func (f Node_NoisePublicKey_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Node_NoisePublicKey_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_DebounceLimit_Field struct {
	_set   bool
	_null  bool
	_value int
}

func Node_DebounceLimit(v int) Node_DebounceLimit_Field {
	return Node_DebounceLimit_Field{_set: true, _value: v}
}

func (f Node_DebounceLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Node_Features_Field struct {
	_set   bool
	_null  bool
	_value int
}

func Node_Features(v int) Node_Features_Field {
	return Node_Features_Field{_set: true, _value: v}
}

func (f Node_Features_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeApiVersion struct {
	Id         []byte
	ApiVersion int
	CreatedAt  time.Time
	UpdatedAt  time.Time
}

func (NodeApiVersion) _Table() string { return "node_api_versions" }

type NodeApiVersion_Update_Fields struct {
	ApiVersion NodeApiVersion_ApiVersion_Field
}

type NodeApiVersion_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func NodeApiVersion_Id(v []byte) NodeApiVersion_Id_Field {
	return NodeApiVersion_Id_Field{_set: true, _value: v}
}

func (f NodeApiVersion_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeApiVersion_ApiVersion_Field struct {
	_set   bool
	_null  bool
	_value int
}

func NodeApiVersion_ApiVersion(v int) NodeApiVersion_ApiVersion_Field {
	return NodeApiVersion_ApiVersion_Field{_set: true, _value: v}
}

func (f NodeApiVersion_ApiVersion_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeApiVersion_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func NodeApiVersion_CreatedAt(v time.Time) NodeApiVersion_CreatedAt_Field {
	return NodeApiVersion_CreatedAt_Field{_set: true, _value: v}
}

func (f NodeApiVersion_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeApiVersion_UpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func NodeApiVersion_UpdatedAt(v time.Time) NodeApiVersion_UpdatedAt_Field {
	return NodeApiVersion_UpdatedAt_Field{_set: true, _value: v}
}

func (f NodeApiVersion_UpdatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeEvent struct {
	Id            []byte
	Email         string
	LastIpPort    *string
	NodeId        []byte
	Event         int
	CreatedAt     time.Time
	LastAttempted *time.Time
	EmailSent     *time.Time
}

func (NodeEvent) _Table() string { return "node_events" }

type NodeEvent_Create_Fields struct {
	LastIpPort    NodeEvent_LastIpPort_Field
	CreatedAt     NodeEvent_CreatedAt_Field
	LastAttempted NodeEvent_LastAttempted_Field
	EmailSent     NodeEvent_EmailSent_Field
}

type NodeEvent_Update_Fields struct {
	LastAttempted NodeEvent_LastAttempted_Field
	EmailSent     NodeEvent_EmailSent_Field
}

type NodeEvent_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func NodeEvent_Id(v []byte) NodeEvent_Id_Field {
	return NodeEvent_Id_Field{_set: true, _value: v}
}

func (f NodeEvent_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeEvent_Email_Field struct {
	_set   bool
	_null  bool
	_value string
}

func NodeEvent_Email(v string) NodeEvent_Email_Field {
	return NodeEvent_Email_Field{_set: true, _value: v}
}

func (f NodeEvent_Email_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeEvent_LastIpPort_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func NodeEvent_LastIpPort(v string) NodeEvent_LastIpPort_Field {
	return NodeEvent_LastIpPort_Field{_set: true, _value: &v}
}

func NodeEvent_LastIpPort_Raw(v *string) NodeEvent_LastIpPort_Field {
	if v == nil {
		return NodeEvent_LastIpPort_Null()
	}
	return NodeEvent_LastIpPort(*v)
}

func NodeEvent_LastIpPort_Null() NodeEvent_LastIpPort_Field {
	return NodeEvent_LastIpPort_Field{_set: true, _null: true}
}

func (f NodeEvent_LastIpPort_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f NodeEvent_LastIpPort_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeEvent_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func NodeEvent_NodeId(v []byte) NodeEvent_NodeId_Field {
	return NodeEvent_NodeId_Field{_set: true, _value: v}
}

func (f NodeEvent_NodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeEvent_Event_Field struct {
	_set   bool
	_null  bool
	_value int
}

func NodeEvent_Event(v int) NodeEvent_Event_Field {
	return NodeEvent_Event_Field{_set: true, _value: v}
}

func (f NodeEvent_Event_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeEvent_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func NodeEvent_CreatedAt(v time.Time) NodeEvent_CreatedAt_Field {
	return NodeEvent_CreatedAt_Field{_set: true, _value: v}
}

func (f NodeEvent_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeEvent_LastAttempted_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func NodeEvent_LastAttempted(v time.Time) NodeEvent_LastAttempted_Field {
	return NodeEvent_LastAttempted_Field{_set: true, _value: &v}
}

func NodeEvent_LastAttempted_Raw(v *time.Time) NodeEvent_LastAttempted_Field {
	if v == nil {
		return NodeEvent_LastAttempted_Null()
	}
	return NodeEvent_LastAttempted(*v)
}

func NodeEvent_LastAttempted_Null() NodeEvent_LastAttempted_Field {
	return NodeEvent_LastAttempted_Field{_set: true, _null: true}
}

func (f NodeEvent_LastAttempted_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f NodeEvent_LastAttempted_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeEvent_EmailSent_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func NodeEvent_EmailSent(v time.Time) NodeEvent_EmailSent_Field {
	return NodeEvent_EmailSent_Field{_set: true, _value: &v}
}

func NodeEvent_EmailSent_Raw(v *time.Time) NodeEvent_EmailSent_Field {
	if v == nil {
		return NodeEvent_EmailSent_Null()
	}
	return NodeEvent_EmailSent(*v)
}

func NodeEvent_EmailSent_Null() NodeEvent_EmailSent_Field {
	return NodeEvent_EmailSent_Field{_set: true, _null: true}
}

func (f NodeEvent_EmailSent_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f NodeEvent_EmailSent_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeTags struct {
	NodeId   []byte
	Name     string
	Value    []byte
	SignedAt time.Time
	Signer   []byte
}

func (NodeTags) _Table() string { return "node_tags" }

type NodeTags_Update_Fields struct {
}

type NodeTags_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func NodeTags_NodeId(v []byte) NodeTags_NodeId_Field {
	return NodeTags_NodeId_Field{_set: true, _value: v}
}

func (f NodeTags_NodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeTags_Name_Field struct {
	_set   bool
	_null  bool
	_value string
}

func NodeTags_Name(v string) NodeTags_Name_Field {
	return NodeTags_Name_Field{_set: true, _value: v}
}

func (f NodeTags_Name_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeTags_Value_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func NodeTags_Value(v []byte) NodeTags_Value_Field {
	return NodeTags_Value_Field{_set: true, _value: v}
}

func (f NodeTags_Value_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeTags_SignedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func NodeTags_SignedAt(v time.Time) NodeTags_SignedAt_Field {
	return NodeTags_SignedAt_Field{_set: true, _value: v}
}

func (f NodeTags_SignedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type NodeTags_Signer_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func NodeTags_Signer(v []byte) NodeTags_Signer_Field {
	return NodeTags_Signer_Field{_set: true, _value: v}
}

func (f NodeTags_Signer_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthClient struct {
	Id              []byte
	EncryptedSecret []byte
	RedirectUrl     string
	UserId          []byte
	AppName         string
	AppLogoUrl      string
}

func (OauthClient) _Table() string { return "oauth_clients" }

type OauthClient_Update_Fields struct {
	EncryptedSecret OauthClient_EncryptedSecret_Field
	RedirectUrl     OauthClient_RedirectUrl_Field
	AppName         OauthClient_AppName_Field
	AppLogoUrl      OauthClient_AppLogoUrl_Field
}

type OauthClient_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func OauthClient_Id(v []byte) OauthClient_Id_Field {
	return OauthClient_Id_Field{_set: true, _value: v}
}

func (f OauthClient_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthClient_EncryptedSecret_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func OauthClient_EncryptedSecret(v []byte) OauthClient_EncryptedSecret_Field {
	return OauthClient_EncryptedSecret_Field{_set: true, _value: v}
}

func (f OauthClient_EncryptedSecret_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthClient_RedirectUrl_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OauthClient_RedirectUrl(v string) OauthClient_RedirectUrl_Field {
	return OauthClient_RedirectUrl_Field{_set: true, _value: v}
}

func (f OauthClient_RedirectUrl_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthClient_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func OauthClient_UserId(v []byte) OauthClient_UserId_Field {
	return OauthClient_UserId_Field{_set: true, _value: v}
}

func (f OauthClient_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthClient_AppName_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OauthClient_AppName(v string) OauthClient_AppName_Field {
	return OauthClient_AppName_Field{_set: true, _value: v}
}

func (f OauthClient_AppName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthClient_AppLogoUrl_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OauthClient_AppLogoUrl(v string) OauthClient_AppLogoUrl_Field {
	return OauthClient_AppLogoUrl_Field{_set: true, _value: v}
}

func (f OauthClient_AppLogoUrl_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode struct {
	ClientId        []byte
	UserId          []byte
	Scope           string
	RedirectUrl     string
	Challenge       string
	ChallengeMethod string
	Code            string
	CreatedAt       time.Time
	ExpiresAt       time.Time
	ClaimedAt       *time.Time
}

func (OauthCode) _Table() string { return "oauth_codes" }

type OauthCode_Create_Fields struct {
	ClaimedAt OauthCode_ClaimedAt_Field
}

type OauthCode_Update_Fields struct {
	ClaimedAt OauthCode_ClaimedAt_Field
}

type OauthCode_ClientId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func OauthCode_ClientId(v []byte) OauthCode_ClientId_Field {
	return OauthCode_ClientId_Field{_set: true, _value: v}
}

func (f OauthCode_ClientId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func OauthCode_UserId(v []byte) OauthCode_UserId_Field {
	return OauthCode_UserId_Field{_set: true, _value: v}
}

func (f OauthCode_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode_Scope_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OauthCode_Scope(v string) OauthCode_Scope_Field {
	return OauthCode_Scope_Field{_set: true, _value: v}
}

func (f OauthCode_Scope_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode_RedirectUrl_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OauthCode_RedirectUrl(v string) OauthCode_RedirectUrl_Field {
	return OauthCode_RedirectUrl_Field{_set: true, _value: v}
}

func (f OauthCode_RedirectUrl_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode_Challenge_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OauthCode_Challenge(v string) OauthCode_Challenge_Field {
	return OauthCode_Challenge_Field{_set: true, _value: v}
}

func (f OauthCode_Challenge_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode_ChallengeMethod_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OauthCode_ChallengeMethod(v string) OauthCode_ChallengeMethod_Field {
	return OauthCode_ChallengeMethod_Field{_set: true, _value: v}
}

func (f OauthCode_ChallengeMethod_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode_Code_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OauthCode_Code(v string) OauthCode_Code_Field {
	return OauthCode_Code_Field{_set: true, _value: v}
}

func (f OauthCode_Code_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func OauthCode_CreatedAt(v time.Time) OauthCode_CreatedAt_Field {
	return OauthCode_CreatedAt_Field{_set: true, _value: v}
}

func (f OauthCode_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode_ExpiresAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func OauthCode_ExpiresAt(v time.Time) OauthCode_ExpiresAt_Field {
	return OauthCode_ExpiresAt_Field{_set: true, _value: v}
}

func (f OauthCode_ExpiresAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthCode_ClaimedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func OauthCode_ClaimedAt(v time.Time) OauthCode_ClaimedAt_Field {
	return OauthCode_ClaimedAt_Field{_set: true, _value: &v}
}

func OauthCode_ClaimedAt_Raw(v *time.Time) OauthCode_ClaimedAt_Field {
	if v == nil {
		return OauthCode_ClaimedAt_Null()
	}
	return OauthCode_ClaimedAt(*v)
}

func OauthCode_ClaimedAt_Null() OauthCode_ClaimedAt_Field {
	return OauthCode_ClaimedAt_Field{_set: true, _null: true}
}

func (f OauthCode_ClaimedAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f OauthCode_ClaimedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthToken struct {
	ClientId  []byte
	UserId    []byte
	Scope     string
	Kind      int
	Token     []byte
	CreatedAt time.Time
	ExpiresAt time.Time
}

func (OauthToken) _Table() string { return "oauth_tokens" }

type OauthToken_Update_Fields struct {
	ExpiresAt OauthToken_ExpiresAt_Field
}

type OauthToken_ClientId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func OauthToken_ClientId(v []byte) OauthToken_ClientId_Field {
	return OauthToken_ClientId_Field{_set: true, _value: v}
}

func (f OauthToken_ClientId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthToken_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func OauthToken_UserId(v []byte) OauthToken_UserId_Field {
	return OauthToken_UserId_Field{_set: true, _value: v}
}

func (f OauthToken_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthToken_Scope_Field struct {
	_set   bool
	_null  bool
	_value string
}

func OauthToken_Scope(v string) OauthToken_Scope_Field {
	return OauthToken_Scope_Field{_set: true, _value: v}
}

func (f OauthToken_Scope_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthToken_Kind_Field struct {
	_set   bool
	_null  bool
	_value int
}

func OauthToken_Kind(v int) OauthToken_Kind_Field {
	return OauthToken_Kind_Field{_set: true, _value: v}
}

func (f OauthToken_Kind_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthToken_Token_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func OauthToken_Token(v []byte) OauthToken_Token_Field {
	return OauthToken_Token_Field{_set: true, _value: v}
}

func (f OauthToken_Token_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthToken_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func OauthToken_CreatedAt(v time.Time) OauthToken_CreatedAt_Field {
	return OauthToken_CreatedAt_Field{_set: true, _value: v}
}

func (f OauthToken_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type OauthToken_ExpiresAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func OauthToken_ExpiresAt(v time.Time) OauthToken_ExpiresAt_Field {
	return OauthToken_ExpiresAt_Field{_set: true, _value: v}
}

func (f OauthToken_ExpiresAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type PeerIdentity struct {
	NodeId           []byte
	LeafSerialNumber []byte
	Chain            []byte
	UpdatedAt        time.Time
}

func (PeerIdentity) _Table() string { return "peer_identities" }

type PeerIdentity_Update_Fields struct {
	LeafSerialNumber PeerIdentity_LeafSerialNumber_Field
	Chain            PeerIdentity_Chain_Field
}

type PeerIdentity_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func PeerIdentity_NodeId(v []byte) PeerIdentity_NodeId_Field {
	return PeerIdentity_NodeId_Field{_set: true, _value: v}
}

func (f PeerIdentity_NodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type PeerIdentity_LeafSerialNumber_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func PeerIdentity_LeafSerialNumber(v []byte) PeerIdentity_LeafSerialNumber_Field {
	return PeerIdentity_LeafSerialNumber_Field{_set: true, _value: v}
}

func (f PeerIdentity_LeafSerialNumber_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type PeerIdentity_Chain_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func PeerIdentity_Chain(v []byte) PeerIdentity_Chain_Field {
	return PeerIdentity_Chain_Field{_set: true, _value: v}
}

func (f PeerIdentity_Chain_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type PeerIdentity_UpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func PeerIdentity_UpdatedAt(v time.Time) PeerIdentity_UpdatedAt_Field {
	return PeerIdentity_UpdatedAt_Field{_set: true, _value: v}
}

func (f PeerIdentity_UpdatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project struct {
	Id                          []byte
	PublicId                    []byte
	Name                        string
	Description                 string
	UsageLimit                  *int64
	BandwidthLimit              *int64
	UserSpecifiedUsageLimit     *int64
	UserSpecifiedBandwidthLimit *int64
	SegmentLimit                *int64
	RateLimit                   *int
	BurstLimit                  *int
	RateLimitHead               *int
	BurstLimitHead              *int
	RateLimitGet                *int
	BurstLimitGet               *int
	RateLimitPut                *int
	BurstLimitPut               *int
	RateLimitList               *int
	BurstLimitList              *int
	RateLimitDel                *int
	BurstLimitDel               *int
	MaxBuckets                  *int
	UserAgent                   []byte
	OwnerId                     []byte
	Salt                        []byte
	Status                      *int
	StatusUpdatedAt             *time.Time
	CreatedAt                   time.Time
	DefaultPlacement            *int
	DefaultVersioning           int
	PromptedForVersioningBeta   bool
	PassphraseEnc               []byte
	PassphraseEncKeyId          *int
	PathEncryption              bool
}

func (Project) _Table() string { return "projects" }

type Project_Create_Fields struct {
	PublicId                    Project_PublicId_Field
	UsageLimit                  Project_UsageLimit_Field
	BandwidthLimit              Project_BandwidthLimit_Field
	UserSpecifiedUsageLimit     Project_UserSpecifiedUsageLimit_Field
	UserSpecifiedBandwidthLimit Project_UserSpecifiedBandwidthLimit_Field
	SegmentLimit                Project_SegmentLimit_Field
	RateLimit                   Project_RateLimit_Field
	BurstLimit                  Project_BurstLimit_Field
	RateLimitHead               Project_RateLimitHead_Field
	BurstLimitHead              Project_BurstLimitHead_Field
	RateLimitGet                Project_RateLimitGet_Field
	BurstLimitGet               Project_BurstLimitGet_Field
	RateLimitPut                Project_RateLimitPut_Field
	BurstLimitPut               Project_BurstLimitPut_Field
	RateLimitList               Project_RateLimitList_Field
	BurstLimitList              Project_BurstLimitList_Field
	RateLimitDel                Project_RateLimitDel_Field
	BurstLimitDel               Project_BurstLimitDel_Field
	MaxBuckets                  Project_MaxBuckets_Field
	UserAgent                   Project_UserAgent_Field
	Salt                        Project_Salt_Field
	Status                      Project_Status_Field
	StatusUpdatedAt             Project_StatusUpdatedAt_Field
	DefaultPlacement            Project_DefaultPlacement_Field
	DefaultVersioning           Project_DefaultVersioning_Field
	PromptedForVersioningBeta   Project_PromptedForVersioningBeta_Field
	PassphraseEnc               Project_PassphraseEnc_Field
	PassphraseEncKeyId          Project_PassphraseEncKeyId_Field
	PathEncryption              Project_PathEncryption_Field
}

type Project_Update_Fields struct {
	Name                        Project_Name_Field
	Description                 Project_Description_Field
	UsageLimit                  Project_UsageLimit_Field
	BandwidthLimit              Project_BandwidthLimit_Field
	UserSpecifiedUsageLimit     Project_UserSpecifiedUsageLimit_Field
	UserSpecifiedBandwidthLimit Project_UserSpecifiedBandwidthLimit_Field
	SegmentLimit                Project_SegmentLimit_Field
	RateLimit                   Project_RateLimit_Field
	BurstLimit                  Project_BurstLimit_Field
	RateLimitHead               Project_RateLimitHead_Field
	BurstLimitHead              Project_BurstLimitHead_Field
	RateLimitGet                Project_RateLimitGet_Field
	BurstLimitGet               Project_BurstLimitGet_Field
	RateLimitPut                Project_RateLimitPut_Field
	BurstLimitPut               Project_BurstLimitPut_Field
	RateLimitList               Project_RateLimitList_Field
	BurstLimitList              Project_BurstLimitList_Field
	RateLimitDel                Project_RateLimitDel_Field
	BurstLimitDel               Project_BurstLimitDel_Field
	MaxBuckets                  Project_MaxBuckets_Field
	UserAgent                   Project_UserAgent_Field
	Status                      Project_Status_Field
	StatusUpdatedAt             Project_StatusUpdatedAt_Field
	DefaultPlacement            Project_DefaultPlacement_Field
	DefaultVersioning           Project_DefaultVersioning_Field
	PromptedForVersioningBeta   Project_PromptedForVersioningBeta_Field
	PassphraseEnc               Project_PassphraseEnc_Field
	PassphraseEncKeyId          Project_PassphraseEncKeyId_Field
	PathEncryption              Project_PathEncryption_Field
}

type Project_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Project_Id(v []byte) Project_Id_Field {
	return Project_Id_Field{_set: true, _value: v}
}

func (f Project_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_PublicId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Project_PublicId(v []byte) Project_PublicId_Field {
	return Project_PublicId_Field{_set: true, _value: v}
}

func Project_PublicId_Raw(v []byte) Project_PublicId_Field {
	if v == nil {
		return Project_PublicId_Null()
	}
	return Project_PublicId(v)
}

func Project_PublicId_Null() Project_PublicId_Field {
	return Project_PublicId_Field{_set: true, _null: true}
}

func (f Project_PublicId_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_PublicId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_Name_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Project_Name(v string) Project_Name_Field {
	return Project_Name_Field{_set: true, _value: v}
}

func (f Project_Name_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_Description_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Project_Description(v string) Project_Description_Field {
	return Project_Description_Field{_set: true, _value: v}
}

func (f Project_Description_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_UsageLimit_Field struct {
	_set   bool
	_null  bool
	_value *int64
}

func Project_UsageLimit(v int64) Project_UsageLimit_Field {
	return Project_UsageLimit_Field{_set: true, _value: &v}
}

func Project_UsageLimit_Raw(v *int64) Project_UsageLimit_Field {
	if v == nil {
		return Project_UsageLimit_Null()
	}
	return Project_UsageLimit(*v)
}

func Project_UsageLimit_Null() Project_UsageLimit_Field {
	return Project_UsageLimit_Field{_set: true, _null: true}
}

func (f Project_UsageLimit_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_UsageLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_BandwidthLimit_Field struct {
	_set   bool
	_null  bool
	_value *int64
}

func Project_BandwidthLimit(v int64) Project_BandwidthLimit_Field {
	return Project_BandwidthLimit_Field{_set: true, _value: &v}
}

func Project_BandwidthLimit_Raw(v *int64) Project_BandwidthLimit_Field {
	if v == nil {
		return Project_BandwidthLimit_Null()
	}
	return Project_BandwidthLimit(*v)
}

func Project_BandwidthLimit_Null() Project_BandwidthLimit_Field {
	return Project_BandwidthLimit_Field{_set: true, _null: true}
}

func (f Project_BandwidthLimit_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_BandwidthLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_UserSpecifiedUsageLimit_Field struct {
	_set   bool
	_null  bool
	_value *int64
}

func Project_UserSpecifiedUsageLimit(v int64) Project_UserSpecifiedUsageLimit_Field {
	return Project_UserSpecifiedUsageLimit_Field{_set: true, _value: &v}
}

func Project_UserSpecifiedUsageLimit_Raw(v *int64) Project_UserSpecifiedUsageLimit_Field {
	if v == nil {
		return Project_UserSpecifiedUsageLimit_Null()
	}
	return Project_UserSpecifiedUsageLimit(*v)
}

func Project_UserSpecifiedUsageLimit_Null() Project_UserSpecifiedUsageLimit_Field {
	return Project_UserSpecifiedUsageLimit_Field{_set: true, _null: true}
}

func (f Project_UserSpecifiedUsageLimit_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f Project_UserSpecifiedUsageLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_UserSpecifiedBandwidthLimit_Field struct {
	_set   bool
	_null  bool
	_value *int64
}

func Project_UserSpecifiedBandwidthLimit(v int64) Project_UserSpecifiedBandwidthLimit_Field {
	return Project_UserSpecifiedBandwidthLimit_Field{_set: true, _value: &v}
}

func Project_UserSpecifiedBandwidthLimit_Raw(v *int64) Project_UserSpecifiedBandwidthLimit_Field {
	if v == nil {
		return Project_UserSpecifiedBandwidthLimit_Null()
	}
	return Project_UserSpecifiedBandwidthLimit(*v)
}

func Project_UserSpecifiedBandwidthLimit_Null() Project_UserSpecifiedBandwidthLimit_Field {
	return Project_UserSpecifiedBandwidthLimit_Field{_set: true, _null: true}
}

func (f Project_UserSpecifiedBandwidthLimit_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f Project_UserSpecifiedBandwidthLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_SegmentLimit_Field struct {
	_set   bool
	_null  bool
	_value *int64
}

func Project_SegmentLimit(v int64) Project_SegmentLimit_Field {
	return Project_SegmentLimit_Field{_set: true, _value: &v}
}

func Project_SegmentLimit_Raw(v *int64) Project_SegmentLimit_Field {
	if v == nil {
		return Project_SegmentLimit_Null()
	}
	return Project_SegmentLimit(*v)
}

func Project_SegmentLimit_Null() Project_SegmentLimit_Field {
	return Project_SegmentLimit_Field{_set: true, _null: true}
}

func (f Project_SegmentLimit_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_SegmentLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_RateLimit_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_RateLimit(v int) Project_RateLimit_Field {
	return Project_RateLimit_Field{_set: true, _value: &v}
}

func Project_RateLimit_Raw(v *int) Project_RateLimit_Field {
	if v == nil {
		return Project_RateLimit_Null()
	}
	return Project_RateLimit(*v)
}

func Project_RateLimit_Null() Project_RateLimit_Field {
	return Project_RateLimit_Field{_set: true, _null: true}
}

func (f Project_RateLimit_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_RateLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_BurstLimit_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_BurstLimit(v int) Project_BurstLimit_Field {
	return Project_BurstLimit_Field{_set: true, _value: &v}
}

func Project_BurstLimit_Raw(v *int) Project_BurstLimit_Field {
	if v == nil {
		return Project_BurstLimit_Null()
	}
	return Project_BurstLimit(*v)
}

func Project_BurstLimit_Null() Project_BurstLimit_Field {
	return Project_BurstLimit_Field{_set: true, _null: true}
}

func (f Project_BurstLimit_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_BurstLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_RateLimitHead_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_RateLimitHead(v int) Project_RateLimitHead_Field {
	return Project_RateLimitHead_Field{_set: true, _value: &v}
}

func Project_RateLimitHead_Raw(v *int) Project_RateLimitHead_Field {
	if v == nil {
		return Project_RateLimitHead_Null()
	}
	return Project_RateLimitHead(*v)
}

func Project_RateLimitHead_Null() Project_RateLimitHead_Field {
	return Project_RateLimitHead_Field{_set: true, _null: true}
}

func (f Project_RateLimitHead_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_RateLimitHead_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_BurstLimitHead_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_BurstLimitHead(v int) Project_BurstLimitHead_Field {
	return Project_BurstLimitHead_Field{_set: true, _value: &v}
}

func Project_BurstLimitHead_Raw(v *int) Project_BurstLimitHead_Field {
	if v == nil {
		return Project_BurstLimitHead_Null()
	}
	return Project_BurstLimitHead(*v)
}

func Project_BurstLimitHead_Null() Project_BurstLimitHead_Field {
	return Project_BurstLimitHead_Field{_set: true, _null: true}
}

func (f Project_BurstLimitHead_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_BurstLimitHead_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_RateLimitGet_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_RateLimitGet(v int) Project_RateLimitGet_Field {
	return Project_RateLimitGet_Field{_set: true, _value: &v}
}

func Project_RateLimitGet_Raw(v *int) Project_RateLimitGet_Field {
	if v == nil {
		return Project_RateLimitGet_Null()
	}
	return Project_RateLimitGet(*v)
}

func Project_RateLimitGet_Null() Project_RateLimitGet_Field {
	return Project_RateLimitGet_Field{_set: true, _null: true}
}

func (f Project_RateLimitGet_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_RateLimitGet_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_BurstLimitGet_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_BurstLimitGet(v int) Project_BurstLimitGet_Field {
	return Project_BurstLimitGet_Field{_set: true, _value: &v}
}

func Project_BurstLimitGet_Raw(v *int) Project_BurstLimitGet_Field {
	if v == nil {
		return Project_BurstLimitGet_Null()
	}
	return Project_BurstLimitGet(*v)
}

func Project_BurstLimitGet_Null() Project_BurstLimitGet_Field {
	return Project_BurstLimitGet_Field{_set: true, _null: true}
}

func (f Project_BurstLimitGet_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_BurstLimitGet_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_RateLimitPut_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_RateLimitPut(v int) Project_RateLimitPut_Field {
	return Project_RateLimitPut_Field{_set: true, _value: &v}
}

func Project_RateLimitPut_Raw(v *int) Project_RateLimitPut_Field {
	if v == nil {
		return Project_RateLimitPut_Null()
	}
	return Project_RateLimitPut(*v)
}

func Project_RateLimitPut_Null() Project_RateLimitPut_Field {
	return Project_RateLimitPut_Field{_set: true, _null: true}
}

func (f Project_RateLimitPut_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_RateLimitPut_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_BurstLimitPut_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_BurstLimitPut(v int) Project_BurstLimitPut_Field {
	return Project_BurstLimitPut_Field{_set: true, _value: &v}
}

func Project_BurstLimitPut_Raw(v *int) Project_BurstLimitPut_Field {
	if v == nil {
		return Project_BurstLimitPut_Null()
	}
	return Project_BurstLimitPut(*v)
}

func Project_BurstLimitPut_Null() Project_BurstLimitPut_Field {
	return Project_BurstLimitPut_Field{_set: true, _null: true}
}

func (f Project_BurstLimitPut_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_BurstLimitPut_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_RateLimitList_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_RateLimitList(v int) Project_RateLimitList_Field {
	return Project_RateLimitList_Field{_set: true, _value: &v}
}

func Project_RateLimitList_Raw(v *int) Project_RateLimitList_Field {
	if v == nil {
		return Project_RateLimitList_Null()
	}
	return Project_RateLimitList(*v)
}

func Project_RateLimitList_Null() Project_RateLimitList_Field {
	return Project_RateLimitList_Field{_set: true, _null: true}
}

func (f Project_RateLimitList_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_RateLimitList_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_BurstLimitList_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_BurstLimitList(v int) Project_BurstLimitList_Field {
	return Project_BurstLimitList_Field{_set: true, _value: &v}
}

func Project_BurstLimitList_Raw(v *int) Project_BurstLimitList_Field {
	if v == nil {
		return Project_BurstLimitList_Null()
	}
	return Project_BurstLimitList(*v)
}

func Project_BurstLimitList_Null() Project_BurstLimitList_Field {
	return Project_BurstLimitList_Field{_set: true, _null: true}
}

func (f Project_BurstLimitList_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_BurstLimitList_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_RateLimitDel_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_RateLimitDel(v int) Project_RateLimitDel_Field {
	return Project_RateLimitDel_Field{_set: true, _value: &v}
}

func Project_RateLimitDel_Raw(v *int) Project_RateLimitDel_Field {
	if v == nil {
		return Project_RateLimitDel_Null()
	}
	return Project_RateLimitDel(*v)
}

func Project_RateLimitDel_Null() Project_RateLimitDel_Field {
	return Project_RateLimitDel_Field{_set: true, _null: true}
}

func (f Project_RateLimitDel_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_RateLimitDel_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_BurstLimitDel_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_BurstLimitDel(v int) Project_BurstLimitDel_Field {
	return Project_BurstLimitDel_Field{_set: true, _value: &v}
}

func Project_BurstLimitDel_Raw(v *int) Project_BurstLimitDel_Field {
	if v == nil {
		return Project_BurstLimitDel_Null()
	}
	return Project_BurstLimitDel(*v)
}

func Project_BurstLimitDel_Null() Project_BurstLimitDel_Field {
	return Project_BurstLimitDel_Field{_set: true, _null: true}
}

func (f Project_BurstLimitDel_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_BurstLimitDel_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_MaxBuckets_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_MaxBuckets(v int) Project_MaxBuckets_Field {
	return Project_MaxBuckets_Field{_set: true, _value: &v}
}

func Project_MaxBuckets_Raw(v *int) Project_MaxBuckets_Field {
	if v == nil {
		return Project_MaxBuckets_Null()
	}
	return Project_MaxBuckets(*v)
}

func Project_MaxBuckets_Null() Project_MaxBuckets_Field {
	return Project_MaxBuckets_Field{_set: true, _null: true}
}

func (f Project_MaxBuckets_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_MaxBuckets_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_UserAgent_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Project_UserAgent(v []byte) Project_UserAgent_Field {
	return Project_UserAgent_Field{_set: true, _value: v}
}

func Project_UserAgent_Raw(v []byte) Project_UserAgent_Field {
	if v == nil {
		return Project_UserAgent_Null()
	}
	return Project_UserAgent(v)
}

func Project_UserAgent_Null() Project_UserAgent_Field {
	return Project_UserAgent_Field{_set: true, _null: true}
}

func (f Project_UserAgent_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_UserAgent_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_OwnerId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Project_OwnerId(v []byte) Project_OwnerId_Field {
	return Project_OwnerId_Field{_set: true, _value: v}
}

func (f Project_OwnerId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_Salt_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Project_Salt(v []byte) Project_Salt_Field {
	return Project_Salt_Field{_set: true, _value: v}
}

func Project_Salt_Raw(v []byte) Project_Salt_Field {
	if v == nil {
		return Project_Salt_Null()
	}
	return Project_Salt(v)
}

func Project_Salt_Null() Project_Salt_Field {
	return Project_Salt_Field{_set: true, _null: true}
}

func (f Project_Salt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_Salt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_Status_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_Status(v int) Project_Status_Field {
	return Project_Status_Field{_set: true, _value: &v}
}

func Project_Status_Raw(v *int) Project_Status_Field {
	if v == nil {
		return Project_Status_Null()
	}
	return Project_Status(*v)
}

func Project_Status_Null() Project_Status_Field {
	return Project_Status_Field{_set: true, _null: true}
}

func (f Project_Status_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_Status_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_StatusUpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Project_StatusUpdatedAt(v time.Time) Project_StatusUpdatedAt_Field {
	return Project_StatusUpdatedAt_Field{_set: true, _value: &v}
}

func Project_StatusUpdatedAt_Raw(v *time.Time) Project_StatusUpdatedAt_Field {
	if v == nil {
		return Project_StatusUpdatedAt_Null()
	}
	return Project_StatusUpdatedAt(*v)
}

func Project_StatusUpdatedAt_Null() Project_StatusUpdatedAt_Field {
	return Project_StatusUpdatedAt_Field{_set: true, _null: true}
}

func (f Project_StatusUpdatedAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_StatusUpdatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Project_CreatedAt(v time.Time) Project_CreatedAt_Field {
	return Project_CreatedAt_Field{_set: true, _value: v}
}

func (f Project_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_DefaultPlacement_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_DefaultPlacement(v int) Project_DefaultPlacement_Field {
	return Project_DefaultPlacement_Field{_set: true, _value: &v}
}

func Project_DefaultPlacement_Raw(v *int) Project_DefaultPlacement_Field {
	if v == nil {
		return Project_DefaultPlacement_Null()
	}
	return Project_DefaultPlacement(*v)
}

func Project_DefaultPlacement_Null() Project_DefaultPlacement_Field {
	return Project_DefaultPlacement_Field{_set: true, _null: true}
}

func (f Project_DefaultPlacement_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_DefaultPlacement_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_DefaultVersioning_Field struct {
	_set   bool
	_null  bool
	_value int
}

func Project_DefaultVersioning(v int) Project_DefaultVersioning_Field {
	return Project_DefaultVersioning_Field{_set: true, _value: v}
}

func (f Project_DefaultVersioning_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_PromptedForVersioningBeta_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func Project_PromptedForVersioningBeta(v bool) Project_PromptedForVersioningBeta_Field {
	return Project_PromptedForVersioningBeta_Field{_set: true, _value: v}
}

func (f Project_PromptedForVersioningBeta_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_PassphraseEnc_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Project_PassphraseEnc(v []byte) Project_PassphraseEnc_Field {
	return Project_PassphraseEnc_Field{_set: true, _value: v}
}

func Project_PassphraseEnc_Raw(v []byte) Project_PassphraseEnc_Field {
	if v == nil {
		return Project_PassphraseEnc_Null()
	}
	return Project_PassphraseEnc(v)
}

func Project_PassphraseEnc_Null() Project_PassphraseEnc_Field {
	return Project_PassphraseEnc_Field{_set: true, _null: true}
}

func (f Project_PassphraseEnc_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_PassphraseEnc_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_PassphraseEncKeyId_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Project_PassphraseEncKeyId(v int) Project_PassphraseEncKeyId_Field {
	return Project_PassphraseEncKeyId_Field{_set: true, _value: &v}
}

func Project_PassphraseEncKeyId_Raw(v *int) Project_PassphraseEncKeyId_Field {
	if v == nil {
		return Project_PassphraseEncKeyId_Null()
	}
	return Project_PassphraseEncKeyId(*v)
}

func Project_PassphraseEncKeyId_Null() Project_PassphraseEncKeyId_Field {
	return Project_PassphraseEncKeyId_Field{_set: true, _null: true}
}

func (f Project_PassphraseEncKeyId_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Project_PassphraseEncKeyId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Project_PathEncryption_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func Project_PathEncryption(v bool) Project_PathEncryption_Field {
	return Project_PathEncryption_Field{_set: true, _value: v}
}

func (f Project_PathEncryption_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectBandwidthDailyRollup struct {
	ProjectId       []byte
	ProductId       *int
	IntervalDay     time.Time
	EgressAllocated uint64
	EgressSettled   uint64
	EgressDead      uint64
}

func (ProjectBandwidthDailyRollup) _Table() string { return "project_bandwidth_daily_rollups" }

type ProjectBandwidthDailyRollup_Create_Fields struct {
	ProductId  ProjectBandwidthDailyRollup_ProductId_Field
	EgressDead ProjectBandwidthDailyRollup_EgressDead_Field
}

type ProjectBandwidthDailyRollup_Update_Fields struct {
	EgressAllocated ProjectBandwidthDailyRollup_EgressAllocated_Field
	EgressSettled   ProjectBandwidthDailyRollup_EgressSettled_Field
	EgressDead      ProjectBandwidthDailyRollup_EgressDead_Field
}

type ProjectBandwidthDailyRollup_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ProjectBandwidthDailyRollup_ProjectId(v []byte) ProjectBandwidthDailyRollup_ProjectId_Field {
	return ProjectBandwidthDailyRollup_ProjectId_Field{_set: true, _value: v}
}

func (f ProjectBandwidthDailyRollup_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectBandwidthDailyRollup_ProductId_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func ProjectBandwidthDailyRollup_ProductId(v int) ProjectBandwidthDailyRollup_ProductId_Field {
	return ProjectBandwidthDailyRollup_ProductId_Field{_set: true, _value: &v}
}

func ProjectBandwidthDailyRollup_ProductId_Raw(v *int) ProjectBandwidthDailyRollup_ProductId_Field {
	if v == nil {
		return ProjectBandwidthDailyRollup_ProductId_Null()
	}
	return ProjectBandwidthDailyRollup_ProductId(*v)
}

func ProjectBandwidthDailyRollup_ProductId_Null() ProjectBandwidthDailyRollup_ProductId_Field {
	return ProjectBandwidthDailyRollup_ProductId_Field{_set: true, _null: true}
}

func (f ProjectBandwidthDailyRollup_ProductId_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f ProjectBandwidthDailyRollup_ProductId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectBandwidthDailyRollup_IntervalDay_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ProjectBandwidthDailyRollup_IntervalDay(v time.Time) ProjectBandwidthDailyRollup_IntervalDay_Field {
	v = toDate(v)
	return ProjectBandwidthDailyRollup_IntervalDay_Field{_set: true, _value: v}
}

func (f ProjectBandwidthDailyRollup_IntervalDay_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectBandwidthDailyRollup_EgressAllocated_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func ProjectBandwidthDailyRollup_EgressAllocated(v uint64) ProjectBandwidthDailyRollup_EgressAllocated_Field {
	return ProjectBandwidthDailyRollup_EgressAllocated_Field{_set: true, _value: v}
}

func (f ProjectBandwidthDailyRollup_EgressAllocated_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectBandwidthDailyRollup_EgressSettled_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func ProjectBandwidthDailyRollup_EgressSettled(v uint64) ProjectBandwidthDailyRollup_EgressSettled_Field {
	return ProjectBandwidthDailyRollup_EgressSettled_Field{_set: true, _value: v}
}

func (f ProjectBandwidthDailyRollup_EgressSettled_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectBandwidthDailyRollup_EgressDead_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func ProjectBandwidthDailyRollup_EgressDead(v uint64) ProjectBandwidthDailyRollup_EgressDead_Field {
	return ProjectBandwidthDailyRollup_EgressDead_Field{_set: true, _value: v}
}

func (f ProjectBandwidthDailyRollup_EgressDead_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RegistrationToken struct {
	Secret       []byte
	OwnerId      []byte
	ProjectLimit int
	CreatedAt    time.Time
}

func (RegistrationToken) _Table() string { return "registration_tokens" }

type RegistrationToken_Create_Fields struct {
	OwnerId RegistrationToken_OwnerId_Field
}

type RegistrationToken_Update_Fields struct {
	OwnerId RegistrationToken_OwnerId_Field
}

type RegistrationToken_Secret_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func RegistrationToken_Secret(v []byte) RegistrationToken_Secret_Field {
	return RegistrationToken_Secret_Field{_set: true, _value: v}
}

func (f RegistrationToken_Secret_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RegistrationToken_OwnerId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func RegistrationToken_OwnerId(v []byte) RegistrationToken_OwnerId_Field {
	return RegistrationToken_OwnerId_Field{_set: true, _value: v}
}

func RegistrationToken_OwnerId_Raw(v []byte) RegistrationToken_OwnerId_Field {
	if v == nil {
		return RegistrationToken_OwnerId_Null()
	}
	return RegistrationToken_OwnerId(v)
}

func RegistrationToken_OwnerId_Null() RegistrationToken_OwnerId_Field {
	return RegistrationToken_OwnerId_Field{_set: true, _null: true}
}

func (f RegistrationToken_OwnerId_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f RegistrationToken_OwnerId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RegistrationToken_ProjectLimit_Field struct {
	_set   bool
	_null  bool
	_value int
}

func RegistrationToken_ProjectLimit(v int) RegistrationToken_ProjectLimit_Field {
	return RegistrationToken_ProjectLimit_Field{_set: true, _value: v}
}

func (f RegistrationToken_ProjectLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RegistrationToken_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func RegistrationToken_CreatedAt(v time.Time) RegistrationToken_CreatedAt_Field {
	return RegistrationToken_CreatedAt_Field{_set: true, _value: v}
}

func (f RegistrationToken_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RepairQueue struct {
	StreamId      []byte
	Position      uint64
	AttemptedAt   *time.Time
	UpdatedAt     time.Time
	InsertedAt    time.Time
	SegmentHealth float64
	Placement     *int
}

func (RepairQueue) _Table() string { return "repair_queue" }

type RepairQueue_Create_Fields struct {
	AttemptedAt   RepairQueue_AttemptedAt_Field
	UpdatedAt     RepairQueue_UpdatedAt_Field
	InsertedAt    RepairQueue_InsertedAt_Field
	SegmentHealth RepairQueue_SegmentHealth_Field
	Placement     RepairQueue_Placement_Field
}

type RepairQueue_Update_Fields struct {
	AttemptedAt RepairQueue_AttemptedAt_Field
	UpdatedAt   RepairQueue_UpdatedAt_Field
	Placement   RepairQueue_Placement_Field
}

type RepairQueue_StreamId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func RepairQueue_StreamId(v []byte) RepairQueue_StreamId_Field {
	return RepairQueue_StreamId_Field{_set: true, _value: v}
}

func (f RepairQueue_StreamId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RepairQueue_Position_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func RepairQueue_Position(v uint64) RepairQueue_Position_Field {
	return RepairQueue_Position_Field{_set: true, _value: v}
}

func (f RepairQueue_Position_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RepairQueue_AttemptedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func RepairQueue_AttemptedAt(v time.Time) RepairQueue_AttemptedAt_Field {
	return RepairQueue_AttemptedAt_Field{_set: true, _value: &v}
}

func RepairQueue_AttemptedAt_Raw(v *time.Time) RepairQueue_AttemptedAt_Field {
	if v == nil {
		return RepairQueue_AttemptedAt_Null()
	}
	return RepairQueue_AttemptedAt(*v)
}

func RepairQueue_AttemptedAt_Null() RepairQueue_AttemptedAt_Field {
	return RepairQueue_AttemptedAt_Field{_set: true, _null: true}
}

func (f RepairQueue_AttemptedAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f RepairQueue_AttemptedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RepairQueue_UpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func RepairQueue_UpdatedAt(v time.Time) RepairQueue_UpdatedAt_Field {
	return RepairQueue_UpdatedAt_Field{_set: true, _value: v}
}

func (f RepairQueue_UpdatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RepairQueue_InsertedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func RepairQueue_InsertedAt(v time.Time) RepairQueue_InsertedAt_Field {
	return RepairQueue_InsertedAt_Field{_set: true, _value: v}
}

func (f RepairQueue_InsertedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RepairQueue_SegmentHealth_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func RepairQueue_SegmentHealth(v float64) RepairQueue_SegmentHealth_Field {
	return RepairQueue_SegmentHealth_Field{_set: true, _value: v}
}

func (f RepairQueue_SegmentHealth_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RepairQueue_Placement_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func RepairQueue_Placement(v int) RepairQueue_Placement_Field {
	return RepairQueue_Placement_Field{_set: true, _value: &v}
}

func RepairQueue_Placement_Raw(v *int) RepairQueue_Placement_Field {
	if v == nil {
		return RepairQueue_Placement_Null()
	}
	return RepairQueue_Placement(*v)
}

func RepairQueue_Placement_Null() RepairQueue_Placement_Field {
	return RepairQueue_Placement_Field{_set: true, _null: true}
}

func (f RepairQueue_Placement_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f RepairQueue_Placement_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation struct {
	Id                          []byte
	AuditSuccessCount           int64
	TotalAuditCount             int64
	VettedAt                    *time.Time
	CreatedAt                   time.Time
	UpdatedAt                   time.Time
	Disqualified                *time.Time
	DisqualificationReason      *int
	UnknownAuditSuspended       *time.Time
	OfflineSuspended            *time.Time
	UnderReview                 *time.Time
	OnlineScore                 float64
	AuditHistory                []byte
	AuditReputationAlpha        float64
	AuditReputationBeta         float64
	UnknownAuditReputationAlpha float64
	UnknownAuditReputationBeta  float64
}

func (Reputation) _Table() string { return "reputations" }

type Reputation_Create_Fields struct {
	AuditSuccessCount           Reputation_AuditSuccessCount_Field
	TotalAuditCount             Reputation_TotalAuditCount_Field
	VettedAt                    Reputation_VettedAt_Field
	Disqualified                Reputation_Disqualified_Field
	DisqualificationReason      Reputation_DisqualificationReason_Field
	UnknownAuditSuspended       Reputation_UnknownAuditSuspended_Field
	OfflineSuspended            Reputation_OfflineSuspended_Field
	UnderReview                 Reputation_UnderReview_Field
	OnlineScore                 Reputation_OnlineScore_Field
	AuditReputationAlpha        Reputation_AuditReputationAlpha_Field
	AuditReputationBeta         Reputation_AuditReputationBeta_Field
	UnknownAuditReputationAlpha Reputation_UnknownAuditReputationAlpha_Field
	UnknownAuditReputationBeta  Reputation_UnknownAuditReputationBeta_Field
}

type Reputation_Update_Fields struct {
	AuditSuccessCount           Reputation_AuditSuccessCount_Field
	TotalAuditCount             Reputation_TotalAuditCount_Field
	VettedAt                    Reputation_VettedAt_Field
	Disqualified                Reputation_Disqualified_Field
	DisqualificationReason      Reputation_DisqualificationReason_Field
	UnknownAuditSuspended       Reputation_UnknownAuditSuspended_Field
	OfflineSuspended            Reputation_OfflineSuspended_Field
	UnderReview                 Reputation_UnderReview_Field
	OnlineScore                 Reputation_OnlineScore_Field
	AuditHistory                Reputation_AuditHistory_Field
	AuditReputationAlpha        Reputation_AuditReputationAlpha_Field
	AuditReputationBeta         Reputation_AuditReputationBeta_Field
	UnknownAuditReputationAlpha Reputation_UnknownAuditReputationAlpha_Field
	UnknownAuditReputationBeta  Reputation_UnknownAuditReputationBeta_Field
}

type Reputation_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Reputation_Id(v []byte) Reputation_Id_Field {
	return Reputation_Id_Field{_set: true, _value: v}
}

func (f Reputation_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_AuditSuccessCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Reputation_AuditSuccessCount(v int64) Reputation_AuditSuccessCount_Field {
	return Reputation_AuditSuccessCount_Field{_set: true, _value: v}
}

func (f Reputation_AuditSuccessCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_TotalAuditCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func Reputation_TotalAuditCount(v int64) Reputation_TotalAuditCount_Field {
	return Reputation_TotalAuditCount_Field{_set: true, _value: v}
}

func (f Reputation_TotalAuditCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_VettedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Reputation_VettedAt(v time.Time) Reputation_VettedAt_Field {
	return Reputation_VettedAt_Field{_set: true, _value: &v}
}

func Reputation_VettedAt_Raw(v *time.Time) Reputation_VettedAt_Field {
	if v == nil {
		return Reputation_VettedAt_Null()
	}
	return Reputation_VettedAt(*v)
}

func Reputation_VettedAt_Null() Reputation_VettedAt_Field {
	return Reputation_VettedAt_Field{_set: true, _null: true}
}

func (f Reputation_VettedAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Reputation_VettedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Reputation_CreatedAt(v time.Time) Reputation_CreatedAt_Field {
	return Reputation_CreatedAt_Field{_set: true, _value: v}
}

func (f Reputation_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_UpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Reputation_UpdatedAt(v time.Time) Reputation_UpdatedAt_Field {
	return Reputation_UpdatedAt_Field{_set: true, _value: v}
}

func (f Reputation_UpdatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_Disqualified_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Reputation_Disqualified(v time.Time) Reputation_Disqualified_Field {
	return Reputation_Disqualified_Field{_set: true, _value: &v}
}

func Reputation_Disqualified_Raw(v *time.Time) Reputation_Disqualified_Field {
	if v == nil {
		return Reputation_Disqualified_Null()
	}
	return Reputation_Disqualified(*v)
}

func Reputation_Disqualified_Null() Reputation_Disqualified_Field {
	return Reputation_Disqualified_Field{_set: true, _null: true}
}

func (f Reputation_Disqualified_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Reputation_Disqualified_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_DisqualificationReason_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func Reputation_DisqualificationReason(v int) Reputation_DisqualificationReason_Field {
	return Reputation_DisqualificationReason_Field{_set: true, _value: &v}
}

func Reputation_DisqualificationReason_Raw(v *int) Reputation_DisqualificationReason_Field {
	if v == nil {
		return Reputation_DisqualificationReason_Null()
	}
	return Reputation_DisqualificationReason(*v)
}

func Reputation_DisqualificationReason_Null() Reputation_DisqualificationReason_Field {
	return Reputation_DisqualificationReason_Field{_set: true, _null: true}
}

func (f Reputation_DisqualificationReason_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f Reputation_DisqualificationReason_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_UnknownAuditSuspended_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Reputation_UnknownAuditSuspended(v time.Time) Reputation_UnknownAuditSuspended_Field {
	return Reputation_UnknownAuditSuspended_Field{_set: true, _value: &v}
}

func Reputation_UnknownAuditSuspended_Raw(v *time.Time) Reputation_UnknownAuditSuspended_Field {
	if v == nil {
		return Reputation_UnknownAuditSuspended_Null()
	}
	return Reputation_UnknownAuditSuspended(*v)
}

func Reputation_UnknownAuditSuspended_Null() Reputation_UnknownAuditSuspended_Field {
	return Reputation_UnknownAuditSuspended_Field{_set: true, _null: true}
}

func (f Reputation_UnknownAuditSuspended_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f Reputation_UnknownAuditSuspended_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_OfflineSuspended_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Reputation_OfflineSuspended(v time.Time) Reputation_OfflineSuspended_Field {
	return Reputation_OfflineSuspended_Field{_set: true, _value: &v}
}

func Reputation_OfflineSuspended_Raw(v *time.Time) Reputation_OfflineSuspended_Field {
	if v == nil {
		return Reputation_OfflineSuspended_Null()
	}
	return Reputation_OfflineSuspended(*v)
}

func Reputation_OfflineSuspended_Null() Reputation_OfflineSuspended_Field {
	return Reputation_OfflineSuspended_Field{_set: true, _null: true}
}

func (f Reputation_OfflineSuspended_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f Reputation_OfflineSuspended_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_UnderReview_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func Reputation_UnderReview(v time.Time) Reputation_UnderReview_Field {
	return Reputation_UnderReview_Field{_set: true, _value: &v}
}

func Reputation_UnderReview_Raw(v *time.Time) Reputation_UnderReview_Field {
	if v == nil {
		return Reputation_UnderReview_Null()
	}
	return Reputation_UnderReview(*v)
}

func Reputation_UnderReview_Null() Reputation_UnderReview_Field {
	return Reputation_UnderReview_Field{_set: true, _null: true}
}

func (f Reputation_UnderReview_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f Reputation_UnderReview_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_OnlineScore_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func Reputation_OnlineScore(v float64) Reputation_OnlineScore_Field {
	return Reputation_OnlineScore_Field{_set: true, _value: v}
}

func (f Reputation_OnlineScore_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_AuditHistory_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Reputation_AuditHistory(v []byte) Reputation_AuditHistory_Field {
	return Reputation_AuditHistory_Field{_set: true, _value: v}
}

func (f Reputation_AuditHistory_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_AuditReputationAlpha_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func Reputation_AuditReputationAlpha(v float64) Reputation_AuditReputationAlpha_Field {
	return Reputation_AuditReputationAlpha_Field{_set: true, _value: v}
}

func (f Reputation_AuditReputationAlpha_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_AuditReputationBeta_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func Reputation_AuditReputationBeta(v float64) Reputation_AuditReputationBeta_Field {
	return Reputation_AuditReputationBeta_Field{_set: true, _value: v}
}

func (f Reputation_AuditReputationBeta_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_UnknownAuditReputationAlpha_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func Reputation_UnknownAuditReputationAlpha(v float64) Reputation_UnknownAuditReputationAlpha_Field {
	return Reputation_UnknownAuditReputationAlpha_Field{_set: true, _value: v}
}

func (f Reputation_UnknownAuditReputationAlpha_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Reputation_UnknownAuditReputationBeta_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func Reputation_UnknownAuditReputationBeta(v float64) Reputation_UnknownAuditReputationBeta_Field {
	return Reputation_UnknownAuditReputationBeta_Field{_set: true, _value: v}
}

func (f Reputation_UnknownAuditReputationBeta_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ResetPasswordToken struct {
	Secret    []byte
	OwnerId   []byte
	CreatedAt time.Time
}

func (ResetPasswordToken) _Table() string { return "reset_password_tokens" }

type ResetPasswordToken_Update_Fields struct {
	OwnerId ResetPasswordToken_OwnerId_Field
}

type ResetPasswordToken_Secret_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ResetPasswordToken_Secret(v []byte) ResetPasswordToken_Secret_Field {
	return ResetPasswordToken_Secret_Field{_set: true, _value: v}
}

func (f ResetPasswordToken_Secret_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ResetPasswordToken_OwnerId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ResetPasswordToken_OwnerId(v []byte) ResetPasswordToken_OwnerId_Field {
	return ResetPasswordToken_OwnerId_Field{_set: true, _value: v}
}

func (f ResetPasswordToken_OwnerId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ResetPasswordToken_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ResetPasswordToken_CreatedAt(v time.Time) ResetPasswordToken_CreatedAt_Field {
	return ResetPasswordToken_CreatedAt_Field{_set: true, _value: v}
}

func (f ResetPasswordToken_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ReverificationAudits struct {
	NodeId        []byte
	StreamId      []byte
	Position      uint64
	PieceNum      int
	InsertedAt    time.Time
	LastAttempt   *time.Time
	ReverifyCount int64
}

func (ReverificationAudits) _Table() string { return "reverification_audits" }

type ReverificationAudits_Create_Fields struct {
	InsertedAt    ReverificationAudits_InsertedAt_Field
	LastAttempt   ReverificationAudits_LastAttempt_Field
	ReverifyCount ReverificationAudits_ReverifyCount_Field
}

type ReverificationAudits_Update_Fields struct {
	LastAttempt   ReverificationAudits_LastAttempt_Field
	ReverifyCount ReverificationAudits_ReverifyCount_Field
}

type ReverificationAudits_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ReverificationAudits_NodeId(v []byte) ReverificationAudits_NodeId_Field {
	return ReverificationAudits_NodeId_Field{_set: true, _value: v}
}

func (f ReverificationAudits_NodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ReverificationAudits_StreamId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ReverificationAudits_StreamId(v []byte) ReverificationAudits_StreamId_Field {
	return ReverificationAudits_StreamId_Field{_set: true, _value: v}
}

func (f ReverificationAudits_StreamId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ReverificationAudits_Position_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func ReverificationAudits_Position(v uint64) ReverificationAudits_Position_Field {
	return ReverificationAudits_Position_Field{_set: true, _value: v}
}

func (f ReverificationAudits_Position_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ReverificationAudits_PieceNum_Field struct {
	_set   bool
	_null  bool
	_value int
}

func ReverificationAudits_PieceNum(v int) ReverificationAudits_PieceNum_Field {
	return ReverificationAudits_PieceNum_Field{_set: true, _value: v}
}

func (f ReverificationAudits_PieceNum_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ReverificationAudits_InsertedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ReverificationAudits_InsertedAt(v time.Time) ReverificationAudits_InsertedAt_Field {
	return ReverificationAudits_InsertedAt_Field{_set: true, _value: v}
}

func (f ReverificationAudits_InsertedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ReverificationAudits_LastAttempt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func ReverificationAudits_LastAttempt(v time.Time) ReverificationAudits_LastAttempt_Field {
	return ReverificationAudits_LastAttempt_Field{_set: true, _value: &v}
}

func ReverificationAudits_LastAttempt_Raw(v *time.Time) ReverificationAudits_LastAttempt_Field {
	if v == nil {
		return ReverificationAudits_LastAttempt_Null()
	}
	return ReverificationAudits_LastAttempt(*v)
}

func ReverificationAudits_LastAttempt_Null() ReverificationAudits_LastAttempt_Field {
	return ReverificationAudits_LastAttempt_Field{_set: true, _null: true}
}

func (f ReverificationAudits_LastAttempt_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f ReverificationAudits_LastAttempt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ReverificationAudits_ReverifyCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func ReverificationAudits_ReverifyCount(v int64) ReverificationAudits_ReverifyCount_Field {
	return ReverificationAudits_ReverifyCount_Field{_set: true, _value: v}
}

func (f ReverificationAudits_ReverifyCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Revocation struct {
	Revoked  []byte
	ApiKeyId []byte
}

func (Revocation) _Table() string { return "revocations" }

type Revocation_Update_Fields struct {
}

type Revocation_Revoked_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Revocation_Revoked(v []byte) Revocation_Revoked_Field {
	return Revocation_Revoked_Field{_set: true, _value: v}
}

func (f Revocation_Revoked_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Revocation_ApiKeyId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Revocation_ApiKeyId(v []byte) Revocation_ApiKeyId_Field {
	return Revocation_ApiKeyId_Field{_set: true, _value: v}
}

func (f Revocation_ApiKeyId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type SegmentPendingAudits struct {
	NodeId            []byte
	StreamId          []byte
	Position          uint64
	PieceId           []byte
	StripeIndex       int64
	ShareSize         int64
	ExpectedShareHash []byte
	ReverifyCount     int64
}

func (SegmentPendingAudits) _Table() string { return "segment_pending_audits" }

type SegmentPendingAudits_Update_Fields struct {
	ReverifyCount SegmentPendingAudits_ReverifyCount_Field
}

type SegmentPendingAudits_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func SegmentPendingAudits_NodeId(v []byte) SegmentPendingAudits_NodeId_Field {
	return SegmentPendingAudits_NodeId_Field{_set: true, _value: v}
}

func (f SegmentPendingAudits_NodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type SegmentPendingAudits_StreamId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func SegmentPendingAudits_StreamId(v []byte) SegmentPendingAudits_StreamId_Field {
	return SegmentPendingAudits_StreamId_Field{_set: true, _value: v}
}

func (f SegmentPendingAudits_StreamId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type SegmentPendingAudits_Position_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func SegmentPendingAudits_Position(v uint64) SegmentPendingAudits_Position_Field {
	return SegmentPendingAudits_Position_Field{_set: true, _value: v}
}

func (f SegmentPendingAudits_Position_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type SegmentPendingAudits_PieceId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func SegmentPendingAudits_PieceId(v []byte) SegmentPendingAudits_PieceId_Field {
	return SegmentPendingAudits_PieceId_Field{_set: true, _value: v}
}

func (f SegmentPendingAudits_PieceId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type SegmentPendingAudits_StripeIndex_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func SegmentPendingAudits_StripeIndex(v int64) SegmentPendingAudits_StripeIndex_Field {
	return SegmentPendingAudits_StripeIndex_Field{_set: true, _value: v}
}

func (f SegmentPendingAudits_StripeIndex_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type SegmentPendingAudits_ShareSize_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func SegmentPendingAudits_ShareSize(v int64) SegmentPendingAudits_ShareSize_Field {
	return SegmentPendingAudits_ShareSize_Field{_set: true, _value: v}
}

func (f SegmentPendingAudits_ShareSize_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type SegmentPendingAudits_ExpectedShareHash_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func SegmentPendingAudits_ExpectedShareHash(v []byte) SegmentPendingAudits_ExpectedShareHash_Field {
	return SegmentPendingAudits_ExpectedShareHash_Field{_set: true, _value: v}
}

func (f SegmentPendingAudits_ExpectedShareHash_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type SegmentPendingAudits_ReverifyCount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func SegmentPendingAudits_ReverifyCount(v int64) SegmentPendingAudits_ReverifyCount_Field {
	return SegmentPendingAudits_ReverifyCount_Field{_set: true, _value: v}
}

func (f SegmentPendingAudits_ReverifyCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollup struct {
	StoragenodeId   []byte
	IntervalStart   time.Time
	IntervalSeconds uint
	Action          uint
	Allocated       *uint64
	Settled         uint64
}

func (StoragenodeBandwidthRollup) _Table() string { return "storagenode_bandwidth_rollups" }

type StoragenodeBandwidthRollup_Create_Fields struct {
	Allocated StoragenodeBandwidthRollup_Allocated_Field
}

type StoragenodeBandwidthRollup_Update_Fields struct {
	Allocated StoragenodeBandwidthRollup_Allocated_Field
	Settled   StoragenodeBandwidthRollup_Settled_Field
}

type StoragenodeBandwidthRollup_StoragenodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StoragenodeBandwidthRollup_StoragenodeId(v []byte) StoragenodeBandwidthRollup_StoragenodeId_Field {
	return StoragenodeBandwidthRollup_StoragenodeId_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollup_StoragenodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollup_IntervalStart_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StoragenodeBandwidthRollup_IntervalStart(v time.Time) StoragenodeBandwidthRollup_IntervalStart_Field {
	return StoragenodeBandwidthRollup_IntervalStart_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollup_IntervalStart_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollup_IntervalSeconds_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func StoragenodeBandwidthRollup_IntervalSeconds(v uint) StoragenodeBandwidthRollup_IntervalSeconds_Field {
	return StoragenodeBandwidthRollup_IntervalSeconds_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollup_IntervalSeconds_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollup_Action_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func StoragenodeBandwidthRollup_Action(v uint) StoragenodeBandwidthRollup_Action_Field {
	return StoragenodeBandwidthRollup_Action_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollup_Action_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollup_Allocated_Field struct {
	_set   bool
	_null  bool
	_value *uint64
}

func StoragenodeBandwidthRollup_Allocated(v uint64) StoragenodeBandwidthRollup_Allocated_Field {
	return StoragenodeBandwidthRollup_Allocated_Field{_set: true, _value: &v}
}

func StoragenodeBandwidthRollup_Allocated_Raw(v *uint64) StoragenodeBandwidthRollup_Allocated_Field {
	if v == nil {
		return StoragenodeBandwidthRollup_Allocated_Null()
	}
	return StoragenodeBandwidthRollup_Allocated(*v)
}

func StoragenodeBandwidthRollup_Allocated_Null() StoragenodeBandwidthRollup_Allocated_Field {
	return StoragenodeBandwidthRollup_Allocated_Field{_set: true, _null: true}
}

func (f StoragenodeBandwidthRollup_Allocated_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f StoragenodeBandwidthRollup_Allocated_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollup_Settled_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func StoragenodeBandwidthRollup_Settled(v uint64) StoragenodeBandwidthRollup_Settled_Field {
	return StoragenodeBandwidthRollup_Settled_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollup_Settled_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollupArchive struct {
	StoragenodeId   []byte
	IntervalStart   time.Time
	IntervalSeconds uint
	Action          uint
	Allocated       *uint64
	Settled         uint64
}

func (StoragenodeBandwidthRollupArchive) _Table() string {
	return "storagenode_bandwidth_rollup_archives"
}

type StoragenodeBandwidthRollupArchive_Create_Fields struct {
	Allocated StoragenodeBandwidthRollupArchive_Allocated_Field
}

type StoragenodeBandwidthRollupArchive_Update_Fields struct {
	Allocated StoragenodeBandwidthRollupArchive_Allocated_Field
	Settled   StoragenodeBandwidthRollupArchive_Settled_Field
}

type StoragenodeBandwidthRollupArchive_StoragenodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StoragenodeBandwidthRollupArchive_StoragenodeId(v []byte) StoragenodeBandwidthRollupArchive_StoragenodeId_Field {
	return StoragenodeBandwidthRollupArchive_StoragenodeId_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollupArchive_StoragenodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollupArchive_IntervalStart_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StoragenodeBandwidthRollupArchive_IntervalStart(v time.Time) StoragenodeBandwidthRollupArchive_IntervalStart_Field {
	return StoragenodeBandwidthRollupArchive_IntervalStart_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollupArchive_IntervalStart_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollupArchive_IntervalSeconds_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func StoragenodeBandwidthRollupArchive_IntervalSeconds(v uint) StoragenodeBandwidthRollupArchive_IntervalSeconds_Field {
	return StoragenodeBandwidthRollupArchive_IntervalSeconds_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollupArchive_IntervalSeconds_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollupArchive_Action_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func StoragenodeBandwidthRollupArchive_Action(v uint) StoragenodeBandwidthRollupArchive_Action_Field {
	return StoragenodeBandwidthRollupArchive_Action_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollupArchive_Action_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollupArchive_Allocated_Field struct {
	_set   bool
	_null  bool
	_value *uint64
}

func StoragenodeBandwidthRollupArchive_Allocated(v uint64) StoragenodeBandwidthRollupArchive_Allocated_Field {
	return StoragenodeBandwidthRollupArchive_Allocated_Field{_set: true, _value: &v}
}

func StoragenodeBandwidthRollupArchive_Allocated_Raw(v *uint64) StoragenodeBandwidthRollupArchive_Allocated_Field {
	if v == nil {
		return StoragenodeBandwidthRollupArchive_Allocated_Null()
	}
	return StoragenodeBandwidthRollupArchive_Allocated(*v)
}

func StoragenodeBandwidthRollupArchive_Allocated_Null() StoragenodeBandwidthRollupArchive_Allocated_Field {
	return StoragenodeBandwidthRollupArchive_Allocated_Field{_set: true, _null: true}
}

func (f StoragenodeBandwidthRollupArchive_Allocated_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f StoragenodeBandwidthRollupArchive_Allocated_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeBandwidthRollupArchive_Settled_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func StoragenodeBandwidthRollupArchive_Settled(v uint64) StoragenodeBandwidthRollupArchive_Settled_Field {
	return StoragenodeBandwidthRollupArchive_Settled_Field{_set: true, _value: v}
}

func (f StoragenodeBandwidthRollupArchive_Settled_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePayment struct {
	Id        int64
	CreatedAt time.Time
	NodeId    []byte
	Period    string
	Amount    int64
	Receipt   *string
	Notes     *string
}

func (StoragenodePayment) _Table() string { return "storagenode_payments" }

type StoragenodePayment_Create_Fields struct {
	Receipt StoragenodePayment_Receipt_Field
	Notes   StoragenodePayment_Notes_Field
}

type StoragenodePayment_Update_Fields struct {
}

type StoragenodePayment_Id_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePayment_Id(v int64) StoragenodePayment_Id_Field {
	return StoragenodePayment_Id_Field{_set: true, _value: v}
}

func (f StoragenodePayment_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePayment_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StoragenodePayment_CreatedAt(v time.Time) StoragenodePayment_CreatedAt_Field {
	return StoragenodePayment_CreatedAt_Field{_set: true, _value: v}
}

func (f StoragenodePayment_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePayment_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StoragenodePayment_NodeId(v []byte) StoragenodePayment_NodeId_Field {
	return StoragenodePayment_NodeId_Field{_set: true, _value: v}
}

func (f StoragenodePayment_NodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePayment_Period_Field struct {
	_set   bool
	_null  bool
	_value string
}

func StoragenodePayment_Period(v string) StoragenodePayment_Period_Field {
	return StoragenodePayment_Period_Field{_set: true, _value: v}
}

func (f StoragenodePayment_Period_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePayment_Amount_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePayment_Amount(v int64) StoragenodePayment_Amount_Field {
	return StoragenodePayment_Amount_Field{_set: true, _value: v}
}

func (f StoragenodePayment_Amount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePayment_Receipt_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func StoragenodePayment_Receipt(v string) StoragenodePayment_Receipt_Field {
	return StoragenodePayment_Receipt_Field{_set: true, _value: &v}
}

func StoragenodePayment_Receipt_Raw(v *string) StoragenodePayment_Receipt_Field {
	if v == nil {
		return StoragenodePayment_Receipt_Null()
	}
	return StoragenodePayment_Receipt(*v)
}

func StoragenodePayment_Receipt_Null() StoragenodePayment_Receipt_Field {
	return StoragenodePayment_Receipt_Field{_set: true, _null: true}
}

func (f StoragenodePayment_Receipt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f StoragenodePayment_Receipt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePayment_Notes_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func StoragenodePayment_Notes(v string) StoragenodePayment_Notes_Field {
	return StoragenodePayment_Notes_Field{_set: true, _value: &v}
}

func StoragenodePayment_Notes_Raw(v *string) StoragenodePayment_Notes_Field {
	if v == nil {
		return StoragenodePayment_Notes_Null()
	}
	return StoragenodePayment_Notes(*v)
}

func StoragenodePayment_Notes_Null() StoragenodePayment_Notes_Field {
	return StoragenodePayment_Notes_Field{_set: true, _null: true}
}

func (f StoragenodePayment_Notes_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f StoragenodePayment_Notes_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub struct {
	Period         string
	NodeId         []byte
	CreatedAt      time.Time
	Codes          string
	UsageAtRest    float64
	UsageGet       int64
	UsagePut       int64
	UsageGetRepair int64
	UsagePutRepair int64
	UsageGetAudit  int64
	CompAtRest     int64
	CompGet        int64
	CompPut        int64
	CompGetRepair  int64
	CompPutRepair  int64
	CompGetAudit   int64
	SurgePercent   int64
	Held           int64
	Owed           int64
	Disposed       int64
	Paid           int64
	Distributed    int64
}

func (StoragenodePaystub) _Table() string { return "storagenode_paystubs" }

type StoragenodePaystub_Update_Fields struct {
}

type StoragenodePaystub_Period_Field struct {
	_set   bool
	_null  bool
	_value string
}

func StoragenodePaystub_Period(v string) StoragenodePaystub_Period_Field {
	return StoragenodePaystub_Period_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_Period_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StoragenodePaystub_NodeId(v []byte) StoragenodePaystub_NodeId_Field {
	return StoragenodePaystub_NodeId_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_NodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StoragenodePaystub_CreatedAt(v time.Time) StoragenodePaystub_CreatedAt_Field {
	return StoragenodePaystub_CreatedAt_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_Codes_Field struct {
	_set   bool
	_null  bool
	_value string
}

func StoragenodePaystub_Codes(v string) StoragenodePaystub_Codes_Field {
	return StoragenodePaystub_Codes_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_Codes_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_UsageAtRest_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func StoragenodePaystub_UsageAtRest(v float64) StoragenodePaystub_UsageAtRest_Field {
	return StoragenodePaystub_UsageAtRest_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_UsageAtRest_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_UsageGet_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_UsageGet(v int64) StoragenodePaystub_UsageGet_Field {
	return StoragenodePaystub_UsageGet_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_UsageGet_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_UsagePut_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_UsagePut(v int64) StoragenodePaystub_UsagePut_Field {
	return StoragenodePaystub_UsagePut_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_UsagePut_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_UsageGetRepair_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_UsageGetRepair(v int64) StoragenodePaystub_UsageGetRepair_Field {
	return StoragenodePaystub_UsageGetRepair_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_UsageGetRepair_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_UsagePutRepair_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_UsagePutRepair(v int64) StoragenodePaystub_UsagePutRepair_Field {
	return StoragenodePaystub_UsagePutRepair_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_UsagePutRepair_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_UsageGetAudit_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_UsageGetAudit(v int64) StoragenodePaystub_UsageGetAudit_Field {
	return StoragenodePaystub_UsageGetAudit_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_UsageGetAudit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_CompAtRest_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_CompAtRest(v int64) StoragenodePaystub_CompAtRest_Field {
	return StoragenodePaystub_CompAtRest_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_CompAtRest_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_CompGet_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_CompGet(v int64) StoragenodePaystub_CompGet_Field {
	return StoragenodePaystub_CompGet_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_CompGet_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_CompPut_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_CompPut(v int64) StoragenodePaystub_CompPut_Field {
	return StoragenodePaystub_CompPut_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_CompPut_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_CompGetRepair_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_CompGetRepair(v int64) StoragenodePaystub_CompGetRepair_Field {
	return StoragenodePaystub_CompGetRepair_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_CompGetRepair_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_CompPutRepair_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_CompPutRepair(v int64) StoragenodePaystub_CompPutRepair_Field {
	return StoragenodePaystub_CompPutRepair_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_CompPutRepair_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_CompGetAudit_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_CompGetAudit(v int64) StoragenodePaystub_CompGetAudit_Field {
	return StoragenodePaystub_CompGetAudit_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_CompGetAudit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_SurgePercent_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_SurgePercent(v int64) StoragenodePaystub_SurgePercent_Field {
	return StoragenodePaystub_SurgePercent_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_SurgePercent_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_Held_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_Held(v int64) StoragenodePaystub_Held_Field {
	return StoragenodePaystub_Held_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_Held_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_Owed_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_Owed(v int64) StoragenodePaystub_Owed_Field {
	return StoragenodePaystub_Owed_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_Owed_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_Disposed_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_Disposed(v int64) StoragenodePaystub_Disposed_Field {
	return StoragenodePaystub_Disposed_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_Disposed_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_Paid_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_Paid(v int64) StoragenodePaystub_Paid_Field {
	return StoragenodePaystub_Paid_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_Paid_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodePaystub_Distributed_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StoragenodePaystub_Distributed(v int64) StoragenodePaystub_Distributed_Field {
	return StoragenodePaystub_Distributed_Field{_set: true, _value: v}
}

func (f StoragenodePaystub_Distributed_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeStorageTally struct {
	NodeId          []byte
	IntervalEndTime time.Time
	DataTotal       float64
}

func (StoragenodeStorageTally) _Table() string { return "storagenode_storage_tallies" }

type StoragenodeStorageTally_Update_Fields struct {
}

type StoragenodeStorageTally_NodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StoragenodeStorageTally_NodeId(v []byte) StoragenodeStorageTally_NodeId_Field {
	return StoragenodeStorageTally_NodeId_Field{_set: true, _value: v}
}

func (f StoragenodeStorageTally_NodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeStorageTally_IntervalEndTime_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StoragenodeStorageTally_IntervalEndTime(v time.Time) StoragenodeStorageTally_IntervalEndTime_Field {
	return StoragenodeStorageTally_IntervalEndTime_Field{_set: true, _value: v}
}

func (f StoragenodeStorageTally_IntervalEndTime_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StoragenodeStorageTally_DataTotal_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func StoragenodeStorageTally_DataTotal(v float64) StoragenodeStorageTally_DataTotal_Field {
	return StoragenodeStorageTally_DataTotal_Field{_set: true, _value: v}
}

func (f StoragenodeStorageTally_DataTotal_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment struct {
	ChainId        int64
	BlockHash      []byte
	BlockNumber    int64
	Transaction    []byte
	LogIndex       int
	FromAddress    []byte
	ToAddress      []byte
	TokenValue     int64
	UsdValue       int64
	Status         string
	BlockTimestamp time.Time
	CreatedAt      time.Time
}

func (StorjscanPayment) _Table() string { return "storjscan_payments" }

type StorjscanPayment_Create_Fields struct {
	ChainId StorjscanPayment_ChainId_Field
}

type StorjscanPayment_Update_Fields struct {
}

type StorjscanPayment_ChainId_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StorjscanPayment_ChainId(v int64) StorjscanPayment_ChainId_Field {
	return StorjscanPayment_ChainId_Field{_set: true, _value: v}
}

func (f StorjscanPayment_ChainId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_BlockHash_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StorjscanPayment_BlockHash(v []byte) StorjscanPayment_BlockHash_Field {
	return StorjscanPayment_BlockHash_Field{_set: true, _value: v}
}

func (f StorjscanPayment_BlockHash_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_BlockNumber_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StorjscanPayment_BlockNumber(v int64) StorjscanPayment_BlockNumber_Field {
	return StorjscanPayment_BlockNumber_Field{_set: true, _value: v}
}

func (f StorjscanPayment_BlockNumber_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_Transaction_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StorjscanPayment_Transaction(v []byte) StorjscanPayment_Transaction_Field {
	return StorjscanPayment_Transaction_Field{_set: true, _value: v}
}

func (f StorjscanPayment_Transaction_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_LogIndex_Field struct {
	_set   bool
	_null  bool
	_value int
}

func StorjscanPayment_LogIndex(v int) StorjscanPayment_LogIndex_Field {
	return StorjscanPayment_LogIndex_Field{_set: true, _value: v}
}

func (f StorjscanPayment_LogIndex_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_FromAddress_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StorjscanPayment_FromAddress(v []byte) StorjscanPayment_FromAddress_Field {
	return StorjscanPayment_FromAddress_Field{_set: true, _value: v}
}

func (f StorjscanPayment_FromAddress_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_ToAddress_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StorjscanPayment_ToAddress(v []byte) StorjscanPayment_ToAddress_Field {
	return StorjscanPayment_ToAddress_Field{_set: true, _value: v}
}

func (f StorjscanPayment_ToAddress_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_TokenValue_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StorjscanPayment_TokenValue(v int64) StorjscanPayment_TokenValue_Field {
	return StorjscanPayment_TokenValue_Field{_set: true, _value: v}
}

func (f StorjscanPayment_TokenValue_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_UsdValue_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StorjscanPayment_UsdValue(v int64) StorjscanPayment_UsdValue_Field {
	return StorjscanPayment_UsdValue_Field{_set: true, _value: v}
}

func (f StorjscanPayment_UsdValue_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_Status_Field struct {
	_set   bool
	_null  bool
	_value string
}

func StorjscanPayment_Status(v string) StorjscanPayment_Status_Field {
	return StorjscanPayment_Status_Field{_set: true, _value: v}
}

func (f StorjscanPayment_Status_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_BlockTimestamp_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StorjscanPayment_BlockTimestamp(v time.Time) StorjscanPayment_BlockTimestamp_Field {
	return StorjscanPayment_BlockTimestamp_Field{_set: true, _value: v}
}

func (f StorjscanPayment_BlockTimestamp_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanPayment_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StorjscanPayment_CreatedAt(v time.Time) StorjscanPayment_CreatedAt_Field {
	return StorjscanPayment_CreatedAt_Field{_set: true, _value: v}
}

func (f StorjscanPayment_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanWallet struct {
	UserId        []byte
	WalletAddress []byte
	CreatedAt     time.Time
}

func (StorjscanWallet) _Table() string { return "storjscan_wallets" }

type StorjscanWallet_Update_Fields struct {
}

type StorjscanWallet_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StorjscanWallet_UserId(v []byte) StorjscanWallet_UserId_Field {
	return StorjscanWallet_UserId_Field{_set: true, _value: v}
}

func (f StorjscanWallet_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanWallet_WalletAddress_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StorjscanWallet_WalletAddress(v []byte) StorjscanWallet_WalletAddress_Field {
	return StorjscanWallet_WalletAddress_Field{_set: true, _value: v}
}

func (f StorjscanWallet_WalletAddress_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StorjscanWallet_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StorjscanWallet_CreatedAt(v time.Time) StorjscanWallet_CreatedAt_Field {
	return StorjscanWallet_CreatedAt_Field{_set: true, _value: v}
}

func (f StorjscanWallet_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripeCustomer struct {
	UserId             []byte
	CustomerId         string
	BillingCustomerId  *string
	PackagePlan        *string
	PurchasedPackageAt *time.Time
	CreatedAt          time.Time
}

func (StripeCustomer) _Table() string { return "stripe_customers" }

type StripeCustomer_Create_Fields struct {
	BillingCustomerId  StripeCustomer_BillingCustomerId_Field
	PackagePlan        StripeCustomer_PackagePlan_Field
	PurchasedPackageAt StripeCustomer_PurchasedPackageAt_Field
}

type StripeCustomer_Update_Fields struct {
	BillingCustomerId  StripeCustomer_BillingCustomerId_Field
	PackagePlan        StripeCustomer_PackagePlan_Field
	PurchasedPackageAt StripeCustomer_PurchasedPackageAt_Field
}

type StripeCustomer_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StripeCustomer_UserId(v []byte) StripeCustomer_UserId_Field {
	return StripeCustomer_UserId_Field{_set: true, _value: v}
}

func (f StripeCustomer_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripeCustomer_CustomerId_Field struct {
	_set   bool
	_null  bool
	_value string
}

func StripeCustomer_CustomerId(v string) StripeCustomer_CustomerId_Field {
	return StripeCustomer_CustomerId_Field{_set: true, _value: v}
}

func (f StripeCustomer_CustomerId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripeCustomer_BillingCustomerId_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func StripeCustomer_BillingCustomerId(v string) StripeCustomer_BillingCustomerId_Field {
	return StripeCustomer_BillingCustomerId_Field{_set: true, _value: &v}
}

func StripeCustomer_BillingCustomerId_Raw(v *string) StripeCustomer_BillingCustomerId_Field {
	if v == nil {
		return StripeCustomer_BillingCustomerId_Null()
	}
	return StripeCustomer_BillingCustomerId(*v)
}

func StripeCustomer_BillingCustomerId_Null() StripeCustomer_BillingCustomerId_Field {
	return StripeCustomer_BillingCustomerId_Field{_set: true, _null: true}
}

func (f StripeCustomer_BillingCustomerId_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f StripeCustomer_BillingCustomerId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripeCustomer_PackagePlan_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func StripeCustomer_PackagePlan(v string) StripeCustomer_PackagePlan_Field {
	return StripeCustomer_PackagePlan_Field{_set: true, _value: &v}
}

func StripeCustomer_PackagePlan_Raw(v *string) StripeCustomer_PackagePlan_Field {
	if v == nil {
		return StripeCustomer_PackagePlan_Null()
	}
	return StripeCustomer_PackagePlan(*v)
}

func StripeCustomer_PackagePlan_Null() StripeCustomer_PackagePlan_Field {
	return StripeCustomer_PackagePlan_Field{_set: true, _null: true}
}

func (f StripeCustomer_PackagePlan_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f StripeCustomer_PackagePlan_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripeCustomer_PurchasedPackageAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func StripeCustomer_PurchasedPackageAt(v time.Time) StripeCustomer_PurchasedPackageAt_Field {
	return StripeCustomer_PurchasedPackageAt_Field{_set: true, _value: &v}
}

func StripeCustomer_PurchasedPackageAt_Raw(v *time.Time) StripeCustomer_PurchasedPackageAt_Field {
	if v == nil {
		return StripeCustomer_PurchasedPackageAt_Null()
	}
	return StripeCustomer_PurchasedPackageAt(*v)
}

func StripeCustomer_PurchasedPackageAt_Null() StripeCustomer_PurchasedPackageAt_Field {
	return StripeCustomer_PurchasedPackageAt_Field{_set: true, _null: true}
}

func (f StripeCustomer_PurchasedPackageAt_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f StripeCustomer_PurchasedPackageAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripeCustomer_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StripeCustomer_CreatedAt(v time.Time) StripeCustomer_CreatedAt_Field {
	return StripeCustomer_CreatedAt_Field{_set: true, _value: v}
}

func (f StripeCustomer_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord struct {
	Id          []byte
	ProjectId   []byte
	Storage     float64
	Egress      int64
	Objects     *int64
	Segments    *int64
	PeriodStart time.Time
	PeriodEnd   time.Time
	State       int
	CreatedAt   time.Time
}

func (StripecoinpaymentsInvoiceProjectRecord) _Table() string {
	return "stripecoinpayments_invoice_project_records"
}

type StripecoinpaymentsInvoiceProjectRecord_Create_Fields struct {
	Objects  StripecoinpaymentsInvoiceProjectRecord_Objects_Field
	Segments StripecoinpaymentsInvoiceProjectRecord_Segments_Field
}

type StripecoinpaymentsInvoiceProjectRecord_Update_Fields struct {
	State StripecoinpaymentsInvoiceProjectRecord_State_Field
}

type StripecoinpaymentsInvoiceProjectRecord_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StripecoinpaymentsInvoiceProjectRecord_Id(v []byte) StripecoinpaymentsInvoiceProjectRecord_Id_Field {
	return StripecoinpaymentsInvoiceProjectRecord_Id_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsInvoiceProjectRecord_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func StripecoinpaymentsInvoiceProjectRecord_ProjectId(v []byte) StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field {
	return StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord_Storage_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func StripecoinpaymentsInvoiceProjectRecord_Storage(v float64) StripecoinpaymentsInvoiceProjectRecord_Storage_Field {
	return StripecoinpaymentsInvoiceProjectRecord_Storage_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsInvoiceProjectRecord_Storage_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord_Egress_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func StripecoinpaymentsInvoiceProjectRecord_Egress(v int64) StripecoinpaymentsInvoiceProjectRecord_Egress_Field {
	return StripecoinpaymentsInvoiceProjectRecord_Egress_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsInvoiceProjectRecord_Egress_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord_Objects_Field struct {
	_set   bool
	_null  bool
	_value *int64
}

func StripecoinpaymentsInvoiceProjectRecord_Objects(v int64) StripecoinpaymentsInvoiceProjectRecord_Objects_Field {
	return StripecoinpaymentsInvoiceProjectRecord_Objects_Field{_set: true, _value: &v}
}

func StripecoinpaymentsInvoiceProjectRecord_Objects_Raw(v *int64) StripecoinpaymentsInvoiceProjectRecord_Objects_Field {
	if v == nil {
		return StripecoinpaymentsInvoiceProjectRecord_Objects_Null()
	}
	return StripecoinpaymentsInvoiceProjectRecord_Objects(*v)
}

func StripecoinpaymentsInvoiceProjectRecord_Objects_Null() StripecoinpaymentsInvoiceProjectRecord_Objects_Field {
	return StripecoinpaymentsInvoiceProjectRecord_Objects_Field{_set: true, _null: true}
}

func (f StripecoinpaymentsInvoiceProjectRecord_Objects_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f StripecoinpaymentsInvoiceProjectRecord_Objects_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord_Segments_Field struct {
	_set   bool
	_null  bool
	_value *int64
}

func StripecoinpaymentsInvoiceProjectRecord_Segments(v int64) StripecoinpaymentsInvoiceProjectRecord_Segments_Field {
	return StripecoinpaymentsInvoiceProjectRecord_Segments_Field{_set: true, _value: &v}
}

func StripecoinpaymentsInvoiceProjectRecord_Segments_Raw(v *int64) StripecoinpaymentsInvoiceProjectRecord_Segments_Field {
	if v == nil {
		return StripecoinpaymentsInvoiceProjectRecord_Segments_Null()
	}
	return StripecoinpaymentsInvoiceProjectRecord_Segments(*v)
}

func StripecoinpaymentsInvoiceProjectRecord_Segments_Null() StripecoinpaymentsInvoiceProjectRecord_Segments_Field {
	return StripecoinpaymentsInvoiceProjectRecord_Segments_Field{_set: true, _null: true}
}

func (f StripecoinpaymentsInvoiceProjectRecord_Segments_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f StripecoinpaymentsInvoiceProjectRecord_Segments_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StripecoinpaymentsInvoiceProjectRecord_PeriodStart(v time.Time) StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field {
	return StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StripecoinpaymentsInvoiceProjectRecord_PeriodEnd(v time.Time) StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field {
	return StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord_State_Field struct {
	_set   bool
	_null  bool
	_value int
}

func StripecoinpaymentsInvoiceProjectRecord_State(v int) StripecoinpaymentsInvoiceProjectRecord_State_Field {
	return StripecoinpaymentsInvoiceProjectRecord_State_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsInvoiceProjectRecord_State_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsInvoiceProjectRecord_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StripecoinpaymentsInvoiceProjectRecord_CreatedAt(v time.Time) StripecoinpaymentsInvoiceProjectRecord_CreatedAt_Field {
	return StripecoinpaymentsInvoiceProjectRecord_CreatedAt_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsInvoiceProjectRecord_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsTxConversionRate struct {
	TxId        string
	RateNumeric float64
	CreatedAt   time.Time
}

func (StripecoinpaymentsTxConversionRate) _Table() string {
	return "stripecoinpayments_tx_conversion_rates"
}

type StripecoinpaymentsTxConversionRate_Update_Fields struct {
}

type StripecoinpaymentsTxConversionRate_TxId_Field struct {
	_set   bool
	_null  bool
	_value string
}

func StripecoinpaymentsTxConversionRate_TxId(v string) StripecoinpaymentsTxConversionRate_TxId_Field {
	return StripecoinpaymentsTxConversionRate_TxId_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsTxConversionRate_TxId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsTxConversionRate_RateNumeric_Field struct {
	_set   bool
	_null  bool
	_value float64
}

func StripecoinpaymentsTxConversionRate_RateNumeric(v float64) StripecoinpaymentsTxConversionRate_RateNumeric_Field {
	return StripecoinpaymentsTxConversionRate_RateNumeric_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsTxConversionRate_RateNumeric_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsTxConversionRate_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StripecoinpaymentsTxConversionRate_CreatedAt(v time.Time) StripecoinpaymentsTxConversionRate_CreatedAt_Field {
	return StripecoinpaymentsTxConversionRate_CreatedAt_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsTxConversionRate_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User struct {
	Id                          []byte
	ExternalId                  *string
	TenantId                    *string
	Email                       string
	NormalizedEmail             string
	FullName                    string
	ShortName                   *string
	PasswordHash                []byte
	NewUnverifiedEmail          *string
	EmailChangeVerificationStep int
	Status                      int
	StatusUpdatedAt             *time.Time
	FinalInvoiceGenerated       bool
	UserAgent                   []byte
	CreatedAt                   time.Time
	ProjectLimit                int
	ProjectBandwidthLimit       int64
	ProjectStorageLimit         int64
	ProjectSegmentLimit         int64
	Kind                        int
	Position                    *string
	CompanyName                 *string
	CompanySize                 *int
	WorkingOn                   *string
	IsProfessional              bool
	EmployeeCount               *string
	HaveSalesContact            bool
	MfaEnabled                  bool
	MfaSecretKey                *string
	MfaRecoveryCodes            *string
	SignupPromoCode             *string
	VerificationReminders       int
	TrialNotifications          int
	FailedLoginCount            *int
	LoginLockoutExpiration      *time.Time
	SignupCaptcha               *float64
	DefaultPlacement            *int
	ActivationCode              *string
	SignupId                    *string
	TrialExpiration             *time.Time
	UpgradeTime                 *time.Time
	HubspotObjectId             *string
}

func (User) _Table() string { return "users" }

type User_Create_Fields struct {
	ExternalId                  User_ExternalId_Field
	TenantId                    User_TenantId_Field
	ShortName                   User_ShortName_Field
	NewUnverifiedEmail          User_NewUnverifiedEmail_Field
	EmailChangeVerificationStep User_EmailChangeVerificationStep_Field
	StatusUpdatedAt             User_StatusUpdatedAt_Field
	FinalInvoiceGenerated       User_FinalInvoiceGenerated_Field
	UserAgent                   User_UserAgent_Field
	ProjectLimit                User_ProjectLimit_Field
	ProjectBandwidthLimit       User_ProjectBandwidthLimit_Field
	ProjectStorageLimit         User_ProjectStorageLimit_Field
	ProjectSegmentLimit         User_ProjectSegmentLimit_Field
	Kind                        User_Kind_Field
	Position                    User_Position_Field
	CompanyName                 User_CompanyName_Field
	CompanySize                 User_CompanySize_Field
	WorkingOn                   User_WorkingOn_Field
	IsProfessional              User_IsProfessional_Field
	EmployeeCount               User_EmployeeCount_Field
	HaveSalesContact            User_HaveSalesContact_Field
	MfaEnabled                  User_MfaEnabled_Field
	MfaSecretKey                User_MfaSecretKey_Field
	MfaRecoveryCodes            User_MfaRecoveryCodes_Field
	SignupPromoCode             User_SignupPromoCode_Field
	VerificationReminders       User_VerificationReminders_Field
	TrialNotifications          User_TrialNotifications_Field
	FailedLoginCount            User_FailedLoginCount_Field
	LoginLockoutExpiration      User_LoginLockoutExpiration_Field
	SignupCaptcha               User_SignupCaptcha_Field
	DefaultPlacement            User_DefaultPlacement_Field
	ActivationCode              User_ActivationCode_Field
	SignupId                    User_SignupId_Field
	TrialExpiration             User_TrialExpiration_Field
	UpgradeTime                 User_UpgradeTime_Field
	HubspotObjectId             User_HubspotObjectId_Field
}

type User_Update_Fields struct {
	ExternalId                  User_ExternalId_Field
	TenantId                    User_TenantId_Field
	Email                       User_Email_Field
	NormalizedEmail             User_NormalizedEmail_Field
	FullName                    User_FullName_Field
	ShortName                   User_ShortName_Field
	PasswordHash                User_PasswordHash_Field
	NewUnverifiedEmail          User_NewUnverifiedEmail_Field
	EmailChangeVerificationStep User_EmailChangeVerificationStep_Field
	Status                      User_Status_Field
	StatusUpdatedAt             User_StatusUpdatedAt_Field
	FinalInvoiceGenerated       User_FinalInvoiceGenerated_Field
	UserAgent                   User_UserAgent_Field
	ProjectLimit                User_ProjectLimit_Field
	ProjectBandwidthLimit       User_ProjectBandwidthLimit_Field
	ProjectStorageLimit         User_ProjectStorageLimit_Field
	ProjectSegmentLimit         User_ProjectSegmentLimit_Field
	Kind                        User_Kind_Field
	Position                    User_Position_Field
	CompanyName                 User_CompanyName_Field
	CompanySize                 User_CompanySize_Field
	WorkingOn                   User_WorkingOn_Field
	IsProfessional              User_IsProfessional_Field
	EmployeeCount               User_EmployeeCount_Field
	HaveSalesContact            User_HaveSalesContact_Field
	MfaEnabled                  User_MfaEnabled_Field
	MfaSecretKey                User_MfaSecretKey_Field
	MfaRecoveryCodes            User_MfaRecoveryCodes_Field
	SignupPromoCode             User_SignupPromoCode_Field
	VerificationReminders       User_VerificationReminders_Field
	TrialNotifications          User_TrialNotifications_Field
	FailedLoginCount            User_FailedLoginCount_Field
	LoginLockoutExpiration      User_LoginLockoutExpiration_Field
	DefaultPlacement            User_DefaultPlacement_Field
	ActivationCode              User_ActivationCode_Field
	SignupId                    User_SignupId_Field
	TrialExpiration             User_TrialExpiration_Field
	UpgradeTime                 User_UpgradeTime_Field
	HubspotObjectId             User_HubspotObjectId_Field
}

type User_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func User_Id(v []byte) User_Id_Field {
	return User_Id_Field{_set: true, _value: v}
}

func (f User_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_ExternalId_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_ExternalId(v string) User_ExternalId_Field {
	return User_ExternalId_Field{_set: true, _value: &v}
}

func User_ExternalId_Raw(v *string) User_ExternalId_Field {
	if v == nil {
		return User_ExternalId_Null()
	}
	return User_ExternalId(*v)
}

func User_ExternalId_Null() User_ExternalId_Field {
	return User_ExternalId_Field{_set: true, _null: true}
}

func (f User_ExternalId_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_ExternalId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_TenantId_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_TenantId(v string) User_TenantId_Field {
	return User_TenantId_Field{_set: true, _value: &v}
}

func User_TenantId_Raw(v *string) User_TenantId_Field {
	if v == nil {
		return User_TenantId_Null()
	}
	return User_TenantId(*v)
}

func User_TenantId_Null() User_TenantId_Field {
	return User_TenantId_Field{_set: true, _null: true}
}

func (f User_TenantId_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_TenantId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_Email_Field struct {
	_set   bool
	_null  bool
	_value string
}

func User_Email(v string) User_Email_Field {
	return User_Email_Field{_set: true, _value: v}
}

func (f User_Email_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_NormalizedEmail_Field struct {
	_set   bool
	_null  bool
	_value string
}

func User_NormalizedEmail(v string) User_NormalizedEmail_Field {
	return User_NormalizedEmail_Field{_set: true, _value: v}
}

func (f User_NormalizedEmail_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_FullName_Field struct {
	_set   bool
	_null  bool
	_value string
}

func User_FullName(v string) User_FullName_Field {
	return User_FullName_Field{_set: true, _value: v}
}

func (f User_FullName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_ShortName_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_ShortName(v string) User_ShortName_Field {
	return User_ShortName_Field{_set: true, _value: &v}
}

func User_ShortName_Raw(v *string) User_ShortName_Field {
	if v == nil {
		return User_ShortName_Null()
	}
	return User_ShortName(*v)
}

func User_ShortName_Null() User_ShortName_Field {
	return User_ShortName_Field{_set: true, _null: true}
}

func (f User_ShortName_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_ShortName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_PasswordHash_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func User_PasswordHash(v []byte) User_PasswordHash_Field {
	return User_PasswordHash_Field{_set: true, _value: v}
}

func (f User_PasswordHash_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_NewUnverifiedEmail_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_NewUnverifiedEmail(v string) User_NewUnverifiedEmail_Field {
	return User_NewUnverifiedEmail_Field{_set: true, _value: &v}
}

func User_NewUnverifiedEmail_Raw(v *string) User_NewUnverifiedEmail_Field {
	if v == nil {
		return User_NewUnverifiedEmail_Null()
	}
	return User_NewUnverifiedEmail(*v)
}

func User_NewUnverifiedEmail_Null() User_NewUnverifiedEmail_Field {
	return User_NewUnverifiedEmail_Field{_set: true, _null: true}
}

func (f User_NewUnverifiedEmail_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_NewUnverifiedEmail_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_EmailChangeVerificationStep_Field struct {
	_set   bool
	_null  bool
	_value int
}

func User_EmailChangeVerificationStep(v int) User_EmailChangeVerificationStep_Field {
	return User_EmailChangeVerificationStep_Field{_set: true, _value: v}
}

func (f User_EmailChangeVerificationStep_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_Status_Field struct {
	_set   bool
	_null  bool
	_value int
}

func User_Status(v int) User_Status_Field {
	return User_Status_Field{_set: true, _value: v}
}

func (f User_Status_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_StatusUpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func User_StatusUpdatedAt(v time.Time) User_StatusUpdatedAt_Field {
	return User_StatusUpdatedAt_Field{_set: true, _value: &v}
}

func User_StatusUpdatedAt_Raw(v *time.Time) User_StatusUpdatedAt_Field {
	if v == nil {
		return User_StatusUpdatedAt_Null()
	}
	return User_StatusUpdatedAt(*v)
}

func User_StatusUpdatedAt_Null() User_StatusUpdatedAt_Field {
	return User_StatusUpdatedAt_Field{_set: true, _null: true}
}

func (f User_StatusUpdatedAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_StatusUpdatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_FinalInvoiceGenerated_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func User_FinalInvoiceGenerated(v bool) User_FinalInvoiceGenerated_Field {
	return User_FinalInvoiceGenerated_Field{_set: true, _value: v}
}

func (f User_FinalInvoiceGenerated_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_UserAgent_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func User_UserAgent(v []byte) User_UserAgent_Field {
	return User_UserAgent_Field{_set: true, _value: v}
}

func User_UserAgent_Raw(v []byte) User_UserAgent_Field {
	if v == nil {
		return User_UserAgent_Null()
	}
	return User_UserAgent(v)
}

func User_UserAgent_Null() User_UserAgent_Field {
	return User_UserAgent_Field{_set: true, _null: true}
}

func (f User_UserAgent_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_UserAgent_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func User_CreatedAt(v time.Time) User_CreatedAt_Field {
	return User_CreatedAt_Field{_set: true, _value: v}
}

func (f User_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_ProjectLimit_Field struct {
	_set   bool
	_null  bool
	_value int
}

func User_ProjectLimit(v int) User_ProjectLimit_Field {
	return User_ProjectLimit_Field{_set: true, _value: v}
}

func (f User_ProjectLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_ProjectBandwidthLimit_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func User_ProjectBandwidthLimit(v int64) User_ProjectBandwidthLimit_Field {
	return User_ProjectBandwidthLimit_Field{_set: true, _value: v}
}

func (f User_ProjectBandwidthLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_ProjectStorageLimit_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func User_ProjectStorageLimit(v int64) User_ProjectStorageLimit_Field {
	return User_ProjectStorageLimit_Field{_set: true, _value: v}
}

func (f User_ProjectStorageLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_ProjectSegmentLimit_Field struct {
	_set   bool
	_null  bool
	_value int64
}

func User_ProjectSegmentLimit(v int64) User_ProjectSegmentLimit_Field {
	return User_ProjectSegmentLimit_Field{_set: true, _value: v}
}

func (f User_ProjectSegmentLimit_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_Kind_Field struct {
	_set   bool
	_null  bool
	_value int
}

func User_Kind(v int) User_Kind_Field {
	return User_Kind_Field{_set: true, _value: v}
}

func (f User_Kind_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_Position_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_Position(v string) User_Position_Field {
	return User_Position_Field{_set: true, _value: &v}
}

func User_Position_Raw(v *string) User_Position_Field {
	if v == nil {
		return User_Position_Null()
	}
	return User_Position(*v)
}

func User_Position_Null() User_Position_Field {
	return User_Position_Field{_set: true, _null: true}
}

func (f User_Position_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_Position_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_CompanyName_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_CompanyName(v string) User_CompanyName_Field {
	return User_CompanyName_Field{_set: true, _value: &v}
}

func User_CompanyName_Raw(v *string) User_CompanyName_Field {
	if v == nil {
		return User_CompanyName_Null()
	}
	return User_CompanyName(*v)
}

func User_CompanyName_Null() User_CompanyName_Field {
	return User_CompanyName_Field{_set: true, _null: true}
}

func (f User_CompanyName_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_CompanyName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_CompanySize_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func User_CompanySize(v int) User_CompanySize_Field {
	return User_CompanySize_Field{_set: true, _value: &v}
}

func User_CompanySize_Raw(v *int) User_CompanySize_Field {
	if v == nil {
		return User_CompanySize_Null()
	}
	return User_CompanySize(*v)
}

func User_CompanySize_Null() User_CompanySize_Field {
	return User_CompanySize_Field{_set: true, _null: true}
}

func (f User_CompanySize_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_CompanySize_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_WorkingOn_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_WorkingOn(v string) User_WorkingOn_Field {
	return User_WorkingOn_Field{_set: true, _value: &v}
}

func User_WorkingOn_Raw(v *string) User_WorkingOn_Field {
	if v == nil {
		return User_WorkingOn_Null()
	}
	return User_WorkingOn(*v)
}

func User_WorkingOn_Null() User_WorkingOn_Field {
	return User_WorkingOn_Field{_set: true, _null: true}
}

func (f User_WorkingOn_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_WorkingOn_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_IsProfessional_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func User_IsProfessional(v bool) User_IsProfessional_Field {
	return User_IsProfessional_Field{_set: true, _value: v}
}

func (f User_IsProfessional_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_EmployeeCount_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_EmployeeCount(v string) User_EmployeeCount_Field {
	return User_EmployeeCount_Field{_set: true, _value: &v}
}

func User_EmployeeCount_Raw(v *string) User_EmployeeCount_Field {
	if v == nil {
		return User_EmployeeCount_Null()
	}
	return User_EmployeeCount(*v)
}

func User_EmployeeCount_Null() User_EmployeeCount_Field {
	return User_EmployeeCount_Field{_set: true, _null: true}
}

func (f User_EmployeeCount_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_EmployeeCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_HaveSalesContact_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func User_HaveSalesContact(v bool) User_HaveSalesContact_Field {
	return User_HaveSalesContact_Field{_set: true, _value: v}
}

func (f User_HaveSalesContact_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_MfaEnabled_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func User_MfaEnabled(v bool) User_MfaEnabled_Field {
	return User_MfaEnabled_Field{_set: true, _value: v}
}

func (f User_MfaEnabled_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_MfaSecretKey_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_MfaSecretKey(v string) User_MfaSecretKey_Field {
	return User_MfaSecretKey_Field{_set: true, _value: &v}
}

func User_MfaSecretKey_Raw(v *string) User_MfaSecretKey_Field {
	if v == nil {
		return User_MfaSecretKey_Null()
	}
	return User_MfaSecretKey(*v)
}

func User_MfaSecretKey_Null() User_MfaSecretKey_Field {
	return User_MfaSecretKey_Field{_set: true, _null: true}
}

func (f User_MfaSecretKey_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_MfaSecretKey_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_MfaRecoveryCodes_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_MfaRecoveryCodes(v string) User_MfaRecoveryCodes_Field {
	return User_MfaRecoveryCodes_Field{_set: true, _value: &v}
}

func User_MfaRecoveryCodes_Raw(v *string) User_MfaRecoveryCodes_Field {
	if v == nil {
		return User_MfaRecoveryCodes_Null()
	}
	return User_MfaRecoveryCodes(*v)
}

func User_MfaRecoveryCodes_Null() User_MfaRecoveryCodes_Field {
	return User_MfaRecoveryCodes_Field{_set: true, _null: true}
}

func (f User_MfaRecoveryCodes_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_MfaRecoveryCodes_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_SignupPromoCode_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_SignupPromoCode(v string) User_SignupPromoCode_Field {
	return User_SignupPromoCode_Field{_set: true, _value: &v}
}

func User_SignupPromoCode_Raw(v *string) User_SignupPromoCode_Field {
	if v == nil {
		return User_SignupPromoCode_Null()
	}
	return User_SignupPromoCode(*v)
}

func User_SignupPromoCode_Null() User_SignupPromoCode_Field {
	return User_SignupPromoCode_Field{_set: true, _null: true}
}

func (f User_SignupPromoCode_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_SignupPromoCode_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_VerificationReminders_Field struct {
	_set   bool
	_null  bool
	_value int
}

func User_VerificationReminders(v int) User_VerificationReminders_Field {
	return User_VerificationReminders_Field{_set: true, _value: v}
}

func (f User_VerificationReminders_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_TrialNotifications_Field struct {
	_set   bool
	_null  bool
	_value int
}

func User_TrialNotifications(v int) User_TrialNotifications_Field {
	return User_TrialNotifications_Field{_set: true, _value: v}
}

func (f User_TrialNotifications_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_FailedLoginCount_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func User_FailedLoginCount(v int) User_FailedLoginCount_Field {
	return User_FailedLoginCount_Field{_set: true, _value: &v}
}

func User_FailedLoginCount_Raw(v *int) User_FailedLoginCount_Field {
	if v == nil {
		return User_FailedLoginCount_Null()
	}
	return User_FailedLoginCount(*v)
}

func User_FailedLoginCount_Null() User_FailedLoginCount_Field {
	return User_FailedLoginCount_Field{_set: true, _null: true}
}

func (f User_FailedLoginCount_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_FailedLoginCount_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_LoginLockoutExpiration_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func User_LoginLockoutExpiration(v time.Time) User_LoginLockoutExpiration_Field {
	return User_LoginLockoutExpiration_Field{_set: true, _value: &v}
}

func User_LoginLockoutExpiration_Raw(v *time.Time) User_LoginLockoutExpiration_Field {
	if v == nil {
		return User_LoginLockoutExpiration_Null()
	}
	return User_LoginLockoutExpiration(*v)
}

func User_LoginLockoutExpiration_Null() User_LoginLockoutExpiration_Field {
	return User_LoginLockoutExpiration_Field{_set: true, _null: true}
}

func (f User_LoginLockoutExpiration_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f User_LoginLockoutExpiration_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_SignupCaptcha_Field struct {
	_set   bool
	_null  bool
	_value *float64
}

func User_SignupCaptcha(v float64) User_SignupCaptcha_Field {
	return User_SignupCaptcha_Field{_set: true, _value: &v}
}

func User_SignupCaptcha_Raw(v *float64) User_SignupCaptcha_Field {
	if v == nil {
		return User_SignupCaptcha_Null()
	}
	return User_SignupCaptcha(*v)
}

func User_SignupCaptcha_Null() User_SignupCaptcha_Field {
	return User_SignupCaptcha_Field{_set: true, _null: true}
}

func (f User_SignupCaptcha_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_SignupCaptcha_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_DefaultPlacement_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func User_DefaultPlacement(v int) User_DefaultPlacement_Field {
	return User_DefaultPlacement_Field{_set: true, _value: &v}
}

func User_DefaultPlacement_Raw(v *int) User_DefaultPlacement_Field {
	if v == nil {
		return User_DefaultPlacement_Null()
	}
	return User_DefaultPlacement(*v)
}

func User_DefaultPlacement_Null() User_DefaultPlacement_Field {
	return User_DefaultPlacement_Field{_set: true, _null: true}
}

func (f User_DefaultPlacement_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_DefaultPlacement_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_ActivationCode_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_ActivationCode(v string) User_ActivationCode_Field {
	return User_ActivationCode_Field{_set: true, _value: &v}
}

func User_ActivationCode_Raw(v *string) User_ActivationCode_Field {
	if v == nil {
		return User_ActivationCode_Null()
	}
	return User_ActivationCode(*v)
}

func User_ActivationCode_Null() User_ActivationCode_Field {
	return User_ActivationCode_Field{_set: true, _null: true}
}

func (f User_ActivationCode_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_ActivationCode_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_SignupId_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_SignupId(v string) User_SignupId_Field {
	return User_SignupId_Field{_set: true, _value: &v}
}

func User_SignupId_Raw(v *string) User_SignupId_Field {
	if v == nil {
		return User_SignupId_Null()
	}
	return User_SignupId(*v)
}

func User_SignupId_Null() User_SignupId_Field {
	return User_SignupId_Field{_set: true, _null: true}
}

func (f User_SignupId_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_SignupId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_TrialExpiration_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func User_TrialExpiration(v time.Time) User_TrialExpiration_Field {
	return User_TrialExpiration_Field{_set: true, _value: &v}
}

func User_TrialExpiration_Raw(v *time.Time) User_TrialExpiration_Field {
	if v == nil {
		return User_TrialExpiration_Null()
	}
	return User_TrialExpiration(*v)
}

func User_TrialExpiration_Null() User_TrialExpiration_Field {
	return User_TrialExpiration_Field{_set: true, _null: true}
}

func (f User_TrialExpiration_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_TrialExpiration_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_UpgradeTime_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func User_UpgradeTime(v time.Time) User_UpgradeTime_Field {
	return User_UpgradeTime_Field{_set: true, _value: &v}
}

func User_UpgradeTime_Raw(v *time.Time) User_UpgradeTime_Field {
	if v == nil {
		return User_UpgradeTime_Null()
	}
	return User_UpgradeTime(*v)
}

func User_UpgradeTime_Null() User_UpgradeTime_Field {
	return User_UpgradeTime_Field{_set: true, _null: true}
}

func (f User_UpgradeTime_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_UpgradeTime_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type User_HubspotObjectId_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func User_HubspotObjectId(v string) User_HubspotObjectId_Field {
	return User_HubspotObjectId_Field{_set: true, _value: &v}
}

func User_HubspotObjectId_Raw(v *string) User_HubspotObjectId_Field {
	if v == nil {
		return User_HubspotObjectId_Null()
	}
	return User_HubspotObjectId(*v)
}

func User_HubspotObjectId_Null() User_HubspotObjectId_Field {
	return User_HubspotObjectId_Field{_set: true, _null: true}
}

func (f User_HubspotObjectId_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f User_HubspotObjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type UserSettings struct {
	UserId           []byte
	SessionMinutes   *uint
	PassphrasePrompt *bool
	OnboardingStart  bool
	OnboardingEnd    bool
	OnboardingStep   *string
	NoticeDismissal  []byte
}

func (UserSettings) _Table() string { return "user_settings" }

type UserSettings_Create_Fields struct {
	SessionMinutes   UserSettings_SessionMinutes_Field
	PassphrasePrompt UserSettings_PassphrasePrompt_Field
	OnboardingStart  UserSettings_OnboardingStart_Field
	OnboardingEnd    UserSettings_OnboardingEnd_Field
	OnboardingStep   UserSettings_OnboardingStep_Field
	NoticeDismissal  UserSettings_NoticeDismissal_Field
}

type UserSettings_Update_Fields struct {
	SessionMinutes   UserSettings_SessionMinutes_Field
	PassphrasePrompt UserSettings_PassphrasePrompt_Field
	OnboardingStart  UserSettings_OnboardingStart_Field
	OnboardingEnd    UserSettings_OnboardingEnd_Field
	OnboardingStep   UserSettings_OnboardingStep_Field
	NoticeDismissal  UserSettings_NoticeDismissal_Field
}

type UserSettings_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func UserSettings_UserId(v []byte) UserSettings_UserId_Field {
	return UserSettings_UserId_Field{_set: true, _value: v}
}

func (f UserSettings_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type UserSettings_SessionMinutes_Field struct {
	_set   bool
	_null  bool
	_value *uint
}

func UserSettings_SessionMinutes(v uint) UserSettings_SessionMinutes_Field {
	return UserSettings_SessionMinutes_Field{_set: true, _value: &v}
}

func UserSettings_SessionMinutes_Raw(v *uint) UserSettings_SessionMinutes_Field {
	if v == nil {
		return UserSettings_SessionMinutes_Null()
	}
	return UserSettings_SessionMinutes(*v)
}

func UserSettings_SessionMinutes_Null() UserSettings_SessionMinutes_Field {
	return UserSettings_SessionMinutes_Field{_set: true, _null: true}
}

func (f UserSettings_SessionMinutes_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f UserSettings_SessionMinutes_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type UserSettings_PassphrasePrompt_Field struct {
	_set   bool
	_null  bool
	_value *bool
}

func UserSettings_PassphrasePrompt(v bool) UserSettings_PassphrasePrompt_Field {
	return UserSettings_PassphrasePrompt_Field{_set: true, _value: &v}
}

func UserSettings_PassphrasePrompt_Raw(v *bool) UserSettings_PassphrasePrompt_Field {
	if v == nil {
		return UserSettings_PassphrasePrompt_Null()
	}
	return UserSettings_PassphrasePrompt(*v)
}

func UserSettings_PassphrasePrompt_Null() UserSettings_PassphrasePrompt_Field {
	return UserSettings_PassphrasePrompt_Field{_set: true, _null: true}
}

func (f UserSettings_PassphrasePrompt_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f UserSettings_PassphrasePrompt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type UserSettings_OnboardingStart_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func UserSettings_OnboardingStart(v bool) UserSettings_OnboardingStart_Field {
	return UserSettings_OnboardingStart_Field{_set: true, _value: v}
}

func (f UserSettings_OnboardingStart_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type UserSettings_OnboardingEnd_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func UserSettings_OnboardingEnd(v bool) UserSettings_OnboardingEnd_Field {
	return UserSettings_OnboardingEnd_Field{_set: true, _value: v}
}

func (f UserSettings_OnboardingEnd_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type UserSettings_OnboardingStep_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func UserSettings_OnboardingStep(v string) UserSettings_OnboardingStep_Field {
	return UserSettings_OnboardingStep_Field{_set: true, _value: &v}
}

func UserSettings_OnboardingStep_Raw(v *string) UserSettings_OnboardingStep_Field {
	if v == nil {
		return UserSettings_OnboardingStep_Null()
	}
	return UserSettings_OnboardingStep(*v)
}

func UserSettings_OnboardingStep_Null() UserSettings_OnboardingStep_Field {
	return UserSettings_OnboardingStep_Field{_set: true, _null: true}
}

func (f UserSettings_OnboardingStep_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f UserSettings_OnboardingStep_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type UserSettings_NoticeDismissal_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func UserSettings_NoticeDismissal(v []byte) UserSettings_NoticeDismissal_Field {
	return UserSettings_NoticeDismissal_Field{_set: true, _value: v}
}

func (f UserSettings_NoticeDismissal_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ValueAttribution struct {
	ProjectId   []byte
	BucketName  []byte
	UserAgent   []byte
	Placement   *int
	LastUpdated time.Time
}

func (ValueAttribution) _Table() string { return "value_attributions" }

type ValueAttribution_Create_Fields struct {
	UserAgent ValueAttribution_UserAgent_Field
	Placement ValueAttribution_Placement_Field
}

type ValueAttribution_Update_Fields struct {
	UserAgent ValueAttribution_UserAgent_Field
	Placement ValueAttribution_Placement_Field
}

type ValueAttribution_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ValueAttribution_ProjectId(v []byte) ValueAttribution_ProjectId_Field {
	return ValueAttribution_ProjectId_Field{_set: true, _value: v}
}

func (f ValueAttribution_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ValueAttribution_BucketName_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ValueAttribution_BucketName(v []byte) ValueAttribution_BucketName_Field {
	return ValueAttribution_BucketName_Field{_set: true, _value: v}
}

func (f ValueAttribution_BucketName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ValueAttribution_UserAgent_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ValueAttribution_UserAgent(v []byte) ValueAttribution_UserAgent_Field {
	return ValueAttribution_UserAgent_Field{_set: true, _value: v}
}

func ValueAttribution_UserAgent_Raw(v []byte) ValueAttribution_UserAgent_Field {
	if v == nil {
		return ValueAttribution_UserAgent_Null()
	}
	return ValueAttribution_UserAgent(v)
}

func ValueAttribution_UserAgent_Null() ValueAttribution_UserAgent_Field {
	return ValueAttribution_UserAgent_Field{_set: true, _null: true}
}

func (f ValueAttribution_UserAgent_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f ValueAttribution_UserAgent_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ValueAttribution_Placement_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func ValueAttribution_Placement(v int) ValueAttribution_Placement_Field {
	return ValueAttribution_Placement_Field{_set: true, _value: &v}
}

func ValueAttribution_Placement_Raw(v *int) ValueAttribution_Placement_Field {
	if v == nil {
		return ValueAttribution_Placement_Null()
	}
	return ValueAttribution_Placement(*v)
}

func ValueAttribution_Placement_Null() ValueAttribution_Placement_Field {
	return ValueAttribution_Placement_Field{_set: true, _null: true}
}

func (f ValueAttribution_Placement_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f ValueAttribution_Placement_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ValueAttribution_LastUpdated_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ValueAttribution_LastUpdated(v time.Time) ValueAttribution_LastUpdated_Field {
	return ValueAttribution_LastUpdated_Field{_set: true, _value: v}
}

func (f ValueAttribution_LastUpdated_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type VerificationAudits struct {
	InsertedAt    time.Time
	StreamId      []byte
	Position      uint64
	ExpiresAt     *time.Time
	EncryptedSize int
}

func (VerificationAudits) _Table() string { return "verification_audits" }

type VerificationAudits_Create_Fields struct {
	InsertedAt VerificationAudits_InsertedAt_Field
	ExpiresAt  VerificationAudits_ExpiresAt_Field
}

type VerificationAudits_Update_Fields struct {
}

type VerificationAudits_InsertedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func VerificationAudits_InsertedAt(v time.Time) VerificationAudits_InsertedAt_Field {
	return VerificationAudits_InsertedAt_Field{_set: true, _value: v}
}

func (f VerificationAudits_InsertedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type VerificationAudits_StreamId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func VerificationAudits_StreamId(v []byte) VerificationAudits_StreamId_Field {
	return VerificationAudits_StreamId_Field{_set: true, _value: v}
}

func (f VerificationAudits_StreamId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type VerificationAudits_Position_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func VerificationAudits_Position(v uint64) VerificationAudits_Position_Field {
	return VerificationAudits_Position_Field{_set: true, _value: v}
}

func (f VerificationAudits_Position_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type VerificationAudits_ExpiresAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func VerificationAudits_ExpiresAt(v time.Time) VerificationAudits_ExpiresAt_Field {
	return VerificationAudits_ExpiresAt_Field{_set: true, _value: &v}
}

func VerificationAudits_ExpiresAt_Raw(v *time.Time) VerificationAudits_ExpiresAt_Field {
	if v == nil {
		return VerificationAudits_ExpiresAt_Null()
	}
	return VerificationAudits_ExpiresAt(*v)
}

func VerificationAudits_ExpiresAt_Null() VerificationAudits_ExpiresAt_Field {
	return VerificationAudits_ExpiresAt_Field{_set: true, _null: true}
}

func (f VerificationAudits_ExpiresAt_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f VerificationAudits_ExpiresAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type VerificationAudits_EncryptedSize_Field struct {
	_set   bool
	_null  bool
	_value int
}

func VerificationAudits_EncryptedSize(v int) VerificationAudits_EncryptedSize_Field {
	return VerificationAudits_EncryptedSize_Field{_set: true, _value: v}
}

func (f VerificationAudits_EncryptedSize_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type WebappSession struct {
	Id        []byte
	UserId    []byte
	IpAddress string
	UserAgent string
	Status    int
	ExpiresAt time.Time
}

func (WebappSession) _Table() string { return "webapp_sessions" }

type WebappSession_Update_Fields struct {
	Status    WebappSession_Status_Field
	ExpiresAt WebappSession_ExpiresAt_Field
}

type WebappSession_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func WebappSession_Id(v []byte) WebappSession_Id_Field {
	return WebappSession_Id_Field{_set: true, _value: v}
}

func (f WebappSession_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type WebappSession_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func WebappSession_UserId(v []byte) WebappSession_UserId_Field {
	return WebappSession_UserId_Field{_set: true, _value: v}
}

func (f WebappSession_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type WebappSession_IpAddress_Field struct {
	_set   bool
	_null  bool
	_value string
}

func WebappSession_IpAddress(v string) WebappSession_IpAddress_Field {
	return WebappSession_IpAddress_Field{_set: true, _value: v}
}

func (f WebappSession_IpAddress_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type WebappSession_UserAgent_Field struct {
	_set   bool
	_null  bool
	_value string
}

func WebappSession_UserAgent(v string) WebappSession_UserAgent_Field {
	return WebappSession_UserAgent_Field{_set: true, _value: v}
}

func (f WebappSession_UserAgent_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type WebappSession_Status_Field struct {
	_set   bool
	_null  bool
	_value int
}

func WebappSession_Status(v int) WebappSession_Status_Field {
	return WebappSession_Status_Field{_set: true, _value: v}
}

func (f WebappSession_Status_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type WebappSession_ExpiresAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func WebappSession_ExpiresAt(v time.Time) WebappSession_ExpiresAt_Field {
	return WebappSession_ExpiresAt_Field{_set: true, _value: v}
}

func (f WebappSession_ExpiresAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKey struct {
	Id        []byte
	ProjectId []byte
	Head      []byte
	Name      string
	Secret    []byte
	UserAgent []byte
	CreatedAt time.Time
	CreatedBy []byte
	Version   uint
}

func (ApiKey) _Table() string { return "api_keys" }

type ApiKey_Create_Fields struct {
	UserAgent ApiKey_UserAgent_Field
	CreatedBy ApiKey_CreatedBy_Field
	Version   ApiKey_Version_Field
}

type ApiKey_Update_Fields struct {
	Name ApiKey_Name_Field
}

type ApiKey_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKey_Id(v []byte) ApiKey_Id_Field {
	return ApiKey_Id_Field{_set: true, _value: v}
}

func (f ApiKey_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKey_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKey_ProjectId(v []byte) ApiKey_ProjectId_Field {
	return ApiKey_ProjectId_Field{_set: true, _value: v}
}

func (f ApiKey_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKey_Head_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKey_Head(v []byte) ApiKey_Head_Field {
	return ApiKey_Head_Field{_set: true, _value: v}
}

func (f ApiKey_Head_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKey_Name_Field struct {
	_set   bool
	_null  bool
	_value string
}

func ApiKey_Name(v string) ApiKey_Name_Field {
	return ApiKey_Name_Field{_set: true, _value: v}
}

func (f ApiKey_Name_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKey_Secret_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKey_Secret(v []byte) ApiKey_Secret_Field {
	return ApiKey_Secret_Field{_set: true, _value: v}
}

func (f ApiKey_Secret_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKey_UserAgent_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKey_UserAgent(v []byte) ApiKey_UserAgent_Field {
	return ApiKey_UserAgent_Field{_set: true, _value: v}
}

func ApiKey_UserAgent_Raw(v []byte) ApiKey_UserAgent_Field {
	if v == nil {
		return ApiKey_UserAgent_Null()
	}
	return ApiKey_UserAgent(v)
}

func ApiKey_UserAgent_Null() ApiKey_UserAgent_Field {
	return ApiKey_UserAgent_Field{_set: true, _null: true}
}

func (f ApiKey_UserAgent_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f ApiKey_UserAgent_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKey_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ApiKey_CreatedAt(v time.Time) ApiKey_CreatedAt_Field {
	return ApiKey_CreatedAt_Field{_set: true, _value: v}
}

func (f ApiKey_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKey_CreatedBy_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKey_CreatedBy(v []byte) ApiKey_CreatedBy_Field {
	return ApiKey_CreatedBy_Field{_set: true, _value: v}
}

func ApiKey_CreatedBy_Raw(v []byte) ApiKey_CreatedBy_Field {
	if v == nil {
		return ApiKey_CreatedBy_Null()
	}
	return ApiKey_CreatedBy(v)
}

func ApiKey_CreatedBy_Null() ApiKey_CreatedBy_Field {
	return ApiKey_CreatedBy_Field{_set: true, _null: true}
}

func (f ApiKey_CreatedBy_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f ApiKey_CreatedBy_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKey_Version_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func ApiKey_Version(v uint) ApiKey_Version_Field {
	return ApiKey_Version_Field{_set: true, _value: v}
}

func (f ApiKey_Version_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo struct {
	Id                              []byte
	ProjectId                       []byte
	Name                            []byte
	Tags                            []byte
	UserAgent                       []byte
	Versioning                      int
	ObjectLockEnabled               bool
	DefaultRetentionMode            *int
	DefaultRetentionDays            *int
	DefaultRetentionYears           *int
	PathCipher                      int
	CreatedAt                       time.Time
	DefaultSegmentSize              int
	DefaultEncryptionCipherSuite    int
	DefaultEncryptionBlockSize      int
	DefaultRedundancyAlgorithm      int
	DefaultRedundancyShareSize      int
	DefaultRedundancyRequiredShares int
	DefaultRedundancyRepairShares   int
	DefaultRedundancyOptimalShares  int
	DefaultRedundancyTotalShares    int
	Placement                       *int
	CreatedBy                       []byte
}

func (BucketMetainfo) _Table() string { return "bucket_metainfos" }

type BucketMetainfo_Create_Fields struct {
	Tags                  BucketMetainfo_Tags_Field
	UserAgent             BucketMetainfo_UserAgent_Field
	Versioning            BucketMetainfo_Versioning_Field
	ObjectLockEnabled     BucketMetainfo_ObjectLockEnabled_Field
	DefaultRetentionMode  BucketMetainfo_DefaultRetentionMode_Field
	DefaultRetentionDays  BucketMetainfo_DefaultRetentionDays_Field
	DefaultRetentionYears BucketMetainfo_DefaultRetentionYears_Field
	Placement             BucketMetainfo_Placement_Field
	CreatedBy             BucketMetainfo_CreatedBy_Field
}

type BucketMetainfo_Update_Fields struct {
	Tags                            BucketMetainfo_Tags_Field
	UserAgent                       BucketMetainfo_UserAgent_Field
	Versioning                      BucketMetainfo_Versioning_Field
	ObjectLockEnabled               BucketMetainfo_ObjectLockEnabled_Field
	DefaultRetentionMode            BucketMetainfo_DefaultRetentionMode_Field
	DefaultRetentionDays            BucketMetainfo_DefaultRetentionDays_Field
	DefaultRetentionYears           BucketMetainfo_DefaultRetentionYears_Field
	DefaultSegmentSize              BucketMetainfo_DefaultSegmentSize_Field
	DefaultEncryptionCipherSuite    BucketMetainfo_DefaultEncryptionCipherSuite_Field
	DefaultEncryptionBlockSize      BucketMetainfo_DefaultEncryptionBlockSize_Field
	DefaultRedundancyAlgorithm      BucketMetainfo_DefaultRedundancyAlgorithm_Field
	DefaultRedundancyShareSize      BucketMetainfo_DefaultRedundancyShareSize_Field
	DefaultRedundancyRequiredShares BucketMetainfo_DefaultRedundancyRequiredShares_Field
	DefaultRedundancyRepairShares   BucketMetainfo_DefaultRedundancyRepairShares_Field
	DefaultRedundancyOptimalShares  BucketMetainfo_DefaultRedundancyOptimalShares_Field
	DefaultRedundancyTotalShares    BucketMetainfo_DefaultRedundancyTotalShares_Field
	Placement                       BucketMetainfo_Placement_Field
}

type BucketMetainfo_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketMetainfo_Id(v []byte) BucketMetainfo_Id_Field {
	return BucketMetainfo_Id_Field{_set: true, _value: v}
}

func (f BucketMetainfo_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketMetainfo_ProjectId(v []byte) BucketMetainfo_ProjectId_Field {
	return BucketMetainfo_ProjectId_Field{_set: true, _value: v}
}

func (f BucketMetainfo_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_Name_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketMetainfo_Name(v []byte) BucketMetainfo_Name_Field {
	return BucketMetainfo_Name_Field{_set: true, _value: v}
}

func (f BucketMetainfo_Name_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_Tags_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketMetainfo_Tags(v []byte) BucketMetainfo_Tags_Field {
	return BucketMetainfo_Tags_Field{_set: true, _value: v}
}

func BucketMetainfo_Tags_Raw(v []byte) BucketMetainfo_Tags_Field {
	if v == nil {
		return BucketMetainfo_Tags_Null()
	}
	return BucketMetainfo_Tags(v)
}

func BucketMetainfo_Tags_Null() BucketMetainfo_Tags_Field {
	return BucketMetainfo_Tags_Field{_set: true, _null: true}
}

func (f BucketMetainfo_Tags_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f BucketMetainfo_Tags_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_UserAgent_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketMetainfo_UserAgent(v []byte) BucketMetainfo_UserAgent_Field {
	return BucketMetainfo_UserAgent_Field{_set: true, _value: v}
}

func BucketMetainfo_UserAgent_Raw(v []byte) BucketMetainfo_UserAgent_Field {
	if v == nil {
		return BucketMetainfo_UserAgent_Null()
	}
	return BucketMetainfo_UserAgent(v)
}

func BucketMetainfo_UserAgent_Null() BucketMetainfo_UserAgent_Field {
	return BucketMetainfo_UserAgent_Field{_set: true, _null: true}
}

func (f BucketMetainfo_UserAgent_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f BucketMetainfo_UserAgent_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_Versioning_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_Versioning(v int) BucketMetainfo_Versioning_Field {
	return BucketMetainfo_Versioning_Field{_set: true, _value: v}
}

func (f BucketMetainfo_Versioning_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_ObjectLockEnabled_Field struct {
	_set   bool
	_null  bool
	_value bool
}

func BucketMetainfo_ObjectLockEnabled(v bool) BucketMetainfo_ObjectLockEnabled_Field {
	return BucketMetainfo_ObjectLockEnabled_Field{_set: true, _value: v}
}

func (f BucketMetainfo_ObjectLockEnabled_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultRetentionMode_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func BucketMetainfo_DefaultRetentionMode(v int) BucketMetainfo_DefaultRetentionMode_Field {
	return BucketMetainfo_DefaultRetentionMode_Field{_set: true, _value: &v}
}

func BucketMetainfo_DefaultRetentionMode_Raw(v *int) BucketMetainfo_DefaultRetentionMode_Field {
	if v == nil {
		return BucketMetainfo_DefaultRetentionMode_Null()
	}
	return BucketMetainfo_DefaultRetentionMode(*v)
}

func BucketMetainfo_DefaultRetentionMode_Null() BucketMetainfo_DefaultRetentionMode_Field {
	return BucketMetainfo_DefaultRetentionMode_Field{_set: true, _null: true}
}

func (f BucketMetainfo_DefaultRetentionMode_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f BucketMetainfo_DefaultRetentionMode_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultRetentionDays_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func BucketMetainfo_DefaultRetentionDays(v int) BucketMetainfo_DefaultRetentionDays_Field {
	return BucketMetainfo_DefaultRetentionDays_Field{_set: true, _value: &v}
}

func BucketMetainfo_DefaultRetentionDays_Raw(v *int) BucketMetainfo_DefaultRetentionDays_Field {
	if v == nil {
		return BucketMetainfo_DefaultRetentionDays_Null()
	}
	return BucketMetainfo_DefaultRetentionDays(*v)
}

func BucketMetainfo_DefaultRetentionDays_Null() BucketMetainfo_DefaultRetentionDays_Field {
	return BucketMetainfo_DefaultRetentionDays_Field{_set: true, _null: true}
}

func (f BucketMetainfo_DefaultRetentionDays_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f BucketMetainfo_DefaultRetentionDays_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultRetentionYears_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func BucketMetainfo_DefaultRetentionYears(v int) BucketMetainfo_DefaultRetentionYears_Field {
	return BucketMetainfo_DefaultRetentionYears_Field{_set: true, _value: &v}
}

func BucketMetainfo_DefaultRetentionYears_Raw(v *int) BucketMetainfo_DefaultRetentionYears_Field {
	if v == nil {
		return BucketMetainfo_DefaultRetentionYears_Null()
	}
	return BucketMetainfo_DefaultRetentionYears(*v)
}

func BucketMetainfo_DefaultRetentionYears_Null() BucketMetainfo_DefaultRetentionYears_Field {
	return BucketMetainfo_DefaultRetentionYears_Field{_set: true, _null: true}
}

func (f BucketMetainfo_DefaultRetentionYears_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f BucketMetainfo_DefaultRetentionYears_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_PathCipher_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_PathCipher(v int) BucketMetainfo_PathCipher_Field {
	return BucketMetainfo_PathCipher_Field{_set: true, _value: v}
}

func (f BucketMetainfo_PathCipher_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func BucketMetainfo_CreatedAt(v time.Time) BucketMetainfo_CreatedAt_Field {
	return BucketMetainfo_CreatedAt_Field{_set: true, _value: v}
}

func (f BucketMetainfo_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultSegmentSize_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_DefaultSegmentSize(v int) BucketMetainfo_DefaultSegmentSize_Field {
	return BucketMetainfo_DefaultSegmentSize_Field{_set: true, _value: v}
}

func (f BucketMetainfo_DefaultSegmentSize_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultEncryptionCipherSuite_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_DefaultEncryptionCipherSuite(v int) BucketMetainfo_DefaultEncryptionCipherSuite_Field {
	return BucketMetainfo_DefaultEncryptionCipherSuite_Field{_set: true, _value: v}
}

func (f BucketMetainfo_DefaultEncryptionCipherSuite_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultEncryptionBlockSize_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_DefaultEncryptionBlockSize(v int) BucketMetainfo_DefaultEncryptionBlockSize_Field {
	return BucketMetainfo_DefaultEncryptionBlockSize_Field{_set: true, _value: v}
}

func (f BucketMetainfo_DefaultEncryptionBlockSize_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultRedundancyAlgorithm_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_DefaultRedundancyAlgorithm(v int) BucketMetainfo_DefaultRedundancyAlgorithm_Field {
	return BucketMetainfo_DefaultRedundancyAlgorithm_Field{_set: true, _value: v}
}

func (f BucketMetainfo_DefaultRedundancyAlgorithm_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultRedundancyShareSize_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_DefaultRedundancyShareSize(v int) BucketMetainfo_DefaultRedundancyShareSize_Field {
	return BucketMetainfo_DefaultRedundancyShareSize_Field{_set: true, _value: v}
}

func (f BucketMetainfo_DefaultRedundancyShareSize_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultRedundancyRequiredShares_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_DefaultRedundancyRequiredShares(v int) BucketMetainfo_DefaultRedundancyRequiredShares_Field {
	return BucketMetainfo_DefaultRedundancyRequiredShares_Field{_set: true, _value: v}
}

func (f BucketMetainfo_DefaultRedundancyRequiredShares_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultRedundancyRepairShares_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_DefaultRedundancyRepairShares(v int) BucketMetainfo_DefaultRedundancyRepairShares_Field {
	return BucketMetainfo_DefaultRedundancyRepairShares_Field{_set: true, _value: v}
}

func (f BucketMetainfo_DefaultRedundancyRepairShares_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultRedundancyOptimalShares_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_DefaultRedundancyOptimalShares(v int) BucketMetainfo_DefaultRedundancyOptimalShares_Field {
	return BucketMetainfo_DefaultRedundancyOptimalShares_Field{_set: true, _value: v}
}

func (f BucketMetainfo_DefaultRedundancyOptimalShares_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_DefaultRedundancyTotalShares_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMetainfo_DefaultRedundancyTotalShares(v int) BucketMetainfo_DefaultRedundancyTotalShares_Field {
	return BucketMetainfo_DefaultRedundancyTotalShares_Field{_set: true, _value: v}
}

func (f BucketMetainfo_DefaultRedundancyTotalShares_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_Placement_Field struct {
	_set   bool
	_null  bool
	_value *int
}

func BucketMetainfo_Placement(v int) BucketMetainfo_Placement_Field {
	return BucketMetainfo_Placement_Field{_set: true, _value: &v}
}

func BucketMetainfo_Placement_Raw(v *int) BucketMetainfo_Placement_Field {
	if v == nil {
		return BucketMetainfo_Placement_Null()
	}
	return BucketMetainfo_Placement(*v)
}

func BucketMetainfo_Placement_Null() BucketMetainfo_Placement_Field {
	return BucketMetainfo_Placement_Field{_set: true, _null: true}
}

func (f BucketMetainfo_Placement_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f BucketMetainfo_Placement_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMetainfo_CreatedBy_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketMetainfo_CreatedBy(v []byte) BucketMetainfo_CreatedBy_Field {
	return BucketMetainfo_CreatedBy_Field{_set: true, _value: v}
}

func BucketMetainfo_CreatedBy_Raw(v []byte) BucketMetainfo_CreatedBy_Field {
	if v == nil {
		return BucketMetainfo_CreatedBy_Null()
	}
	return BucketMetainfo_CreatedBy(v)
}

func BucketMetainfo_CreatedBy_Null() BucketMetainfo_CreatedBy_Field {
	return BucketMetainfo_CreatedBy_Field{_set: true, _null: true}
}

func (f BucketMetainfo_CreatedBy_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f BucketMetainfo_CreatedBy_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration struct {
	Id             []byte
	ProjectId      []byte
	BucketName     []byte
	FromPlacement  int
	ToPlacement    int
	MigrationType  int
	State          string
	BytesProcessed uint64
	ErrorMessage   *string
	CreatedAt      time.Time
	UpdatedAt      time.Time
	CompletedAt    *time.Time
}

func (BucketMigration) _Table() string { return "bucket_migrations" }

type BucketMigration_Create_Fields struct {
	BytesProcessed BucketMigration_BytesProcessed_Field
	ErrorMessage   BucketMigration_ErrorMessage_Field
	CompletedAt    BucketMigration_CompletedAt_Field
}

type BucketMigration_Update_Fields struct {
	State          BucketMigration_State_Field
	BytesProcessed BucketMigration_BytesProcessed_Field
	ErrorMessage   BucketMigration_ErrorMessage_Field
	CompletedAt    BucketMigration_CompletedAt_Field
}

type BucketMigration_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketMigration_Id(v []byte) BucketMigration_Id_Field {
	return BucketMigration_Id_Field{_set: true, _value: v}
}

func (f BucketMigration_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketMigration_ProjectId(v []byte) BucketMigration_ProjectId_Field {
	return BucketMigration_ProjectId_Field{_set: true, _value: v}
}

func (f BucketMigration_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_BucketName_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func BucketMigration_BucketName(v []byte) BucketMigration_BucketName_Field {
	return BucketMigration_BucketName_Field{_set: true, _value: v}
}

func (f BucketMigration_BucketName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_FromPlacement_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMigration_FromPlacement(v int) BucketMigration_FromPlacement_Field {
	return BucketMigration_FromPlacement_Field{_set: true, _value: v}
}

func (f BucketMigration_FromPlacement_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_ToPlacement_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMigration_ToPlacement(v int) BucketMigration_ToPlacement_Field {
	return BucketMigration_ToPlacement_Field{_set: true, _value: v}
}

func (f BucketMigration_ToPlacement_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_MigrationType_Field struct {
	_set   bool
	_null  bool
	_value int
}

func BucketMigration_MigrationType(v int) BucketMigration_MigrationType_Field {
	return BucketMigration_MigrationType_Field{_set: true, _value: v}
}

func (f BucketMigration_MigrationType_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_State_Field struct {
	_set   bool
	_null  bool
	_value string
}

func BucketMigration_State(v string) BucketMigration_State_Field {
	return BucketMigration_State_Field{_set: true, _value: v}
}

func (f BucketMigration_State_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_BytesProcessed_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func BucketMigration_BytesProcessed(v uint64) BucketMigration_BytesProcessed_Field {
	return BucketMigration_BytesProcessed_Field{_set: true, _value: v}
}

func (f BucketMigration_BytesProcessed_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_ErrorMessage_Field struct {
	_set   bool
	_null  bool
	_value *string
}

func BucketMigration_ErrorMessage(v string) BucketMigration_ErrorMessage_Field {
	return BucketMigration_ErrorMessage_Field{_set: true, _value: &v}
}

func BucketMigration_ErrorMessage_Raw(v *string) BucketMigration_ErrorMessage_Field {
	if v == nil {
		return BucketMigration_ErrorMessage_Null()
	}
	return BucketMigration_ErrorMessage(*v)
}

func BucketMigration_ErrorMessage_Null() BucketMigration_ErrorMessage_Field {
	return BucketMigration_ErrorMessage_Field{_set: true, _null: true}
}

func (f BucketMigration_ErrorMessage_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f BucketMigration_ErrorMessage_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func BucketMigration_CreatedAt(v time.Time) BucketMigration_CreatedAt_Field {
	return BucketMigration_CreatedAt_Field{_set: true, _value: v}
}

func (f BucketMigration_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_UpdatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func BucketMigration_UpdatedAt(v time.Time) BucketMigration_UpdatedAt_Field {
	return BucketMigration_UpdatedAt_Field{_set: true, _value: v}
}

func (f BucketMigration_UpdatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type BucketMigration_CompletedAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func BucketMigration_CompletedAt(v time.Time) BucketMigration_CompletedAt_Field {
	return BucketMigration_CompletedAt_Field{_set: true, _value: &v}
}

func BucketMigration_CompletedAt_Raw(v *time.Time) BucketMigration_CompletedAt_Field {
	if v == nil {
		return BucketMigration_CompletedAt_Null()
	}
	return BucketMigration_CompletedAt(*v)
}

func BucketMigration_CompletedAt_Null() BucketMigration_CompletedAt_Field {
	return BucketMigration_CompletedAt_Field{_set: true, _null: true}
}

func (f BucketMigration_CompletedAt_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f BucketMigration_CompletedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Domain struct {
	Subdomain string
	ProjectId []byte
	Prefix    string
	AccessId  string
	CreatedBy []byte
	CreatedAt time.Time
}

func (Domain) _Table() string { return "domains" }

type Domain_Update_Fields struct {
	Prefix   Domain_Prefix_Field
	AccessId Domain_AccessId_Field
}

type Domain_Subdomain_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Domain_Subdomain(v string) Domain_Subdomain_Field {
	return Domain_Subdomain_Field{_set: true, _value: v}
}

func (f Domain_Subdomain_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Domain_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Domain_ProjectId(v []byte) Domain_ProjectId_Field {
	return Domain_ProjectId_Field{_set: true, _value: v}
}

func (f Domain_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Domain_Prefix_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Domain_Prefix(v string) Domain_Prefix_Field {
	return Domain_Prefix_Field{_set: true, _value: v}
}

func (f Domain_Prefix_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Domain_AccessId_Field struct {
	_set   bool
	_null  bool
	_value string
}

func Domain_AccessId(v string) Domain_AccessId_Field {
	return Domain_AccessId_Field{_set: true, _value: v}
}

func (f Domain_AccessId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Domain_CreatedBy_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func Domain_CreatedBy(v []byte) Domain_CreatedBy_Field {
	return Domain_CreatedBy_Field{_set: true, _value: v}
}

func (f Domain_CreatedBy_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type Domain_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func Domain_CreatedAt(v time.Time) Domain_CreatedAt_Field {
	return Domain_CreatedAt_Field{_set: true, _value: v}
}

func (f Domain_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectInvitation struct {
	ProjectId []byte
	Email     string
	InviterId []byte
	CreatedAt time.Time
}

func (ProjectInvitation) _Table() string { return "project_invitations" }

type ProjectInvitation_Create_Fields struct {
	InviterId ProjectInvitation_InviterId_Field
}

type ProjectInvitation_Update_Fields struct {
	InviterId ProjectInvitation_InviterId_Field
	CreatedAt ProjectInvitation_CreatedAt_Field
}

type ProjectInvitation_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ProjectInvitation_ProjectId(v []byte) ProjectInvitation_ProjectId_Field {
	return ProjectInvitation_ProjectId_Field{_set: true, _value: v}
}

func (f ProjectInvitation_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectInvitation_Email_Field struct {
	_set   bool
	_null  bool
	_value string
}

func ProjectInvitation_Email(v string) ProjectInvitation_Email_Field {
	return ProjectInvitation_Email_Field{_set: true, _value: v}
}

func (f ProjectInvitation_Email_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectInvitation_InviterId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ProjectInvitation_InviterId(v []byte) ProjectInvitation_InviterId_Field {
	return ProjectInvitation_InviterId_Field{_set: true, _value: v}
}

func ProjectInvitation_InviterId_Raw(v []byte) ProjectInvitation_InviterId_Field {
	if v == nil {
		return ProjectInvitation_InviterId_Null()
	}
	return ProjectInvitation_InviterId(v)
}

func ProjectInvitation_InviterId_Null() ProjectInvitation_InviterId_Field {
	return ProjectInvitation_InviterId_Field{_set: true, _null: true}
}

func (f ProjectInvitation_InviterId_Field) isnull() bool {
	return !f._set || f._null || f._value == nil
}

func (f ProjectInvitation_InviterId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectInvitation_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ProjectInvitation_CreatedAt(v time.Time) ProjectInvitation_CreatedAt_Field {
	return ProjectInvitation_CreatedAt_Field{_set: true, _value: v}
}

func (f ProjectInvitation_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectMember struct {
	MemberId  []byte
	ProjectId []byte
	Role      int
	CreatedAt time.Time
}

func (ProjectMember) _Table() string { return "project_members" }

type ProjectMember_Create_Fields struct {
	Role ProjectMember_Role_Field
}

type ProjectMember_Update_Fields struct {
	Role ProjectMember_Role_Field
}

type ProjectMember_MemberId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ProjectMember_MemberId(v []byte) ProjectMember_MemberId_Field {
	return ProjectMember_MemberId_Field{_set: true, _value: v}
}

func (f ProjectMember_MemberId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectMember_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ProjectMember_ProjectId(v []byte) ProjectMember_ProjectId_Field {
	return ProjectMember_ProjectId_Field{_set: true, _value: v}
}

func (f ProjectMember_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectMember_Role_Field struct {
	_set   bool
	_null  bool
	_value int
}

func ProjectMember_Role(v int) ProjectMember_Role_Field {
	return ProjectMember_Role_Field{_set: true, _value: v}
}

func (f ProjectMember_Role_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ProjectMember_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ProjectMember_CreatedAt(v time.Time) ProjectMember_CreatedAt_Field {
	return ProjectMember_CreatedAt_Field{_set: true, _value: v}
}

func (f ProjectMember_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RestApiKey struct {
	Id        []byte
	UserId    []byte
	Token     []byte
	Name      string
	ExpiresAt *time.Time
	CreatedAt time.Time
}

func (RestApiKey) _Table() string { return "rest_api_keys" }

type RestApiKey_Create_Fields struct {
	ExpiresAt RestApiKey_ExpiresAt_Field
}

type RestApiKey_Update_Fields struct {
	ExpiresAt RestApiKey_ExpiresAt_Field
}

type RestApiKey_Id_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func RestApiKey_Id(v []byte) RestApiKey_Id_Field {
	return RestApiKey_Id_Field{_set: true, _value: v}
}

func (f RestApiKey_Id_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RestApiKey_UserId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func RestApiKey_UserId(v []byte) RestApiKey_UserId_Field {
	return RestApiKey_UserId_Field{_set: true, _value: v}
}

func (f RestApiKey_UserId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RestApiKey_Token_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func RestApiKey_Token(v []byte) RestApiKey_Token_Field {
	return RestApiKey_Token_Field{_set: true, _value: v}
}

func (f RestApiKey_Token_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RestApiKey_Name_Field struct {
	_set   bool
	_null  bool
	_value string
}

func RestApiKey_Name(v string) RestApiKey_Name_Field {
	return RestApiKey_Name_Field{_set: true, _value: v}
}

func (f RestApiKey_Name_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RestApiKey_ExpiresAt_Field struct {
	_set   bool
	_null  bool
	_value *time.Time
}

func RestApiKey_ExpiresAt(v time.Time) RestApiKey_ExpiresAt_Field {
	return RestApiKey_ExpiresAt_Field{_set: true, _value: &v}
}

func RestApiKey_ExpiresAt_Raw(v *time.Time) RestApiKey_ExpiresAt_Field {
	if v == nil {
		return RestApiKey_ExpiresAt_Null()
	}
	return RestApiKey_ExpiresAt(*v)
}

func RestApiKey_ExpiresAt_Null() RestApiKey_ExpiresAt_Field {
	return RestApiKey_ExpiresAt_Field{_set: true, _null: true}
}

func (f RestApiKey_ExpiresAt_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f RestApiKey_ExpiresAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type RestApiKey_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func RestApiKey_CreatedAt(v time.Time) RestApiKey_CreatedAt_Field {
	return RestApiKey_CreatedAt_Field{_set: true, _value: v}
}

func (f RestApiKey_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsApplyBalanceIntent struct {
	TxId      string
	State     int
	CreatedAt time.Time
}

func (StripecoinpaymentsApplyBalanceIntent) _Table() string {
	return "stripecoinpayments_apply_balance_intents"
}

type StripecoinpaymentsApplyBalanceIntent_Update_Fields struct {
	State StripecoinpaymentsApplyBalanceIntent_State_Field
}

type StripecoinpaymentsApplyBalanceIntent_TxId_Field struct {
	_set   bool
	_null  bool
	_value string
}

func StripecoinpaymentsApplyBalanceIntent_TxId(v string) StripecoinpaymentsApplyBalanceIntent_TxId_Field {
	return StripecoinpaymentsApplyBalanceIntent_TxId_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsApplyBalanceIntent_TxId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsApplyBalanceIntent_State_Field struct {
	_set   bool
	_null  bool
	_value int
}

func StripecoinpaymentsApplyBalanceIntent_State(v int) StripecoinpaymentsApplyBalanceIntent_State_Field {
	return StripecoinpaymentsApplyBalanceIntent_State_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsApplyBalanceIntent_State_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type StripecoinpaymentsApplyBalanceIntent_CreatedAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func StripecoinpaymentsApplyBalanceIntent_CreatedAt(v time.Time) StripecoinpaymentsApplyBalanceIntent_CreatedAt_Field {
	return StripecoinpaymentsApplyBalanceIntent_CreatedAt_Field{_set: true, _value: v}
}

func (f StripecoinpaymentsApplyBalanceIntent_CreatedAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKeyTail struct {
	RootKeyId  []byte
	Tail       []byte
	ParentTail []byte
	Caveat     []byte
	LastUsed   time.Time
}

func (ApiKeyTail) _Table() string { return "api_key_tails" }

type ApiKeyTail_Create_Fields struct {
	RootKeyId ApiKeyTail_RootKeyId_Field
}

type ApiKeyTail_Update_Fields struct {
	LastUsed ApiKeyTail_LastUsed_Field
}

type ApiKeyTail_RootKeyId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKeyTail_RootKeyId(v []byte) ApiKeyTail_RootKeyId_Field {
	return ApiKeyTail_RootKeyId_Field{_set: true, _value: v}
}

func ApiKeyTail_RootKeyId_Raw(v []byte) ApiKeyTail_RootKeyId_Field {
	if v == nil {
		return ApiKeyTail_RootKeyId_Null()
	}
	return ApiKeyTail_RootKeyId(v)
}

func ApiKeyTail_RootKeyId_Null() ApiKeyTail_RootKeyId_Field {
	return ApiKeyTail_RootKeyId_Field{_set: true, _null: true}
}

func (f ApiKeyTail_RootKeyId_Field) isnull() bool { return !f._set || f._null || f._value == nil }

func (f ApiKeyTail_RootKeyId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKeyTail_Tail_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKeyTail_Tail(v []byte) ApiKeyTail_Tail_Field {
	return ApiKeyTail_Tail_Field{_set: true, _value: v}
}

func (f ApiKeyTail_Tail_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKeyTail_ParentTail_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKeyTail_ParentTail(v []byte) ApiKeyTail_ParentTail_Field {
	return ApiKeyTail_ParentTail_Field{_set: true, _value: v}
}

func (f ApiKeyTail_ParentTail_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKeyTail_Caveat_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ApiKeyTail_Caveat(v []byte) ApiKeyTail_Caveat_Field {
	return ApiKeyTail_Caveat_Field{_set: true, _value: v}
}

func (f ApiKeyTail_Caveat_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ApiKeyTail_LastUsed_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ApiKeyTail_LastUsed(v time.Time) ApiKeyTail_LastUsed_Field {
	return ApiKeyTail_LastUsed_Field{_set: true, _value: v}
}

func (f ApiKeyTail_LastUsed_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func toUTC(t time.Time) time.Time {
	return t.UTC()
}

func toDate(t time.Time) time.Time {
	// keep up the minute portion so that translations between timezones will
	// continue to reflect properly.
	return t.Truncate(time.Minute)
}

//
// runtime support for building sql statements
//

type __sqlbundle_SQL interface {
	Render() string

	private()
}

type __sqlbundle_Dialect interface {
	// Rebind gives the opportunity to rewrite provided SQL into a SQL dialect.
	Rebind(sql string) string
}

type __sqlbundle_RenderOp int

const (
	__sqlbundle_NoFlatten __sqlbundle_RenderOp = iota
	__sqlbundle_NoTerminate
)

func __sqlbundle_RenderAll(dialect __sqlbundle_Dialect, sqls []__sqlbundle_SQL, ops ...__sqlbundle_RenderOp) []string {
	var rs []string
	for _, sql := range sqls {
		rs = append(rs, __sqlbundle_Render(dialect, sql, ops...))
	}
	return rs
}

func __sqlbundle_Render(dialect __sqlbundle_Dialect, sql __sqlbundle_SQL, ops ...__sqlbundle_RenderOp) string {
	out := sql.Render()

	flatten := true
	terminate := true
	for _, op := range ops {
		switch op {
		case __sqlbundle_NoFlatten:
			flatten = false
		case __sqlbundle_NoTerminate:
			terminate = false
		}
	}

	if flatten {
		out = __sqlbundle_flattenSQL(out)
	}
	if terminate {
		out += ";"
	}

	return dialect.Rebind(out)
}

func __sqlbundle_flattenSQL(x string) string {
	// trim whitespace from beginning and end
	s, e := 0, len(x)-1
	for s < len(x) && (x[s] == ' ' || x[s] == '\t' || x[s] == '\n') {
		s++
	}
	for s <= e && (x[e] == ' ' || x[e] == '\t' || x[e] == '\n') {
		e--
	}
	if s > e {
		return ""
	}
	x = x[s : e+1]

	// check for whitespace that needs fixing
	wasSpace := false
	for i := 0; i < len(x); i++ {
		r := x[i]
		justSpace := r == ' '
		if (wasSpace && justSpace) || r == '\t' || r == '\n' {
			// whitespace detected, start writing a new string
			var result strings.Builder
			result.Grow(len(x))
			if wasSpace {
				result.WriteString(x[:i-1])
			} else {
				result.WriteString(x[:i])
			}
			for p := i; p < len(x); p++ {
				for p < len(x) && (x[p] == ' ' || x[p] == '\t' || x[p] == '\n') {
					p++
				}
				result.WriteByte(' ')

				start := p
				for p < len(x) && !(x[p] == ' ' || x[p] == '\t' || x[p] == '\n') {
					p++
				}
				result.WriteString(x[start:p])
			}

			return result.String()
		}
		wasSpace = justSpace
	}

	// no problematic whitespace found
	return x
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_cockroach struct{}

func (p __sqlbundle_cockroach) Rebind(sql string) string {
	return __sqlbundle_postgres{}.Rebind(sql)
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_pgx struct{}

func (p __sqlbundle_pgx) Rebind(sql string) string {
	return __sqlbundle_postgres{}.Rebind(sql)
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_pgxcockroach struct{}

func (p __sqlbundle_pgxcockroach) Rebind(sql string) string {
	return __sqlbundle_postgres{}.Rebind(sql)
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_postgres struct{}

func (p __sqlbundle_postgres) Rebind(sql string) string {
	type sqlParseState int
	const (
		sqlParseStart sqlParseState = iota
		sqlParseInStringLiteral
		sqlParseInQuotedIdentifier
		sqlParseInComment
	)

	out := make([]byte, 0, len(sql)+10)

	j := 1
	state := sqlParseStart
	for i := 0; i < len(sql); i++ {
		ch := sql[i]
		switch state {
		case sqlParseStart:
			switch ch {
			case '?':
				out = append(out, '$')
				out = append(out, strconv.Itoa(j)...)
				state = sqlParseStart
				j++
				continue
			case '-':
				if i+1 < len(sql) && sql[i+1] == '-' {
					state = sqlParseInComment
				}
			case '"':
				state = sqlParseInQuotedIdentifier
			case '\'':
				state = sqlParseInStringLiteral
			}
		case sqlParseInStringLiteral:
			if ch == '\'' {
				state = sqlParseStart
			}
		case sqlParseInQuotedIdentifier:
			if ch == '"' {
				state = sqlParseStart
			}
		case sqlParseInComment:
			if ch == '\n' {
				state = sqlParseStart
			}
		}
		out = append(out, ch)
	}

	return string(out)
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_spanner struct{}

func (p __sqlbundle_spanner) Rebind(sql string) string {
	return sql
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_sqlite3 struct{}

func (s __sqlbundle_sqlite3) Rebind(sql string) string {
	return sql
}

type __sqlbundle_Literal string

func (__sqlbundle_Literal) private() {}

func (l __sqlbundle_Literal) Render() string { return string(l) }

type __sqlbundle_Literals struct {
	Join string
	SQLs []__sqlbundle_SQL
}

func (__sqlbundle_Literals) private() {}

func (l __sqlbundle_Literals) Render() string {
	var out bytes.Buffer

	first := true
	for _, sql := range l.SQLs {
		if sql == nil {
			continue
		}
		if !first {
			out.WriteString(l.Join)
		}
		first = false
		out.WriteString(sql.Render())
	}

	return out.String()
}

type __sqlbundle_Condition struct {
	// set at compile/embed time
	Name  string
	Left  string
	Equal bool
	Right string

	// set at runtime
	Null bool
}

func (*__sqlbundle_Condition) private() {}

func (c *__sqlbundle_Condition) Render() string {
	// TODO(jeff): maybe check if we can use placeholders instead of the
	// literal null: this would make the templates easier.

	switch {
	case c.Equal && c.Null:
		return c.Left + " is null"
	case c.Equal && !c.Null:
		return c.Left + " = " + c.Right
	case !c.Equal && c.Null:
		return c.Left + " is not null"
	case !c.Equal && !c.Null:
		return c.Left + " != " + c.Right
	default:
		panic("unhandled case")
	}
}

type __sqlbundle_Hole struct {
	// set at compiile/embed time
	Name string

	// set at runtime or possibly embed time
	SQL __sqlbundle_SQL
}

func (*__sqlbundle_Hole) private() {}

func (h *__sqlbundle_Hole) Render() string {
	if h.SQL == nil {
		return ""
	}
	return h.SQL.Render()
}

//
// end runtime support for building sql statements
//

type ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row struct {
	ApiKey                              ApiKey
	Project_PublicId                    []byte
	Project_RateLimit                   *int
	Project_BurstLimit                  *int
	Project_RateLimitHead               *int
	Project_BurstLimitHead              *int
	Project_RateLimitGet                *int
	Project_BurstLimitGet               *int
	Project_RateLimitPut                *int
	Project_BurstLimitPut               *int
	Project_RateLimitList               *int
	Project_BurstLimitList              *int
	Project_RateLimitDel                *int
	Project_BurstLimitDel               *int
	Project_SegmentLimit                *int64
	Project_UsageLimit                  *int64
	Project_BandwidthLimit              *int64
	Project_UserSpecifiedUsageLimit     *int64
	Project_UserSpecifiedBandwidthLimit *int64
}

type ApiKey_Project_PublicId_Row struct {
	ApiKey           ApiKey
	Project_PublicId []byte
}

type Balance_Row struct {
	Balance int64
}

type BandwidthLimit_Row struct {
	BandwidthLimit *int64
}

type BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row struct {
	BandwidthLimit              *int64
	UserSpecifiedBandwidthLimit *int64
	UsageLimit                  *int64
	UserSpecifiedUsageLimit     *int64
	SegmentLimit                *int64
	RateLimit                   *int
	BurstLimit                  *int
	RateLimitHead               *int
	BurstLimitHead              *int
	RateLimitGet                *int
	BurstLimitGet               *int
	RateLimitPut                *int
	BurstLimitPut               *int
	RateLimitList               *int
	BurstLimitList              *int
	RateLimitDel                *int
	BurstLimitDel               *int
}

type BlockNumber_Row struct {
	BlockNumber int64
}

type CreatedBy_CreatedAt_Placement_Row struct {
	CreatedBy []byte
	CreatedAt time.Time
	Placement *int
}

type CustomerId_BillingCustomerId_Row struct {
	CustomerId        string
	BillingCustomerId *string
}

type CustomerId_Row struct {
	CustomerId string
}

type DefaultVersioning_Row struct {
	DefaultVersioning int
}

type Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row struct {
	Id                    []byte
	CreatedBy             []byte
	UserAgent             []byte
	CreatedAt             time.Time
	Placement             *int
	Versioning            int
	ObjectLockEnabled     bool
	DefaultRetentionMode  *int
	DefaultRetentionDays  *int
	DefaultRetentionYears *int
}

type Id_Email_FullName_Row struct {
	Id       []byte
	Email    string
	FullName string
}

type Id_PieceCount_Row struct {
	Id         []byte
	PieceCount int64
}

type Id_PublicId_OwnerId_Row struct {
	Id       []byte
	PublicId []byte
	OwnerId  []byte
}

type Id_Row struct {
	Id []byte
}

type IntervalEndTime_Row struct {
	IntervalEndTime time.Time
}

type Kind_Row struct {
	Kind int
}

type LeafSerialNumber_Row struct {
	LeafSerialNumber []byte
}

type MaxBuckets_Row struct {
	MaxBuckets *int
}

type Metadata_Row struct {
	Metadata []byte
}

type ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row struct {
	ObjectLockEnabled     bool
	DefaultRetentionMode  *int
	DefaultRetentionDays  *int
	DefaultRetentionYears *int
}

type ObjectLockEnabled_Row struct {
	ObjectLockEnabled bool
}

type PackagePlan_PurchasedPackageAt_Row struct {
	PackagePlan        *string
	PurchasedPackageAt *time.Time
}

type Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation struct {
	_value_user_id []byte
	_value_event   int
	_set           bool
}

type Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation struct {
	_value_bucket_name    []byte
	_value_project_id     []byte
	_value_interval_start time.Time
	_value_action         uint
	_set                  bool
}

type Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation struct {
	_value_project_id     []byte
	_value_bucket_name    []byte
	_value_interval_start time.Time
	_value_action         uint
	_set                  bool
}

type Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation struct {
	_value_project_id []byte
	_value_name       []byte
	_set              bool
}

type Paged_Node_Continuation struct {
	_value_id []byte
	_set      bool
}

type Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation struct {
	_value_storagenode_id []byte
	_value_interval_start time.Time
	_value_action         uint
	_set                  bool
}

type Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation struct {
	_value_storagenode_id []byte
	_value_interval_start time.Time
	_value_action         uint
	_set                  bool
}

type Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation struct {
	_value_storagenode_id []byte
	_value_interval_start time.Time
	_value_action         uint
	_set                  bool
}

type PassphraseEnc_PassphraseEncKeyId_Row struct {
	PassphraseEnc      []byte
	PassphraseEncKeyId *int
}

type Placement_Row struct {
	Placement *int
}

type ProjectId_Name_Row struct {
	ProjectId []byte
	Name      []byte
}

type ProjectLimit_Row struct {
	ProjectLimit int
}

type ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row struct {
	ProjectStorageLimit   int64
	ProjectBandwidthLimit int64
	ProjectSegmentLimit   int64
}

type PublicId_Row struct {
	PublicId []byte
}

type Salt_Row struct {
	Salt []byte
}

type SegmentLimit_Row struct {
	SegmentLimit *int64
}

type Status_Row struct {
	Status int
}

type Subdomain_Row struct {
	Subdomain string
}

type Tags_Row struct {
	Tags []byte
}

type UpgradeTime_Row struct {
	UpgradeTime *time.Time
}

type UsageLimit_Row struct {
	UsageLimit *int64
}

type UserAgent_Row struct {
	UserAgent []byte
}

type UserId_Row struct {
	UserId []byte
}

type UserSpecifiedBandwidthLimit_Row struct {
	UserSpecifiedBandwidthLimit *int64
}

type UserSpecifiedUsageLimit_Row struct {
	UserSpecifiedUsageLimit *int64
}

type Value_Row struct {
	Value time.Time
}

type Versioning_Row struct {
	Versioning int
}

type WalletAddress_Row struct {
	WalletAddress []byte
}

func (obj *pgxImpl) ReplaceNoReturn_AccountingTimestamps(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	accounting_timestamps_value AccountingTimestamps_Value_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__name_val := accounting_timestamps_name.value()
	__value_val := accounting_timestamps_value.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO accounting_timestamps ( name, value ) VALUES ( ?, ? ) ON CONFLICT ( name ) DO UPDATE SET name = EXCLUDED.name, value = EXCLUDED.value")

	var __values []any
	__values = append(__values, __name_val, __value_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Create_StoragenodeBandwidthRollup(ctx context.Context,
	storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
	storagenode_bandwidth_rollup_interval_start StoragenodeBandwidthRollup_IntervalStart_Field,
	storagenode_bandwidth_rollup_interval_seconds StoragenodeBandwidthRollup_IntervalSeconds_Field,
	storagenode_bandwidth_rollup_action StoragenodeBandwidthRollup_Action_Field,
	storagenode_bandwidth_rollup_settled StoragenodeBandwidthRollup_Settled_Field,
	optional StoragenodeBandwidthRollup_Create_Fields) (
	storagenode_bandwidth_rollup *StoragenodeBandwidthRollup, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__storagenode_id_val := storagenode_bandwidth_rollup_storagenode_id.value()
	__interval_start_val := storagenode_bandwidth_rollup_interval_start.value()
	__interval_seconds_val := storagenode_bandwidth_rollup_interval_seconds.value()
	__action_val := storagenode_bandwidth_rollup_action.value()
	__settled_val := storagenode_bandwidth_rollup_settled.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("storagenode_id, interval_start, interval_seconds, action, settled")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO storagenode_bandwidth_rollups "), __clause, __sqlbundle_Literal(" RETURNING storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled")}}

	var __values []any
	__values = append(__values, __storagenode_id_val, __interval_start_val, __interval_seconds_val, __action_val, __settled_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Allocated._set {
		__values = append(__values, optional.Allocated.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("allocated"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	storagenode_bandwidth_rollup = &StoragenodeBandwidthRollup{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return storagenode_bandwidth_rollup, nil

}

func (obj *pgxImpl) Create_ReverificationAudits(ctx context.Context,
	reverification_audits_node_id ReverificationAudits_NodeId_Field,
	reverification_audits_stream_id ReverificationAudits_StreamId_Field,
	reverification_audits_position ReverificationAudits_Position_Field,
	reverification_audits_piece_num ReverificationAudits_PieceNum_Field,
	optional ReverificationAudits_Create_Fields) (
	reverification_audits *ReverificationAudits, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__node_id_val := reverification_audits_node_id.value()
	__stream_id_val := reverification_audits_stream_id.value()
	__position_val := reverification_audits_position.value()
	__piece_num_val := reverification_audits_piece_num.value()
	__last_attempt_val := optional.LastAttempt.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("node_id, stream_id, position, piece_num, last_attempt")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO reverification_audits "), __clause, __sqlbundle_Literal(" RETURNING reverification_audits.node_id, reverification_audits.stream_id, reverification_audits.position, reverification_audits.piece_num, reverification_audits.inserted_at, reverification_audits.last_attempt, reverification_audits.reverify_count")}}

	var __values []any
	__values = append(__values, __node_id_val, __stream_id_val, __position_val, __piece_num_val, __last_attempt_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.InsertedAt._set {
		__values = append(__values, optional.InsertedAt.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("inserted_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ReverifyCount._set {
		__values = append(__values, optional.ReverifyCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("reverify_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reverification_audits = &ReverificationAudits{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reverification_audits.NodeId, &reverification_audits.StreamId, &reverification_audits.Position, &reverification_audits.PieceNum, &reverification_audits.InsertedAt, &reverification_audits.LastAttempt, &reverification_audits.ReverifyCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reverification_audits, nil

}

func (obj *pgxImpl) Create_StripeCustomer(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field,
	stripe_customer_customer_id StripeCustomer_CustomerId_Field,
	optional StripeCustomer_Create_Fields) (
	stripe_customer *StripeCustomer, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := stripe_customer_user_id.value()
	__customer_id_val := stripe_customer_customer_id.value()
	__billing_customer_id_val := optional.BillingCustomerId.value()
	__package_plan_val := optional.PackagePlan.value()
	__purchased_package_at_val := optional.PurchasedPackageAt.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO stripe_customers ( user_id, customer_id, billing_customer_id, package_plan, purchased_package_at, created_at ) VALUES ( ?, ?, ?, ?, ?, ? ) RETURNING stripe_customers.user_id, stripe_customers.customer_id, stripe_customers.billing_customer_id, stripe_customers.package_plan, stripe_customers.purchased_package_at, stripe_customers.created_at")

	var __values []any
	__values = append(__values, __user_id_val, __customer_id_val, __billing_customer_id_val, __package_plan_val, __purchased_package_at_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripe_customer = &StripeCustomer{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripe_customer.UserId, &stripe_customer.CustomerId, &stripe_customer.BillingCustomerId, &stripe_customer.PackagePlan, &stripe_customer.PurchasedPackageAt, &stripe_customer.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripe_customer, nil

}

func (obj *pgxImpl) CreateNoReturn_BillingBalance(ctx context.Context,
	billing_balance_user_id BillingBalance_UserId_Field,
	billing_balance_balance BillingBalance_Balance_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := billing_balance_user_id.value()
	__balance_val := billing_balance_balance.value()
	__last_updated_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO billing_balances ( user_id, balance, last_updated ) VALUES ( ?, ?, ? )")

	var __values []any
	__values = append(__values, __user_id_val, __balance_val, __last_updated_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Create_BillingTransaction(ctx context.Context,
	billing_transaction_user_id BillingTransaction_UserId_Field,
	billing_transaction_amount BillingTransaction_Amount_Field,
	billing_transaction_currency BillingTransaction_Currency_Field,
	billing_transaction_description BillingTransaction_Description_Field,
	billing_transaction_source BillingTransaction_Source_Field,
	billing_transaction_status BillingTransaction_Status_Field,
	billing_transaction_type BillingTransaction_Type_Field,
	billing_transaction_metadata BillingTransaction_Metadata_Field,
	billing_transaction_tx_timestamp BillingTransaction_TxTimestamp_Field) (
	billing_transaction *BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := billing_transaction_user_id.value()
	__amount_val := billing_transaction_amount.value()
	__currency_val := billing_transaction_currency.value()
	__description_val := billing_transaction_description.value()
	__source_val := billing_transaction_source.value()
	__status_val := billing_transaction_status.value()
	__type_val := billing_transaction_type.value()
	__metadata_val := billing_transaction_metadata.value()
	__tx_timestamp_val := billing_transaction_tx_timestamp.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO billing_transactions ( user_id, amount, currency, description, source, status, type, metadata, tx_timestamp, created_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) RETURNING billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at")

	var __values []any
	__values = append(__values, __user_id_val, __amount_val, __currency_val, __description_val, __source_val, __status_val, __type_val, __metadata_val, __tx_timestamp_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	billing_transaction = &BillingTransaction{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return billing_transaction, nil

}

func (obj *pgxImpl) CreateNoReturn_StorjscanWallet(ctx context.Context,
	storjscan_wallet_user_id StorjscanWallet_UserId_Field,
	storjscan_wallet_wallet_address StorjscanWallet_WalletAddress_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := storjscan_wallet_user_id.value()
	__wallet_address_val := storjscan_wallet_wallet_address.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO storjscan_wallets ( user_id, wallet_address, created_at ) VALUES ( ?, ?, ? )")

	var __values []any
	__values = append(__values, __user_id_val, __wallet_address_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Create_CoinpaymentsTransaction(ctx context.Context,
	coinpayments_transaction_id CoinpaymentsTransaction_Id_Field,
	coinpayments_transaction_user_id CoinpaymentsTransaction_UserId_Field,
	coinpayments_transaction_address CoinpaymentsTransaction_Address_Field,
	coinpayments_transaction_amount_numeric CoinpaymentsTransaction_AmountNumeric_Field,
	coinpayments_transaction_received_numeric CoinpaymentsTransaction_ReceivedNumeric_Field,
	coinpayments_transaction_status CoinpaymentsTransaction_Status_Field,
	coinpayments_transaction_key CoinpaymentsTransaction_Key_Field,
	coinpayments_transaction_timeout CoinpaymentsTransaction_Timeout_Field) (
	coinpayments_transaction *CoinpaymentsTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := coinpayments_transaction_id.value()
	__user_id_val := coinpayments_transaction_user_id.value()
	__address_val := coinpayments_transaction_address.value()
	__amount_numeric_val := coinpayments_transaction_amount_numeric.value()
	__received_numeric_val := coinpayments_transaction_received_numeric.value()
	__status_val := coinpayments_transaction_status.value()
	__key_val := coinpayments_transaction_key.value()
	__timeout_val := coinpayments_transaction_timeout.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO coinpayments_transactions ( id, user_id, address, amount_numeric, received_numeric, status, key, timeout, created_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ? ) RETURNING coinpayments_transactions.id, coinpayments_transactions.user_id, coinpayments_transactions.address, coinpayments_transactions.amount_numeric, coinpayments_transactions.received_numeric, coinpayments_transactions.status, coinpayments_transactions.key, coinpayments_transactions.timeout, coinpayments_transactions.created_at")

	var __values []any
	__values = append(__values, __id_val, __user_id_val, __address_val, __amount_numeric_val, __received_numeric_val, __status_val, __key_val, __timeout_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	coinpayments_transaction = &CoinpaymentsTransaction{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return coinpayments_transaction, nil

}

func (obj *pgxImpl) Create_StripecoinpaymentsInvoiceProjectRecord(ctx context.Context,
	stripecoinpayments_invoice_project_record_id StripecoinpaymentsInvoiceProjectRecord_Id_Field,
	stripecoinpayments_invoice_project_record_project_id StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field,
	stripecoinpayments_invoice_project_record_storage StripecoinpaymentsInvoiceProjectRecord_Storage_Field,
	stripecoinpayments_invoice_project_record_egress StripecoinpaymentsInvoiceProjectRecord_Egress_Field,
	stripecoinpayments_invoice_project_record_period_start StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field,
	stripecoinpayments_invoice_project_record_period_end StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field,
	stripecoinpayments_invoice_project_record_state StripecoinpaymentsInvoiceProjectRecord_State_Field,
	optional StripecoinpaymentsInvoiceProjectRecord_Create_Fields) (
	stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := stripecoinpayments_invoice_project_record_id.value()
	__project_id_val := stripecoinpayments_invoice_project_record_project_id.value()
	__storage_val := stripecoinpayments_invoice_project_record_storage.value()
	__egress_val := stripecoinpayments_invoice_project_record_egress.value()
	__objects_val := optional.Objects.value()
	__segments_val := optional.Segments.value()
	__period_start_val := stripecoinpayments_invoice_project_record_period_start.value()
	__period_end_val := stripecoinpayments_invoice_project_record_period_end.value()
	__state_val := stripecoinpayments_invoice_project_record_state.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO stripecoinpayments_invoice_project_records ( id, project_id, storage, egress, objects, segments, period_start, period_end, state, created_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) RETURNING stripecoinpayments_invoice_project_records.id, stripecoinpayments_invoice_project_records.project_id, stripecoinpayments_invoice_project_records.storage, stripecoinpayments_invoice_project_records.egress, stripecoinpayments_invoice_project_records.objects, stripecoinpayments_invoice_project_records.segments, stripecoinpayments_invoice_project_records.period_start, stripecoinpayments_invoice_project_records.period_end, stripecoinpayments_invoice_project_records.state, stripecoinpayments_invoice_project_records.created_at")

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __storage_val, __egress_val, __objects_val, __segments_val, __period_start_val, __period_end_val, __state_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_invoice_project_record = &StripecoinpaymentsInvoiceProjectRecord{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripecoinpayments_invoice_project_record, nil

}

func (obj *pgxImpl) Create_StripecoinpaymentsTxConversionRate(ctx context.Context,
	stripecoinpayments_tx_conversion_rate_tx_id StripecoinpaymentsTxConversionRate_TxId_Field,
	stripecoinpayments_tx_conversion_rate_rate_numeric StripecoinpaymentsTxConversionRate_RateNumeric_Field) (
	stripecoinpayments_tx_conversion_rate *StripecoinpaymentsTxConversionRate, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__tx_id_val := stripecoinpayments_tx_conversion_rate_tx_id.value()
	__rate_numeric_val := stripecoinpayments_tx_conversion_rate_rate_numeric.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO stripecoinpayments_tx_conversion_rates ( tx_id, rate_numeric, created_at ) VALUES ( ?, ?, ? ) RETURNING stripecoinpayments_tx_conversion_rates.tx_id, stripecoinpayments_tx_conversion_rates.rate_numeric, stripecoinpayments_tx_conversion_rates.created_at")

	var __values []any
	__values = append(__values, __tx_id_val, __rate_numeric_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_tx_conversion_rate = &StripecoinpaymentsTxConversionRate{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_tx_conversion_rate.TxId, &stripecoinpayments_tx_conversion_rate.RateNumeric, &stripecoinpayments_tx_conversion_rate.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripecoinpayments_tx_conversion_rate, nil

}

func (obj *pgxImpl) CreateNoReturn_StorjscanPayment(ctx context.Context,
	storjscan_payment_block_hash StorjscanPayment_BlockHash_Field,
	storjscan_payment_block_number StorjscanPayment_BlockNumber_Field,
	storjscan_payment_transaction StorjscanPayment_Transaction_Field,
	storjscan_payment_log_index StorjscanPayment_LogIndex_Field,
	storjscan_payment_from_address StorjscanPayment_FromAddress_Field,
	storjscan_payment_to_address StorjscanPayment_ToAddress_Field,
	storjscan_payment_token_value StorjscanPayment_TokenValue_Field,
	storjscan_payment_usd_value StorjscanPayment_UsdValue_Field,
	storjscan_payment_status StorjscanPayment_Status_Field,
	storjscan_payment_block_timestamp StorjscanPayment_BlockTimestamp_Field,
	optional StorjscanPayment_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__block_hash_val := storjscan_payment_block_hash.value()
	__block_number_val := storjscan_payment_block_number.value()
	__transaction_val := storjscan_payment_transaction.value()
	__log_index_val := storjscan_payment_log_index.value()
	__from_address_val := storjscan_payment_from_address.value()
	__to_address_val := storjscan_payment_to_address.value()
	__token_value_val := storjscan_payment_token_value.value()
	__usd_value_val := storjscan_payment_usd_value.value()
	__status_val := storjscan_payment_status.value()
	__block_timestamp_val := storjscan_payment_block_timestamp.value()
	__created_at_val := __now

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("block_hash, block_number, transaction, log_index, from_address, to_address, token_value, usd_value, status, block_timestamp, created_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO storjscan_payments "), __clause}}

	var __values []any
	__values = append(__values, __block_hash_val, __block_number_val, __transaction_val, __log_index_val, __from_address_val, __to_address_val, __token_value_val, __usd_value_val, __status_val, __block_timestamp_val, __created_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.ChainId._set {
		__values = append(__values, optional.ChainId.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("chain_id"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Create_ChangeHistory(ctx context.Context,
	change_history_id ChangeHistory_Id_Field,
	change_history_admin_email ChangeHistory_AdminEmail_Field,
	change_history_user_id ChangeHistory_UserId_Field,
	change_history_item_type ChangeHistory_ItemType_Field,
	change_history_operation ChangeHistory_Operation_Field,
	change_history_reason ChangeHistory_Reason_Field,
	change_history_changes ChangeHistory_Changes_Field,
	optional ChangeHistory_Create_Fields) (
	change_history *ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := change_history_id.value()
	__admin_email_val := change_history_admin_email.value()
	__user_id_val := change_history_user_id.value()
	__project_id_val := optional.ProjectId.value()
	__bucket_name_val := optional.BucketName.value()
	__item_type_val := change_history_item_type.value()
	__operation_val := change_history_operation.value()
	__reason_val := change_history_reason.value()
	__changes_val := change_history_changes.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, admin_email, user_id, project_id, bucket_name, item_type, operation, reason, changes")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO change_histories "), __clause, __sqlbundle_Literal(" RETURNING change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp")}}

	var __values []any
	__values = append(__values, __id_val, __admin_email_val, __user_id_val, __project_id_val, __bucket_name_val, __item_type_val, __operation_val, __reason_val, __changes_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Timestamp._set {
		__values = append(__values, optional.Timestamp.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("timestamp"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	change_history = &ChangeHistory{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return change_history, nil

}

func (obj *pgxImpl) Create_Domain(ctx context.Context,
	domain_subdomain Domain_Subdomain_Field,
	domain_project_id Domain_ProjectId_Field,
	domain_prefix Domain_Prefix_Field,
	domain_access_id Domain_AccessId_Field,
	domain_created_by Domain_CreatedBy_Field) (
	domain *Domain, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__subdomain_val := domain_subdomain.value()
	__project_id_val := domain_project_id.value()
	__prefix_val := domain_prefix.value()
	__access_id_val := domain_access_id.value()
	__created_by_val := domain_created_by.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO domains ( subdomain, project_id, prefix, access_id, created_by, created_at ) VALUES ( ?, ?, ?, ?, ?, ? ) RETURNING domains.subdomain, domains.project_id, domains.prefix, domains.access_id, domains.created_by, domains.created_at")

	var __values []any
	__values = append(__values, __subdomain_val, __project_id_val, __prefix_val, __access_id_val, __created_by_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	domain = &Domain{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&domain.Subdomain, &domain.ProjectId, &domain.Prefix, &domain.AccessId, &domain.CreatedBy, &domain.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return domain, nil

}

func (obj *pgxImpl) Replace_Entitlement(ctx context.Context,
	entitlement_scope Entitlement_Scope_Field,
	entitlement_updated_at Entitlement_UpdatedAt_Field,
	optional Entitlement_Create_Fields) (
	entitlement *Entitlement, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__scope_val := entitlement_scope.value()
	__updated_at_val := entitlement_updated_at.value()
	__created_at_val := __now

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("scope, updated_at, created_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO entitlements "), __clause, __sqlbundle_Literal(" ON CONFLICT ( scope ) DO UPDATE SET scope = EXCLUDED.scope, updated_at = EXCLUDED.updated_at, created_at = EXCLUDED.created_at, features = EXCLUDED.features RETURNING entitlements.scope, entitlements.features, entitlements.updated_at, entitlements.created_at")}}

	var __values []any
	__values = append(__values, __scope_val, __updated_at_val, __created_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Features._set {
		__values = append(__values, optional.Features.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("features"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	entitlement = &Entitlement{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&entitlement.Scope, &entitlement.Features, &entitlement.UpdatedAt, &entitlement.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return entitlement, nil

}

func (obj *pgxImpl) CreateNoReturn_PeerIdentity(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field,
	peer_identity_leaf_serial_number PeerIdentity_LeafSerialNumber_Field,
	peer_identity_chain PeerIdentity_Chain_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__node_id_val := peer_identity_node_id.value()
	__leaf_serial_number_val := peer_identity_leaf_serial_number.value()
	__chain_val := peer_identity_chain.value()
	__updated_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO peer_identities ( node_id, leaf_serial_number, chain, updated_at ) VALUES ( ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __node_id_val, __leaf_serial_number_val, __chain_val, __updated_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) CreateNoReturn_Revocation(ctx context.Context,
	revocation_revoked Revocation_Revoked_Field,
	revocation_api_key_id Revocation_ApiKeyId_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__revoked_val := revocation_revoked.value()
	__api_key_id_val := revocation_api_key_id.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO revocations ( revoked, api_key_id ) VALUES ( ?, ? )")

	var __values []any
	__values = append(__values, __revoked_val, __api_key_id_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) ReplaceNoReturn_NodeApiVersion(ctx context.Context,
	node_api_version_id NodeApiVersion_Id_Field,
	node_api_version_api_version NodeApiVersion_ApiVersion_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := node_api_version_id.value()
	__api_version_val := node_api_version_api_version.value()
	__created_at_val := __now
	__updated_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO node_api_versions ( id, api_version, created_at, updated_at ) VALUES ( ?, ?, ?, ? ) ON CONFLICT ( id ) DO UPDATE SET id = EXCLUDED.id, api_version = EXCLUDED.api_version, created_at = EXCLUDED.created_at, updated_at = EXCLUDED.updated_at")

	var __values []any
	__values = append(__values, __id_val, __api_version_val, __created_at_val, __updated_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Create_NodeEvent(ctx context.Context,
	node_event_id NodeEvent_Id_Field,
	node_event_email NodeEvent_Email_Field,
	node_event_node_id NodeEvent_NodeId_Field,
	node_event_event NodeEvent_Event_Field,
	optional NodeEvent_Create_Fields) (
	node_event *NodeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := node_event_id.value()
	__email_val := node_event_email.value()
	__last_ip_port_val := optional.LastIpPort.value()
	__node_id_val := node_event_node_id.value()
	__event_val := node_event_event.value()
	__last_attempted_val := optional.LastAttempted.value()
	__email_sent_val := optional.EmailSent.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, email, last_ip_port, node_id, event, last_attempted, email_sent")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO node_events "), __clause, __sqlbundle_Literal(" RETURNING node_events.id, node_events.email, node_events.last_ip_port, node_events.node_id, node_events.event, node_events.created_at, node_events.last_attempted, node_events.email_sent")}}

	var __values []any
	__values = append(__values, __id_val, __email_val, __last_ip_port_val, __node_id_val, __event_val, __last_attempted_val, __email_sent_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.CreatedAt._set {
		__values = append(__values, optional.CreatedAt.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("created_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node_event = &NodeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node_event, nil

}

func (obj *pgxImpl) ReplaceNoReturn_NodeTags(ctx context.Context,
	node_tags_node_id NodeTags_NodeId_Field,
	node_tags_name NodeTags_Name_Field,
	node_tags_value NodeTags_Value_Field,
	node_tags_signed_at NodeTags_SignedAt_Field,
	node_tags_signer NodeTags_Signer_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__node_id_val := node_tags_node_id.value()
	__name_val := node_tags_name.value()
	__value_val := node_tags_value.value()
	__signed_at_val := node_tags_signed_at.value()
	__signer_val := node_tags_signer.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO node_tags ( node_id, name, value, signed_at, signer ) VALUES ( ?, ?, ?, ?, ? ) ON CONFLICT ( node_id, name, signer ) DO UPDATE SET node_id = EXCLUDED.node_id, name = EXCLUDED.name, value = EXCLUDED.value, signed_at = EXCLUDED.signed_at, signer = EXCLUDED.signer")

	var __values []any
	__values = append(__values, __node_id_val, __name_val, __value_val, __signed_at_val, __signer_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) ReplaceNoReturn_StoragenodePaystub(ctx context.Context,
	storagenode_paystub_period StoragenodePaystub_Period_Field,
	storagenode_paystub_node_id StoragenodePaystub_NodeId_Field,
	storagenode_paystub_codes StoragenodePaystub_Codes_Field,
	storagenode_paystub_usage_at_rest StoragenodePaystub_UsageAtRest_Field,
	storagenode_paystub_usage_get StoragenodePaystub_UsageGet_Field,
	storagenode_paystub_usage_put StoragenodePaystub_UsagePut_Field,
	storagenode_paystub_usage_get_repair StoragenodePaystub_UsageGetRepair_Field,
	storagenode_paystub_usage_put_repair StoragenodePaystub_UsagePutRepair_Field,
	storagenode_paystub_usage_get_audit StoragenodePaystub_UsageGetAudit_Field,
	storagenode_paystub_comp_at_rest StoragenodePaystub_CompAtRest_Field,
	storagenode_paystub_comp_get StoragenodePaystub_CompGet_Field,
	storagenode_paystub_comp_put StoragenodePaystub_CompPut_Field,
	storagenode_paystub_comp_get_repair StoragenodePaystub_CompGetRepair_Field,
	storagenode_paystub_comp_put_repair StoragenodePaystub_CompPutRepair_Field,
	storagenode_paystub_comp_get_audit StoragenodePaystub_CompGetAudit_Field,
	storagenode_paystub_surge_percent StoragenodePaystub_SurgePercent_Field,
	storagenode_paystub_held StoragenodePaystub_Held_Field,
	storagenode_paystub_owed StoragenodePaystub_Owed_Field,
	storagenode_paystub_disposed StoragenodePaystub_Disposed_Field,
	storagenode_paystub_paid StoragenodePaystub_Paid_Field,
	storagenode_paystub_distributed StoragenodePaystub_Distributed_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__period_val := storagenode_paystub_period.value()
	__node_id_val := storagenode_paystub_node_id.value()
	__created_at_val := __now
	__codes_val := storagenode_paystub_codes.value()
	__usage_at_rest_val := storagenode_paystub_usage_at_rest.value()
	__usage_get_val := storagenode_paystub_usage_get.value()
	__usage_put_val := storagenode_paystub_usage_put.value()
	__usage_get_repair_val := storagenode_paystub_usage_get_repair.value()
	__usage_put_repair_val := storagenode_paystub_usage_put_repair.value()
	__usage_get_audit_val := storagenode_paystub_usage_get_audit.value()
	__comp_at_rest_val := storagenode_paystub_comp_at_rest.value()
	__comp_get_val := storagenode_paystub_comp_get.value()
	__comp_put_val := storagenode_paystub_comp_put.value()
	__comp_get_repair_val := storagenode_paystub_comp_get_repair.value()
	__comp_put_repair_val := storagenode_paystub_comp_put_repair.value()
	__comp_get_audit_val := storagenode_paystub_comp_get_audit.value()
	__surge_percent_val := storagenode_paystub_surge_percent.value()
	__held_val := storagenode_paystub_held.value()
	__owed_val := storagenode_paystub_owed.value()
	__disposed_val := storagenode_paystub_disposed.value()
	__paid_val := storagenode_paystub_paid.value()
	__distributed_val := storagenode_paystub_distributed.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO storagenode_paystubs ( period, node_id, created_at, codes, usage_at_rest, usage_get, usage_put, usage_get_repair, usage_put_repair, usage_get_audit, comp_at_rest, comp_get, comp_put, comp_get_repair, comp_put_repair, comp_get_audit, surge_percent, held, owed, disposed, paid, distributed ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) ON CONFLICT ( period, node_id ) DO UPDATE SET period = EXCLUDED.period, node_id = EXCLUDED.node_id, created_at = EXCLUDED.created_at, codes = EXCLUDED.codes, usage_at_rest = EXCLUDED.usage_at_rest, usage_get = EXCLUDED.usage_get, usage_put = EXCLUDED.usage_put, usage_get_repair = EXCLUDED.usage_get_repair, usage_put_repair = EXCLUDED.usage_put_repair, usage_get_audit = EXCLUDED.usage_get_audit, comp_at_rest = EXCLUDED.comp_at_rest, comp_get = EXCLUDED.comp_get, comp_put = EXCLUDED.comp_put, comp_get_repair = EXCLUDED.comp_get_repair, comp_put_repair = EXCLUDED.comp_put_repair, comp_get_audit = EXCLUDED.comp_get_audit, surge_percent = EXCLUDED.surge_percent, held = EXCLUDED.held, owed = EXCLUDED.owed, disposed = EXCLUDED.disposed, paid = EXCLUDED.paid, distributed = EXCLUDED.distributed")

	var __values []any
	__values = append(__values, __period_val, __node_id_val, __created_at_val, __codes_val, __usage_at_rest_val, __usage_get_val, __usage_put_val, __usage_get_repair_val, __usage_put_repair_val, __usage_get_audit_val, __comp_at_rest_val, __comp_get_val, __comp_put_val, __comp_get_repair_val, __comp_put_repair_val, __comp_get_audit_val, __surge_percent_val, __held_val, __owed_val, __disposed_val, __paid_val, __distributed_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) CreateNoReturn_StoragenodePayment(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field,
	storagenode_payment_period StoragenodePayment_Period_Field,
	storagenode_payment_amount StoragenodePayment_Amount_Field,
	optional StoragenodePayment_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__created_at_val := __now
	__node_id_val := storagenode_payment_node_id.value()
	__period_val := storagenode_payment_period.value()
	__amount_val := storagenode_payment_amount.value()
	__receipt_val := optional.Receipt.value()
	__notes_val := optional.Notes.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO storagenode_payments ( created_at, node_id, period, amount, receipt, notes ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __created_at_val, __node_id_val, __period_val, __amount_val, __receipt_val, __notes_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Create_Reputation(ctx context.Context,
	reputation_id Reputation_Id_Field,
	reputation_audit_history Reputation_AuditHistory_Field,
	optional Reputation_Create_Fields) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := reputation_id.value()
	__vetted_at_val := optional.VettedAt.value()
	__disqualified_val := optional.Disqualified.value()
	__disqualification_reason_val := optional.DisqualificationReason.value()
	__unknown_audit_suspended_val := optional.UnknownAuditSuspended.value()
	__offline_suspended_val := optional.OfflineSuspended.value()
	__under_review_val := optional.UnderReview.value()
	__audit_history_val := reputation_audit_history.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, vetted_at, disqualified, disqualification_reason, unknown_audit_suspended, offline_suspended, under_review, audit_history")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO reputations "), __clause, __sqlbundle_Literal(" RETURNING reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta")}}

	var __values []any
	__values = append(__values, __id_val, __vetted_at_val, __disqualified_val, __disqualification_reason_val, __unknown_audit_suspended_val, __offline_suspended_val, __under_review_val, __audit_history_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.AuditSuccessCount._set {
		__values = append(__values, optional.AuditSuccessCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_success_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.TotalAuditCount._set {
		__values = append(__values, optional.TotalAuditCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("total_audit_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.OnlineScore._set {
		__values = append(__values, optional.OnlineScore.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("online_score"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.AuditReputationAlpha._set {
		__values = append(__values, optional.AuditReputationAlpha.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_reputation_alpha"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.AuditReputationBeta._set {
		__values = append(__values, optional.AuditReputationBeta.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_reputation_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.UnknownAuditReputationAlpha._set {
		__values = append(__values, optional.UnknownAuditReputationAlpha.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.UnknownAuditReputationBeta._set {
		__values = append(__values, optional.UnknownAuditReputationBeta.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reputation, nil

}

func (obj *pgxImpl) CreateNoReturn_OauthClient(ctx context.Context,
	oauth_client_id OauthClient_Id_Field,
	oauth_client_encrypted_secret OauthClient_EncryptedSecret_Field,
	oauth_client_redirect_url OauthClient_RedirectUrl_Field,
	oauth_client_user_id OauthClient_UserId_Field,
	oauth_client_app_name OauthClient_AppName_Field,
	oauth_client_app_logo_url OauthClient_AppLogoUrl_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := oauth_client_id.value()
	__encrypted_secret_val := oauth_client_encrypted_secret.value()
	__redirect_url_val := oauth_client_redirect_url.value()
	__user_id_val := oauth_client_user_id.value()
	__app_name_val := oauth_client_app_name.value()
	__app_logo_url_val := oauth_client_app_logo_url.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO oauth_clients ( id, encrypted_secret, redirect_url, user_id, app_name, app_logo_url ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __id_val, __encrypted_secret_val, __redirect_url_val, __user_id_val, __app_name_val, __app_logo_url_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) CreateNoReturn_OauthCode(ctx context.Context,
	oauth_code_client_id OauthCode_ClientId_Field,
	oauth_code_user_id OauthCode_UserId_Field,
	oauth_code_scope OauthCode_Scope_Field,
	oauth_code_redirect_url OauthCode_RedirectUrl_Field,
	oauth_code_challenge OauthCode_Challenge_Field,
	oauth_code_challenge_method OauthCode_ChallengeMethod_Field,
	oauth_code_code OauthCode_Code_Field,
	oauth_code_created_at OauthCode_CreatedAt_Field,
	oauth_code_expires_at OauthCode_ExpiresAt_Field,
	optional OauthCode_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__client_id_val := oauth_code_client_id.value()
	__user_id_val := oauth_code_user_id.value()
	__scope_val := oauth_code_scope.value()
	__redirect_url_val := oauth_code_redirect_url.value()
	__challenge_val := oauth_code_challenge.value()
	__challenge_method_val := oauth_code_challenge_method.value()
	__code_val := oauth_code_code.value()
	__created_at_val := oauth_code_created_at.value()
	__expires_at_val := oauth_code_expires_at.value()
	__claimed_at_val := optional.ClaimedAt.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO oauth_codes ( client_id, user_id, scope, redirect_url, challenge, challenge_method, code, created_at, expires_at, claimed_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __client_id_val, __user_id_val, __scope_val, __redirect_url_val, __challenge_val, __challenge_method_val, __code_val, __created_at_val, __expires_at_val, __claimed_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) CreateNoReturn_OauthToken(ctx context.Context,
	oauth_token_client_id OauthToken_ClientId_Field,
	oauth_token_user_id OauthToken_UserId_Field,
	oauth_token_scope OauthToken_Scope_Field,
	oauth_token_kind OauthToken_Kind_Field,
	oauth_token_token OauthToken_Token_Field,
	oauth_token_created_at OauthToken_CreatedAt_Field,
	oauth_token_expires_at OauthToken_ExpiresAt_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__client_id_val := oauth_token_client_id.value()
	__user_id_val := oauth_token_user_id.value()
	__scope_val := oauth_token_scope.value()
	__kind_val := oauth_token_kind.value()
	__token_val := oauth_token_token.value()
	__created_at_val := oauth_token_created_at.value()
	__expires_at_val := oauth_token_expires_at.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO oauth_tokens ( client_id, user_id, scope, kind, token, created_at, expires_at ) VALUES ( ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __client_id_val, __user_id_val, __scope_val, __kind_val, __token_val, __created_at_val, __expires_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Create_Project(ctx context.Context,
	project_id Project_Id_Field,
	project_name Project_Name_Field,
	project_description Project_Description_Field,
	project_owner_id Project_OwnerId_Field,
	optional Project_Create_Fields) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := project_id.value()
	__public_id_val := optional.PublicId.value()
	__name_val := project_name.value()
	__description_val := project_description.value()
	__usage_limit_val := optional.UsageLimit.value()
	__bandwidth_limit_val := optional.BandwidthLimit.value()
	__user_specified_usage_limit_val := optional.UserSpecifiedUsageLimit.value()
	__user_specified_bandwidth_limit_val := optional.UserSpecifiedBandwidthLimit.value()
	__rate_limit_val := optional.RateLimit.value()
	__burst_limit_val := optional.BurstLimit.value()
	__rate_limit_head_val := optional.RateLimitHead.value()
	__burst_limit_head_val := optional.BurstLimitHead.value()
	__rate_limit_get_val := optional.RateLimitGet.value()
	__burst_limit_get_val := optional.BurstLimitGet.value()
	__rate_limit_put_val := optional.RateLimitPut.value()
	__burst_limit_put_val := optional.BurstLimitPut.value()
	__rate_limit_list_val := optional.RateLimitList.value()
	__burst_limit_list_val := optional.BurstLimitList.value()
	__rate_limit_del_val := optional.RateLimitDel.value()
	__burst_limit_del_val := optional.BurstLimitDel.value()
	__max_buckets_val := optional.MaxBuckets.value()
	__user_agent_val := optional.UserAgent.value()
	__owner_id_val := project_owner_id.value()
	__salt_val := optional.Salt.value()
	__status_updated_at_val := optional.StatusUpdatedAt.value()
	__created_at_val := __now
	__default_placement_val := optional.DefaultPlacement.value()
	__passphrase_enc_val := optional.PassphraseEnc.value()
	__passphrase_enc_key_id_val := optional.PassphraseEncKeyId.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, public_id, name, description, usage_limit, bandwidth_limit, user_specified_usage_limit, user_specified_bandwidth_limit, rate_limit, burst_limit, rate_limit_head, burst_limit_head, rate_limit_get, burst_limit_get, rate_limit_put, burst_limit_put, rate_limit_list, burst_limit_list, rate_limit_del, burst_limit_del, max_buckets, user_agent, owner_id, salt, status_updated_at, created_at, default_placement, passphrase_enc, passphrase_enc_key_id")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO projects "), __clause, __sqlbundle_Literal(" RETURNING projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption")}}

	var __values []any
	__values = append(__values, __id_val, __public_id_val, __name_val, __description_val, __usage_limit_val, __bandwidth_limit_val, __user_specified_usage_limit_val, __user_specified_bandwidth_limit_val, __rate_limit_val, __burst_limit_val, __rate_limit_head_val, __burst_limit_head_val, __rate_limit_get_val, __burst_limit_get_val, __rate_limit_put_val, __burst_limit_put_val, __rate_limit_list_val, __burst_limit_list_val, __rate_limit_del_val, __burst_limit_del_val, __max_buckets_val, __user_agent_val, __owner_id_val, __salt_val, __status_updated_at_val, __created_at_val, __default_placement_val, __passphrase_enc_val, __passphrase_enc_key_id_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.SegmentLimit._set {
		__values = append(__values, optional.SegmentLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("segment_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.Status._set {
		__values = append(__values, optional.Status.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("status"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.DefaultVersioning._set {
		__values = append(__values, optional.DefaultVersioning.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("default_versioning"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.PromptedForVersioningBeta._set {
		__values = append(__values, optional.PromptedForVersioningBeta.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("prompted_for_versioning_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.PathEncryption._set {
		__values = append(__values, optional.PathEncryption.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("path_encryption"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil

}

func (obj *pgxImpl) Create_ProjectMember(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field,
	optional ProjectMember_Create_Fields) (
	project_member *ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__member_id_val := project_member_member_id.value()
	__project_id_val := project_member_project_id.value()
	__created_at_val := __now

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("member_id, project_id, created_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO project_members "), __clause, __sqlbundle_Literal(" RETURNING project_members.member_id, project_members.project_id, project_members.role, project_members.created_at")}}

	var __values []any
	__values = append(__values, __member_id_val, __project_id_val, __created_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Role._set {
		__values = append(__values, optional.Role.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("role"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_member = &ProjectMember{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_member, nil

}

func (obj *pgxImpl) Replace_ProjectInvitation(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field,
	optional ProjectInvitation_Create_Fields) (
	project_invitation *ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__project_id_val := project_invitation_project_id.value()
	__email_val := project_invitation_email.value()
	__inviter_id_val := optional.InviterId.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO project_invitations ( project_id, email, inviter_id, created_at ) VALUES ( ?, ?, ?, ? ) ON CONFLICT ( project_id, email ) DO UPDATE SET project_id = EXCLUDED.project_id, email = EXCLUDED.email, inviter_id = EXCLUDED.inviter_id, created_at = EXCLUDED.created_at RETURNING project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at")

	var __values []any
	__values = append(__values, __project_id_val, __email_val, __inviter_id_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_invitation = &ProjectInvitation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_invitation, nil

}

func (obj *pgxImpl) Create_ApiKey(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	api_key_project_id ApiKey_ProjectId_Field,
	api_key_head ApiKey_Head_Field,
	api_key_name ApiKey_Name_Field,
	api_key_secret ApiKey_Secret_Field,
	optional ApiKey_Create_Fields) (
	api_key *ApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := api_key_id.value()
	__project_id_val := api_key_project_id.value()
	__head_val := api_key_head.value()
	__name_val := api_key_name.value()
	__secret_val := api_key_secret.value()
	__user_agent_val := optional.UserAgent.value()
	__created_at_val := __now
	__created_by_val := optional.CreatedBy.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, project_id, head, name, secret, user_agent, created_at, created_by")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO api_keys "), __clause, __sqlbundle_Literal(" RETURNING api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version")}}

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __head_val, __name_val, __secret_val, __user_agent_val, __created_at_val, __created_by_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Version._set {
		__values = append(__values, optional.Version.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("version"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key = &ApiKey{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Head, &api_key.Name, &api_key.Secret, &api_key.UserAgent, &api_key.CreatedAt, &api_key.CreatedBy, &api_key.Version)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil

}

func (obj *pgxImpl) Replace_ApiKeyTail(ctx context.Context,
	api_key_tail_tail ApiKeyTail_Tail_Field,
	api_key_tail_parent_tail ApiKeyTail_ParentTail_Field,
	api_key_tail_caveat ApiKeyTail_Caveat_Field,
	api_key_tail_last_used ApiKeyTail_LastUsed_Field,
	optional ApiKeyTail_Create_Fields) (
	api_key_tail *ApiKeyTail, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__root_key_id_val := optional.RootKeyId.value()
	__tail_val := api_key_tail_tail.value()
	__parent_tail_val := api_key_tail_parent_tail.value()
	__caveat_val := api_key_tail_caveat.value()
	__last_used_val := api_key_tail_last_used.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO api_key_tails ( root_key_id, tail, parent_tail, caveat, last_used ) VALUES ( ?, ?, ?, ?, ? ) ON CONFLICT ( tail ) DO UPDATE SET root_key_id = EXCLUDED.root_key_id, tail = EXCLUDED.tail, parent_tail = EXCLUDED.parent_tail, caveat = EXCLUDED.caveat, last_used = EXCLUDED.last_used RETURNING api_key_tails.root_key_id, api_key_tails.tail, api_key_tails.parent_tail, api_key_tails.caveat, api_key_tails.last_used")

	var __values []any
	__values = append(__values, __root_key_id_val, __tail_val, __parent_tail_val, __caveat_val, __last_used_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key_tail = &ApiKeyTail{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&api_key_tail.RootKeyId, &api_key_tail.Tail, &api_key_tail.ParentTail, &api_key_tail.Caveat, &api_key_tail.LastUsed)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key_tail, nil

}

func (obj *pgxImpl) Create_BucketMetainfo(ctx context.Context,
	bucket_metainfo_id BucketMetainfo_Id_Field,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	bucket_metainfo_path_cipher BucketMetainfo_PathCipher_Field,
	bucket_metainfo_default_segment_size BucketMetainfo_DefaultSegmentSize_Field,
	bucket_metainfo_default_encryption_cipher_suite BucketMetainfo_DefaultEncryptionCipherSuite_Field,
	bucket_metainfo_default_encryption_block_size BucketMetainfo_DefaultEncryptionBlockSize_Field,
	bucket_metainfo_default_redundancy_algorithm BucketMetainfo_DefaultRedundancyAlgorithm_Field,
	bucket_metainfo_default_redundancy_share_size BucketMetainfo_DefaultRedundancyShareSize_Field,
	bucket_metainfo_default_redundancy_required_shares BucketMetainfo_DefaultRedundancyRequiredShares_Field,
	bucket_metainfo_default_redundancy_repair_shares BucketMetainfo_DefaultRedundancyRepairShares_Field,
	bucket_metainfo_default_redundancy_optimal_shares BucketMetainfo_DefaultRedundancyOptimalShares_Field,
	bucket_metainfo_default_redundancy_total_shares BucketMetainfo_DefaultRedundancyTotalShares_Field,
	optional BucketMetainfo_Create_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := bucket_metainfo_id.value()
	__project_id_val := bucket_metainfo_project_id.value()
	__name_val := bucket_metainfo_name.value()
	__tags_val := optional.Tags.value()
	__user_agent_val := optional.UserAgent.value()
	__default_retention_mode_val := optional.DefaultRetentionMode.value()
	__default_retention_days_val := optional.DefaultRetentionDays.value()
	__default_retention_years_val := optional.DefaultRetentionYears.value()
	__path_cipher_val := bucket_metainfo_path_cipher.value()
	__created_at_val := __now
	__default_segment_size_val := bucket_metainfo_default_segment_size.value()
	__default_encryption_cipher_suite_val := bucket_metainfo_default_encryption_cipher_suite.value()
	__default_encryption_block_size_val := bucket_metainfo_default_encryption_block_size.value()
	__default_redundancy_algorithm_val := bucket_metainfo_default_redundancy_algorithm.value()
	__default_redundancy_share_size_val := bucket_metainfo_default_redundancy_share_size.value()
	__default_redundancy_required_shares_val := bucket_metainfo_default_redundancy_required_shares.value()
	__default_redundancy_repair_shares_val := bucket_metainfo_default_redundancy_repair_shares.value()
	__default_redundancy_optimal_shares_val := bucket_metainfo_default_redundancy_optimal_shares.value()
	__default_redundancy_total_shares_val := bucket_metainfo_default_redundancy_total_shares.value()
	__placement_val := optional.Placement.value()
	__created_by_val := optional.CreatedBy.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, project_id, name, tags, user_agent, default_retention_mode, default_retention_days, default_retention_years, path_cipher, created_at, default_segment_size, default_encryption_cipher_suite, default_encryption_block_size, default_redundancy_algorithm, default_redundancy_share_size, default_redundancy_required_shares, default_redundancy_repair_shares, default_redundancy_optimal_shares, default_redundancy_total_shares, placement, created_by")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO bucket_metainfos "), __clause, __sqlbundle_Literal(" RETURNING bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __name_val, __tags_val, __user_agent_val, __default_retention_mode_val, __default_retention_days_val, __default_retention_years_val, __path_cipher_val, __created_at_val, __default_segment_size_val, __default_encryption_cipher_suite_val, __default_encryption_block_size_val, __default_redundancy_algorithm_val, __default_redundancy_share_size_val, __default_redundancy_required_shares_val, __default_redundancy_repair_shares_val, __default_redundancy_optimal_shares_val, __default_redundancy_total_shares_val, __placement_val, __created_by_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Versioning._set {
		__values = append(__values, optional.Versioning.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("versioning"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ObjectLockEnabled._set {
		__values = append(__values, optional.ObjectLockEnabled.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("object_lock_enabled"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil

}

func (obj *pgxImpl) Create_ValueAttribution(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field,
	optional ValueAttribution_Create_Fields) (
	value_attribution *ValueAttribution, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__project_id_val := value_attribution_project_id.value()
	__bucket_name_val := value_attribution_bucket_name.value()
	__user_agent_val := optional.UserAgent.value()
	__placement_val := optional.Placement.value()
	__last_updated_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO value_attributions ( project_id, bucket_name, user_agent, placement, last_updated ) VALUES ( ?, ?, ?, ?, ? ) RETURNING value_attributions.project_id, value_attributions.bucket_name, value_attributions.user_agent, value_attributions.placement, value_attributions.last_updated")

	var __values []any
	__values = append(__values, __project_id_val, __bucket_name_val, __user_agent_val, __placement_val, __last_updated_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	value_attribution = &ValueAttribution{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return value_attribution, nil

}

func (obj *pgxImpl) Create_BucketMigration(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field,
	bucket_migration_project_id BucketMigration_ProjectId_Field,
	bucket_migration_bucket_name BucketMigration_BucketName_Field,
	bucket_migration_from_placement BucketMigration_FromPlacement_Field,
	bucket_migration_to_placement BucketMigration_ToPlacement_Field,
	bucket_migration_migration_type BucketMigration_MigrationType_Field,
	bucket_migration_state BucketMigration_State_Field,
	optional BucketMigration_Create_Fields) (
	bucket_migration *BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := bucket_migration_id.value()
	__project_id_val := bucket_migration_project_id.value()
	__bucket_name_val := bucket_migration_bucket_name.value()
	__from_placement_val := bucket_migration_from_placement.value()
	__to_placement_val := bucket_migration_to_placement.value()
	__migration_type_val := bucket_migration_migration_type.value()
	__state_val := bucket_migration_state.value()
	__error_message_val := optional.ErrorMessage.value()
	__created_at_val := __now
	__updated_at_val := __now
	__completed_at_val := optional.CompletedAt.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, project_id, bucket_name, from_placement, to_placement, migration_type, state, error_message, created_at, updated_at, completed_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO bucket_migrations "), __clause, __sqlbundle_Literal(" RETURNING bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at")}}

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __bucket_name_val, __from_placement_val, __to_placement_val, __migration_type_val, __state_val, __error_message_val, __created_at_val, __updated_at_val, __completed_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.BytesProcessed._set {
		__values = append(__values, optional.BytesProcessed.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("bytes_processed"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_migration = &BucketMigration{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_migration, nil

}

func (obj *pgxImpl) CreateNoReturn_RestApiKey(ctx context.Context,
	rest_api_key_id RestApiKey_Id_Field,
	rest_api_key_user_id RestApiKey_UserId_Field,
	rest_api_key_token RestApiKey_Token_Field,
	rest_api_key_name RestApiKey_Name_Field,
	optional RestApiKey_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := rest_api_key_id.value()
	__user_id_val := rest_api_key_user_id.value()
	__token_val := rest_api_key_token.value()
	__name_val := rest_api_key_name.value()
	__expires_at_val := optional.ExpiresAt.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO rest_api_keys ( id, user_id, token, name, expires_at, created_at ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __id_val, __user_id_val, __token_val, __name_val, __expires_at_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Create_User(ctx context.Context,
	user_id User_Id_Field,
	user_email User_Email_Field,
	user_normalized_email User_NormalizedEmail_Field,
	user_full_name User_FullName_Field,
	user_password_hash User_PasswordHash_Field,
	optional User_Create_Fields) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := user_id.value()
	__external_id_val := optional.ExternalId.value()
	__tenant_id_val := optional.TenantId.value()
	__email_val := user_email.value()
	__normalized_email_val := user_normalized_email.value()
	__full_name_val := user_full_name.value()
	__short_name_val := optional.ShortName.value()
	__password_hash_val := user_password_hash.value()
	__new_unverified_email_val := optional.NewUnverifiedEmail.value()
	__status_val := int(0)
	__status_updated_at_val := optional.StatusUpdatedAt.value()
	__user_agent_val := optional.UserAgent.value()
	__created_at_val := __now
	__position_val := optional.Position.value()
	__company_name_val := optional.CompanyName.value()
	__company_size_val := optional.CompanySize.value()
	__working_on_val := optional.WorkingOn.value()
	__employee_count_val := optional.EmployeeCount.value()
	__mfa_secret_key_val := optional.MfaSecretKey.value()
	__mfa_recovery_codes_val := optional.MfaRecoveryCodes.value()
	__signup_promo_code_val := optional.SignupPromoCode.value()
	__failed_login_count_val := optional.FailedLoginCount.value()
	__login_lockout_expiration_val := optional.LoginLockoutExpiration.value()
	__signup_captcha_val := optional.SignupCaptcha.value()
	__default_placement_val := optional.DefaultPlacement.value()
	__activation_code_val := optional.ActivationCode.value()
	__signup_id_val := optional.SignupId.value()
	__trial_expiration_val := optional.TrialExpiration.value()
	__upgrade_time_val := optional.UpgradeTime.value()
	__hubspot_object_id_val := optional.HubspotObjectId.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, external_id, tenant_id, email, normalized_email, full_name, short_name, password_hash, new_unverified_email, status, status_updated_at, user_agent, created_at, position, company_name, company_size, working_on, employee_count, mfa_secret_key, mfa_recovery_codes, signup_promo_code, failed_login_count, login_lockout_expiration, signup_captcha, default_placement, activation_code, signup_id, trial_expiration, upgrade_time, hubspot_object_id")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO users "), __clause, __sqlbundle_Literal(" RETURNING users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id")}}

	var __values []any
	__values = append(__values, __id_val, __external_id_val, __tenant_id_val, __email_val, __normalized_email_val, __full_name_val, __short_name_val, __password_hash_val, __new_unverified_email_val, __status_val, __status_updated_at_val, __user_agent_val, __created_at_val, __position_val, __company_name_val, __company_size_val, __working_on_val, __employee_count_val, __mfa_secret_key_val, __mfa_recovery_codes_val, __signup_promo_code_val, __failed_login_count_val, __login_lockout_expiration_val, __signup_captcha_val, __default_placement_val, __activation_code_val, __signup_id_val, __trial_expiration_val, __upgrade_time_val, __hubspot_object_id_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.EmailChangeVerificationStep._set {
		__values = append(__values, optional.EmailChangeVerificationStep.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("email_change_verification_step"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.FinalInvoiceGenerated._set {
		__values = append(__values, optional.FinalInvoiceGenerated.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("final_invoice_generated"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectLimit._set {
		__values = append(__values, optional.ProjectLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectBandwidthLimit._set {
		__values = append(__values, optional.ProjectBandwidthLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_bandwidth_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectStorageLimit._set {
		__values = append(__values, optional.ProjectStorageLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_storage_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectSegmentLimit._set {
		__values = append(__values, optional.ProjectSegmentLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_segment_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.Kind._set {
		__values = append(__values, optional.Kind.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("kind"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.IsProfessional._set {
		__values = append(__values, optional.IsProfessional.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("is_professional"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.HaveSalesContact._set {
		__values = append(__values, optional.HaveSalesContact.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("have_sales_contact"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.MfaEnabled._set {
		__values = append(__values, optional.MfaEnabled.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("mfa_enabled"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.VerificationReminders._set {
		__values = append(__values, optional.VerificationReminders.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("verification_reminders"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.TrialNotifications._set {
		__values = append(__values, optional.TrialNotifications.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("trial_notifications"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil

}

func (obj *pgxImpl) Create_WebappSession(ctx context.Context,
	webapp_session_id WebappSession_Id_Field,
	webapp_session_user_id WebappSession_UserId_Field,
	webapp_session_ip_address WebappSession_IpAddress_Field,
	webapp_session_user_agent WebappSession_UserAgent_Field,
	webapp_session_expires_at WebappSession_ExpiresAt_Field) (
	webapp_session *WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := webapp_session_id.value()
	__user_id_val := webapp_session_user_id.value()
	__ip_address_val := webapp_session_ip_address.value()
	__user_agent_val := webapp_session_user_agent.value()
	__status_val := int(0)
	__expires_at_val := webapp_session_expires_at.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO webapp_sessions ( id, user_id, ip_address, user_agent, status, expires_at ) VALUES ( ?, ?, ?, ?, ?, ? ) RETURNING webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at")

	var __values []any
	__values = append(__values, __id_val, __user_id_val, __ip_address_val, __user_agent_val, __status_val, __expires_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	webapp_session = &WebappSession{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return webapp_session, nil

}

func (obj *pgxImpl) Create_RegistrationToken(ctx context.Context,
	registration_token_secret RegistrationToken_Secret_Field,
	registration_token_project_limit RegistrationToken_ProjectLimit_Field,
	optional RegistrationToken_Create_Fields) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__secret_val := registration_token_secret.value()
	__owner_id_val := optional.OwnerId.value()
	__project_limit_val := registration_token_project_limit.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO registration_tokens ( secret, owner_id, project_limit, created_at ) VALUES ( ?, ?, ?, ? ) RETURNING registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at")

	var __values []any
	__values = append(__values, __secret_val, __owner_id_val, __project_limit_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return registration_token, nil

}

func (obj *pgxImpl) Create_ResetPasswordToken(ctx context.Context,
	reset_password_token_secret ResetPasswordToken_Secret_Field,
	reset_password_token_owner_id ResetPasswordToken_OwnerId_Field) (
	reset_password_token *ResetPasswordToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__secret_val := reset_password_token_secret.value()
	__owner_id_val := reset_password_token_owner_id.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO reset_password_tokens ( secret, owner_id, created_at ) VALUES ( ?, ?, ? ) RETURNING reset_password_tokens.secret, reset_password_tokens.owner_id, reset_password_tokens.created_at")

	var __values []any
	__values = append(__values, __secret_val, __owner_id_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reset_password_token = &ResetPasswordToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reset_password_token, nil

}

func (obj *pgxImpl) Replace_AccountFreezeEvent(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field,
	optional AccountFreezeEvent_Create_Fields) (
	account_freeze_event *AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__user_id_val := account_freeze_event_user_id.value()
	__event_val := account_freeze_event_event.value()
	__limits_val := optional.Limits.value()
	__days_till_escalation_val := optional.DaysTillEscalation.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("user_id, event, limits, days_till_escalation")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO account_freeze_events "), __clause, __sqlbundle_Literal(" ON CONFLICT ( user_id, event ) DO UPDATE SET user_id = EXCLUDED.user_id, event = EXCLUDED.event, limits = EXCLUDED.limits, days_till_escalation = EXCLUDED.days_till_escalation, notifications_count = EXCLUDED.notifications_count, created_at = EXCLUDED.created_at RETURNING account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at")}}

	var __values []any
	__values = append(__values, __user_id_val, __event_val, __limits_val, __days_till_escalation_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.NotificationsCount._set {
		__values = append(__values, optional.NotificationsCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("notifications_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.CreatedAt._set {
		__values = append(__values, optional.CreatedAt.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("created_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	account_freeze_event = &AccountFreezeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return account_freeze_event, nil

}

func (obj *pgxImpl) CreateNoReturn_UserSettings(ctx context.Context,
	user_settings_user_id UserSettings_UserId_Field,
	optional UserSettings_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__user_id_val := user_settings_user_id.value()
	__session_minutes_val := optional.SessionMinutes.value()
	__passphrase_prompt_val := optional.PassphrasePrompt.value()
	__onboarding_step_val := optional.OnboardingStep.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("user_id, session_minutes, passphrase_prompt, onboarding_step")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO user_settings "), __clause}}

	var __values []any
	__values = append(__values, __user_id_val, __session_minutes_val, __passphrase_prompt_val, __onboarding_step_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.OnboardingStart._set {
		__values = append(__values, optional.OnboardingStart.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("onboarding_start"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.OnboardingEnd._set {
		__values = append(__values, optional.OnboardingEnd.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("onboarding_end"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.NoticeDismissal._set {
		__values = append(__values, optional.NoticeDismissal.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("notice_dismissal"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Find_AccountingTimestamps_Value_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field) (
	row *Value_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_timestamps.value FROM accounting_timestamps WHERE accounting_timestamps.name = ?")

	var __values []any
	__values = append(__values, accounting_timestamps_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Value_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Value)
	if errors.Is(err, sql.ErrNoRows) {
		return (*Value_Row)(nil), nil
	}
	if err != nil {
		return (*Value_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) All_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart(ctx context.Context,
	storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
	storagenode_bandwidth_rollup_interval_start StoragenodeBandwidthRollup_IntervalStart_Field) (
	rows []*StoragenodeBandwidthRollup, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.storagenode_id = ? AND storagenode_bandwidth_rollups.interval_start = ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_storagenode_id.value(), storagenode_bandwidth_rollup_interval_start.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodeBandwidthRollup, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_bandwidth_rollup := &StoragenodeBandwidthRollup{}
				err = __rows.Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	storagenode_bandwidth_rollup_interval_start_greater_or_equal StoragenodeBandwidthRollup_IntervalStart_Field,
	limit int, start *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.interval_start >= ? AND (storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action) > (?, ?, ?) ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.interval_start >= ? ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_storagenode_id, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				storagenode_bandwidth_rollup := &StoragenodeBandwidthRollup{}
				err = __rows.Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled, &__continuation._value_storagenode_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxImpl) Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual(ctx context.Context,
	storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
	storagenode_bandwidth_rollup_interval_start_greater_or_equal StoragenodeBandwidthRollup_IntervalStart_Field,
	limit int, start *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.storagenode_id = ? AND storagenode_bandwidth_rollups.interval_start >= ? AND (storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action) > (?, ?, ?) ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.storagenode_id = ? AND storagenode_bandwidth_rollups.interval_start >= ? ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_storagenode_id.value(), storagenode_bandwidth_rollup_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_storagenode_id, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				storagenode_bandwidth_rollup := &StoragenodeBandwidthRollup{}
				err = __rows.Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled, &__continuation._value_storagenode_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxImpl) Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	storagenode_bandwidth_rollup_archive_interval_start_greater_or_equal StoragenodeBandwidthRollupArchive_IntervalStart_Field,
	limit int, start *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*StoragenodeBandwidthRollupArchive, next *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.interval_seconds, storagenode_bandwidth_rollup_archives.action, storagenode_bandwidth_rollup_archives.allocated, storagenode_bandwidth_rollup_archives.settled, storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action FROM storagenode_bandwidth_rollup_archives WHERE storagenode_bandwidth_rollup_archives.interval_start >= ? AND (storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action) > (?, ?, ?) ORDER BY storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.interval_seconds, storagenode_bandwidth_rollup_archives.action, storagenode_bandwidth_rollup_archives.allocated, storagenode_bandwidth_rollup_archives.settled, storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action FROM storagenode_bandwidth_rollup_archives WHERE storagenode_bandwidth_rollup_archives.interval_start >= ? ORDER BY storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action LIMIT ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_archive_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_storagenode_id, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*StoragenodeBandwidthRollupArchive, next *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				storagenode_bandwidth_rollup_archive := &StoragenodeBandwidthRollupArchive{}
				err = __rows.Scan(&storagenode_bandwidth_rollup_archive.StoragenodeId, &storagenode_bandwidth_rollup_archive.IntervalStart, &storagenode_bandwidth_rollup_archive.IntervalSeconds, &storagenode_bandwidth_rollup_archive.Action, &storagenode_bandwidth_rollup_archive.Allocated, &storagenode_bandwidth_rollup_archive.Settled, &__continuation._value_storagenode_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup_archive)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxImpl) All_StoragenodeStorageTally(ctx context.Context) (
	rows []*StoragenodeStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_storage_tallies.node_id, storagenode_storage_tallies.interval_end_time, storagenode_storage_tallies.data_total FROM storagenode_storage_tallies")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodeStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_storage_tally := &StoragenodeStorageTally{}
				err = __rows.Scan(&storagenode_storage_tally.NodeId, &storagenode_storage_tally.IntervalEndTime, &storagenode_storage_tally.DataTotal)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_StoragenodeStorageTally_By_IntervalEndTime_GreaterOrEqual(ctx context.Context,
	storagenode_storage_tally_interval_end_time_greater_or_equal StoragenodeStorageTally_IntervalEndTime_Field) (
	rows []*StoragenodeStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_storage_tallies.node_id, storagenode_storage_tallies.interval_end_time, storagenode_storage_tallies.data_total FROM storagenode_storage_tallies WHERE storagenode_storage_tallies.interval_end_time >= ?")

	var __values []any
	__values = append(__values, storagenode_storage_tally_interval_end_time_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodeStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_storage_tally := &StoragenodeStorageTally{}
				err = __rows.Scan(&storagenode_storage_tally.NodeId, &storagenode_storage_tally.IntervalEndTime, &storagenode_storage_tally.DataTotal)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) First_StoragenodeStorageTally_IntervalEndTime_OrderBy_Asc_IntervalEndTime(ctx context.Context) (
	row *IntervalEndTime_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_storage_tallies.interval_end_time FROM storagenode_storage_tallies ORDER BY storagenode_storage_tallies.interval_end_time LIMIT 1 OFFSET 0")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *IntervalEndTime_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			row = &IntervalEndTime_Row{}
			err = __rows.Scan(&row.IntervalEndTime)
			if err != nil {
				return nil, err
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *pgxImpl) Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	bucket_bandwidth_rollup_interval_start_greater_or_equal BucketBandwidthRollup_IntervalStart_Field,
	limit int, start *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*BucketBandwidthRollup, next *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.interval_seconds, bucket_bandwidth_rollups.action, bucket_bandwidth_rollups.product_id, bucket_bandwidth_rollups.inline, bucket_bandwidth_rollups.allocated, bucket_bandwidth_rollups.settled, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action FROM bucket_bandwidth_rollups WHERE bucket_bandwidth_rollups.interval_start >= ? AND (bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action) > (?, ?, ?, ?) ORDER BY bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.interval_seconds, bucket_bandwidth_rollups.action, bucket_bandwidth_rollups.product_id, bucket_bandwidth_rollups.inline, bucket_bandwidth_rollups.allocated, bucket_bandwidth_rollups.settled, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action FROM bucket_bandwidth_rollups WHERE bucket_bandwidth_rollups.interval_start >= ? ORDER BY bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action LIMIT ?")

	var __values []any
	__values = append(__values, bucket_bandwidth_rollup_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_project_id, start._value_bucket_name, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*BucketBandwidthRollup, next *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				bucket_bandwidth_rollup := &BucketBandwidthRollup{}
				err = __rows.Scan(&bucket_bandwidth_rollup.BucketName, &bucket_bandwidth_rollup.ProjectId, &bucket_bandwidth_rollup.IntervalStart, &bucket_bandwidth_rollup.IntervalSeconds, &bucket_bandwidth_rollup.Action, &bucket_bandwidth_rollup.ProductId, &bucket_bandwidth_rollup.Inline, &bucket_bandwidth_rollup.Allocated, &bucket_bandwidth_rollup.Settled, &__continuation._value_project_id, &__continuation._value_bucket_name, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, bucket_bandwidth_rollup)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxImpl) Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	bucket_bandwidth_rollup_archive_interval_start_greater_or_equal BucketBandwidthRollupArchive_IntervalStart_Field,
	limit int, start *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*BucketBandwidthRollupArchive, next *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.product_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.interval_seconds, bucket_bandwidth_rollup_archives.action, bucket_bandwidth_rollup_archives.inline, bucket_bandwidth_rollup_archives.allocated, bucket_bandwidth_rollup_archives.settled, bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action FROM bucket_bandwidth_rollup_archives WHERE bucket_bandwidth_rollup_archives.interval_start >= ? AND (bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action) > (?, ?, ?, ?) ORDER BY bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.product_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.interval_seconds, bucket_bandwidth_rollup_archives.action, bucket_bandwidth_rollup_archives.inline, bucket_bandwidth_rollup_archives.allocated, bucket_bandwidth_rollup_archives.settled, bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action FROM bucket_bandwidth_rollup_archives WHERE bucket_bandwidth_rollup_archives.interval_start >= ? ORDER BY bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action LIMIT ?")

	var __values []any
	__values = append(__values, bucket_bandwidth_rollup_archive_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_bucket_name, start._value_project_id, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*BucketBandwidthRollupArchive, next *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				bucket_bandwidth_rollup_archive := &BucketBandwidthRollupArchive{}
				err = __rows.Scan(&bucket_bandwidth_rollup_archive.BucketName, &bucket_bandwidth_rollup_archive.ProjectId, &bucket_bandwidth_rollup_archive.ProductId, &bucket_bandwidth_rollup_archive.IntervalStart, &bucket_bandwidth_rollup_archive.IntervalSeconds, &bucket_bandwidth_rollup_archive.Action, &bucket_bandwidth_rollup_archive.Inline, &bucket_bandwidth_rollup_archive.Allocated, &bucket_bandwidth_rollup_archive.Settled, &__continuation._value_bucket_name, &__continuation._value_project_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, bucket_bandwidth_rollup_archive)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxImpl) All_BucketStorageTally_OrderBy_Desc_IntervalStart(ctx context.Context) (
	rows []*BucketStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_storage_tallies.bucket_name, bucket_storage_tallies.project_id, bucket_storage_tallies.interval_start, bucket_storage_tallies.product_id, bucket_storage_tallies.total_bytes, bucket_storage_tallies.inline, bucket_storage_tallies.remote, bucket_storage_tallies.total_segments_count, bucket_storage_tallies.remote_segments_count, bucket_storage_tallies.inline_segments_count, bucket_storage_tallies.object_count, bucket_storage_tallies.metadata_size FROM bucket_storage_tallies ORDER BY bucket_storage_tallies.interval_start DESC")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_storage_tally := &BucketStorageTally{}
				err = __rows.Scan(&bucket_storage_tally.BucketName, &bucket_storage_tally.ProjectId, &bucket_storage_tally.IntervalStart, &bucket_storage_tally.ProductId, &bucket_storage_tally.TotalBytes, &bucket_storage_tally.Inline, &bucket_storage_tally.Remote, &bucket_storage_tally.TotalSegmentsCount, &bucket_storage_tally.RemoteSegmentsCount, &bucket_storage_tally.InlineSegmentsCount, &bucket_storage_tally.ObjectCount, &bucket_storage_tally.MetadataSize)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_BucketStorageTally_By_ProjectId_And_BucketName_And_IntervalStart_GreaterOrEqual_And_IntervalStart_LessOrEqual_OrderBy_Desc_IntervalStart(ctx context.Context,
	bucket_storage_tally_project_id BucketStorageTally_ProjectId_Field,
	bucket_storage_tally_bucket_name BucketStorageTally_BucketName_Field,
	bucket_storage_tally_interval_start_greater_or_equal BucketStorageTally_IntervalStart_Field,
	bucket_storage_tally_interval_start_less_or_equal BucketStorageTally_IntervalStart_Field) (
	rows []*BucketStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_storage_tallies.bucket_name, bucket_storage_tallies.project_id, bucket_storage_tallies.interval_start, bucket_storage_tallies.product_id, bucket_storage_tallies.total_bytes, bucket_storage_tallies.inline, bucket_storage_tallies.remote, bucket_storage_tallies.total_segments_count, bucket_storage_tallies.remote_segments_count, bucket_storage_tallies.inline_segments_count, bucket_storage_tallies.object_count, bucket_storage_tallies.metadata_size FROM bucket_storage_tallies WHERE bucket_storage_tallies.project_id = ? AND bucket_storage_tallies.bucket_name = ? AND bucket_storage_tallies.interval_start >= ? AND bucket_storage_tallies.interval_start <= ? ORDER BY bucket_storage_tallies.interval_start DESC")

	var __values []any
	__values = append(__values, bucket_storage_tally_project_id.value(), bucket_storage_tally_bucket_name.value(), bucket_storage_tally_interval_start_greater_or_equal.value(), bucket_storage_tally_interval_start_less_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_storage_tally := &BucketStorageTally{}
				err = __rows.Scan(&bucket_storage_tally.BucketName, &bucket_storage_tally.ProjectId, &bucket_storage_tally.IntervalStart, &bucket_storage_tally.ProductId, &bucket_storage_tally.TotalBytes, &bucket_storage_tally.Inline, &bucket_storage_tally.Remote, &bucket_storage_tally.TotalSegmentsCount, &bucket_storage_tally.RemoteSegmentsCount, &bucket_storage_tally.InlineSegmentsCount, &bucket_storage_tally.ObjectCount, &bucket_storage_tally.MetadataSize)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) First_ReverificationAudits_By_NodeId_OrderBy_Asc_StreamId_Asc_Position(ctx context.Context,
	reverification_audits_node_id ReverificationAudits_NodeId_Field) (
	reverification_audits *ReverificationAudits, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reverification_audits.node_id, reverification_audits.stream_id, reverification_audits.position, reverification_audits.piece_num, reverification_audits.inserted_at, reverification_audits.last_attempt, reverification_audits.reverify_count FROM reverification_audits WHERE reverification_audits.node_id = ? ORDER BY reverification_audits.stream_id, reverification_audits.position LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, reverification_audits_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		reverification_audits, err = func() (reverification_audits *ReverificationAudits, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			reverification_audits = &ReverificationAudits{}
			err = __rows.Scan(&reverification_audits.NodeId, &reverification_audits.StreamId, &reverification_audits.Position, &reverification_audits.PieceNum, &reverification_audits.InsertedAt, &reverification_audits.LastAttempt, &reverification_audits.ReverifyCount)
			if err != nil {
				return nil, err
			}

			return reverification_audits, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return reverification_audits, nil
	}

}

func (obj *pgxImpl) Get_StripeCustomer_PackagePlan_StripeCustomer_PurchasedPackageAt_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field) (
	row *PackagePlan_PurchasedPackageAt_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.package_plan, stripe_customers.purchased_package_at FROM stripe_customers WHERE stripe_customers.user_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &PackagePlan_PurchasedPackageAt_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.PackagePlan, &row.PurchasedPackageAt)
	if err != nil {
		return (*PackagePlan_PurchasedPackageAt_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_StripeCustomer_CustomerId_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field) (
	row *CustomerId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.customer_id FROM stripe_customers WHERE stripe_customers.user_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &CustomerId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.CustomerId)
	if err != nil {
		return (*CustomerId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_StripeCustomer_UserId_By_CustomerId(ctx context.Context,
	stripe_customer_customer_id StripeCustomer_CustomerId_Field) (
	row *UserId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.user_id FROM stripe_customers WHERE stripe_customers.customer_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_customer_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserId)
	if err != nil {
		return (*UserId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_StripeCustomer_CustomerId_StripeCustomer_BillingCustomerId_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field) (
	row *CustomerId_BillingCustomerId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.customer_id, stripe_customers.billing_customer_id FROM stripe_customers WHERE stripe_customers.user_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &CustomerId_BillingCustomerId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.CustomerId, &row.BillingCustomerId)
	if err != nil {
		return (*CustomerId_BillingCustomerId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_BillingBalance_Balance_By_UserId(ctx context.Context,
	billing_balance_user_id BillingBalance_UserId_Field) (
	row *Balance_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_balances.balance FROM billing_balances WHERE billing_balances.user_id = ?")

	var __values []any
	__values = append(__values, billing_balance_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Balance_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Balance)
	if err != nil {
		return (*Balance_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_BillingTransaction_By_Id(ctx context.Context,
	billing_transaction_id BillingTransaction_Id_Field) (
	billing_transaction *BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.id = ?")

	var __values []any
	__values = append(__values, billing_transaction_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	billing_transaction = &BillingTransaction{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
	if err != nil {
		return (*BillingTransaction)(nil), obj.makeErr(err)
	}
	return billing_transaction, nil

}

func (obj *pgxImpl) Get_BillingTransaction_Metadata_By_Id(ctx context.Context,
	billing_transaction_id BillingTransaction_Id_Field) (
	row *Metadata_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.metadata FROM billing_transactions WHERE billing_transactions.id = ?")

	var __values []any
	__values = append(__values, billing_transaction_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Metadata_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Metadata)
	if err != nil {
		return (*Metadata_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) All_BillingTransaction_By_UserId_OrderBy_Desc_TxTimestamp(ctx context.Context,
	billing_transaction_user_id BillingTransaction_UserId_Field) (
	rows []*BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.user_id = ? ORDER BY billing_transactions.tx_timestamp DESC")

	var __values []any
	__values = append(__values, billing_transaction_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BillingTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				billing_transaction := &BillingTransaction{}
				err = __rows.Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, billing_transaction)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_BillingTransaction_By_UserId_And_Source_OrderBy_Desc_TxTimestamp(ctx context.Context,
	billing_transaction_user_id BillingTransaction_UserId_Field,
	billing_transaction_source BillingTransaction_Source_Field) (
	rows []*BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.user_id = ? AND billing_transactions.source = ? ORDER BY billing_transactions.tx_timestamp DESC")

	var __values []any
	__values = append(__values, billing_transaction_user_id.value(), billing_transaction_source.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BillingTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				billing_transaction := &BillingTransaction{}
				err = __rows.Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, billing_transaction)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) First_BillingTransaction_By_Source_And_Type_OrderBy_Desc_CreatedAt(ctx context.Context,
	billing_transaction_source BillingTransaction_Source_Field,
	billing_transaction_type BillingTransaction_Type_Field) (
	billing_transaction *BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.source = ? AND billing_transactions.type = ? ORDER BY billing_transactions.created_at DESC LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, billing_transaction_source.value(), billing_transaction_type.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		billing_transaction, err = func() (billing_transaction *BillingTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			billing_transaction = &BillingTransaction{}
			err = __rows.Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
			if err != nil {
				return nil, err
			}

			return billing_transaction, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return billing_transaction, nil
	}

}

func (obj *pgxImpl) Get_StorjscanWallet_UserId_By_WalletAddress(ctx context.Context,
	storjscan_wallet_wallet_address StorjscanWallet_WalletAddress_Field) (
	row *UserId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_wallets.user_id FROM storjscan_wallets WHERE storjscan_wallets.wallet_address = ? LIMIT 2")

	var __values []any
	__values = append(__values, storjscan_wallet_wallet_address.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *UserId_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			row = &UserId_Row{}
			err = __rows.Scan(&row.UserId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("StorjscanWallet_UserId_By_WalletAddress")
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *pgxImpl) Get_StorjscanWallet_WalletAddress_By_UserId(ctx context.Context,
	storjscan_wallet_user_id StorjscanWallet_UserId_Field) (
	row *WalletAddress_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_wallets.wallet_address FROM storjscan_wallets WHERE storjscan_wallets.user_id = ? LIMIT 2")

	var __values []any
	__values = append(__values, storjscan_wallet_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *WalletAddress_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			row = &WalletAddress_Row{}
			err = __rows.Scan(&row.WalletAddress)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("StorjscanWallet_WalletAddress_By_UserId")
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *pgxImpl) All_StorjscanWallet(ctx context.Context) (
	rows []*StorjscanWallet, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_wallets.user_id, storjscan_wallets.wallet_address, storjscan_wallets.created_at FROM storjscan_wallets")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StorjscanWallet, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storjscan_wallet := &StorjscanWallet{}
				err = __rows.Scan(&storjscan_wallet.UserId, &storjscan_wallet.WalletAddress, &storjscan_wallet.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storjscan_wallet)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_CoinpaymentsTransaction_By_UserId_OrderBy_Desc_CreatedAt(ctx context.Context,
	coinpayments_transaction_user_id CoinpaymentsTransaction_UserId_Field) (
	rows []*CoinpaymentsTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT coinpayments_transactions.id, coinpayments_transactions.user_id, coinpayments_transactions.address, coinpayments_transactions.amount_numeric, coinpayments_transactions.received_numeric, coinpayments_transactions.status, coinpayments_transactions.key, coinpayments_transactions.timeout, coinpayments_transactions.created_at FROM coinpayments_transactions WHERE coinpayments_transactions.user_id = ? ORDER BY coinpayments_transactions.created_at DESC")

	var __values []any
	__values = append(__values, coinpayments_transaction_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*CoinpaymentsTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				coinpayments_transaction := &CoinpaymentsTransaction{}
				err = __rows.Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, coinpayments_transaction)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_StripecoinpaymentsInvoiceProjectRecord_By_ProjectId_And_PeriodStart_And_PeriodEnd(ctx context.Context,
	stripecoinpayments_invoice_project_record_project_id StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field,
	stripecoinpayments_invoice_project_record_period_start StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field,
	stripecoinpayments_invoice_project_record_period_end StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field) (
	stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripecoinpayments_invoice_project_records.id, stripecoinpayments_invoice_project_records.project_id, stripecoinpayments_invoice_project_records.storage, stripecoinpayments_invoice_project_records.egress, stripecoinpayments_invoice_project_records.objects, stripecoinpayments_invoice_project_records.segments, stripecoinpayments_invoice_project_records.period_start, stripecoinpayments_invoice_project_records.period_end, stripecoinpayments_invoice_project_records.state, stripecoinpayments_invoice_project_records.created_at FROM stripecoinpayments_invoice_project_records WHERE stripecoinpayments_invoice_project_records.project_id = ? AND stripecoinpayments_invoice_project_records.period_start = ? AND stripecoinpayments_invoice_project_records.period_end = ?")

	var __values []any
	__values = append(__values, stripecoinpayments_invoice_project_record_project_id.value(), stripecoinpayments_invoice_project_record_period_start.value(), stripecoinpayments_invoice_project_record_period_end.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_invoice_project_record = &StripecoinpaymentsInvoiceProjectRecord{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
	if err != nil {
		return (*StripecoinpaymentsInvoiceProjectRecord)(nil), obj.makeErr(err)
	}
	return stripecoinpayments_invoice_project_record, nil

}

func (obj *pgxImpl) Get_StripecoinpaymentsTxConversionRate_By_TxId(ctx context.Context,
	stripecoinpayments_tx_conversion_rate_tx_id StripecoinpaymentsTxConversionRate_TxId_Field) (
	stripecoinpayments_tx_conversion_rate *StripecoinpaymentsTxConversionRate, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripecoinpayments_tx_conversion_rates.tx_id, stripecoinpayments_tx_conversion_rates.rate_numeric, stripecoinpayments_tx_conversion_rates.created_at FROM stripecoinpayments_tx_conversion_rates WHERE stripecoinpayments_tx_conversion_rates.tx_id = ?")

	var __values []any
	__values = append(__values, stripecoinpayments_tx_conversion_rate_tx_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_tx_conversion_rate = &StripecoinpaymentsTxConversionRate{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_tx_conversion_rate.TxId, &stripecoinpayments_tx_conversion_rate.RateNumeric, &stripecoinpayments_tx_conversion_rate.CreatedAt)
	if err != nil {
		return (*StripecoinpaymentsTxConversionRate)(nil), obj.makeErr(err)
	}
	return stripecoinpayments_tx_conversion_rate, nil

}

func (obj *pgxImpl) All_StorjscanPayment_OrderBy_Asc_ChainId_Asc_BlockNumber_Asc_LogIndex(ctx context.Context) (
	rows []*StorjscanPayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_payments.chain_id, storjscan_payments.block_hash, storjscan_payments.block_number, storjscan_payments.transaction, storjscan_payments.log_index, storjscan_payments.from_address, storjscan_payments.to_address, storjscan_payments.token_value, storjscan_payments.usd_value, storjscan_payments.status, storjscan_payments.block_timestamp, storjscan_payments.created_at FROM storjscan_payments ORDER BY storjscan_payments.chain_id, storjscan_payments.block_number, storjscan_payments.log_index")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StorjscanPayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storjscan_payment := &StorjscanPayment{}
				err = __rows.Scan(&storjscan_payment.ChainId, &storjscan_payment.BlockHash, &storjscan_payment.BlockNumber, &storjscan_payment.Transaction, &storjscan_payment.LogIndex, &storjscan_payment.FromAddress, &storjscan_payment.ToAddress, &storjscan_payment.TokenValue, &storjscan_payment.UsdValue, &storjscan_payment.Status, &storjscan_payment.BlockTimestamp, &storjscan_payment.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storjscan_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Limited_StorjscanPayment_By_ToAddress_OrderBy_Desc_ChainId_Desc_BlockNumber_Desc_LogIndex(ctx context.Context,
	storjscan_payment_to_address StorjscanPayment_ToAddress_Field,
	limit int, offset int64) (
	rows []*StorjscanPayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_payments.chain_id, storjscan_payments.block_hash, storjscan_payments.block_number, storjscan_payments.transaction, storjscan_payments.log_index, storjscan_payments.from_address, storjscan_payments.to_address, storjscan_payments.token_value, storjscan_payments.usd_value, storjscan_payments.status, storjscan_payments.block_timestamp, storjscan_payments.created_at FROM storjscan_payments WHERE storjscan_payments.to_address = ? ORDER BY storjscan_payments.chain_id DESC, storjscan_payments.block_number DESC, storjscan_payments.log_index DESC LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, storjscan_payment_to_address.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StorjscanPayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storjscan_payment := &StorjscanPayment{}
				err = __rows.Scan(&storjscan_payment.ChainId, &storjscan_payment.BlockHash, &storjscan_payment.BlockNumber, &storjscan_payment.Transaction, &storjscan_payment.LogIndex, &storjscan_payment.FromAddress, &storjscan_payment.ToAddress, &storjscan_payment.TokenValue, &storjscan_payment.UsdValue, &storjscan_payment.Status, &storjscan_payment.BlockTimestamp, &storjscan_payment.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storjscan_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) First_StorjscanPayment_BlockNumber_By_Status_And_ChainId_OrderBy_Desc_BlockNumber_Desc_LogIndex(ctx context.Context,
	storjscan_payment_status StorjscanPayment_Status_Field,
	storjscan_payment_chain_id StorjscanPayment_ChainId_Field) (
	row *BlockNumber_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_payments.block_number FROM storjscan_payments WHERE storjscan_payments.status = ? AND storjscan_payments.chain_id = ? ORDER BY storjscan_payments.block_number DESC, storjscan_payments.log_index DESC LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, storjscan_payment_status.value(), storjscan_payment_chain_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *BlockNumber_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			row = &BlockNumber_Row{}
			err = __rows.Scan(&row.BlockNumber)
			if err != nil {
				return nil, err
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *pgxImpl) All_ChangeHistory_By_UserId_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_user_id ChangeHistory_UserId_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE change_histories.user_id = ? ORDER BY change_histories.timestamp DESC")

	var __values []any
	__values = append(__values, change_history_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_ChangeHistory_By_UserId_And_ItemType_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_user_id ChangeHistory_UserId_Field,
	change_history_item_type ChangeHistory_ItemType_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE change_histories.user_id = ? AND change_histories.item_type = ? ORDER BY change_histories.timestamp DESC")

	var __values []any
	__values = append(__values, change_history_user_id.value(), change_history_item_type.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_ChangeHistory_By_ProjectId_And_ItemType_Not_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_project_id ChangeHistory_ProjectId_Field,
	change_history_item_type_not ChangeHistory_ItemType_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "change_histories.project_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE "), __cond_0, __sqlbundle_Literal(" AND change_histories.item_type != ? ORDER BY change_histories.timestamp DESC")}}

	var __values []any
	if !change_history_project_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, change_history_project_id.value())
	}
	__values = append(__values, change_history_item_type_not.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_ChangeHistory_By_ProjectId_And_ItemType_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_project_id ChangeHistory_ProjectId_Field,
	change_history_item_type ChangeHistory_ItemType_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "change_histories.project_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE "), __cond_0, __sqlbundle_Literal(" AND change_histories.item_type = ? ORDER BY change_histories.timestamp DESC")}}

	var __values []any
	if !change_history_project_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, change_history_project_id.value())
	}
	__values = append(__values, change_history_item_type.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_ChangeHistory_By_BucketName_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_bucket_name ChangeHistory_BucketName_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "change_histories.bucket_name", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE "), __cond_0, __sqlbundle_Literal(" ORDER BY change_histories.timestamp DESC")}}

	var __values []any
	if !change_history_bucket_name.isnull() {
		__cond_0.Null = false
		__values = append(__values, change_history_bucket_name.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_Domain_By_ProjectId_And_Subdomain(ctx context.Context,
	domain_project_id Domain_ProjectId_Field,
	domain_subdomain Domain_Subdomain_Field) (
	domain *Domain, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT domains.subdomain, domains.project_id, domains.prefix, domains.access_id, domains.created_by, domains.created_at FROM domains WHERE domains.project_id = ? AND domains.subdomain = ?")

	var __values []any
	__values = append(__values, domain_project_id.value(), domain_subdomain.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	domain = &Domain{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&domain.Subdomain, &domain.ProjectId, &domain.Prefix, &domain.AccessId, &domain.CreatedBy, &domain.CreatedAt)
	if err != nil {
		return (*Domain)(nil), obj.makeErr(err)
	}
	return domain, nil

}

func (obj *pgxImpl) All_Domain_Subdomain_By_ProjectId(ctx context.Context,
	domain_project_id Domain_ProjectId_Field) (
	rows []*Subdomain_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT domains.subdomain FROM domains WHERE domains.project_id = ?")

	var __values []any
	__values = append(__values, domain_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Subdomain_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Subdomain_Row{}
				err = __rows.Scan(&row.Subdomain)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_Entitlement_By_Scope(ctx context.Context,
	entitlement_scope Entitlement_Scope_Field) (
	entitlement *Entitlement, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT entitlements.scope, entitlements.features, entitlements.updated_at, entitlements.created_at FROM entitlements WHERE entitlements.scope = ?")

	var __values []any
	__values = append(__values, entitlement_scope.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	entitlement = &Entitlement{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&entitlement.Scope, &entitlement.Features, &entitlement.UpdatedAt, &entitlement.CreatedAt)
	if err != nil {
		return (*Entitlement)(nil), obj.makeErr(err)
	}
	return entitlement, nil

}

func (obj *pgxImpl) Get_PeerIdentity_By_NodeId(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field) (
	peer_identity *PeerIdentity, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT peer_identities.node_id, peer_identities.leaf_serial_number, peer_identities.chain, peer_identities.updated_at FROM peer_identities WHERE peer_identities.node_id = ?")

	var __values []any
	__values = append(__values, peer_identity_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	peer_identity = &PeerIdentity{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&peer_identity.NodeId, &peer_identity.LeafSerialNumber, &peer_identity.Chain, &peer_identity.UpdatedAt)
	if err != nil {
		return (*PeerIdentity)(nil), obj.makeErr(err)
	}
	return peer_identity, nil

}

func (obj *pgxImpl) Get_PeerIdentity_LeafSerialNumber_By_NodeId(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field) (
	row *LeafSerialNumber_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT peer_identities.leaf_serial_number FROM peer_identities WHERE peer_identities.node_id = ?")

	var __values []any
	__values = append(__values, peer_identity_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &LeafSerialNumber_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.LeafSerialNumber)
	if err != nil {
		return (*LeafSerialNumber_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field) (
	node *Node, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features FROM nodes WHERE nodes.id = ?")

	var __values []any
	__values = append(__values, node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node.Id, &node.Address, &node.LastNet, &node.LastIpPort, &node.CountryCode, &node.Protocol, &node.Email, &node.Wallet, &node.WalletFeatures, &node.FreeDisk, &node.PieceCount, &node.Major, &node.Minor, &node.Patch, &node.CommitHash, &node.ReleaseTimestamp, &node.Release, &node.Latency90, &node.VettedAt, &node.CreatedAt, &node.UpdatedAt, &node.LastContactSuccess, &node.LastContactFailure, &node.Disqualified, &node.DisqualificationReason, &node.UnknownAuditSuspended, &node.OfflineSuspended, &node.UnderReview, &node.ExitInitiatedAt, &node.ExitLoopCompletedAt, &node.ExitFinishedAt, &node.ExitSuccess, &node.Contained, &node.LastOfflineEmail, &node.LastSoftwareUpdateEmail, &node.NoiseProto, &node.NoisePublicKey, &node.DebounceLimit, &node.Features)
	if err != nil {
		return (*Node)(nil), obj.makeErr(err)
	}
	return node, nil

}

func (obj *pgxImpl) All_Node_Id(ctx context.Context) (
	rows []*Id_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id FROM nodes")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_Row{}
				err = __rows.Scan(&row.Id)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Paged_Node(ctx context.Context,
	limit int, start *Paged_Node_Continuation) (
	rows []*Node, next *Paged_Node_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features, nodes.id FROM nodes WHERE (nodes.id) > ? ORDER BY nodes.id LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features, nodes.id FROM nodes ORDER BY nodes.id LIMIT ?")

	var __values []any

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_id, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*Node, next *Paged_Node_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_Node_Continuation
			__continuation._set = true

			for __rows.Next() {
				node := &Node{}
				err = __rows.Scan(&node.Id, &node.Address, &node.LastNet, &node.LastIpPort, &node.CountryCode, &node.Protocol, &node.Email, &node.Wallet, &node.WalletFeatures, &node.FreeDisk, &node.PieceCount, &node.Major, &node.Minor, &node.Patch, &node.CommitHash, &node.ReleaseTimestamp, &node.Release, &node.Latency90, &node.VettedAt, &node.CreatedAt, &node.UpdatedAt, &node.LastContactSuccess, &node.LastContactFailure, &node.Disqualified, &node.DisqualificationReason, &node.UnknownAuditSuspended, &node.OfflineSuspended, &node.UnderReview, &node.ExitInitiatedAt, &node.ExitLoopCompletedAt, &node.ExitFinishedAt, &node.ExitSuccess, &node.Contained, &node.LastOfflineEmail, &node.LastSoftwareUpdateEmail, &node.NoiseProto, &node.NoisePublicKey, &node.DebounceLimit, &node.Features, &__continuation._value_id)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, node)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxImpl) All_Node_Id_Node_PieceCount_By_Disqualified_Is_Null_And_ExitInitiatedAt_Is_Null_And_ExitFinishedAt_Is_Null(ctx context.Context) (
	rows []*Id_PieceCount_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.piece_count FROM nodes WHERE nodes.disqualified is NULL AND nodes.exit_initiated_at is NULL AND nodes.exit_finished_at is NULL")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_PieceCount_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_PieceCount_Row{}
				err = __rows.Scan(&row.Id, &row.PieceCount)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Has_NodeApiVersion_By_Id_And_ApiVersion_GreaterOrEqual(ctx context.Context,
	node_api_version_id NodeApiVersion_Id_Field,
	node_api_version_api_version_greater_or_equal NodeApiVersion_ApiVersion_Field) (
	has bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT EXISTS( SELECT 1 FROM node_api_versions WHERE node_api_versions.id = ? AND node_api_versions.api_version >= ? )")

	var __values []any
	__values = append(__values, node_api_version_id.value(), node_api_version_api_version_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&has)
	if err != nil {
		return false, obj.makeErr(err)
	}
	return has, nil

}

func (obj *pgxImpl) Get_NodeEvent_By_Id(ctx context.Context,
	node_event_id NodeEvent_Id_Field) (
	node_event *NodeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_events.id, node_events.email, node_events.last_ip_port, node_events.node_id, node_events.event, node_events.created_at, node_events.last_attempted, node_events.email_sent FROM node_events WHERE node_events.id = ?")

	var __values []any
	__values = append(__values, node_event_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node_event = &NodeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
	if err != nil {
		return (*NodeEvent)(nil), obj.makeErr(err)
	}
	return node_event, nil

}

func (obj *pgxImpl) First_NodeEvent_By_Email_And_Event_OrderBy_Desc_CreatedAt(ctx context.Context,
	node_event_email NodeEvent_Email_Field,
	node_event_event NodeEvent_Event_Field) (
	node_event *NodeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_events.id, node_events.email, node_events.last_ip_port, node_events.node_id, node_events.event, node_events.created_at, node_events.last_attempted, node_events.email_sent FROM node_events WHERE node_events.email = ? AND node_events.event = ? ORDER BY node_events.created_at DESC LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, node_event_email.value(), node_event_event.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		node_event, err = func() (node_event *NodeEvent, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			node_event = &NodeEvent{}
			err = __rows.Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
			if err != nil {
				return nil, err
			}

			return node_event, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return node_event, nil
	}

}

func (obj *pgxImpl) All_NodeTags_By_NodeId(ctx context.Context,
	node_tags_node_id NodeTags_NodeId_Field) (
	rows []*NodeTags, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_tags.node_id, node_tags.name, node_tags.value, node_tags.signed_at, node_tags.signer FROM node_tags WHERE node_tags.node_id = ?")

	var __values []any
	__values = append(__values, node_tags_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*NodeTags, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				node_tags := &NodeTags{}
				err = __rows.Scan(&node_tags.NodeId, &node_tags.Name, &node_tags.Value, &node_tags.SignedAt, &node_tags.Signer)
				if err != nil {
					return nil, err
				}
				rows = append(rows, node_tags)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_NodeTags(ctx context.Context) (
	rows []*NodeTags, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_tags.node_id, node_tags.name, node_tags.value, node_tags.signed_at, node_tags.signer FROM node_tags")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*NodeTags, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				node_tags := &NodeTags{}
				err = __rows.Scan(&node_tags.NodeId, &node_tags.Name, &node_tags.Value, &node_tags.SignedAt, &node_tags.Signer)
				if err != nil {
					return nil, err
				}
				rows = append(rows, node_tags)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_StoragenodePaystub_By_NodeId_And_Period(ctx context.Context,
	storagenode_paystub_node_id StoragenodePaystub_NodeId_Field,
	storagenode_paystub_period StoragenodePaystub_Period_Field) (
	storagenode_paystub *StoragenodePaystub, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_paystubs.period, storagenode_paystubs.node_id, storagenode_paystubs.created_at, storagenode_paystubs.codes, storagenode_paystubs.usage_at_rest, storagenode_paystubs.usage_get, storagenode_paystubs.usage_put, storagenode_paystubs.usage_get_repair, storagenode_paystubs.usage_put_repair, storagenode_paystubs.usage_get_audit, storagenode_paystubs.comp_at_rest, storagenode_paystubs.comp_get, storagenode_paystubs.comp_put, storagenode_paystubs.comp_get_repair, storagenode_paystubs.comp_put_repair, storagenode_paystubs.comp_get_audit, storagenode_paystubs.surge_percent, storagenode_paystubs.held, storagenode_paystubs.owed, storagenode_paystubs.disposed, storagenode_paystubs.paid, storagenode_paystubs.distributed FROM storagenode_paystubs WHERE storagenode_paystubs.node_id = ? AND storagenode_paystubs.period = ?")

	var __values []any
	__values = append(__values, storagenode_paystub_node_id.value(), storagenode_paystub_period.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	storagenode_paystub = &StoragenodePaystub{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&storagenode_paystub.Period, &storagenode_paystub.NodeId, &storagenode_paystub.CreatedAt, &storagenode_paystub.Codes, &storagenode_paystub.UsageAtRest, &storagenode_paystub.UsageGet, &storagenode_paystub.UsagePut, &storagenode_paystub.UsageGetRepair, &storagenode_paystub.UsagePutRepair, &storagenode_paystub.UsageGetAudit, &storagenode_paystub.CompAtRest, &storagenode_paystub.CompGet, &storagenode_paystub.CompPut, &storagenode_paystub.CompGetRepair, &storagenode_paystub.CompPutRepair, &storagenode_paystub.CompGetAudit, &storagenode_paystub.SurgePercent, &storagenode_paystub.Held, &storagenode_paystub.Owed, &storagenode_paystub.Disposed, &storagenode_paystub.Paid, &storagenode_paystub.Distributed)
	if err != nil {
		return (*StoragenodePaystub)(nil), obj.makeErr(err)
	}
	return storagenode_paystub, nil

}

func (obj *pgxImpl) All_StoragenodePaystub_By_NodeId(ctx context.Context,
	storagenode_paystub_node_id StoragenodePaystub_NodeId_Field) (
	rows []*StoragenodePaystub, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_paystubs.period, storagenode_paystubs.node_id, storagenode_paystubs.created_at, storagenode_paystubs.codes, storagenode_paystubs.usage_at_rest, storagenode_paystubs.usage_get, storagenode_paystubs.usage_put, storagenode_paystubs.usage_get_repair, storagenode_paystubs.usage_put_repair, storagenode_paystubs.usage_get_audit, storagenode_paystubs.comp_at_rest, storagenode_paystubs.comp_get, storagenode_paystubs.comp_put, storagenode_paystubs.comp_get_repair, storagenode_paystubs.comp_put_repair, storagenode_paystubs.comp_get_audit, storagenode_paystubs.surge_percent, storagenode_paystubs.held, storagenode_paystubs.owed, storagenode_paystubs.disposed, storagenode_paystubs.paid, storagenode_paystubs.distributed FROM storagenode_paystubs WHERE storagenode_paystubs.node_id = ?")

	var __values []any
	__values = append(__values, storagenode_paystub_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePaystub, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_paystub := &StoragenodePaystub{}
				err = __rows.Scan(&storagenode_paystub.Period, &storagenode_paystub.NodeId, &storagenode_paystub.CreatedAt, &storagenode_paystub.Codes, &storagenode_paystub.UsageAtRest, &storagenode_paystub.UsageGet, &storagenode_paystub.UsagePut, &storagenode_paystub.UsageGetRepair, &storagenode_paystub.UsagePutRepair, &storagenode_paystub.UsageGetAudit, &storagenode_paystub.CompAtRest, &storagenode_paystub.CompGet, &storagenode_paystub.CompPut, &storagenode_paystub.CompGetRepair, &storagenode_paystub.CompPutRepair, &storagenode_paystub.CompGetAudit, &storagenode_paystub.SurgePercent, &storagenode_paystub.Held, &storagenode_paystub.Owed, &storagenode_paystub.Disposed, &storagenode_paystub.Paid, &storagenode_paystub.Distributed)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_paystub)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Limited_StoragenodePayment_By_NodeId_And_Period_OrderBy_Desc_Id(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field,
	storagenode_payment_period StoragenodePayment_Period_Field,
	limit int, offset int64) (
	rows []*StoragenodePayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_payments.id, storagenode_payments.created_at, storagenode_payments.node_id, storagenode_payments.period, storagenode_payments.amount, storagenode_payments.receipt, storagenode_payments.notes FROM storagenode_payments WHERE storagenode_payments.node_id = ? AND storagenode_payments.period = ? ORDER BY storagenode_payments.id DESC LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, storagenode_payment_node_id.value(), storagenode_payment_period.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_payment := &StoragenodePayment{}
				err = __rows.Scan(&storagenode_payment.Id, &storagenode_payment.CreatedAt, &storagenode_payment.NodeId, &storagenode_payment.Period, &storagenode_payment.Amount, &storagenode_payment.Receipt, &storagenode_payment.Notes)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_StoragenodePayment_By_NodeId(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field) (
	rows []*StoragenodePayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_payments.id, storagenode_payments.created_at, storagenode_payments.node_id, storagenode_payments.period, storagenode_payments.amount, storagenode_payments.receipt, storagenode_payments.notes FROM storagenode_payments WHERE storagenode_payments.node_id = ?")

	var __values []any
	__values = append(__values, storagenode_payment_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_payment := &StoragenodePayment{}
				err = __rows.Scan(&storagenode_payment.Id, &storagenode_payment.CreatedAt, &storagenode_payment.NodeId, &storagenode_payment.Period, &storagenode_payment.Amount, &storagenode_payment.Receipt, &storagenode_payment.Notes)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_StoragenodePayment_By_NodeId_And_Period(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field,
	storagenode_payment_period StoragenodePayment_Period_Field) (
	rows []*StoragenodePayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_payments.id, storagenode_payments.created_at, storagenode_payments.node_id, storagenode_payments.period, storagenode_payments.amount, storagenode_payments.receipt, storagenode_payments.notes FROM storagenode_payments WHERE storagenode_payments.node_id = ? AND storagenode_payments.period = ?")

	var __values []any
	__values = append(__values, storagenode_payment_node_id.value(), storagenode_payment_period.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_payment := &StoragenodePayment{}
				err = __rows.Scan(&storagenode_payment.Id, &storagenode_payment.CreatedAt, &storagenode_payment.NodeId, &storagenode_payment.Period, &storagenode_payment.Amount, &storagenode_payment.Receipt, &storagenode_payment.Notes)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_Reputation_By_Id(ctx context.Context,
	reputation_id Reputation_Id_Field) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta FROM reputations WHERE reputations.id = ?")

	var __values []any
	__values = append(__values, reputation_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if err != nil {
		return (*Reputation)(nil), obj.makeErr(err)
	}
	return reputation, nil

}

func (obj *pgxImpl) Get_OauthClient_By_Id(ctx context.Context,
	oauth_client_id OauthClient_Id_Field) (
	oauth_client *OauthClient, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT oauth_clients.id, oauth_clients.encrypted_secret, oauth_clients.redirect_url, oauth_clients.user_id, oauth_clients.app_name, oauth_clients.app_logo_url FROM oauth_clients WHERE oauth_clients.id = ?")

	var __values []any
	__values = append(__values, oauth_client_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	oauth_client = &OauthClient{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&oauth_client.Id, &oauth_client.EncryptedSecret, &oauth_client.RedirectUrl, &oauth_client.UserId, &oauth_client.AppName, &oauth_client.AppLogoUrl)
	if err != nil {
		return (*OauthClient)(nil), obj.makeErr(err)
	}
	return oauth_client, nil

}

func (obj *pgxImpl) Get_OauthCode_By_Code_And_ClaimedAt_Is_Null(ctx context.Context,
	oauth_code_code OauthCode_Code_Field) (
	oauth_code *OauthCode, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT oauth_codes.client_id, oauth_codes.user_id, oauth_codes.scope, oauth_codes.redirect_url, oauth_codes.challenge, oauth_codes.challenge_method, oauth_codes.code, oauth_codes.created_at, oauth_codes.expires_at, oauth_codes.claimed_at FROM oauth_codes WHERE oauth_codes.code = ? AND oauth_codes.claimed_at is NULL")

	var __values []any
	__values = append(__values, oauth_code_code.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	oauth_code = &OauthCode{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&oauth_code.ClientId, &oauth_code.UserId, &oauth_code.Scope, &oauth_code.RedirectUrl, &oauth_code.Challenge, &oauth_code.ChallengeMethod, &oauth_code.Code, &oauth_code.CreatedAt, &oauth_code.ExpiresAt, &oauth_code.ClaimedAt)
	if err != nil {
		return (*OauthCode)(nil), obj.makeErr(err)
	}
	return oauth_code, nil

}

func (obj *pgxImpl) Get_OauthToken_By_Kind_And_Token(ctx context.Context,
	oauth_token_kind OauthToken_Kind_Field,
	oauth_token_token OauthToken_Token_Field) (
	oauth_token *OauthToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT oauth_tokens.client_id, oauth_tokens.user_id, oauth_tokens.scope, oauth_tokens.kind, oauth_tokens.token, oauth_tokens.created_at, oauth_tokens.expires_at FROM oauth_tokens WHERE oauth_tokens.kind = ? AND oauth_tokens.token = ?")

	var __values []any
	__values = append(__values, oauth_token_kind.value(), oauth_token_token.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	oauth_token = &OauthToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&oauth_token.ClientId, &oauth_token.UserId, &oauth_token.Scope, &oauth_token.Kind, &oauth_token.Token, &oauth_token.CreatedAt, &oauth_token.ExpiresAt)
	if err != nil {
		return (*OauthToken)(nil), obj.makeErr(err)
	}
	return oauth_token, nil

}

func (obj *pgxImpl) Get_Project_PassphraseEnc_Project_PassphraseEncKeyId_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *PassphraseEnc_PassphraseEncKeyId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.passphrase_enc, projects.passphrase_enc_key_id FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &PassphraseEnc_PassphraseEncKeyId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.PassphraseEnc, &row.PassphraseEncKeyId)
	if err != nil {
		return (*PassphraseEnc_PassphraseEncKeyId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_Salt_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *Salt_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.salt FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Salt_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Salt)
	if err != nil {
		return (*Salt_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_By_PublicId(ctx context.Context,
	project_public_id Project_PublicId_Field) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.public_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE "), __cond_0, __sqlbundle_Literal(" LIMIT 2")}}

	var __values []any
	if !project_public_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_public_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		project, err = func() (project *Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			project = &Project{}
			err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return project, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("Project_By_PublicId")
			}
			return nil, obj.makeErr(err)
		}
		return project, nil
	}

}

func (obj *pgxImpl) Get_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
	if err != nil {
		return (*Project)(nil), obj.makeErr(err)
	}
	return project, nil

}

func (obj *pgxImpl) Get_Project_By__Id_Or_PublicId(ctx context.Context,
	project_id Project_Id_Field,
	project_public_id Project_PublicId_Field) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.public_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE (projects.id = ? OR "), __cond_0, __sqlbundle_Literal(") LIMIT 2")}}

	var __values []any
	__values = append(__values, project_id.value())
	if !project_public_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_public_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		project, err = func() (project *Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			project = &Project{}
			err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return project, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("Project_By__Id_Or_PublicId")
			}
			return nil, obj.makeErr(err)
		}
		return project, nil
	}

}

func (obj *pgxImpl) Get_Project_UsageLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UsageLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.usage_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UsageLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UsageLimit)
	if err != nil {
		return (*UsageLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_BandwidthLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *BandwidthLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.bandwidth_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &BandwidthLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.BandwidthLimit)
	if err != nil {
		return (*BandwidthLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_UserSpecifiedUsageLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UserSpecifiedUsageLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.user_specified_usage_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserSpecifiedUsageLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserSpecifiedUsageLimit)
	if err != nil {
		return (*UserSpecifiedUsageLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_UserSpecifiedBandwidthLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UserSpecifiedBandwidthLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.user_specified_bandwidth_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserSpecifiedBandwidthLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserSpecifiedBandwidthLimit)
	if err != nil {
		return (*UserSpecifiedBandwidthLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_SegmentLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *SegmentLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.segment_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &SegmentLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.SegmentLimit)
	if err != nil {
		return (*SegmentLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_MaxBuckets_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *MaxBuckets_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.max_buckets FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &MaxBuckets_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.MaxBuckets)
	if err != nil {
		return (*MaxBuckets_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_BandwidthLimit_Project_UserSpecifiedBandwidthLimit_Project_UsageLimit_Project_UserSpecifiedUsageLimit_Project_SegmentLimit_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.bandwidth_limit, projects.user_specified_bandwidth_limit, projects.usage_limit, projects.user_specified_usage_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.BandwidthLimit, &row.UserSpecifiedBandwidthLimit, &row.UsageLimit, &row.UserSpecifiedUsageLimit, &row.SegmentLimit, &row.RateLimit, &row.BurstLimit, &row.RateLimitHead, &row.BurstLimitHead, &row.RateLimitGet, &row.BurstLimitGet, &row.RateLimitPut, &row.BurstLimitPut, &row.RateLimitList, &row.BurstLimitList, &row.RateLimitDel, &row.BurstLimitDel)
	if err != nil {
		return (*BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_DefaultVersioning_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *DefaultVersioning_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.default_versioning FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &DefaultVersioning_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.DefaultVersioning)
	if err != nil {
		return (*DefaultVersioning_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_UserAgent_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UserAgent_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.user_agent FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserAgent_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserAgent)
	if err != nil {
		return (*UserAgent_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Project_PublicId_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *PublicId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.public_id FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &PublicId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.PublicId)
	if err != nil {
		return (*PublicId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) All_Project(ctx context.Context) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_Project_By_CreatedAt_Less_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_created_at_less Project_CreatedAt_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.created_at < ? ORDER BY projects.created_at")

	var __values []any
	__values = append(__values, project_created_at_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_Project_By_OwnerId_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_owner_id Project_OwnerId_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.owner_id = ? ORDER BY projects.created_at")

	var __values []any
	__values = append(__values, project_owner_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_Project_By_OwnerId_And_Status_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_owner_id Project_OwnerId_Field,
	project_status Project_Status_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.status", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.owner_id = ? AND "), __cond_0, __sqlbundle_Literal(" ORDER BY projects.created_at")}}

	var __values []any
	__values = append(__values, project_owner_id.value())
	if !project_status.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_status.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_Project_By_ProjectMember_MemberId_OrderBy_Asc_Project_Name(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects  JOIN project_members ON projects.id = project_members.project_id WHERE project_members.member_id = ? ORDER BY projects.name")

	var __values []any
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Limited_Project_By_CreatedAt_Less_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_created_at_less Project_CreatedAt_Field,
	limit int, offset int64) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.created_at < ? ORDER BY projects.created_at LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, project_created_at_less.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Limited_Project_Id_Project_PublicId_Project_OwnerId_By_Status_And_StatusUpdatedAt_Less_OrderBy_Asc_StatusUpdatedAt(ctx context.Context,
	project_status Project_Status_Field,
	project_status_updated_at_less Project_StatusUpdatedAt_Field,
	limit int, offset int64) (
	rows []*Id_PublicId_OwnerId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.status", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.owner_id FROM projects WHERE "), __cond_0, __sqlbundle_Literal(" AND projects.status_updated_at < ? ORDER BY projects.status_updated_at LIMIT ? OFFSET ?")}}

	var __values []any
	if !project_status.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_status.value())
	}
	__values = append(__values, project_status_updated_at_less.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_PublicId_OwnerId_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_PublicId_OwnerId_Row{}
				err = __rows.Scan(&row.Id, &row.PublicId, &row.OwnerId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	project_member *ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.role, project_members.created_at FROM project_members WHERE project_members.member_id = ? AND project_members.project_id = ?")

	var __values []any
	__values = append(__values, project_member_member_id.value(), project_member_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_member = &ProjectMember{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
	if err != nil {
		return (*ProjectMember)(nil), obj.makeErr(err)
	}
	return project_member, nil

}

func (obj *pgxImpl) All_ProjectMember_By_MemberId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.role, project_members.created_at FROM project_members WHERE project_members.member_id = ?")

	var __values []any
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectMember, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_member := &ProjectMember{}
				err = __rows.Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_member)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field) (
	project_invitation *ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations WHERE project_invitations.project_id = ? AND project_invitations.email = ?")

	var __values []any
	__values = append(__values, project_invitation_project_id.value(), project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_invitation = &ProjectInvitation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
	if err != nil {
		return (*ProjectInvitation)(nil), obj.makeErr(err)
	}
	return project_invitation, nil

}

func (obj *pgxImpl) All_ProjectInvitation_By_Email(ctx context.Context,
	project_invitation_email ProjectInvitation_Email_Field) (
	rows []*ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations WHERE project_invitations.email = ?")

	var __values []any
	__values = append(__values, project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectInvitation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_invitation := &ProjectInvitation{}
				err = __rows.Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_invitation)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_ProjectInvitation_By_Project_Status_And_ProjectInvitation_Email(ctx context.Context,
	project_status Project_Status_Field,
	project_invitation_email ProjectInvitation_Email_Field) (
	rows []*ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.status", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations  JOIN projects ON project_invitations.project_id = projects.id WHERE "), __cond_0, __sqlbundle_Literal(" AND project_invitations.email = ?")}}

	var __values []any
	if !project_status.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_status.value())
	}
	__values = append(__values, project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectInvitation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_invitation := &ProjectInvitation{}
				err = __rows.Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_invitation)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_ProjectInvitation_By_ProjectId(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field) (
	rows []*ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations WHERE project_invitations.project_id = ?")

	var __values []any
	__values = append(__values, project_invitation_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectInvitation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_invitation := &ProjectInvitation{}
				err = __rows.Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_invitation)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_ApiKey_Project_PublicId_By_ApiKey_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	row *ApiKey_Project_PublicId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version, projects.public_id FROM projects  JOIN api_keys ON projects.id = api_keys.project_id WHERE api_keys.id = ?")

	var __values []any
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ApiKey_Project_PublicId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ApiKey.Id, &row.ApiKey.ProjectId, &row.ApiKey.Head, &row.ApiKey.Name, &row.ApiKey.Secret, &row.ApiKey.UserAgent, &row.ApiKey.CreatedAt, &row.ApiKey.CreatedBy, &row.ApiKey.Version, &row.Project_PublicId)
	if err != nil {
		return (*ApiKey_Project_PublicId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_By_ApiKey_Head(ctx context.Context,
	api_key_head ApiKey_Head_Field) (
	row *ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version, projects.public_id, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.segment_limit, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit FROM projects  JOIN api_keys ON projects.id = api_keys.project_id WHERE api_keys.head = ?")

	var __values []any
	__values = append(__values, api_key_head.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ApiKey.Id, &row.ApiKey.ProjectId, &row.ApiKey.Head, &row.ApiKey.Name, &row.ApiKey.Secret, &row.ApiKey.UserAgent, &row.ApiKey.CreatedAt, &row.ApiKey.CreatedBy, &row.ApiKey.Version, &row.Project_PublicId, &row.Project_RateLimit, &row.Project_BurstLimit, &row.Project_RateLimitHead, &row.Project_BurstLimitHead, &row.Project_RateLimitGet, &row.Project_BurstLimitGet, &row.Project_RateLimitPut, &row.Project_BurstLimitPut, &row.Project_RateLimitList, &row.Project_BurstLimitList, &row.Project_RateLimitDel, &row.Project_BurstLimitDel, &row.Project_SegmentLimit, &row.Project_UsageLimit, &row.Project_BandwidthLimit, &row.Project_UserSpecifiedUsageLimit, &row.Project_UserSpecifiedBandwidthLimit)
	if err != nil {
		return (*ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_ApiKey_Project_PublicId_By_ApiKey_Name_And_ApiKey_ProjectId(ctx context.Context,
	api_key_name ApiKey_Name_Field,
	api_key_project_id ApiKey_ProjectId_Field) (
	row *ApiKey_Project_PublicId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version, projects.public_id FROM projects  JOIN api_keys ON projects.id = api_keys.project_id WHERE api_keys.name = ? AND api_keys.project_id = ?")

	var __values []any
	__values = append(__values, api_key_name.value(), api_key_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ApiKey_Project_PublicId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ApiKey.Id, &row.ApiKey.ProjectId, &row.ApiKey.Head, &row.ApiKey.Name, &row.ApiKey.Secret, &row.ApiKey.UserAgent, &row.ApiKey.CreatedAt, &row.ApiKey.CreatedBy, &row.ApiKey.Version, &row.Project_PublicId)
	if err != nil {
		return (*ApiKey_Project_PublicId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_ApiKeyTail_By_Tail(ctx context.Context,
	api_key_tail_tail ApiKeyTail_Tail_Field) (
	api_key_tail *ApiKeyTail, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_key_tails.root_key_id, api_key_tails.tail, api_key_tails.parent_tail, api_key_tails.caveat, api_key_tails.last_used FROM api_key_tails WHERE api_key_tails.tail = ?")

	var __values []any
	__values = append(__values, api_key_tail_tail.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key_tail = &ApiKeyTail{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&api_key_tail.RootKeyId, &api_key_tail.Tail, &api_key_tail.ParentTail, &api_key_tail.Caveat, &api_key_tail.LastUsed)
	if err != nil {
		return (*ApiKeyTail)(nil), obj.makeErr(err)
	}
	return api_key_tail, nil

}

func (obj *pgxImpl) Get_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err != nil {
		return (*BucketMetainfo)(nil), obj.makeErr(err)
	}
	return bucket_metainfo, nil

}

func (obj *pgxImpl) Get_BucketMetainfo_Tags_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Tags_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.tags FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Tags_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Tags)
	if err != nil {
		return (*Tags_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_BucketMetainfo_CreatedBy_BucketMetainfo_CreatedAt_BucketMetainfo_Placement_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *CreatedBy_CreatedAt_Placement_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.created_by, bucket_metainfos.created_at, bucket_metainfos.placement FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &CreatedBy_CreatedAt_Placement_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.CreatedBy, &row.CreatedAt, &row.Placement)
	if err != nil {
		return (*CreatedBy_CreatedAt_Placement_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_BucketMetainfo_Placement_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Placement_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.placement FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Placement_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Placement)
	if err != nil {
		return (*Placement_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_BucketMetainfo_UserAgent_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *UserAgent_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.user_agent FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserAgent_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserAgent)
	if err != nil {
		return (*UserAgent_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_BucketMetainfo_Versioning_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Versioning_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.versioning FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Versioning_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Versioning)
	if err != nil {
		return (*Versioning_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_BucketMetainfo_ObjectLockEnabled_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *ObjectLockEnabled_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.object_lock_enabled FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ObjectLockEnabled_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ObjectLockEnabled)
	if err != nil {
		return (*ObjectLockEnabled_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_BucketMetainfo_ObjectLockEnabled_BucketMetainfo_DefaultRetentionMode_BucketMetainfo_DefaultRetentionDays_BucketMetainfo_DefaultRetentionYears_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ObjectLockEnabled, &row.DefaultRetentionMode, &row.DefaultRetentionDays, &row.DefaultRetentionYears)
	if err != nil {
		return (*ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_Bucket(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.created_by, bucket_metainfos.user_agent, bucket_metainfos.created_at, bucket_metainfos.placement, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Id, &row.CreatedBy, &row.UserAgent, &row.CreatedAt, &row.Placement, &row.Versioning, &row.ObjectLockEnabled, &row.DefaultRetentionMode, &row.DefaultRetentionDays, &row.DefaultRetentionYears)
	if err != nil {
		return (*Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Has_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	has bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT EXISTS( SELECT 1 FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? )")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&has)
	if err != nil {
		return false, obj.makeErr(err)
	}
	return has, nil

}

func (obj *pgxImpl) Limited_BucketMetainfo_By_ProjectId_And_Name_GreaterOrEqual_OrderBy_Asc_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name_greater_or_equal BucketMetainfo_Name_Field,
	limit int, offset int64) (
	rows []*BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name >= ? ORDER BY bucket_metainfos.name LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name_greater_or_equal.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMetainfo, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_metainfo := &BucketMetainfo{}
				err = __rows.Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_metainfo)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Limited_BucketMetainfo_By_ProjectId_And_Name_Greater_OrderBy_Asc_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name_greater BucketMetainfo_Name_Field,
	limit int, offset int64) (
	rows []*BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name > ? ORDER BY bucket_metainfos.name LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name_greater.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMetainfo, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_metainfo := &BucketMetainfo{}
				err = __rows.Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_metainfo)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Count_BucketMetainfo_Name_By_ProjectId(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT COUNT(*) FROM bucket_metainfos WHERE bucket_metainfos.project_id = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&count)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Count_BucketMetainfo_Name_By_ProjectId_And_ObjectLockEnabled_Equal_True(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT COUNT(*) FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.object_lock_enabled = true")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&count)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name(ctx context.Context,
	limit int, start *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation) (
	rows []*ProjectId_Name_Row, next *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.project_id, bucket_metainfos.name FROM bucket_metainfos WHERE (bucket_metainfos.project_id, bucket_metainfos.name) > (?, ?) ORDER BY bucket_metainfos.project_id, bucket_metainfos.name LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.project_id, bucket_metainfos.name FROM bucket_metainfos ORDER BY bucket_metainfos.project_id, bucket_metainfos.name LIMIT ?")

	var __values []any

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_project_id, start._value_name, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*ProjectId_Name_Row, next *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation
			__continuation._set = true

			for __rows.Next() {
				row := &ProjectId_Name_Row{}
				err = __rows.Scan(&row.ProjectId, &row.Name, &__continuation._value_project_id, &__continuation._value_name)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, row)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxImpl) Get_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field) (
	value_attribution *ValueAttribution, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT value_attributions.project_id, value_attributions.bucket_name, value_attributions.user_agent, value_attributions.placement, value_attributions.last_updated FROM value_attributions WHERE value_attributions.project_id = ? AND value_attributions.bucket_name = ?")

	var __values []any
	__values = append(__values, value_attribution_project_id.value(), value_attribution_bucket_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	value_attribution = &ValueAttribution{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
	if err != nil {
		return (*ValueAttribution)(nil), obj.makeErr(err)
	}
	return value_attribution, nil

}

func (obj *pgxImpl) Get_BucketMigration_By_Id(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field) (
	bucket_migration *BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at FROM bucket_migrations WHERE bucket_migrations.id = ?")

	var __values []any
	__values = append(__values, bucket_migration_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_migration = &BucketMigration{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
	if err != nil {
		return (*BucketMigration)(nil), obj.makeErr(err)
	}
	return bucket_migration, nil

}

func (obj *pgxImpl) All_BucketMigration_By_ProjectId_And_BucketName_OrderBy_Desc_CreatedAt(ctx context.Context,
	bucket_migration_project_id BucketMigration_ProjectId_Field,
	bucket_migration_bucket_name BucketMigration_BucketName_Field) (
	rows []*BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at FROM bucket_migrations WHERE bucket_migrations.project_id = ? AND bucket_migrations.bucket_name = ? ORDER BY bucket_migrations.created_at DESC")

	var __values []any
	__values = append(__values, bucket_migration_project_id.value(), bucket_migration_bucket_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMigration, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_migration := &BucketMigration{}
				err = __rows.Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_migration)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Limited_BucketMigration_By_State_OrderBy_Asc_CreatedAt(ctx context.Context,
	bucket_migration_state BucketMigration_State_Field,
	limit int, offset int64) (
	rows []*BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at FROM bucket_migrations WHERE bucket_migrations.state = ? ORDER BY bucket_migrations.created_at LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, bucket_migration_state.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMigration, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_migration := &BucketMigration{}
				err = __rows.Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_migration)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_RestApiKey_By_Id(ctx context.Context,
	rest_api_key_id RestApiKey_Id_Field) (
	rest_api_key *RestApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT rest_api_keys.id, rest_api_keys.user_id, rest_api_keys.token, rest_api_keys.name, rest_api_keys.expires_at, rest_api_keys.created_at FROM rest_api_keys WHERE rest_api_keys.id = ?")

	var __values []any
	__values = append(__values, rest_api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	rest_api_key = &RestApiKey{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&rest_api_key.Id, &rest_api_key.UserId, &rest_api_key.Token, &rest_api_key.Name, &rest_api_key.ExpiresAt, &rest_api_key.CreatedAt)
	if err != nil {
		return (*RestApiKey)(nil), obj.makeErr(err)
	}
	return rest_api_key, nil

}

func (obj *pgxImpl) Get_RestApiKey_By_Token(ctx context.Context,
	rest_api_key_token RestApiKey_Token_Field) (
	rest_api_key *RestApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT rest_api_keys.id, rest_api_keys.user_id, rest_api_keys.token, rest_api_keys.name, rest_api_keys.expires_at, rest_api_keys.created_at FROM rest_api_keys WHERE rest_api_keys.token = ?")

	var __values []any
	__values = append(__values, rest_api_key_token.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	rest_api_key = &RestApiKey{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&rest_api_key.Id, &rest_api_key.UserId, &rest_api_key.Token, &rest_api_key.Name, &rest_api_key.ExpiresAt, &rest_api_key.CreatedAt)
	if err != nil {
		return (*RestApiKey)(nil), obj.makeErr(err)
	}
	return rest_api_key, nil

}

func (obj *pgxImpl) All_RestApiKey_By_UserId(ctx context.Context,
	rest_api_key_user_id RestApiKey_UserId_Field) (
	rows []*RestApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT rest_api_keys.id, rest_api_keys.user_id, rest_api_keys.token, rest_api_keys.name, rest_api_keys.expires_at, rest_api_keys.created_at FROM rest_api_keys WHERE rest_api_keys.user_id = ?")

	var __values []any
	__values = append(__values, rest_api_key_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*RestApiKey, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				rest_api_key := &RestApiKey{}
				err = __rows.Scan(&rest_api_key.Id, &rest_api_key.UserId, &rest_api_key.Token, &rest_api_key.Name, &rest_api_key.ExpiresAt, &rest_api_key.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, rest_api_key)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_User(ctx context.Context) (
	rows []*User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				user := &User{}
				err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, user)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_User_By_NormalizedEmail(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field) (
	rows []*User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ?")

	var __values []any
	__values = append(__values, user_normalized_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				user := &User{}
				err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, user)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) All_User_By_NormalizedEmail_And_TenantId(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field,
	user_tenant_id User_TenantId_Field) (
	rows []*User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "users.tenant_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ? AND "), __cond_0}}

	var __values []any
	__values = append(__values, user_normalized_email.value())
	if !user_tenant_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_tenant_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				user := &User{}
				err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, user)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_User_By_NormalizedEmail_And_Status_Not_Number(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ? AND users.status != 0 LIMIT 2")

	var __values []any
	__values = append(__values, user_normalized_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		user, err = func() (user *User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			user = &User{}
			err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return user, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("User_By_NormalizedEmail_And_Status_Not_Number")
			}
			return nil, obj.makeErr(err)
		}
		return user, nil
	}

}

func (obj *pgxImpl) Get_User_By_NormalizedEmail_And_TenantId_And_Status_Not_Number(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field,
	user_tenant_id User_TenantId_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "users.tenant_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ? AND "), __cond_0, __sqlbundle_Literal(" AND users.status != 0 LIMIT 2")}}

	var __values []any
	__values = append(__values, user_normalized_email.value())
	if !user_tenant_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_tenant_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		user, err = func() (user *User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			user = &User{}
			err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return user, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("User_By_NormalizedEmail_And_TenantId_And_Status_Not_Number")
			}
			return nil, obj.makeErr(err)
		}
		return user, nil
	}

}

func (obj *pgxImpl) Get_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
	if err != nil {
		return (*User)(nil), obj.makeErr(err)
	}
	return user, nil

}

func (obj *pgxImpl) Get_User_ProjectLimit_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *ProjectLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.project_limit FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ProjectLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ProjectLimit)
	if err != nil {
		return (*ProjectLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_User_Kind_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *Kind_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.kind FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Kind_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Kind)
	if err != nil {
		return (*Kind_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_User_UpgradeTime_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *UpgradeTime_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.upgrade_time FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UpgradeTime_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UpgradeTime)
	if err != nil {
		return (*UpgradeTime_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Get_User_By_ExternalId(ctx context.Context,
	user_external_id User_ExternalId_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "users.external_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE "), __cond_0, __sqlbundle_Literal(" LIMIT 2")}}

	var __values []any
	if !user_external_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_external_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		user, err = func() (user *User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			user = &User{}
			err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return user, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("User_By_ExternalId")
			}
			return nil, obj.makeErr(err)
		}
		return user, nil
	}

}

func (obj *pgxImpl) Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event(ctx context.Context,
	user_status_not User_Status_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field,
	limit int, start *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation) (
	rows []*AccountFreezeEvent, next *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at, account_freeze_events.user_id, account_freeze_events.event FROM account_freeze_events  JOIN users ON account_freeze_events.user_id = users.id WHERE users.status != ? AND account_freeze_events.event = ? AND (account_freeze_events.user_id, account_freeze_events.event) > (?, ?) ORDER BY account_freeze_events.user_id, account_freeze_events.event LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at, account_freeze_events.user_id, account_freeze_events.event FROM account_freeze_events  JOIN users ON account_freeze_events.user_id = users.id WHERE users.status != ? AND account_freeze_events.event = ? ORDER BY account_freeze_events.user_id, account_freeze_events.event LIMIT ?")

	var __values []any
	__values = append(__values, user_status_not.value(), account_freeze_event_event.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_user_id, start._value_event, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*AccountFreezeEvent, next *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation
			__continuation._set = true

			for __rows.Next() {
				account_freeze_event := &AccountFreezeEvent{}
				err = __rows.Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt, &__continuation._value_user_id, &__continuation._value_event)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, account_freeze_event)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxImpl) Get_User_ProjectStorageLimit_User_ProjectBandwidthLimit_User_ProjectSegmentLimit_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.project_storage_limit, users.project_bandwidth_limit, users.project_segment_limit FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ProjectStorageLimit, &row.ProjectBandwidthLimit, &row.ProjectSegmentLimit)
	if err != nil {
		return (*ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) Count_User_By_Status(ctx context.Context,
	user_status User_Status_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT COUNT(*) FROM users WHERE users.status = ?")

	var __values []any
	__values = append(__values, user_status.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&count)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Limited_User_Id_User_Email_User_FullName_By_Status(ctx context.Context,
	user_status User_Status_Field,
	limit int, offset int64) (
	rows []*Id_Email_FullName_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.email, users.full_name FROM users WHERE users.status = ? LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, user_status.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_Email_FullName_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_Email_FullName_Row{}
				err = __rows.Scan(&row.Id, &row.Email, &row.FullName)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_User_Status_By_Project_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *Status_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.status FROM users  JOIN projects ON users.id = projects.owner_id WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Status_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Status)
	if err != nil {
		return (*Status_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxImpl) All_WebappSession_By_UserId(ctx context.Context,
	webapp_session_user_id WebappSession_UserId_Field) (
	rows []*WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at FROM webapp_sessions WHERE webapp_sessions.user_id = ?")

	var __values []any
	__values = append(__values, webapp_session_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*WebappSession, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				webapp_session := &WebappSession{}
				err = __rows.Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, webapp_session)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_WebappSession_By_Id(ctx context.Context,
	webapp_session_id WebappSession_Id_Field) (
	webapp_session *WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at FROM webapp_sessions WHERE webapp_sessions.id = ?")

	var __values []any
	__values = append(__values, webapp_session_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	webapp_session = &WebappSession{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
	if err != nil {
		return (*WebappSession)(nil), obj.makeErr(err)
	}
	return webapp_session, nil

}

func (obj *pgxImpl) Get_RegistrationToken_By_Secret(ctx context.Context,
	registration_token_secret RegistrationToken_Secret_Field) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at FROM registration_tokens WHERE registration_tokens.secret = ?")

	var __values []any
	__values = append(__values, registration_token_secret.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err != nil {
		return (*RegistrationToken)(nil), obj.makeErr(err)
	}
	return registration_token, nil

}

func (obj *pgxImpl) Get_RegistrationToken_By_OwnerId(ctx context.Context,
	registration_token_owner_id RegistrationToken_OwnerId_Field) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "registration_tokens.owner_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at FROM registration_tokens WHERE "), __cond_0}}

	var __values []any
	if !registration_token_owner_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, registration_token_owner_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err != nil {
		return (*RegistrationToken)(nil), obj.makeErr(err)
	}
	return registration_token, nil

}

func (obj *pgxImpl) Get_ResetPasswordToken_By_Secret(ctx context.Context,
	reset_password_token_secret ResetPasswordToken_Secret_Field) (
	reset_password_token *ResetPasswordToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reset_password_tokens.secret, reset_password_tokens.owner_id, reset_password_tokens.created_at FROM reset_password_tokens WHERE reset_password_tokens.secret = ?")

	var __values []any
	__values = append(__values, reset_password_token_secret.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reset_password_token = &ResetPasswordToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
	if err != nil {
		return (*ResetPasswordToken)(nil), obj.makeErr(err)
	}
	return reset_password_token, nil

}

func (obj *pgxImpl) Get_ResetPasswordToken_By_OwnerId(ctx context.Context,
	reset_password_token_owner_id ResetPasswordToken_OwnerId_Field) (
	reset_password_token *ResetPasswordToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reset_password_tokens.secret, reset_password_tokens.owner_id, reset_password_tokens.created_at FROM reset_password_tokens WHERE reset_password_tokens.owner_id = ?")

	var __values []any
	__values = append(__values, reset_password_token_owner_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reset_password_token = &ResetPasswordToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
	if err != nil {
		return (*ResetPasswordToken)(nil), obj.makeErr(err)
	}
	return reset_password_token, nil

}

func (obj *pgxImpl) Get_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field) (
	account_freeze_event *AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at FROM account_freeze_events WHERE account_freeze_events.user_id = ? AND account_freeze_events.event = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value(), account_freeze_event_event.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	account_freeze_event = &AccountFreezeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
	if err != nil {
		return (*AccountFreezeEvent)(nil), obj.makeErr(err)
	}
	return account_freeze_event, nil

}

func (obj *pgxImpl) All_AccountFreezeEvent_By_UserId(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field) (
	rows []*AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at FROM account_freeze_events WHERE account_freeze_events.user_id = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*AccountFreezeEvent, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				account_freeze_event := &AccountFreezeEvent{}
				err = __rows.Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, account_freeze_event)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxImpl) Get_UserSettings_By_UserId(ctx context.Context,
	user_settings_user_id UserSettings_UserId_Field) (
	user_settings *UserSettings, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT user_settings.user_id, user_settings.session_minutes, user_settings.passphrase_prompt, user_settings.onboarding_start, user_settings.onboarding_end, user_settings.onboarding_step, user_settings.notice_dismissal FROM user_settings WHERE user_settings.user_id = ?")

	var __values []any
	__values = append(__values, user_settings_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user_settings = &UserSettings{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user_settings.UserId, &user_settings.SessionMinutes, &user_settings.PassphrasePrompt, &user_settings.OnboardingStart, &user_settings.OnboardingEnd, &user_settings.OnboardingStep, &user_settings.NoticeDismissal)
	if err != nil {
		return (*UserSettings)(nil), obj.makeErr(err)
	}
	return user_settings, nil

}

func (obj *pgxImpl) UpdateNoReturn_AccountingTimestamps_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	update AccountingTimestamps_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE accounting_timestamps SET "), __sets, __sqlbundle_Literal(" WHERE accounting_timestamps.name = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Value._set {
		__values = append(__values, update.Value.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("value = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, accounting_timestamps_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) Update_StripeCustomer_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field,
	update StripeCustomer_Update_Fields) (
	stripe_customer *StripeCustomer, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE stripe_customers SET "), __sets, __sqlbundle_Literal(" WHERE stripe_customers.user_id = ? RETURNING stripe_customers.user_id, stripe_customers.customer_id, stripe_customers.billing_customer_id, stripe_customers.package_plan, stripe_customers.purchased_package_at, stripe_customers.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.BillingCustomerId._set {
		__values = append(__values, update.BillingCustomerId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("billing_customer_id = ?"))
	}

	if update.PackagePlan._set {
		__values = append(__values, update.PackagePlan.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("package_plan = ?"))
	}

	if update.PurchasedPackageAt._set {
		__values = append(__values, update.PurchasedPackageAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("purchased_package_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, stripe_customer_user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripe_customer = &StripeCustomer{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripe_customer.UserId, &stripe_customer.CustomerId, &stripe_customer.BillingCustomerId, &stripe_customer.PackagePlan, &stripe_customer.PurchasedPackageAt, &stripe_customer.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripe_customer, nil
}

func (obj *pgxImpl) Update_BillingBalance_By_UserId_And_Balance(ctx context.Context,
	billing_balance_user_id BillingBalance_UserId_Field,
	billing_balance_balance BillingBalance_Balance_Field,
	update BillingBalance_Update_Fields) (
	billing_balance *BillingBalance, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE billing_balances SET "), __sets, __sqlbundle_Literal(" WHERE billing_balances.user_id = ? AND billing_balances.balance = ? RETURNING billing_balances.user_id, billing_balances.balance, billing_balances.last_updated")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Balance._set {
		__values = append(__values, update.Balance.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("balance = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_updated = ?"))

	__args = append(__args, billing_balance_user_id.value(), billing_balance_balance.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	billing_balance = &BillingBalance{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&billing_balance.UserId, &billing_balance.Balance, &billing_balance.LastUpdated)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return billing_balance, nil
}

func (obj *pgxImpl) UpdateNoReturn_BillingTransaction_By_Id_And_Status(ctx context.Context,
	billing_transaction_id BillingTransaction_Id_Field,
	billing_transaction_status BillingTransaction_Status_Field,
	update BillingTransaction_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE billing_transactions SET "), __sets, __sqlbundle_Literal(" WHERE billing_transactions.id = ? AND billing_transactions.status = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if update.Metadata._set {
		__values = append(__values, update.Metadata.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("metadata = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, billing_transaction_id.value(), billing_transaction_status.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) Update_CoinpaymentsTransaction_By_Id(ctx context.Context,
	coinpayments_transaction_id CoinpaymentsTransaction_Id_Field,
	update CoinpaymentsTransaction_Update_Fields) (
	coinpayments_transaction *CoinpaymentsTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE coinpayments_transactions SET "), __sets, __sqlbundle_Literal(" WHERE coinpayments_transactions.id = ? RETURNING coinpayments_transactions.id, coinpayments_transactions.user_id, coinpayments_transactions.address, coinpayments_transactions.amount_numeric, coinpayments_transactions.received_numeric, coinpayments_transactions.status, coinpayments_transactions.key, coinpayments_transactions.timeout, coinpayments_transactions.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ReceivedNumeric._set {
		__values = append(__values, update.ReceivedNumeric.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("received_numeric = ?"))
	}

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, coinpayments_transaction_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	coinpayments_transaction = &CoinpaymentsTransaction{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return coinpayments_transaction, nil
}

func (obj *pgxImpl) Update_StripecoinpaymentsInvoiceProjectRecord_By_Id(ctx context.Context,
	stripecoinpayments_invoice_project_record_id StripecoinpaymentsInvoiceProjectRecord_Id_Field,
	update StripecoinpaymentsInvoiceProjectRecord_Update_Fields) (
	stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE stripecoinpayments_invoice_project_records SET "), __sets, __sqlbundle_Literal(" WHERE stripecoinpayments_invoice_project_records.id = ? RETURNING stripecoinpayments_invoice_project_records.id, stripecoinpayments_invoice_project_records.project_id, stripecoinpayments_invoice_project_records.storage, stripecoinpayments_invoice_project_records.egress, stripecoinpayments_invoice_project_records.objects, stripecoinpayments_invoice_project_records.segments, stripecoinpayments_invoice_project_records.period_start, stripecoinpayments_invoice_project_records.period_end, stripecoinpayments_invoice_project_records.state, stripecoinpayments_invoice_project_records.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.State._set {
		__values = append(__values, update.State.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("state = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, stripecoinpayments_invoice_project_record_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_invoice_project_record = &StripecoinpaymentsInvoiceProjectRecord{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripecoinpayments_invoice_project_record, nil
}

func (obj *pgxImpl) UpdateNoReturn_PeerIdentity_By_NodeId(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field,
	update PeerIdentity_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE peer_identities SET "), __sets, __sqlbundle_Literal(" WHERE peer_identities.node_id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.LeafSerialNumber._set {
		__values = append(__values, update.LeafSerialNumber.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("leaf_serial_number = ?"))
	}

	if update.Chain._set {
		__values = append(__values, update.Chain.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("chain = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, peer_identity_node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) Update_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	node *Node, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ? RETURNING nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}

	if update.LastNet._set {
		__values = append(__values, update.LastNet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_net = ?"))
	}

	if update.LastIpPort._set {
		__values = append(__values, update.LastIpPort.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_ip_port = ?"))
	}

	if update.CountryCode._set {
		__values = append(__values, update.CountryCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("country_code = ?"))
	}

	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.Wallet._set {
		__values = append(__values, update.Wallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet = ?"))
	}

	if update.WalletFeatures._set {
		__values = append(__values, update.WalletFeatures.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet_features = ?"))
	}

	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}

	if update.PieceCount._set {
		__values = append(__values, update.PieceCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("piece_count = ?"))
	}

	if update.Major._set {
		__values = append(__values, update.Major.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("major = ?"))
	}

	if update.Minor._set {
		__values = append(__values, update.Minor.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("minor = ?"))
	}

	if update.Patch._set {
		__values = append(__values, update.Patch.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("patch = ?"))
	}

	if update.CommitHash._set {
		__values = append(__values, update.CommitHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("commit_hash = ?"))
	}

	if update.ReleaseTimestamp._set {
		__values = append(__values, update.ReleaseTimestamp.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release_timestamp = ?"))
	}

	if update.Release._set {
		__values = append(__values, update.Release.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release = ?"))
	}

	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.LastContactSuccess._set {
		__values = append(__values, update.LastContactSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_success = ?"))
	}

	if update.LastContactFailure._set {
		__values = append(__values, update.LastContactFailure.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_failure = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.ExitInitiatedAt._set {
		__values = append(__values, update.ExitInitiatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_initiated_at = ?"))
	}

	if update.ExitLoopCompletedAt._set {
		__values = append(__values, update.ExitLoopCompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_loop_completed_at = ?"))
	}

	if update.ExitFinishedAt._set {
		__values = append(__values, update.ExitFinishedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_finished_at = ?"))
	}

	if update.ExitSuccess._set {
		__values = append(__values, update.ExitSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_success = ?"))
	}

	if update.Contained._set {
		__values = append(__values, update.Contained.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("contained = ?"))
	}

	if update.LastOfflineEmail._set {
		__values = append(__values, update.LastOfflineEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_offline_email = ?"))
	}

	if update.LastSoftwareUpdateEmail._set {
		__values = append(__values, update.LastSoftwareUpdateEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_software_update_email = ?"))
	}

	if update.NoiseProto._set {
		__values = append(__values, update.NoiseProto.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_proto = ?"))
	}

	if update.NoisePublicKey._set {
		__values = append(__values, update.NoisePublicKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_public_key = ?"))
	}

	if update.DebounceLimit._set {
		__values = append(__values, update.DebounceLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("debounce_limit = ?"))
	}

	if update.Features._set {
		__values = append(__values, update.Features.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("features = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node.Id, &node.Address, &node.LastNet, &node.LastIpPort, &node.CountryCode, &node.Protocol, &node.Email, &node.Wallet, &node.WalletFeatures, &node.FreeDisk, &node.PieceCount, &node.Major, &node.Minor, &node.Patch, &node.CommitHash, &node.ReleaseTimestamp, &node.Release, &node.Latency90, &node.VettedAt, &node.CreatedAt, &node.UpdatedAt, &node.LastContactSuccess, &node.LastContactFailure, &node.Disqualified, &node.DisqualificationReason, &node.UnknownAuditSuspended, &node.OfflineSuspended, &node.UnderReview, &node.ExitInitiatedAt, &node.ExitLoopCompletedAt, &node.ExitFinishedAt, &node.ExitSuccess, &node.Contained, &node.LastOfflineEmail, &node.LastSoftwareUpdateEmail, &node.NoiseProto, &node.NoisePublicKey, &node.DebounceLimit, &node.Features)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node, nil
}

func (obj *pgxImpl) UpdateNoReturn_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}

	if update.LastNet._set {
		__values = append(__values, update.LastNet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_net = ?"))
	}

	if update.LastIpPort._set {
		__values = append(__values, update.LastIpPort.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_ip_port = ?"))
	}

	if update.CountryCode._set {
		__values = append(__values, update.CountryCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("country_code = ?"))
	}

	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.Wallet._set {
		__values = append(__values, update.Wallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet = ?"))
	}

	if update.WalletFeatures._set {
		__values = append(__values, update.WalletFeatures.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet_features = ?"))
	}

	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}

	if update.PieceCount._set {
		__values = append(__values, update.PieceCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("piece_count = ?"))
	}

	if update.Major._set {
		__values = append(__values, update.Major.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("major = ?"))
	}

	if update.Minor._set {
		__values = append(__values, update.Minor.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("minor = ?"))
	}

	if update.Patch._set {
		__values = append(__values, update.Patch.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("patch = ?"))
	}

	if update.CommitHash._set {
		__values = append(__values, update.CommitHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("commit_hash = ?"))
	}

	if update.ReleaseTimestamp._set {
		__values = append(__values, update.ReleaseTimestamp.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release_timestamp = ?"))
	}

	if update.Release._set {
		__values = append(__values, update.Release.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release = ?"))
	}

	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.LastContactSuccess._set {
		__values = append(__values, update.LastContactSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_success = ?"))
	}

	if update.LastContactFailure._set {
		__values = append(__values, update.LastContactFailure.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_failure = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.ExitInitiatedAt._set {
		__values = append(__values, update.ExitInitiatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_initiated_at = ?"))
	}

	if update.ExitLoopCompletedAt._set {
		__values = append(__values, update.ExitLoopCompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_loop_completed_at = ?"))
	}

	if update.ExitFinishedAt._set {
		__values = append(__values, update.ExitFinishedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_finished_at = ?"))
	}

	if update.ExitSuccess._set {
		__values = append(__values, update.ExitSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_success = ?"))
	}

	if update.Contained._set {
		__values = append(__values, update.Contained.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("contained = ?"))
	}

	if update.LastOfflineEmail._set {
		__values = append(__values, update.LastOfflineEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_offline_email = ?"))
	}

	if update.LastSoftwareUpdateEmail._set {
		__values = append(__values, update.LastSoftwareUpdateEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_software_update_email = ?"))
	}

	if update.NoiseProto._set {
		__values = append(__values, update.NoiseProto.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_proto = ?"))
	}

	if update.NoisePublicKey._set {
		__values = append(__values, update.NoisePublicKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_public_key = ?"))
	}

	if update.DebounceLimit._set {
		__values = append(__values, update.DebounceLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("debounce_limit = ?"))
	}

	if update.Features._set {
		__values = append(__values, update.Features.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("features = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) UpdateNoReturn_Node_By_Id_And_Disqualified_Is_Null_And_ExitFinishedAt_Is_Null(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ? AND nodes.disqualified is NULL AND nodes.exit_finished_at is NULL")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}

	if update.LastNet._set {
		__values = append(__values, update.LastNet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_net = ?"))
	}

	if update.LastIpPort._set {
		__values = append(__values, update.LastIpPort.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_ip_port = ?"))
	}

	if update.CountryCode._set {
		__values = append(__values, update.CountryCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("country_code = ?"))
	}

	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.Wallet._set {
		__values = append(__values, update.Wallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet = ?"))
	}

	if update.WalletFeatures._set {
		__values = append(__values, update.WalletFeatures.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet_features = ?"))
	}

	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}

	if update.PieceCount._set {
		__values = append(__values, update.PieceCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("piece_count = ?"))
	}

	if update.Major._set {
		__values = append(__values, update.Major.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("major = ?"))
	}

	if update.Minor._set {
		__values = append(__values, update.Minor.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("minor = ?"))
	}

	if update.Patch._set {
		__values = append(__values, update.Patch.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("patch = ?"))
	}

	if update.CommitHash._set {
		__values = append(__values, update.CommitHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("commit_hash = ?"))
	}

	if update.ReleaseTimestamp._set {
		__values = append(__values, update.ReleaseTimestamp.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release_timestamp = ?"))
	}

	if update.Release._set {
		__values = append(__values, update.Release.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release = ?"))
	}

	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.LastContactSuccess._set {
		__values = append(__values, update.LastContactSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_success = ?"))
	}

	if update.LastContactFailure._set {
		__values = append(__values, update.LastContactFailure.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_failure = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.ExitInitiatedAt._set {
		__values = append(__values, update.ExitInitiatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_initiated_at = ?"))
	}

	if update.ExitLoopCompletedAt._set {
		__values = append(__values, update.ExitLoopCompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_loop_completed_at = ?"))
	}

	if update.ExitFinishedAt._set {
		__values = append(__values, update.ExitFinishedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_finished_at = ?"))
	}

	if update.ExitSuccess._set {
		__values = append(__values, update.ExitSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_success = ?"))
	}

	if update.Contained._set {
		__values = append(__values, update.Contained.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("contained = ?"))
	}

	if update.LastOfflineEmail._set {
		__values = append(__values, update.LastOfflineEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_offline_email = ?"))
	}

	if update.LastSoftwareUpdateEmail._set {
		__values = append(__values, update.LastSoftwareUpdateEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_software_update_email = ?"))
	}

	if update.NoiseProto._set {
		__values = append(__values, update.NoiseProto.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_proto = ?"))
	}

	if update.NoisePublicKey._set {
		__values = append(__values, update.NoisePublicKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_public_key = ?"))
	}

	if update.DebounceLimit._set {
		__values = append(__values, update.DebounceLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("debounce_limit = ?"))
	}

	if update.Features._set {
		__values = append(__values, update.Features.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("features = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) UpdateNoReturn_NodeApiVersion_By_Id_And_ApiVersion_Less(ctx context.Context,
	node_api_version_id NodeApiVersion_Id_Field,
	node_api_version_api_version_less NodeApiVersion_ApiVersion_Field,
	update NodeApiVersion_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE node_api_versions SET "), __sets, __sqlbundle_Literal(" WHERE node_api_versions.id = ? AND node_api_versions.api_version < ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ApiVersion._set {
		__values = append(__values, update.ApiVersion.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("api_version = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_api_version_id.value(), node_api_version_api_version_less.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) Update_Reputation_By_Id(ctx context.Context,
	reputation_id Reputation_Id_Field,
	update Reputation_Update_Fields) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE reputations SET "), __sets, __sqlbundle_Literal(" WHERE reputations.id = ? RETURNING reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.OnlineScore._set {
		__values = append(__values, update.OnlineScore.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("online_score = ?"))
	}

	if update.AuditHistory._set {
		__values = append(__values, update.AuditHistory.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_history = ?"))
	}

	if update.AuditReputationAlpha._set {
		__values = append(__values, update.AuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_alpha = ?"))
	}

	if update.AuditReputationBeta._set {
		__values = append(__values, update.AuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_beta = ?"))
	}

	if update.UnknownAuditReputationAlpha._set {
		__values = append(__values, update.UnknownAuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha = ?"))
	}

	if update.UnknownAuditReputationBeta._set {
		__values = append(__values, update.UnknownAuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, reputation_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reputation, nil
}

func (obj *pgxImpl) Update_Reputation_By_Id_And_AuditHistory(ctx context.Context,
	reputation_id Reputation_Id_Field,
	reputation_audit_history Reputation_AuditHistory_Field,
	update Reputation_Update_Fields) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE reputations SET "), __sets, __sqlbundle_Literal(" WHERE reputations.id = ? AND reputations.audit_history = ? RETURNING reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.OnlineScore._set {
		__values = append(__values, update.OnlineScore.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("online_score = ?"))
	}

	if update.AuditHistory._set {
		__values = append(__values, update.AuditHistory.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_history = ?"))
	}

	if update.AuditReputationAlpha._set {
		__values = append(__values, update.AuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_alpha = ?"))
	}

	if update.AuditReputationBeta._set {
		__values = append(__values, update.AuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_beta = ?"))
	}

	if update.UnknownAuditReputationAlpha._set {
		__values = append(__values, update.UnknownAuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha = ?"))
	}

	if update.UnknownAuditReputationBeta._set {
		__values = append(__values, update.UnknownAuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, reputation_id.value(), reputation_audit_history.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reputation, nil
}

func (obj *pgxImpl) UpdateNoReturn_Reputation_By_Id(ctx context.Context,
	reputation_id Reputation_Id_Field,
	update Reputation_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE reputations SET "), __sets, __sqlbundle_Literal(" WHERE reputations.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.OnlineScore._set {
		__values = append(__values, update.OnlineScore.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("online_score = ?"))
	}

	if update.AuditHistory._set {
		__values = append(__values, update.AuditHistory.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_history = ?"))
	}

	if update.AuditReputationAlpha._set {
		__values = append(__values, update.AuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_alpha = ?"))
	}

	if update.AuditReputationBeta._set {
		__values = append(__values, update.AuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_beta = ?"))
	}

	if update.UnknownAuditReputationAlpha._set {
		__values = append(__values, update.UnknownAuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha = ?"))
	}

	if update.UnknownAuditReputationBeta._set {
		__values = append(__values, update.UnknownAuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, reputation_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) UpdateNoReturn_OauthClient_By_Id(ctx context.Context,
	oauth_client_id OauthClient_Id_Field,
	update OauthClient_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE oauth_clients SET "), __sets, __sqlbundle_Literal(" WHERE oauth_clients.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.EncryptedSecret._set {
		__values = append(__values, update.EncryptedSecret.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("encrypted_secret = ?"))
	}

	if update.RedirectUrl._set {
		__values = append(__values, update.RedirectUrl.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("redirect_url = ?"))
	}

	if update.AppName._set {
		__values = append(__values, update.AppName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("app_name = ?"))
	}

	if update.AppLogoUrl._set {
		__values = append(__values, update.AppLogoUrl.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("app_logo_url = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, oauth_client_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) UpdateNoReturn_OauthCode_By_Code_And_ClaimedAt_Is_Null(ctx context.Context,
	oauth_code_code OauthCode_Code_Field,
	update OauthCode_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE oauth_codes SET "), __sets, __sqlbundle_Literal(" WHERE oauth_codes.code = ? AND oauth_codes.claimed_at is NULL")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ClaimedAt._set {
		__values = append(__values, update.ClaimedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("claimed_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, oauth_code_code.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) UpdateNoReturn_OauthToken_By_Token_And_Kind(ctx context.Context,
	oauth_token_token OauthToken_Token_Field,
	oauth_token_kind OauthToken_Kind_Field,
	update OauthToken_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE oauth_tokens SET "), __sets, __sqlbundle_Literal(" WHERE oauth_tokens.token = ? AND oauth_tokens.kind = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ExpiresAt._set {
		__values = append(__values, update.ExpiresAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("expires_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, oauth_token_token.value(), oauth_token_kind.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) Update_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field,
	update Project_Update_Fields) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE projects SET "), __sets, __sqlbundle_Literal(" WHERE projects.id = ? RETURNING projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Name._set {
		__values = append(__values, update.Name.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("name = ?"))
	}

	if update.Description._set {
		__values = append(__values, update.Description.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("description = ?"))
	}

	if update.UsageLimit._set {
		__values = append(__values, update.UsageLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("usage_limit = ?"))
	}

	if update.BandwidthLimit._set {
		__values = append(__values, update.BandwidthLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("bandwidth_limit = ?"))
	}

	if update.UserSpecifiedUsageLimit._set {
		__values = append(__values, update.UserSpecifiedUsageLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_specified_usage_limit = ?"))
	}

	if update.UserSpecifiedBandwidthLimit._set {
		__values = append(__values, update.UserSpecifiedBandwidthLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_specified_bandwidth_limit = ?"))
	}

	if update.SegmentLimit._set {
		__values = append(__values, update.SegmentLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("segment_limit = ?"))
	}

	if update.RateLimit._set {
		__values = append(__values, update.RateLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit = ?"))
	}

	if update.BurstLimit._set {
		__values = append(__values, update.BurstLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit = ?"))
	}

	if update.RateLimitHead._set {
		__values = append(__values, update.RateLimitHead.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_head = ?"))
	}

	if update.BurstLimitHead._set {
		__values = append(__values, update.BurstLimitHead.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_head = ?"))
	}

	if update.RateLimitGet._set {
		__values = append(__values, update.RateLimitGet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_get = ?"))
	}

	if update.BurstLimitGet._set {
		__values = append(__values, update.BurstLimitGet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_get = ?"))
	}

	if update.RateLimitPut._set {
		__values = append(__values, update.RateLimitPut.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_put = ?"))
	}

	if update.BurstLimitPut._set {
		__values = append(__values, update.BurstLimitPut.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_put = ?"))
	}

	if update.RateLimitList._set {
		__values = append(__values, update.RateLimitList.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_list = ?"))
	}

	if update.BurstLimitList._set {
		__values = append(__values, update.BurstLimitList.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_list = ?"))
	}

	if update.RateLimitDel._set {
		__values = append(__values, update.RateLimitDel.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_del = ?"))
	}

	if update.BurstLimitDel._set {
		__values = append(__values, update.BurstLimitDel.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_del = ?"))
	}

	if update.MaxBuckets._set {
		__values = append(__values, update.MaxBuckets.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("max_buckets = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if update.StatusUpdatedAt._set {
		__values = append(__values, update.StatusUpdatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status_updated_at = ?"))
	}

	if update.DefaultPlacement._set {
		__values = append(__values, update.DefaultPlacement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_placement = ?"))
	}

	if update.DefaultVersioning._set {
		__values = append(__values, update.DefaultVersioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_versioning = ?"))
	}

	if update.PromptedForVersioningBeta._set {
		__values = append(__values, update.PromptedForVersioningBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("prompted_for_versioning_beta = ?"))
	}

	if update.PassphraseEnc._set {
		__values = append(__values, update.PassphraseEnc.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("passphrase_enc = ?"))
	}

	if update.PassphraseEncKeyId._set {
		__values = append(__values, update.PassphraseEncKeyId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("passphrase_enc_key_id = ?"))
	}

	if update.PathEncryption._set {
		__values = append(__values, update.PathEncryption.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("path_encryption = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil
}

func (obj *pgxImpl) Update_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field,
	update ProjectMember_Update_Fields) (
	project_member *ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE project_members SET "), __sets, __sqlbundle_Literal(" WHERE project_members.member_id = ? AND project_members.project_id = ? RETURNING project_members.member_id, project_members.project_id, project_members.role, project_members.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Role._set {
		__values = append(__values, update.Role.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("role = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_member_member_id.value(), project_member_project_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_member = &ProjectMember{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_member, nil
}

func (obj *pgxImpl) Update_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field,
	update ProjectInvitation_Update_Fields) (
	project_invitation *ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE project_invitations SET "), __sets, __sqlbundle_Literal(" WHERE project_invitations.project_id = ? AND project_invitations.email = ? RETURNING project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.InviterId._set {
		__values = append(__values, update.InviterId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("inviter_id = ?"))
	}

	if update.CreatedAt._set {
		__values = append(__values, update.CreatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("created_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_invitation_project_id.value(), project_invitation_email.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_invitation = &ProjectInvitation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_invitation, nil
}

func (obj *pgxImpl) UpdateNoReturn_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	update ApiKey_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE api_keys SET "), __sets, __sqlbundle_Literal(" WHERE api_keys.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Name._set {
		__values = append(__values, update.Name.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("name = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, api_key_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxImpl) Update_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	update BucketMetainfo_Update_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_metainfos SET "), __sets, __sqlbundle_Literal(" WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? RETURNING bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Tags._set {
		__values = append(__values, update.Tags.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tags = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Versioning._set {
		__values = append(__values, update.Versioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("versioning = ?"))
	}

	if update.ObjectLockEnabled._set {
		__values = append(__values, update.ObjectLockEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("object_lock_enabled = ?"))
	}

	if update.DefaultRetentionMode._set {
		__values = append(__values, update.DefaultRetentionMode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_mode = ?"))
	}

	if update.DefaultRetentionDays._set {
		__values = append(__values, update.DefaultRetentionDays.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_days = ?"))
	}

	if update.DefaultRetentionYears._set {
		__values = append(__values, update.DefaultRetentionYears.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_years = ?"))
	}

	if update.DefaultSegmentSize._set {
		__values = append(__values, update.DefaultSegmentSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_segment_size = ?"))
	}

	if update.DefaultEncryptionCipherSuite._set {
		__values = append(__values, update.DefaultEncryptionCipherSuite.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_cipher_suite = ?"))
	}

	if update.DefaultEncryptionBlockSize._set {
		__values = append(__values, update.DefaultEncryptionBlockSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_block_size = ?"))
	}

	if update.DefaultRedundancyAlgorithm._set {
		__values = append(__values, update.DefaultRedundancyAlgorithm.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_algorithm = ?"))
	}

	if update.DefaultRedundancyShareSize._set {
		__values = append(__values, update.DefaultRedundancyShareSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_share_size = ?"))
	}

	if update.DefaultRedundancyRequiredShares._set {
		__values = append(__values, update.DefaultRedundancyRequiredShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_required_shares = ?"))
	}

	if update.DefaultRedundancyRepairShares._set {
		__values = append(__values, update.DefaultRedundancyRepairShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_repair_shares = ?"))
	}

	if update.DefaultRedundancyOptimalShares._set {
		__values = append(__values, update.DefaultRedundancyOptimalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_optimal_shares = ?"))
	}

	if update.DefaultRedundancyTotalShares._set {
		__values = append(__values, update.DefaultRedundancyTotalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_total_shares = ?"))
	}

	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil
}

func (obj *pgxImpl) Update_BucketMetainfo_By_ProjectId_And_Name_And_Versioning_GreaterOrEqual(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	bucket_metainfo_versioning_greater_or_equal BucketMetainfo_Versioning_Field,
	update BucketMetainfo_Update_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_metainfos SET "), __sets, __sqlbundle_Literal(" WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? AND bucket_metainfos.versioning >= ? RETURNING bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Tags._set {
		__values = append(__values, update.Tags.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tags = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Versioning._set {
		__values = append(__values, update.Versioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("versioning = ?"))
	}

	if update.ObjectLockEnabled._set {
		__values = append(__values, update.ObjectLockEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("object_lock_enabled = ?"))
	}

	if update.DefaultRetentionMode._set {
		__values = append(__values, update.DefaultRetentionMode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_mode = ?"))
	}

	if update.DefaultRetentionDays._set {
		__values = append(__values, update.DefaultRetentionDays.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_days = ?"))
	}

	if update.DefaultRetentionYears._set {
		__values = append(__values, update.DefaultRetentionYears.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_years = ?"))
	}

	if update.DefaultSegmentSize._set {
		__values = append(__values, update.DefaultSegmentSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_segment_size = ?"))
	}

	if update.DefaultEncryptionCipherSuite._set {
		__values = append(__values, update.DefaultEncryptionCipherSuite.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_cipher_suite = ?"))
	}

	if update.DefaultEncryptionBlockSize._set {
		__values = append(__values, update.DefaultEncryptionBlockSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_block_size = ?"))
	}

	if update.DefaultRedundancyAlgorithm._set {
		__values = append(__values, update.DefaultRedundancyAlgorithm.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_algorithm = ?"))
	}

	if update.DefaultRedundancyShareSize._set {
		__values = append(__values, update.DefaultRedundancyShareSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_share_size = ?"))
	}

	if update.DefaultRedundancyRequiredShares._set {
		__values = append(__values, update.DefaultRedundancyRequiredShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_required_shares = ?"))
	}

	if update.DefaultRedundancyRepairShares._set {
		__values = append(__values, update.DefaultRedundancyRepairShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_repair_shares = ?"))
	}

	if update.DefaultRedundancyOptimalShares._set {
		__values = append(__values, update.DefaultRedundancyOptimalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_optimal_shares = ?"))
	}

	if update.DefaultRedundancyTotalShares._set {
		__values = append(__values, update.DefaultRedundancyTotalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_total_shares = ?"))
	}

	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, bucket_metainfo_project_id.value(), bucket_metainfo_name.value(), bucket_metainfo_versioning_greater_or_equal.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil
}

func (obj *pgxImpl) Update_BucketMetainfo_By_ProjectId_And_Name_And_Versioning_GreaterOrEqual_And_ObjectLockEnabled_Equal_False(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	bucket_metainfo_versioning_greater_or_equal BucketMetainfo_Versioning_Field,
	update BucketMetainfo_Update_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_metainfos SET "), __sets, __sqlbundle_Literal(" WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? AND bucket_metainfos.versioning >= ? AND bucket_metainfos.object_lock_enabled = false RETURNING bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Tags._set {
		__values = append(__values, update.Tags.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tags = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Versioning._set {
		__values = append(__values, update.Versioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("versioning = ?"))
	}

	if update.ObjectLockEnabled._set {
		__values = append(__values, update.ObjectLockEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("object_lock_enabled = ?"))
	}

	if update.DefaultRetentionMode._set {
		__values = append(__values, update.DefaultRetentionMode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_mode = ?"))
	}

	if update.DefaultRetentionDays._set {
		__values = append(__values, update.DefaultRetentionDays.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_days = ?"))
	}

	if update.DefaultRetentionYears._set {
		__values = append(__values, update.DefaultRetentionYears.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_years = ?"))
	}

	if update.DefaultSegmentSize._set {
		__values = append(__values, update.DefaultSegmentSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_segment_size = ?"))
	}

	if update.DefaultEncryptionCipherSuite._set {
		__values = append(__values, update.DefaultEncryptionCipherSuite.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_cipher_suite = ?"))
	}

	if update.DefaultEncryptionBlockSize._set {
		__values = append(__values, update.DefaultEncryptionBlockSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_block_size = ?"))
	}

	if update.DefaultRedundancyAlgorithm._set {
		__values = append(__values, update.DefaultRedundancyAlgorithm.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_algorithm = ?"))
	}

	if update.DefaultRedundancyShareSize._set {
		__values = append(__values, update.DefaultRedundancyShareSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_share_size = ?"))
	}

	if update.DefaultRedundancyRequiredShares._set {
		__values = append(__values, update.DefaultRedundancyRequiredShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_required_shares = ?"))
	}

	if update.DefaultRedundancyRepairShares._set {
		__values = append(__values, update.DefaultRedundancyRepairShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_repair_shares = ?"))
	}

	if update.DefaultRedundancyOptimalShares._set {
		__values = append(__values, update.DefaultRedundancyOptimalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_optimal_shares = ?"))
	}

	if update.DefaultRedundancyTotalShares._set {
		__values = append(__values, update.DefaultRedundancyTotalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_total_shares = ?"))
	}

	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, bucket_metainfo_project_id.value(), bucket_metainfo_name.value(), bucket_metainfo_versioning_greater_or_equal.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil
}

func (obj *pgxImpl) Update_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field,
	update ValueAttribution_Update_Fields) (
	value_attribution *ValueAttribution, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE value_attributions SET "), __sets, __sqlbundle_Literal(" WHERE value_attributions.project_id = ? AND value_attributions.bucket_name = ? RETURNING value_attributions.project_id, value_attributions.bucket_name, value_attributions.user_agent, value_attributions.placement, value_attributions.last_updated")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_updated = ?"))

	__args = append(__args, value_attribution_project_id.value(), value_attribution_bucket_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	value_attribution = &ValueAttribution{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return value_attribution, nil
}

func (obj *pgxImpl) Update_BucketMigration_By_Id(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field,
	update BucketMigration_Update_Fields) (
	bucket_migration *BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_migrations SET "), __sets, __sqlbundle_Literal(" WHERE bucket_migrations.id = ? RETURNING bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.State._set {
		__values = append(__values, update.State.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("state = ?"))
	}

	if update.BytesProcessed._set {
		__values = append(__values, update.BytesProcessed.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("bytes_processed = ?"))
	}

	if update.ErrorMessage._set {
		__values = append(__values, update.ErrorMessage.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("error_message = ?"))
	}

	if update.CompletedAt._set {
		__values = append(__values, update.CompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("completed_at = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, bucket_migration_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_migration = &BucketMigration{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_migration, nil
}

func (obj *pgxImpl) Update_User_By_Id(ctx context.Context,
	user_id User_Id_Field,
	update User_Update_Fields) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE users SET "), __sets, __sqlbundle_Literal(" WHERE users.id = ? RETURNING users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ExternalId._set {
		__values = append(__values, update.ExternalId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("external_id = ?"))
	}

	if update.TenantId._set {
		__values = append(__values, update.TenantId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tenant_id = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.NormalizedEmail._set {
		__values = append(__values, update.NormalizedEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("normalized_email = ?"))
	}

	if update.FullName._set {
		__values = append(__values, update.FullName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("full_name = ?"))
	}

	if update.ShortName._set {
		__values = append(__values, update.ShortName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("short_name = ?"))
	}

	if update.PasswordHash._set {
		__values = append(__values, update.PasswordHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("password_hash = ?"))
	}

	if update.NewUnverifiedEmail._set {
		__values = append(__values, update.NewUnverifiedEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("new_unverified_email = ?"))
	}

	if update.EmailChangeVerificationStep._set {
		__values = append(__values, update.EmailChangeVerificationStep.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email_change_verification_step = ?"))
	}

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if update.StatusUpdatedAt._set {
		__values = append(__values, update.StatusUpdatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status_updated_at = ?"))
	}

	if update.FinalInvoiceGenerated._set {
		__values = append(__values, update.FinalInvoiceGenerated.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("final_invoice_generated = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.ProjectLimit._set {
		__values = append(__values, update.ProjectLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_limit = ?"))
	}

	if update.ProjectBandwidthLimit._set {
		__values = append(__values, update.ProjectBandwidthLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_bandwidth_limit = ?"))
	}

	if update.ProjectStorageLimit._set {
		__values = append(__values, update.ProjectStorageLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_storage_limit = ?"))
	}

	if update.ProjectSegmentLimit._set {
		__values = append(__values, update.ProjectSegmentLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_segment_limit = ?"))
	}

	if update.Kind._set {
		__values = append(__values, update.Kind.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("kind = ?"))
	}

	if update.Position._set {
		__values = append(__values, update.Position.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("position = ?"))
	}

	if update.CompanyName._set {
		__values = append(__values, update.CompanyName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("company_name = ?"))
	}

	if update.CompanySize._set {
		__values = append(__values, update.CompanySize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("company_size = ?"))
	}

	if update.WorkingOn._set {
		__values = append(__values, update.WorkingOn.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("working_on = ?"))
	}

	if update.IsProfessional._set {
		__values = append(__values, update.IsProfessional.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("is_professional = ?"))
	}

	if update.EmployeeCount._set {
		__values = append(__values, update.EmployeeCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("employee_count = ?"))
	}

	if update.HaveSalesContact._set {
		__values = append(__values, update.HaveSalesContact.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("have_sales_contact = ?"))
	}

	if update.MfaEnabled._set {
		__values = append(__values, update.MfaEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("mfa_enabled = ?"))
	}

	if update.MfaSecretKey._set {
		__values = append(__values, update.MfaSecretKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("mfa_secret_key = ?"))
	}

	if update.MfaRecoveryCodes._set {
		__values = append(__values, update.MfaRecoveryCodes.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("mfa_recovery_codes = ?"))
	}

	if update.SignupPromoCode._set {
		__values = append(__values, update.SignupPromoCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("signup_promo_code = ?"))
	}

	if update.VerificationReminders._set {
		__values = append(__values, update.VerificationReminders.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("verification_reminders = ?"))
	}

	if update.TrialNotifications._set {
		__values = append(__values, update.TrialNotifications.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("trial_notifications = ?"))
	}

	if update.FailedLoginCount._set {
		__values = append(__values, update.FailedLoginCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("failed_login_count = ?"))
	}

	if update.LoginLockoutExpiration._set {
		__values = append(__values, update.LoginLockoutExpiration.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("login_lockout_expiration = ?"))
	}

	if update.DefaultPlacement._set {
		__values = append(__values, update.DefaultPlacement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_placement = ?"))
	}

	if update.ActivationCode._set {
		__values = append(__values, update.ActivationCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("activation_code = ?"))
	}

	if update.SignupId._set {
		__values = append(__values, update.SignupId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("signup_id = ?"))
	}

	if update.TrialExpiration._set {
		__values = append(__values, update.TrialExpiration.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("trial_expiration = ?"))
	}

	if update.UpgradeTime._set {
		__values = append(__values, update.UpgradeTime.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("upgrade_time = ?"))
	}

	if update.HubspotObjectId._set {
		__values = append(__values, update.HubspotObjectId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("hubspot_object_id = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil
}

func (obj *pgxImpl) Update_WebappSession_By_Id(ctx context.Context,
	webapp_session_id WebappSession_Id_Field,
	update WebappSession_Update_Fields) (
	webapp_session *WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE webapp_sessions SET "), __sets, __sqlbundle_Literal(" WHERE webapp_sessions.id = ? RETURNING webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if update.ExpiresAt._set {
		__values = append(__values, update.ExpiresAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("expires_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, webapp_session_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	webapp_session = &WebappSession{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return webapp_session, nil
}

func (obj *pgxImpl) Update_RegistrationToken_By_Secret(ctx context.Context,
	registration_token_secret RegistrationToken_Secret_Field,
	update RegistrationToken_Update_Fields) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE registration_tokens SET "), __sets, __sqlbundle_Literal(" WHERE registration_tokens.secret = ? RETURNING registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.OwnerId._set {
		__values = append(__values, update.OwnerId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("owner_id = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, registration_token_secret.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return registration_token, nil
}

func (obj *pgxImpl) Update_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field,
	update AccountFreezeEvent_Update_Fields) (
	account_freeze_event *AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE account_freeze_events SET "), __sets, __sqlbundle_Literal(" WHERE account_freeze_events.user_id = ? AND account_freeze_events.event = ? RETURNING account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Limits._set {
		__values = append(__values, update.Limits.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("limits = ?"))
	}

	if update.DaysTillEscalation._set {
		__values = append(__values, update.DaysTillEscalation.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("days_till_escalation = ?"))
	}

	if update.NotificationsCount._set {
		__values = append(__values, update.NotificationsCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("notifications_count = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, account_freeze_event_user_id.value(), account_freeze_event_event.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	account_freeze_event = &AccountFreezeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return account_freeze_event, nil
}

func (obj *pgxImpl) Update_UserSettings_By_UserId(ctx context.Context,
	user_settings_user_id UserSettings_UserId_Field,
	update UserSettings_Update_Fields) (
	user_settings *UserSettings, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE user_settings SET "), __sets, __sqlbundle_Literal(" WHERE user_settings.user_id = ? RETURNING user_settings.user_id, user_settings.session_minutes, user_settings.passphrase_prompt, user_settings.onboarding_start, user_settings.onboarding_end, user_settings.onboarding_step, user_settings.notice_dismissal")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.SessionMinutes._set {
		__values = append(__values, update.SessionMinutes.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("session_minutes = ?"))
	}

	if update.PassphrasePrompt._set {
		__values = append(__values, update.PassphrasePrompt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("passphrase_prompt = ?"))
	}

	if update.OnboardingStart._set {
		__values = append(__values, update.OnboardingStart.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("onboarding_start = ?"))
	}

	if update.OnboardingEnd._set {
		__values = append(__values, update.OnboardingEnd.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("onboarding_end = ?"))
	}

	if update.OnboardingStep._set {
		__values = append(__values, update.OnboardingStep.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("onboarding_step = ?"))
	}

	if update.NoticeDismissal._set {
		__values = append(__values, update.NoticeDismissal.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("notice_dismissal = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, user_settings_user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user_settings = &UserSettings{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user_settings.UserId, &user_settings.SessionMinutes, &user_settings.PassphrasePrompt, &user_settings.OnboardingStart, &user_settings.OnboardingEnd, &user_settings.OnboardingStep, &user_settings.NoticeDismissal)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user_settings, nil
}

func (obj *pgxImpl) Delete_StoragenodeStorageTally_By_IntervalEndTime_Less(ctx context.Context,
	storagenode_storage_tally_interval_end_time_less StoragenodeStorageTally_IntervalEndTime_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM storagenode_storage_tallies WHERE storagenode_storage_tallies.interval_end_time < ?")

	var __values []any
	__values = append(__values, storagenode_storage_tally_interval_end_time_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_BucketStorageTally_By_IntervalStart_Less(ctx context.Context,
	bucket_storage_tally_interval_start_less BucketStorageTally_IntervalStart_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM bucket_storage_tallies WHERE bucket_storage_tallies.interval_start < ?")

	var __values []any
	__values = append(__values, bucket_storage_tally_interval_start_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_ReverificationAudits_By_NodeId_And_StreamId_And_Position(ctx context.Context,
	reverification_audits_node_id ReverificationAudits_NodeId_Field,
	reverification_audits_stream_id ReverificationAudits_StreamId_Field,
	reverification_audits_position ReverificationAudits_Position_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM reverification_audits WHERE reverification_audits.node_id = ? AND reverification_audits.stream_id = ? AND reverification_audits.position = ?")

	var __values []any
	__values = append(__values, reverification_audits_node_id.value(), reverification_audits_stream_id.value(), reverification_audits_position.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_StorjscanPayment_By_Status(ctx context.Context,
	storjscan_payment_status StorjscanPayment_Status_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM storjscan_payments WHERE storjscan_payments.status = ?")

	var __values []any
	__values = append(__values, storjscan_payment_status.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_Domain_By_ProjectId_And_Subdomain(ctx context.Context,
	domain_project_id Domain_ProjectId_Field,
	domain_subdomain Domain_Subdomain_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM domains WHERE domains.project_id = ? AND domains.subdomain = ?")

	var __values []any
	__values = append(__values, domain_project_id.value(), domain_subdomain.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_Domain_By_ProjectId(ctx context.Context,
	domain_project_id Domain_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM domains WHERE domains.project_id = ?")

	var __values []any
	__values = append(__values, domain_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_Entitlement_By_Scope(ctx context.Context,
	entitlement_scope Entitlement_Scope_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM entitlements WHERE entitlements.scope = ?")

	var __values []any
	__values = append(__values, entitlement_scope.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_NodeEvent_By_CreatedAt_Less(ctx context.Context,
	node_event_created_at_less NodeEvent_CreatedAt_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM node_events WHERE node_events.created_at < ?")

	var __values []any
	__values = append(__values, node_event_created_at_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_OauthClient_By_Id(ctx context.Context,
	oauth_client_id OauthClient_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM oauth_clients WHERE oauth_clients.id = ?")

	var __values []any
	__values = append(__values, oauth_client_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM project_members WHERE project_members.member_id = ? AND project_members.project_id = ?")

	var __values []any
	__values = append(__values, project_member_member_id.value(), project_member_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM project_invitations WHERE project_invitations.project_id = ? AND project_invitations.email = ?")

	var __values []any
	__values = append(__values, project_invitation_project_id.value(), project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM api_keys WHERE api_keys.id = ?")

	var __values []any
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_ApiKey_By_ProjectId(ctx context.Context,
	api_key_project_id ApiKey_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM api_keys WHERE api_keys.project_id = ?")

	var __values []any
	__values = append(__values, api_key_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM value_attributions WHERE value_attributions.project_id = ? AND value_attributions.bucket_name = ?")

	var __values []any
	__values = append(__values, value_attribution_project_id.value(), value_attribution_bucket_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_BucketMigration_By_Id(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM bucket_migrations WHERE bucket_migrations.id = ?")

	var __values []any
	__values = append(__values, bucket_migration_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_RepairQueue_By_UpdatedAt_Less(ctx context.Context,
	repair_queue_updated_at_less RepairQueue_UpdatedAt_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM repair_queue WHERE repair_queue.updated_at < ?")

	var __values []any
	__values = append(__values, repair_queue_updated_at_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_RestApiKey_By_Id(ctx context.Context,
	rest_api_key_id RestApiKey_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM rest_api_keys WHERE rest_api_keys.id = ?")

	var __values []any
	__values = append(__values, rest_api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_WebappSession_By_Id(ctx context.Context,
	webapp_session_id WebappSession_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM webapp_sessions WHERE webapp_sessions.id = ?")

	var __values []any
	__values = append(__values, webapp_session_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_WebappSession_By_UserId_And_Id_Not(ctx context.Context,
	webapp_session_user_id WebappSession_UserId_Field,
	webapp_session_id_not WebappSession_Id_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM webapp_sessions WHERE webapp_sessions.user_id = ? AND webapp_sessions.id != ?")

	var __values []any
	__values = append(__values, webapp_session_user_id.value(), webapp_session_id_not.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_WebappSession_By_UserId(ctx context.Context,
	webapp_session_user_id WebappSession_UserId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM webapp_sessions WHERE webapp_sessions.user_id = ?")

	var __values []any
	__values = append(__values, webapp_session_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_ResetPasswordToken_By_Secret(ctx context.Context,
	reset_password_token_secret ResetPasswordToken_Secret_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM reset_password_tokens WHERE reset_password_tokens.secret = ?")

	var __values []any
	__values = append(__values, reset_password_token_secret.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxImpl) Delete_AccountFreezeEvent_By_UserId(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM account_freeze_events WHERE account_freeze_events.user_id = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxImpl) Delete_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM account_freeze_events WHERE account_freeze_events.user_id = ? AND account_freeze_events.event = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value(), account_freeze_event_event.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (impl pgxImpl) isConstraintError(err error) (constraint string, ok bool) {
	if e, ok := err.(*pgconn.PgError); ok {
		if e.Code[:2] == "23" {
			return e.ConstraintName, true
		}
	}
	return "", false
}

func (obj *pgxImpl) deleteAll(ctx context.Context) (count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	var __res sql.Result
	var __count int64
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM api_key_tails;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripecoinpayments_apply_balance_intents;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM rest_api_keys;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM project_members;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM project_invitations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM domains;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_migrations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_metainfos;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM api_keys;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM webapp_sessions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM verification_audits;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM value_attributions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM user_settings;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM users;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripecoinpayments_tx_conversion_rates;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripecoinpayments_invoice_project_records;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripe_customers;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storjscan_wallets;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storjscan_payments;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_storage_tallies;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_paystubs;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_payments;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_bandwidth_rollup_archives;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_bandwidth_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM segment_pending_audits;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM revocations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM reverification_audits;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM reset_password_tokens;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM reputations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM repair_queue;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM registration_tokens;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM project_bandwidth_daily_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM projects;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM peer_identities;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM oauth_tokens;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM oauth_codes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM oauth_clients;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM node_tags;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM node_events;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM node_api_versions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM nodes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM entitlements;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM coinpayments_transactions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM change_histories;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_storage_tallies;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_bandwidth_rollup_archives;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_bandwidth_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM billing_transactions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM billing_balances;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM accounting_timestamps;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM accounting_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM account_freeze_events;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count

	return count, nil

}

func (obj *pgxcockroachImpl) ReplaceNoReturn_AccountingTimestamps(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	accounting_timestamps_value AccountingTimestamps_Value_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__name_val := accounting_timestamps_name.value()
	__value_val := accounting_timestamps_value.value()

	var __embed_stmt = __sqlbundle_Literal("UPSERT INTO accounting_timestamps ( name, value ) VALUES ( ?, ? )")

	var __values []any
	__values = append(__values, __name_val, __value_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Create_StoragenodeBandwidthRollup(ctx context.Context,
	storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
	storagenode_bandwidth_rollup_interval_start StoragenodeBandwidthRollup_IntervalStart_Field,
	storagenode_bandwidth_rollup_interval_seconds StoragenodeBandwidthRollup_IntervalSeconds_Field,
	storagenode_bandwidth_rollup_action StoragenodeBandwidthRollup_Action_Field,
	storagenode_bandwidth_rollup_settled StoragenodeBandwidthRollup_Settled_Field,
	optional StoragenodeBandwidthRollup_Create_Fields) (
	storagenode_bandwidth_rollup *StoragenodeBandwidthRollup, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__storagenode_id_val := storagenode_bandwidth_rollup_storagenode_id.value()
	__interval_start_val := storagenode_bandwidth_rollup_interval_start.value()
	__interval_seconds_val := storagenode_bandwidth_rollup_interval_seconds.value()
	__action_val := storagenode_bandwidth_rollup_action.value()
	__settled_val := storagenode_bandwidth_rollup_settled.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("storagenode_id, interval_start, interval_seconds, action, settled")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO storagenode_bandwidth_rollups "), __clause, __sqlbundle_Literal(" RETURNING storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled")}}

	var __values []any
	__values = append(__values, __storagenode_id_val, __interval_start_val, __interval_seconds_val, __action_val, __settled_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Allocated._set {
		__values = append(__values, optional.Allocated.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("allocated"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	storagenode_bandwidth_rollup = &StoragenodeBandwidthRollup{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return storagenode_bandwidth_rollup, nil

}

func (obj *pgxcockroachImpl) Create_ReverificationAudits(ctx context.Context,
	reverification_audits_node_id ReverificationAudits_NodeId_Field,
	reverification_audits_stream_id ReverificationAudits_StreamId_Field,
	reverification_audits_position ReverificationAudits_Position_Field,
	reverification_audits_piece_num ReverificationAudits_PieceNum_Field,
	optional ReverificationAudits_Create_Fields) (
	reverification_audits *ReverificationAudits, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__node_id_val := reverification_audits_node_id.value()
	__stream_id_val := reverification_audits_stream_id.value()
	__position_val := reverification_audits_position.value()
	__piece_num_val := reverification_audits_piece_num.value()
	__last_attempt_val := optional.LastAttempt.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("node_id, stream_id, position, piece_num, last_attempt")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO reverification_audits "), __clause, __sqlbundle_Literal(" RETURNING reverification_audits.node_id, reverification_audits.stream_id, reverification_audits.position, reverification_audits.piece_num, reverification_audits.inserted_at, reverification_audits.last_attempt, reverification_audits.reverify_count")}}

	var __values []any
	__values = append(__values, __node_id_val, __stream_id_val, __position_val, __piece_num_val, __last_attempt_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.InsertedAt._set {
		__values = append(__values, optional.InsertedAt.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("inserted_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ReverifyCount._set {
		__values = append(__values, optional.ReverifyCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("reverify_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reverification_audits = &ReverificationAudits{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reverification_audits.NodeId, &reverification_audits.StreamId, &reverification_audits.Position, &reverification_audits.PieceNum, &reverification_audits.InsertedAt, &reverification_audits.LastAttempt, &reverification_audits.ReverifyCount)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reverification_audits, nil

}

func (obj *pgxcockroachImpl) Create_StripeCustomer(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field,
	stripe_customer_customer_id StripeCustomer_CustomerId_Field,
	optional StripeCustomer_Create_Fields) (
	stripe_customer *StripeCustomer, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := stripe_customer_user_id.value()
	__customer_id_val := stripe_customer_customer_id.value()
	__billing_customer_id_val := optional.BillingCustomerId.value()
	__package_plan_val := optional.PackagePlan.value()
	__purchased_package_at_val := optional.PurchasedPackageAt.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO stripe_customers ( user_id, customer_id, billing_customer_id, package_plan, purchased_package_at, created_at ) VALUES ( ?, ?, ?, ?, ?, ? ) RETURNING stripe_customers.user_id, stripe_customers.customer_id, stripe_customers.billing_customer_id, stripe_customers.package_plan, stripe_customers.purchased_package_at, stripe_customers.created_at")

	var __values []any
	__values = append(__values, __user_id_val, __customer_id_val, __billing_customer_id_val, __package_plan_val, __purchased_package_at_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripe_customer = &StripeCustomer{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripe_customer.UserId, &stripe_customer.CustomerId, &stripe_customer.BillingCustomerId, &stripe_customer.PackagePlan, &stripe_customer.PurchasedPackageAt, &stripe_customer.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripe_customer, nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_BillingBalance(ctx context.Context,
	billing_balance_user_id BillingBalance_UserId_Field,
	billing_balance_balance BillingBalance_Balance_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := billing_balance_user_id.value()
	__balance_val := billing_balance_balance.value()
	__last_updated_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO billing_balances ( user_id, balance, last_updated ) VALUES ( ?, ?, ? )")

	var __values []any
	__values = append(__values, __user_id_val, __balance_val, __last_updated_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Create_BillingTransaction(ctx context.Context,
	billing_transaction_user_id BillingTransaction_UserId_Field,
	billing_transaction_amount BillingTransaction_Amount_Field,
	billing_transaction_currency BillingTransaction_Currency_Field,
	billing_transaction_description BillingTransaction_Description_Field,
	billing_transaction_source BillingTransaction_Source_Field,
	billing_transaction_status BillingTransaction_Status_Field,
	billing_transaction_type BillingTransaction_Type_Field,
	billing_transaction_metadata BillingTransaction_Metadata_Field,
	billing_transaction_tx_timestamp BillingTransaction_TxTimestamp_Field) (
	billing_transaction *BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := billing_transaction_user_id.value()
	__amount_val := billing_transaction_amount.value()
	__currency_val := billing_transaction_currency.value()
	__description_val := billing_transaction_description.value()
	__source_val := billing_transaction_source.value()
	__status_val := billing_transaction_status.value()
	__type_val := billing_transaction_type.value()
	__metadata_val := billing_transaction_metadata.value()
	__tx_timestamp_val := billing_transaction_tx_timestamp.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO billing_transactions ( user_id, amount, currency, description, source, status, type, metadata, tx_timestamp, created_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) RETURNING billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at")

	var __values []any
	__values = append(__values, __user_id_val, __amount_val, __currency_val, __description_val, __source_val, __status_val, __type_val, __metadata_val, __tx_timestamp_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	billing_transaction = &BillingTransaction{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return billing_transaction, nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_StorjscanWallet(ctx context.Context,
	storjscan_wallet_user_id StorjscanWallet_UserId_Field,
	storjscan_wallet_wallet_address StorjscanWallet_WalletAddress_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := storjscan_wallet_user_id.value()
	__wallet_address_val := storjscan_wallet_wallet_address.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO storjscan_wallets ( user_id, wallet_address, created_at ) VALUES ( ?, ?, ? )")

	var __values []any
	__values = append(__values, __user_id_val, __wallet_address_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Create_CoinpaymentsTransaction(ctx context.Context,
	coinpayments_transaction_id CoinpaymentsTransaction_Id_Field,
	coinpayments_transaction_user_id CoinpaymentsTransaction_UserId_Field,
	coinpayments_transaction_address CoinpaymentsTransaction_Address_Field,
	coinpayments_transaction_amount_numeric CoinpaymentsTransaction_AmountNumeric_Field,
	coinpayments_transaction_received_numeric CoinpaymentsTransaction_ReceivedNumeric_Field,
	coinpayments_transaction_status CoinpaymentsTransaction_Status_Field,
	coinpayments_transaction_key CoinpaymentsTransaction_Key_Field,
	coinpayments_transaction_timeout CoinpaymentsTransaction_Timeout_Field) (
	coinpayments_transaction *CoinpaymentsTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := coinpayments_transaction_id.value()
	__user_id_val := coinpayments_transaction_user_id.value()
	__address_val := coinpayments_transaction_address.value()
	__amount_numeric_val := coinpayments_transaction_amount_numeric.value()
	__received_numeric_val := coinpayments_transaction_received_numeric.value()
	__status_val := coinpayments_transaction_status.value()
	__key_val := coinpayments_transaction_key.value()
	__timeout_val := coinpayments_transaction_timeout.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO coinpayments_transactions ( id, user_id, address, amount_numeric, received_numeric, status, key, timeout, created_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ? ) RETURNING coinpayments_transactions.id, coinpayments_transactions.user_id, coinpayments_transactions.address, coinpayments_transactions.amount_numeric, coinpayments_transactions.received_numeric, coinpayments_transactions.status, coinpayments_transactions.key, coinpayments_transactions.timeout, coinpayments_transactions.created_at")

	var __values []any
	__values = append(__values, __id_val, __user_id_val, __address_val, __amount_numeric_val, __received_numeric_val, __status_val, __key_val, __timeout_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	coinpayments_transaction = &CoinpaymentsTransaction{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return coinpayments_transaction, nil

}

func (obj *pgxcockroachImpl) Create_StripecoinpaymentsInvoiceProjectRecord(ctx context.Context,
	stripecoinpayments_invoice_project_record_id StripecoinpaymentsInvoiceProjectRecord_Id_Field,
	stripecoinpayments_invoice_project_record_project_id StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field,
	stripecoinpayments_invoice_project_record_storage StripecoinpaymentsInvoiceProjectRecord_Storage_Field,
	stripecoinpayments_invoice_project_record_egress StripecoinpaymentsInvoiceProjectRecord_Egress_Field,
	stripecoinpayments_invoice_project_record_period_start StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field,
	stripecoinpayments_invoice_project_record_period_end StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field,
	stripecoinpayments_invoice_project_record_state StripecoinpaymentsInvoiceProjectRecord_State_Field,
	optional StripecoinpaymentsInvoiceProjectRecord_Create_Fields) (
	stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := stripecoinpayments_invoice_project_record_id.value()
	__project_id_val := stripecoinpayments_invoice_project_record_project_id.value()
	__storage_val := stripecoinpayments_invoice_project_record_storage.value()
	__egress_val := stripecoinpayments_invoice_project_record_egress.value()
	__objects_val := optional.Objects.value()
	__segments_val := optional.Segments.value()
	__period_start_val := stripecoinpayments_invoice_project_record_period_start.value()
	__period_end_val := stripecoinpayments_invoice_project_record_period_end.value()
	__state_val := stripecoinpayments_invoice_project_record_state.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO stripecoinpayments_invoice_project_records ( id, project_id, storage, egress, objects, segments, period_start, period_end, state, created_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) RETURNING stripecoinpayments_invoice_project_records.id, stripecoinpayments_invoice_project_records.project_id, stripecoinpayments_invoice_project_records.storage, stripecoinpayments_invoice_project_records.egress, stripecoinpayments_invoice_project_records.objects, stripecoinpayments_invoice_project_records.segments, stripecoinpayments_invoice_project_records.period_start, stripecoinpayments_invoice_project_records.period_end, stripecoinpayments_invoice_project_records.state, stripecoinpayments_invoice_project_records.created_at")

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __storage_val, __egress_val, __objects_val, __segments_val, __period_start_val, __period_end_val, __state_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_invoice_project_record = &StripecoinpaymentsInvoiceProjectRecord{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripecoinpayments_invoice_project_record, nil

}

func (obj *pgxcockroachImpl) Create_StripecoinpaymentsTxConversionRate(ctx context.Context,
	stripecoinpayments_tx_conversion_rate_tx_id StripecoinpaymentsTxConversionRate_TxId_Field,
	stripecoinpayments_tx_conversion_rate_rate_numeric StripecoinpaymentsTxConversionRate_RateNumeric_Field) (
	stripecoinpayments_tx_conversion_rate *StripecoinpaymentsTxConversionRate, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__tx_id_val := stripecoinpayments_tx_conversion_rate_tx_id.value()
	__rate_numeric_val := stripecoinpayments_tx_conversion_rate_rate_numeric.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO stripecoinpayments_tx_conversion_rates ( tx_id, rate_numeric, created_at ) VALUES ( ?, ?, ? ) RETURNING stripecoinpayments_tx_conversion_rates.tx_id, stripecoinpayments_tx_conversion_rates.rate_numeric, stripecoinpayments_tx_conversion_rates.created_at")

	var __values []any
	__values = append(__values, __tx_id_val, __rate_numeric_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_tx_conversion_rate = &StripecoinpaymentsTxConversionRate{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_tx_conversion_rate.TxId, &stripecoinpayments_tx_conversion_rate.RateNumeric, &stripecoinpayments_tx_conversion_rate.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripecoinpayments_tx_conversion_rate, nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_StorjscanPayment(ctx context.Context,
	storjscan_payment_block_hash StorjscanPayment_BlockHash_Field,
	storjscan_payment_block_number StorjscanPayment_BlockNumber_Field,
	storjscan_payment_transaction StorjscanPayment_Transaction_Field,
	storjscan_payment_log_index StorjscanPayment_LogIndex_Field,
	storjscan_payment_from_address StorjscanPayment_FromAddress_Field,
	storjscan_payment_to_address StorjscanPayment_ToAddress_Field,
	storjscan_payment_token_value StorjscanPayment_TokenValue_Field,
	storjscan_payment_usd_value StorjscanPayment_UsdValue_Field,
	storjscan_payment_status StorjscanPayment_Status_Field,
	storjscan_payment_block_timestamp StorjscanPayment_BlockTimestamp_Field,
	optional StorjscanPayment_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__block_hash_val := storjscan_payment_block_hash.value()
	__block_number_val := storjscan_payment_block_number.value()
	__transaction_val := storjscan_payment_transaction.value()
	__log_index_val := storjscan_payment_log_index.value()
	__from_address_val := storjscan_payment_from_address.value()
	__to_address_val := storjscan_payment_to_address.value()
	__token_value_val := storjscan_payment_token_value.value()
	__usd_value_val := storjscan_payment_usd_value.value()
	__status_val := storjscan_payment_status.value()
	__block_timestamp_val := storjscan_payment_block_timestamp.value()
	__created_at_val := __now

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("block_hash, block_number, transaction, log_index, from_address, to_address, token_value, usd_value, status, block_timestamp, created_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO storjscan_payments "), __clause}}

	var __values []any
	__values = append(__values, __block_hash_val, __block_number_val, __transaction_val, __log_index_val, __from_address_val, __to_address_val, __token_value_val, __usd_value_val, __status_val, __block_timestamp_val, __created_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.ChainId._set {
		__values = append(__values, optional.ChainId.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("chain_id"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Create_ChangeHistory(ctx context.Context,
	change_history_id ChangeHistory_Id_Field,
	change_history_admin_email ChangeHistory_AdminEmail_Field,
	change_history_user_id ChangeHistory_UserId_Field,
	change_history_item_type ChangeHistory_ItemType_Field,
	change_history_operation ChangeHistory_Operation_Field,
	change_history_reason ChangeHistory_Reason_Field,
	change_history_changes ChangeHistory_Changes_Field,
	optional ChangeHistory_Create_Fields) (
	change_history *ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := change_history_id.value()
	__admin_email_val := change_history_admin_email.value()
	__user_id_val := change_history_user_id.value()
	__project_id_val := optional.ProjectId.value()
	__bucket_name_val := optional.BucketName.value()
	__item_type_val := change_history_item_type.value()
	__operation_val := change_history_operation.value()
	__reason_val := change_history_reason.value()
	__changes_val := change_history_changes.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, admin_email, user_id, project_id, bucket_name, item_type, operation, reason, changes")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO change_histories "), __clause, __sqlbundle_Literal(" RETURNING change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp")}}

	var __values []any
	__values = append(__values, __id_val, __admin_email_val, __user_id_val, __project_id_val, __bucket_name_val, __item_type_val, __operation_val, __reason_val, __changes_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Timestamp._set {
		__values = append(__values, optional.Timestamp.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("timestamp"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	change_history = &ChangeHistory{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return change_history, nil

}

func (obj *pgxcockroachImpl) Create_Domain(ctx context.Context,
	domain_subdomain Domain_Subdomain_Field,
	domain_project_id Domain_ProjectId_Field,
	domain_prefix Domain_Prefix_Field,
	domain_access_id Domain_AccessId_Field,
	domain_created_by Domain_CreatedBy_Field) (
	domain *Domain, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__subdomain_val := domain_subdomain.value()
	__project_id_val := domain_project_id.value()
	__prefix_val := domain_prefix.value()
	__access_id_val := domain_access_id.value()
	__created_by_val := domain_created_by.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO domains ( subdomain, project_id, prefix, access_id, created_by, created_at ) VALUES ( ?, ?, ?, ?, ?, ? ) RETURNING domains.subdomain, domains.project_id, domains.prefix, domains.access_id, domains.created_by, domains.created_at")

	var __values []any
	__values = append(__values, __subdomain_val, __project_id_val, __prefix_val, __access_id_val, __created_by_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	domain = &Domain{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&domain.Subdomain, &domain.ProjectId, &domain.Prefix, &domain.AccessId, &domain.CreatedBy, &domain.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return domain, nil

}

func (obj *pgxcockroachImpl) Replace_Entitlement(ctx context.Context,
	entitlement_scope Entitlement_Scope_Field,
	entitlement_updated_at Entitlement_UpdatedAt_Field,
	optional Entitlement_Create_Fields) (
	entitlement *Entitlement, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__scope_val := entitlement_scope.value()
	__updated_at_val := entitlement_updated_at.value()
	__created_at_val := __now

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("scope, updated_at, created_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPSERT INTO entitlements "), __clause, __sqlbundle_Literal(" RETURNING entitlements.scope, entitlements.features, entitlements.updated_at, entitlements.created_at")}}

	var __values []any
	__values = append(__values, __scope_val, __updated_at_val, __created_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Features._set {
		__values = append(__values, optional.Features.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("features"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	entitlement = &Entitlement{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&entitlement.Scope, &entitlement.Features, &entitlement.UpdatedAt, &entitlement.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return entitlement, nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_PeerIdentity(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field,
	peer_identity_leaf_serial_number PeerIdentity_LeafSerialNumber_Field,
	peer_identity_chain PeerIdentity_Chain_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__node_id_val := peer_identity_node_id.value()
	__leaf_serial_number_val := peer_identity_leaf_serial_number.value()
	__chain_val := peer_identity_chain.value()
	__updated_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO peer_identities ( node_id, leaf_serial_number, chain, updated_at ) VALUES ( ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __node_id_val, __leaf_serial_number_val, __chain_val, __updated_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_Revocation(ctx context.Context,
	revocation_revoked Revocation_Revoked_Field,
	revocation_api_key_id Revocation_ApiKeyId_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__revoked_val := revocation_revoked.value()
	__api_key_id_val := revocation_api_key_id.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO revocations ( revoked, api_key_id ) VALUES ( ?, ? )")

	var __values []any
	__values = append(__values, __revoked_val, __api_key_id_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) ReplaceNoReturn_NodeApiVersion(ctx context.Context,
	node_api_version_id NodeApiVersion_Id_Field,
	node_api_version_api_version NodeApiVersion_ApiVersion_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := node_api_version_id.value()
	__api_version_val := node_api_version_api_version.value()
	__created_at_val := __now
	__updated_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("UPSERT INTO node_api_versions ( id, api_version, created_at, updated_at ) VALUES ( ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __id_val, __api_version_val, __created_at_val, __updated_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Create_NodeEvent(ctx context.Context,
	node_event_id NodeEvent_Id_Field,
	node_event_email NodeEvent_Email_Field,
	node_event_node_id NodeEvent_NodeId_Field,
	node_event_event NodeEvent_Event_Field,
	optional NodeEvent_Create_Fields) (
	node_event *NodeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := node_event_id.value()
	__email_val := node_event_email.value()
	__last_ip_port_val := optional.LastIpPort.value()
	__node_id_val := node_event_node_id.value()
	__event_val := node_event_event.value()
	__last_attempted_val := optional.LastAttempted.value()
	__email_sent_val := optional.EmailSent.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, email, last_ip_port, node_id, event, last_attempted, email_sent")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO node_events "), __clause, __sqlbundle_Literal(" RETURNING node_events.id, node_events.email, node_events.last_ip_port, node_events.node_id, node_events.event, node_events.created_at, node_events.last_attempted, node_events.email_sent")}}

	var __values []any
	__values = append(__values, __id_val, __email_val, __last_ip_port_val, __node_id_val, __event_val, __last_attempted_val, __email_sent_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.CreatedAt._set {
		__values = append(__values, optional.CreatedAt.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("created_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node_event = &NodeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node_event, nil

}

func (obj *pgxcockroachImpl) ReplaceNoReturn_NodeTags(ctx context.Context,
	node_tags_node_id NodeTags_NodeId_Field,
	node_tags_name NodeTags_Name_Field,
	node_tags_value NodeTags_Value_Field,
	node_tags_signed_at NodeTags_SignedAt_Field,
	node_tags_signer NodeTags_Signer_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__node_id_val := node_tags_node_id.value()
	__name_val := node_tags_name.value()
	__value_val := node_tags_value.value()
	__signed_at_val := node_tags_signed_at.value()
	__signer_val := node_tags_signer.value()

	var __embed_stmt = __sqlbundle_Literal("UPSERT INTO node_tags ( node_id, name, value, signed_at, signer ) VALUES ( ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __node_id_val, __name_val, __value_val, __signed_at_val, __signer_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) ReplaceNoReturn_StoragenodePaystub(ctx context.Context,
	storagenode_paystub_period StoragenodePaystub_Period_Field,
	storagenode_paystub_node_id StoragenodePaystub_NodeId_Field,
	storagenode_paystub_codes StoragenodePaystub_Codes_Field,
	storagenode_paystub_usage_at_rest StoragenodePaystub_UsageAtRest_Field,
	storagenode_paystub_usage_get StoragenodePaystub_UsageGet_Field,
	storagenode_paystub_usage_put StoragenodePaystub_UsagePut_Field,
	storagenode_paystub_usage_get_repair StoragenodePaystub_UsageGetRepair_Field,
	storagenode_paystub_usage_put_repair StoragenodePaystub_UsagePutRepair_Field,
	storagenode_paystub_usage_get_audit StoragenodePaystub_UsageGetAudit_Field,
	storagenode_paystub_comp_at_rest StoragenodePaystub_CompAtRest_Field,
	storagenode_paystub_comp_get StoragenodePaystub_CompGet_Field,
	storagenode_paystub_comp_put StoragenodePaystub_CompPut_Field,
	storagenode_paystub_comp_get_repair StoragenodePaystub_CompGetRepair_Field,
	storagenode_paystub_comp_put_repair StoragenodePaystub_CompPutRepair_Field,
	storagenode_paystub_comp_get_audit StoragenodePaystub_CompGetAudit_Field,
	storagenode_paystub_surge_percent StoragenodePaystub_SurgePercent_Field,
	storagenode_paystub_held StoragenodePaystub_Held_Field,
	storagenode_paystub_owed StoragenodePaystub_Owed_Field,
	storagenode_paystub_disposed StoragenodePaystub_Disposed_Field,
	storagenode_paystub_paid StoragenodePaystub_Paid_Field,
	storagenode_paystub_distributed StoragenodePaystub_Distributed_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__period_val := storagenode_paystub_period.value()
	__node_id_val := storagenode_paystub_node_id.value()
	__created_at_val := __now
	__codes_val := storagenode_paystub_codes.value()
	__usage_at_rest_val := storagenode_paystub_usage_at_rest.value()
	__usage_get_val := storagenode_paystub_usage_get.value()
	__usage_put_val := storagenode_paystub_usage_put.value()
	__usage_get_repair_val := storagenode_paystub_usage_get_repair.value()
	__usage_put_repair_val := storagenode_paystub_usage_put_repair.value()
	__usage_get_audit_val := storagenode_paystub_usage_get_audit.value()
	__comp_at_rest_val := storagenode_paystub_comp_at_rest.value()
	__comp_get_val := storagenode_paystub_comp_get.value()
	__comp_put_val := storagenode_paystub_comp_put.value()
	__comp_get_repair_val := storagenode_paystub_comp_get_repair.value()
	__comp_put_repair_val := storagenode_paystub_comp_put_repair.value()
	__comp_get_audit_val := storagenode_paystub_comp_get_audit.value()
	__surge_percent_val := storagenode_paystub_surge_percent.value()
	__held_val := storagenode_paystub_held.value()
	__owed_val := storagenode_paystub_owed.value()
	__disposed_val := storagenode_paystub_disposed.value()
	__paid_val := storagenode_paystub_paid.value()
	__distributed_val := storagenode_paystub_distributed.value()

	var __embed_stmt = __sqlbundle_Literal("UPSERT INTO storagenode_paystubs ( period, node_id, created_at, codes, usage_at_rest, usage_get, usage_put, usage_get_repair, usage_put_repair, usage_get_audit, comp_at_rest, comp_get, comp_put, comp_get_repair, comp_put_repair, comp_get_audit, surge_percent, held, owed, disposed, paid, distributed ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __period_val, __node_id_val, __created_at_val, __codes_val, __usage_at_rest_val, __usage_get_val, __usage_put_val, __usage_get_repair_val, __usage_put_repair_val, __usage_get_audit_val, __comp_at_rest_val, __comp_get_val, __comp_put_val, __comp_get_repair_val, __comp_put_repair_val, __comp_get_audit_val, __surge_percent_val, __held_val, __owed_val, __disposed_val, __paid_val, __distributed_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_StoragenodePayment(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field,
	storagenode_payment_period StoragenodePayment_Period_Field,
	storagenode_payment_amount StoragenodePayment_Amount_Field,
	optional StoragenodePayment_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__created_at_val := __now
	__node_id_val := storagenode_payment_node_id.value()
	__period_val := storagenode_payment_period.value()
	__amount_val := storagenode_payment_amount.value()
	__receipt_val := optional.Receipt.value()
	__notes_val := optional.Notes.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO storagenode_payments ( created_at, node_id, period, amount, receipt, notes ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __created_at_val, __node_id_val, __period_val, __amount_val, __receipt_val, __notes_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Create_Reputation(ctx context.Context,
	reputation_id Reputation_Id_Field,
	reputation_audit_history Reputation_AuditHistory_Field,
	optional Reputation_Create_Fields) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := reputation_id.value()
	__vetted_at_val := optional.VettedAt.value()
	__disqualified_val := optional.Disqualified.value()
	__disqualification_reason_val := optional.DisqualificationReason.value()
	__unknown_audit_suspended_val := optional.UnknownAuditSuspended.value()
	__offline_suspended_val := optional.OfflineSuspended.value()
	__under_review_val := optional.UnderReview.value()
	__audit_history_val := reputation_audit_history.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, vetted_at, disqualified, disqualification_reason, unknown_audit_suspended, offline_suspended, under_review, audit_history")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO reputations "), __clause, __sqlbundle_Literal(" RETURNING reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta")}}

	var __values []any
	__values = append(__values, __id_val, __vetted_at_val, __disqualified_val, __disqualification_reason_val, __unknown_audit_suspended_val, __offline_suspended_val, __under_review_val, __audit_history_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.AuditSuccessCount._set {
		__values = append(__values, optional.AuditSuccessCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_success_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.TotalAuditCount._set {
		__values = append(__values, optional.TotalAuditCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("total_audit_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.OnlineScore._set {
		__values = append(__values, optional.OnlineScore.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("online_score"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.AuditReputationAlpha._set {
		__values = append(__values, optional.AuditReputationAlpha.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_reputation_alpha"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.AuditReputationBeta._set {
		__values = append(__values, optional.AuditReputationBeta.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_reputation_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.UnknownAuditReputationAlpha._set {
		__values = append(__values, optional.UnknownAuditReputationAlpha.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.UnknownAuditReputationBeta._set {
		__values = append(__values, optional.UnknownAuditReputationBeta.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reputation, nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_OauthClient(ctx context.Context,
	oauth_client_id OauthClient_Id_Field,
	oauth_client_encrypted_secret OauthClient_EncryptedSecret_Field,
	oauth_client_redirect_url OauthClient_RedirectUrl_Field,
	oauth_client_user_id OauthClient_UserId_Field,
	oauth_client_app_name OauthClient_AppName_Field,
	oauth_client_app_logo_url OauthClient_AppLogoUrl_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := oauth_client_id.value()
	__encrypted_secret_val := oauth_client_encrypted_secret.value()
	__redirect_url_val := oauth_client_redirect_url.value()
	__user_id_val := oauth_client_user_id.value()
	__app_name_val := oauth_client_app_name.value()
	__app_logo_url_val := oauth_client_app_logo_url.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO oauth_clients ( id, encrypted_secret, redirect_url, user_id, app_name, app_logo_url ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __id_val, __encrypted_secret_val, __redirect_url_val, __user_id_val, __app_name_val, __app_logo_url_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_OauthCode(ctx context.Context,
	oauth_code_client_id OauthCode_ClientId_Field,
	oauth_code_user_id OauthCode_UserId_Field,
	oauth_code_scope OauthCode_Scope_Field,
	oauth_code_redirect_url OauthCode_RedirectUrl_Field,
	oauth_code_challenge OauthCode_Challenge_Field,
	oauth_code_challenge_method OauthCode_ChallengeMethod_Field,
	oauth_code_code OauthCode_Code_Field,
	oauth_code_created_at OauthCode_CreatedAt_Field,
	oauth_code_expires_at OauthCode_ExpiresAt_Field,
	optional OauthCode_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__client_id_val := oauth_code_client_id.value()
	__user_id_val := oauth_code_user_id.value()
	__scope_val := oauth_code_scope.value()
	__redirect_url_val := oauth_code_redirect_url.value()
	__challenge_val := oauth_code_challenge.value()
	__challenge_method_val := oauth_code_challenge_method.value()
	__code_val := oauth_code_code.value()
	__created_at_val := oauth_code_created_at.value()
	__expires_at_val := oauth_code_expires_at.value()
	__claimed_at_val := optional.ClaimedAt.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO oauth_codes ( client_id, user_id, scope, redirect_url, challenge, challenge_method, code, created_at, expires_at, claimed_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __client_id_val, __user_id_val, __scope_val, __redirect_url_val, __challenge_val, __challenge_method_val, __code_val, __created_at_val, __expires_at_val, __claimed_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_OauthToken(ctx context.Context,
	oauth_token_client_id OauthToken_ClientId_Field,
	oauth_token_user_id OauthToken_UserId_Field,
	oauth_token_scope OauthToken_Scope_Field,
	oauth_token_kind OauthToken_Kind_Field,
	oauth_token_token OauthToken_Token_Field,
	oauth_token_created_at OauthToken_CreatedAt_Field,
	oauth_token_expires_at OauthToken_ExpiresAt_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__client_id_val := oauth_token_client_id.value()
	__user_id_val := oauth_token_user_id.value()
	__scope_val := oauth_token_scope.value()
	__kind_val := oauth_token_kind.value()
	__token_val := oauth_token_token.value()
	__created_at_val := oauth_token_created_at.value()
	__expires_at_val := oauth_token_expires_at.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO oauth_tokens ( client_id, user_id, scope, kind, token, created_at, expires_at ) VALUES ( ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __client_id_val, __user_id_val, __scope_val, __kind_val, __token_val, __created_at_val, __expires_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Create_Project(ctx context.Context,
	project_id Project_Id_Field,
	project_name Project_Name_Field,
	project_description Project_Description_Field,
	project_owner_id Project_OwnerId_Field,
	optional Project_Create_Fields) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := project_id.value()
	__public_id_val := optional.PublicId.value()
	__name_val := project_name.value()
	__description_val := project_description.value()
	__usage_limit_val := optional.UsageLimit.value()
	__bandwidth_limit_val := optional.BandwidthLimit.value()
	__user_specified_usage_limit_val := optional.UserSpecifiedUsageLimit.value()
	__user_specified_bandwidth_limit_val := optional.UserSpecifiedBandwidthLimit.value()
	__rate_limit_val := optional.RateLimit.value()
	__burst_limit_val := optional.BurstLimit.value()
	__rate_limit_head_val := optional.RateLimitHead.value()
	__burst_limit_head_val := optional.BurstLimitHead.value()
	__rate_limit_get_val := optional.RateLimitGet.value()
	__burst_limit_get_val := optional.BurstLimitGet.value()
	__rate_limit_put_val := optional.RateLimitPut.value()
	__burst_limit_put_val := optional.BurstLimitPut.value()
	__rate_limit_list_val := optional.RateLimitList.value()
	__burst_limit_list_val := optional.BurstLimitList.value()
	__rate_limit_del_val := optional.RateLimitDel.value()
	__burst_limit_del_val := optional.BurstLimitDel.value()
	__max_buckets_val := optional.MaxBuckets.value()
	__user_agent_val := optional.UserAgent.value()
	__owner_id_val := project_owner_id.value()
	__salt_val := optional.Salt.value()
	__status_updated_at_val := optional.StatusUpdatedAt.value()
	__created_at_val := __now
	__default_placement_val := optional.DefaultPlacement.value()
	__passphrase_enc_val := optional.PassphraseEnc.value()
	__passphrase_enc_key_id_val := optional.PassphraseEncKeyId.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, public_id, name, description, usage_limit, bandwidth_limit, user_specified_usage_limit, user_specified_bandwidth_limit, rate_limit, burst_limit, rate_limit_head, burst_limit_head, rate_limit_get, burst_limit_get, rate_limit_put, burst_limit_put, rate_limit_list, burst_limit_list, rate_limit_del, burst_limit_del, max_buckets, user_agent, owner_id, salt, status_updated_at, created_at, default_placement, passphrase_enc, passphrase_enc_key_id")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO projects "), __clause, __sqlbundle_Literal(" RETURNING projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption")}}

	var __values []any
	__values = append(__values, __id_val, __public_id_val, __name_val, __description_val, __usage_limit_val, __bandwidth_limit_val, __user_specified_usage_limit_val, __user_specified_bandwidth_limit_val, __rate_limit_val, __burst_limit_val, __rate_limit_head_val, __burst_limit_head_val, __rate_limit_get_val, __burst_limit_get_val, __rate_limit_put_val, __burst_limit_put_val, __rate_limit_list_val, __burst_limit_list_val, __rate_limit_del_val, __burst_limit_del_val, __max_buckets_val, __user_agent_val, __owner_id_val, __salt_val, __status_updated_at_val, __created_at_val, __default_placement_val, __passphrase_enc_val, __passphrase_enc_key_id_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.SegmentLimit._set {
		__values = append(__values, optional.SegmentLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("segment_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.Status._set {
		__values = append(__values, optional.Status.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("status"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.DefaultVersioning._set {
		__values = append(__values, optional.DefaultVersioning.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("default_versioning"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.PromptedForVersioningBeta._set {
		__values = append(__values, optional.PromptedForVersioningBeta.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("prompted_for_versioning_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.PathEncryption._set {
		__values = append(__values, optional.PathEncryption.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("path_encryption"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil

}

func (obj *pgxcockroachImpl) Create_ProjectMember(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field,
	optional ProjectMember_Create_Fields) (
	project_member *ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__member_id_val := project_member_member_id.value()
	__project_id_val := project_member_project_id.value()
	__created_at_val := __now

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("member_id, project_id, created_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO project_members "), __clause, __sqlbundle_Literal(" RETURNING project_members.member_id, project_members.project_id, project_members.role, project_members.created_at")}}

	var __values []any
	__values = append(__values, __member_id_val, __project_id_val, __created_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Role._set {
		__values = append(__values, optional.Role.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("role"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_member = &ProjectMember{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_member, nil

}

func (obj *pgxcockroachImpl) Replace_ProjectInvitation(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field,
	optional ProjectInvitation_Create_Fields) (
	project_invitation *ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__project_id_val := project_invitation_project_id.value()
	__email_val := project_invitation_email.value()
	__inviter_id_val := optional.InviterId.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("UPSERT INTO project_invitations ( project_id, email, inviter_id, created_at ) VALUES ( ?, ?, ?, ? ) RETURNING project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at")

	var __values []any
	__values = append(__values, __project_id_val, __email_val, __inviter_id_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_invitation = &ProjectInvitation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_invitation, nil

}

func (obj *pgxcockroachImpl) Create_ApiKey(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	api_key_project_id ApiKey_ProjectId_Field,
	api_key_head ApiKey_Head_Field,
	api_key_name ApiKey_Name_Field,
	api_key_secret ApiKey_Secret_Field,
	optional ApiKey_Create_Fields) (
	api_key *ApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := api_key_id.value()
	__project_id_val := api_key_project_id.value()
	__head_val := api_key_head.value()
	__name_val := api_key_name.value()
	__secret_val := api_key_secret.value()
	__user_agent_val := optional.UserAgent.value()
	__created_at_val := __now
	__created_by_val := optional.CreatedBy.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, project_id, head, name, secret, user_agent, created_at, created_by")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO api_keys "), __clause, __sqlbundle_Literal(" RETURNING api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version")}}

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __head_val, __name_val, __secret_val, __user_agent_val, __created_at_val, __created_by_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Version._set {
		__values = append(__values, optional.Version.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("version"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key = &ApiKey{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Head, &api_key.Name, &api_key.Secret, &api_key.UserAgent, &api_key.CreatedAt, &api_key.CreatedBy, &api_key.Version)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil

}

func (obj *pgxcockroachImpl) Replace_ApiKeyTail(ctx context.Context,
	api_key_tail_tail ApiKeyTail_Tail_Field,
	api_key_tail_parent_tail ApiKeyTail_ParentTail_Field,
	api_key_tail_caveat ApiKeyTail_Caveat_Field,
	api_key_tail_last_used ApiKeyTail_LastUsed_Field,
	optional ApiKeyTail_Create_Fields) (
	api_key_tail *ApiKeyTail, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__root_key_id_val := optional.RootKeyId.value()
	__tail_val := api_key_tail_tail.value()
	__parent_tail_val := api_key_tail_parent_tail.value()
	__caveat_val := api_key_tail_caveat.value()
	__last_used_val := api_key_tail_last_used.value()

	var __embed_stmt = __sqlbundle_Literal("UPSERT INTO api_key_tails ( root_key_id, tail, parent_tail, caveat, last_used ) VALUES ( ?, ?, ?, ?, ? ) RETURNING api_key_tails.root_key_id, api_key_tails.tail, api_key_tails.parent_tail, api_key_tails.caveat, api_key_tails.last_used")

	var __values []any
	__values = append(__values, __root_key_id_val, __tail_val, __parent_tail_val, __caveat_val, __last_used_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key_tail = &ApiKeyTail{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&api_key_tail.RootKeyId, &api_key_tail.Tail, &api_key_tail.ParentTail, &api_key_tail.Caveat, &api_key_tail.LastUsed)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key_tail, nil

}

func (obj *pgxcockroachImpl) Create_BucketMetainfo(ctx context.Context,
	bucket_metainfo_id BucketMetainfo_Id_Field,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	bucket_metainfo_path_cipher BucketMetainfo_PathCipher_Field,
	bucket_metainfo_default_segment_size BucketMetainfo_DefaultSegmentSize_Field,
	bucket_metainfo_default_encryption_cipher_suite BucketMetainfo_DefaultEncryptionCipherSuite_Field,
	bucket_metainfo_default_encryption_block_size BucketMetainfo_DefaultEncryptionBlockSize_Field,
	bucket_metainfo_default_redundancy_algorithm BucketMetainfo_DefaultRedundancyAlgorithm_Field,
	bucket_metainfo_default_redundancy_share_size BucketMetainfo_DefaultRedundancyShareSize_Field,
	bucket_metainfo_default_redundancy_required_shares BucketMetainfo_DefaultRedundancyRequiredShares_Field,
	bucket_metainfo_default_redundancy_repair_shares BucketMetainfo_DefaultRedundancyRepairShares_Field,
	bucket_metainfo_default_redundancy_optimal_shares BucketMetainfo_DefaultRedundancyOptimalShares_Field,
	bucket_metainfo_default_redundancy_total_shares BucketMetainfo_DefaultRedundancyTotalShares_Field,
	optional BucketMetainfo_Create_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := bucket_metainfo_id.value()
	__project_id_val := bucket_metainfo_project_id.value()
	__name_val := bucket_metainfo_name.value()
	__tags_val := optional.Tags.value()
	__user_agent_val := optional.UserAgent.value()
	__default_retention_mode_val := optional.DefaultRetentionMode.value()
	__default_retention_days_val := optional.DefaultRetentionDays.value()
	__default_retention_years_val := optional.DefaultRetentionYears.value()
	__path_cipher_val := bucket_metainfo_path_cipher.value()
	__created_at_val := __now
	__default_segment_size_val := bucket_metainfo_default_segment_size.value()
	__default_encryption_cipher_suite_val := bucket_metainfo_default_encryption_cipher_suite.value()
	__default_encryption_block_size_val := bucket_metainfo_default_encryption_block_size.value()
	__default_redundancy_algorithm_val := bucket_metainfo_default_redundancy_algorithm.value()
	__default_redundancy_share_size_val := bucket_metainfo_default_redundancy_share_size.value()
	__default_redundancy_required_shares_val := bucket_metainfo_default_redundancy_required_shares.value()
	__default_redundancy_repair_shares_val := bucket_metainfo_default_redundancy_repair_shares.value()
	__default_redundancy_optimal_shares_val := bucket_metainfo_default_redundancy_optimal_shares.value()
	__default_redundancy_total_shares_val := bucket_metainfo_default_redundancy_total_shares.value()
	__placement_val := optional.Placement.value()
	__created_by_val := optional.CreatedBy.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, project_id, name, tags, user_agent, default_retention_mode, default_retention_days, default_retention_years, path_cipher, created_at, default_segment_size, default_encryption_cipher_suite, default_encryption_block_size, default_redundancy_algorithm, default_redundancy_share_size, default_redundancy_required_shares, default_redundancy_repair_shares, default_redundancy_optimal_shares, default_redundancy_total_shares, placement, created_by")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO bucket_metainfos "), __clause, __sqlbundle_Literal(" RETURNING bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __name_val, __tags_val, __user_agent_val, __default_retention_mode_val, __default_retention_days_val, __default_retention_years_val, __path_cipher_val, __created_at_val, __default_segment_size_val, __default_encryption_cipher_suite_val, __default_encryption_block_size_val, __default_redundancy_algorithm_val, __default_redundancy_share_size_val, __default_redundancy_required_shares_val, __default_redundancy_repair_shares_val, __default_redundancy_optimal_shares_val, __default_redundancy_total_shares_val, __placement_val, __created_by_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Versioning._set {
		__values = append(__values, optional.Versioning.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("versioning"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ObjectLockEnabled._set {
		__values = append(__values, optional.ObjectLockEnabled.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("object_lock_enabled"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil

}

func (obj *pgxcockroachImpl) Create_ValueAttribution(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field,
	optional ValueAttribution_Create_Fields) (
	value_attribution *ValueAttribution, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__project_id_val := value_attribution_project_id.value()
	__bucket_name_val := value_attribution_bucket_name.value()
	__user_agent_val := optional.UserAgent.value()
	__placement_val := optional.Placement.value()
	__last_updated_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO value_attributions ( project_id, bucket_name, user_agent, placement, last_updated ) VALUES ( ?, ?, ?, ?, ? ) RETURNING value_attributions.project_id, value_attributions.bucket_name, value_attributions.user_agent, value_attributions.placement, value_attributions.last_updated")

	var __values []any
	__values = append(__values, __project_id_val, __bucket_name_val, __user_agent_val, __placement_val, __last_updated_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	value_attribution = &ValueAttribution{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return value_attribution, nil

}

func (obj *pgxcockroachImpl) Create_BucketMigration(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field,
	bucket_migration_project_id BucketMigration_ProjectId_Field,
	bucket_migration_bucket_name BucketMigration_BucketName_Field,
	bucket_migration_from_placement BucketMigration_FromPlacement_Field,
	bucket_migration_to_placement BucketMigration_ToPlacement_Field,
	bucket_migration_migration_type BucketMigration_MigrationType_Field,
	bucket_migration_state BucketMigration_State_Field,
	optional BucketMigration_Create_Fields) (
	bucket_migration *BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := bucket_migration_id.value()
	__project_id_val := bucket_migration_project_id.value()
	__bucket_name_val := bucket_migration_bucket_name.value()
	__from_placement_val := bucket_migration_from_placement.value()
	__to_placement_val := bucket_migration_to_placement.value()
	__migration_type_val := bucket_migration_migration_type.value()
	__state_val := bucket_migration_state.value()
	__error_message_val := optional.ErrorMessage.value()
	__created_at_val := __now
	__updated_at_val := __now
	__completed_at_val := optional.CompletedAt.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, project_id, bucket_name, from_placement, to_placement, migration_type, state, error_message, created_at, updated_at, completed_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO bucket_migrations "), __clause, __sqlbundle_Literal(" RETURNING bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at")}}

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __bucket_name_val, __from_placement_val, __to_placement_val, __migration_type_val, __state_val, __error_message_val, __created_at_val, __updated_at_val, __completed_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.BytesProcessed._set {
		__values = append(__values, optional.BytesProcessed.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("bytes_processed"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_migration = &BucketMigration{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_migration, nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_RestApiKey(ctx context.Context,
	rest_api_key_id RestApiKey_Id_Field,
	rest_api_key_user_id RestApiKey_UserId_Field,
	rest_api_key_token RestApiKey_Token_Field,
	rest_api_key_name RestApiKey_Name_Field,
	optional RestApiKey_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := rest_api_key_id.value()
	__user_id_val := rest_api_key_user_id.value()
	__token_val := rest_api_key_token.value()
	__name_val := rest_api_key_name.value()
	__expires_at_val := optional.ExpiresAt.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO rest_api_keys ( id, user_id, token, name, expires_at, created_at ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __id_val, __user_id_val, __token_val, __name_val, __expires_at_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Create_User(ctx context.Context,
	user_id User_Id_Field,
	user_email User_Email_Field,
	user_normalized_email User_NormalizedEmail_Field,
	user_full_name User_FullName_Field,
	user_password_hash User_PasswordHash_Field,
	optional User_Create_Fields) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := user_id.value()
	__external_id_val := optional.ExternalId.value()
	__tenant_id_val := optional.TenantId.value()
	__email_val := user_email.value()
	__normalized_email_val := user_normalized_email.value()
	__full_name_val := user_full_name.value()
	__short_name_val := optional.ShortName.value()
	__password_hash_val := user_password_hash.value()
	__new_unverified_email_val := optional.NewUnverifiedEmail.value()
	__status_val := int(0)
	__status_updated_at_val := optional.StatusUpdatedAt.value()
	__user_agent_val := optional.UserAgent.value()
	__created_at_val := __now
	__position_val := optional.Position.value()
	__company_name_val := optional.CompanyName.value()
	__company_size_val := optional.CompanySize.value()
	__working_on_val := optional.WorkingOn.value()
	__employee_count_val := optional.EmployeeCount.value()
	__mfa_secret_key_val := optional.MfaSecretKey.value()
	__mfa_recovery_codes_val := optional.MfaRecoveryCodes.value()
	__signup_promo_code_val := optional.SignupPromoCode.value()
	__failed_login_count_val := optional.FailedLoginCount.value()
	__login_lockout_expiration_val := optional.LoginLockoutExpiration.value()
	__signup_captcha_val := optional.SignupCaptcha.value()
	__default_placement_val := optional.DefaultPlacement.value()
	__activation_code_val := optional.ActivationCode.value()
	__signup_id_val := optional.SignupId.value()
	__trial_expiration_val := optional.TrialExpiration.value()
	__upgrade_time_val := optional.UpgradeTime.value()
	__hubspot_object_id_val := optional.HubspotObjectId.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, external_id, tenant_id, email, normalized_email, full_name, short_name, password_hash, new_unverified_email, status, status_updated_at, user_agent, created_at, position, company_name, company_size, working_on, employee_count, mfa_secret_key, mfa_recovery_codes, signup_promo_code, failed_login_count, login_lockout_expiration, signup_captcha, default_placement, activation_code, signup_id, trial_expiration, upgrade_time, hubspot_object_id")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO users "), __clause, __sqlbundle_Literal(" RETURNING users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id")}}

	var __values []any
	__values = append(__values, __id_val, __external_id_val, __tenant_id_val, __email_val, __normalized_email_val, __full_name_val, __short_name_val, __password_hash_val, __new_unverified_email_val, __status_val, __status_updated_at_val, __user_agent_val, __created_at_val, __position_val, __company_name_val, __company_size_val, __working_on_val, __employee_count_val, __mfa_secret_key_val, __mfa_recovery_codes_val, __signup_promo_code_val, __failed_login_count_val, __login_lockout_expiration_val, __signup_captcha_val, __default_placement_val, __activation_code_val, __signup_id_val, __trial_expiration_val, __upgrade_time_val, __hubspot_object_id_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.EmailChangeVerificationStep._set {
		__values = append(__values, optional.EmailChangeVerificationStep.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("email_change_verification_step"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.FinalInvoiceGenerated._set {
		__values = append(__values, optional.FinalInvoiceGenerated.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("final_invoice_generated"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectLimit._set {
		__values = append(__values, optional.ProjectLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectBandwidthLimit._set {
		__values = append(__values, optional.ProjectBandwidthLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_bandwidth_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectStorageLimit._set {
		__values = append(__values, optional.ProjectStorageLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_storage_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectSegmentLimit._set {
		__values = append(__values, optional.ProjectSegmentLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_segment_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.Kind._set {
		__values = append(__values, optional.Kind.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("kind"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.IsProfessional._set {
		__values = append(__values, optional.IsProfessional.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("is_professional"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.HaveSalesContact._set {
		__values = append(__values, optional.HaveSalesContact.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("have_sales_contact"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.MfaEnabled._set {
		__values = append(__values, optional.MfaEnabled.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("mfa_enabled"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.VerificationReminders._set {
		__values = append(__values, optional.VerificationReminders.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("verification_reminders"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.TrialNotifications._set {
		__values = append(__values, optional.TrialNotifications.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("trial_notifications"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil

}

func (obj *pgxcockroachImpl) Create_WebappSession(ctx context.Context,
	webapp_session_id WebappSession_Id_Field,
	webapp_session_user_id WebappSession_UserId_Field,
	webapp_session_ip_address WebappSession_IpAddress_Field,
	webapp_session_user_agent WebappSession_UserAgent_Field,
	webapp_session_expires_at WebappSession_ExpiresAt_Field) (
	webapp_session *WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := webapp_session_id.value()
	__user_id_val := webapp_session_user_id.value()
	__ip_address_val := webapp_session_ip_address.value()
	__user_agent_val := webapp_session_user_agent.value()
	__status_val := int(0)
	__expires_at_val := webapp_session_expires_at.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO webapp_sessions ( id, user_id, ip_address, user_agent, status, expires_at ) VALUES ( ?, ?, ?, ?, ?, ? ) RETURNING webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at")

	var __values []any
	__values = append(__values, __id_val, __user_id_val, __ip_address_val, __user_agent_val, __status_val, __expires_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	webapp_session = &WebappSession{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return webapp_session, nil

}

func (obj *pgxcockroachImpl) Create_RegistrationToken(ctx context.Context,
	registration_token_secret RegistrationToken_Secret_Field,
	registration_token_project_limit RegistrationToken_ProjectLimit_Field,
	optional RegistrationToken_Create_Fields) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__secret_val := registration_token_secret.value()
	__owner_id_val := optional.OwnerId.value()
	__project_limit_val := registration_token_project_limit.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO registration_tokens ( secret, owner_id, project_limit, created_at ) VALUES ( ?, ?, ?, ? ) RETURNING registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at")

	var __values []any
	__values = append(__values, __secret_val, __owner_id_val, __project_limit_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return registration_token, nil

}

func (obj *pgxcockroachImpl) Create_ResetPasswordToken(ctx context.Context,
	reset_password_token_secret ResetPasswordToken_Secret_Field,
	reset_password_token_owner_id ResetPasswordToken_OwnerId_Field) (
	reset_password_token *ResetPasswordToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__secret_val := reset_password_token_secret.value()
	__owner_id_val := reset_password_token_owner_id.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO reset_password_tokens ( secret, owner_id, created_at ) VALUES ( ?, ?, ? ) RETURNING reset_password_tokens.secret, reset_password_tokens.owner_id, reset_password_tokens.created_at")

	var __values []any
	__values = append(__values, __secret_val, __owner_id_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reset_password_token = &ResetPasswordToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reset_password_token, nil

}

func (obj *pgxcockroachImpl) Replace_AccountFreezeEvent(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field,
	optional AccountFreezeEvent_Create_Fields) (
	account_freeze_event *AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__user_id_val := account_freeze_event_user_id.value()
	__event_val := account_freeze_event_event.value()
	__limits_val := optional.Limits.value()
	__days_till_escalation_val := optional.DaysTillEscalation.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("user_id, event, limits, days_till_escalation")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPSERT INTO account_freeze_events "), __clause, __sqlbundle_Literal(" RETURNING account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at")}}

	var __values []any
	__values = append(__values, __user_id_val, __event_val, __limits_val, __days_till_escalation_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.NotificationsCount._set {
		__values = append(__values, optional.NotificationsCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("notifications_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.CreatedAt._set {
		__values = append(__values, optional.CreatedAt.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("created_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	account_freeze_event = &AccountFreezeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return account_freeze_event, nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_UserSettings(ctx context.Context,
	user_settings_user_id UserSettings_UserId_Field,
	optional UserSettings_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__user_id_val := user_settings_user_id.value()
	__session_minutes_val := optional.SessionMinutes.value()
	__passphrase_prompt_val := optional.PassphrasePrompt.value()
	__onboarding_step_val := optional.OnboardingStep.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("user_id, session_minutes, passphrase_prompt, onboarding_step")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO user_settings "), __clause}}

	var __values []any
	__values = append(__values, __user_id_val, __session_minutes_val, __passphrase_prompt_val, __onboarding_step_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.OnboardingStart._set {
		__values = append(__values, optional.OnboardingStart.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("onboarding_start"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.OnboardingEnd._set {
		__values = append(__values, optional.OnboardingEnd.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("onboarding_end"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.NoticeDismissal._set {
		__values = append(__values, optional.NoticeDismissal.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("notice_dismissal"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 {
		if __columns.SQL == nil {
			__clause.SQL = __sqlbundle_Literal("DEFAULT VALUES")
		}
	} else {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}
	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Find_AccountingTimestamps_Value_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field) (
	row *Value_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_timestamps.value FROM accounting_timestamps WHERE accounting_timestamps.name = ?")

	var __values []any
	__values = append(__values, accounting_timestamps_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Value_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Value)
	if errors.Is(err, sql.ErrNoRows) {
		return (*Value_Row)(nil), nil
	}
	if err != nil {
		return (*Value_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) All_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart(ctx context.Context,
	storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
	storagenode_bandwidth_rollup_interval_start StoragenodeBandwidthRollup_IntervalStart_Field) (
	rows []*StoragenodeBandwidthRollup, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.storagenode_id = ? AND storagenode_bandwidth_rollups.interval_start = ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_storagenode_id.value(), storagenode_bandwidth_rollup_interval_start.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodeBandwidthRollup, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_bandwidth_rollup := &StoragenodeBandwidthRollup{}
				err = __rows.Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	storagenode_bandwidth_rollup_interval_start_greater_or_equal StoragenodeBandwidthRollup_IntervalStart_Field,
	limit int, start *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.interval_start >= ? AND (storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action) > (?, ?, ?) ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.interval_start >= ? ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_storagenode_id, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				storagenode_bandwidth_rollup := &StoragenodeBandwidthRollup{}
				err = __rows.Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled, &__continuation._value_storagenode_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxcockroachImpl) Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual(ctx context.Context,
	storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
	storagenode_bandwidth_rollup_interval_start_greater_or_equal StoragenodeBandwidthRollup_IntervalStart_Field,
	limit int, start *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.storagenode_id = ? AND storagenode_bandwidth_rollups.interval_start >= ? AND (storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action) > (?, ?, ?) ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.storagenode_id = ? AND storagenode_bandwidth_rollups.interval_start >= ? ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_storagenode_id.value(), storagenode_bandwidth_rollup_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_storagenode_id, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				storagenode_bandwidth_rollup := &StoragenodeBandwidthRollup{}
				err = __rows.Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled, &__continuation._value_storagenode_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxcockroachImpl) Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	storagenode_bandwidth_rollup_archive_interval_start_greater_or_equal StoragenodeBandwidthRollupArchive_IntervalStart_Field,
	limit int, start *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*StoragenodeBandwidthRollupArchive, next *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.interval_seconds, storagenode_bandwidth_rollup_archives.action, storagenode_bandwidth_rollup_archives.allocated, storagenode_bandwidth_rollup_archives.settled, storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action FROM storagenode_bandwidth_rollup_archives WHERE storagenode_bandwidth_rollup_archives.interval_start >= ? AND (storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action) > (?, ?, ?) ORDER BY storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.interval_seconds, storagenode_bandwidth_rollup_archives.action, storagenode_bandwidth_rollup_archives.allocated, storagenode_bandwidth_rollup_archives.settled, storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action FROM storagenode_bandwidth_rollup_archives WHERE storagenode_bandwidth_rollup_archives.interval_start >= ? ORDER BY storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action LIMIT ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_archive_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_storagenode_id, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*StoragenodeBandwidthRollupArchive, next *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				storagenode_bandwidth_rollup_archive := &StoragenodeBandwidthRollupArchive{}
				err = __rows.Scan(&storagenode_bandwidth_rollup_archive.StoragenodeId, &storagenode_bandwidth_rollup_archive.IntervalStart, &storagenode_bandwidth_rollup_archive.IntervalSeconds, &storagenode_bandwidth_rollup_archive.Action, &storagenode_bandwidth_rollup_archive.Allocated, &storagenode_bandwidth_rollup_archive.Settled, &__continuation._value_storagenode_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup_archive)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxcockroachImpl) All_StoragenodeStorageTally(ctx context.Context) (
	rows []*StoragenodeStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_storage_tallies.node_id, storagenode_storage_tallies.interval_end_time, storagenode_storage_tallies.data_total FROM storagenode_storage_tallies")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodeStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_storage_tally := &StoragenodeStorageTally{}
				err = __rows.Scan(&storagenode_storage_tally.NodeId, &storagenode_storage_tally.IntervalEndTime, &storagenode_storage_tally.DataTotal)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_StoragenodeStorageTally_By_IntervalEndTime_GreaterOrEqual(ctx context.Context,
	storagenode_storage_tally_interval_end_time_greater_or_equal StoragenodeStorageTally_IntervalEndTime_Field) (
	rows []*StoragenodeStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_storage_tallies.node_id, storagenode_storage_tallies.interval_end_time, storagenode_storage_tallies.data_total FROM storagenode_storage_tallies WHERE storagenode_storage_tallies.interval_end_time >= ?")

	var __values []any
	__values = append(__values, storagenode_storage_tally_interval_end_time_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodeStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_storage_tally := &StoragenodeStorageTally{}
				err = __rows.Scan(&storagenode_storage_tally.NodeId, &storagenode_storage_tally.IntervalEndTime, &storagenode_storage_tally.DataTotal)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) First_StoragenodeStorageTally_IntervalEndTime_OrderBy_Asc_IntervalEndTime(ctx context.Context) (
	row *IntervalEndTime_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_storage_tallies.interval_end_time FROM storagenode_storage_tallies ORDER BY storagenode_storage_tallies.interval_end_time LIMIT 1 OFFSET 0")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *IntervalEndTime_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			row = &IntervalEndTime_Row{}
			err = __rows.Scan(&row.IntervalEndTime)
			if err != nil {
				return nil, err
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *pgxcockroachImpl) Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	bucket_bandwidth_rollup_interval_start_greater_or_equal BucketBandwidthRollup_IntervalStart_Field,
	limit int, start *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*BucketBandwidthRollup, next *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.interval_seconds, bucket_bandwidth_rollups.action, bucket_bandwidth_rollups.product_id, bucket_bandwidth_rollups.inline, bucket_bandwidth_rollups.allocated, bucket_bandwidth_rollups.settled, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action FROM bucket_bandwidth_rollups WHERE bucket_bandwidth_rollups.interval_start >= ? AND (bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action) > (?, ?, ?, ?) ORDER BY bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.interval_seconds, bucket_bandwidth_rollups.action, bucket_bandwidth_rollups.product_id, bucket_bandwidth_rollups.inline, bucket_bandwidth_rollups.allocated, bucket_bandwidth_rollups.settled, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action FROM bucket_bandwidth_rollups WHERE bucket_bandwidth_rollups.interval_start >= ? ORDER BY bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action LIMIT ?")

	var __values []any
	__values = append(__values, bucket_bandwidth_rollup_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_project_id, start._value_bucket_name, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*BucketBandwidthRollup, next *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				bucket_bandwidth_rollup := &BucketBandwidthRollup{}
				err = __rows.Scan(&bucket_bandwidth_rollup.BucketName, &bucket_bandwidth_rollup.ProjectId, &bucket_bandwidth_rollup.IntervalStart, &bucket_bandwidth_rollup.IntervalSeconds, &bucket_bandwidth_rollup.Action, &bucket_bandwidth_rollup.ProductId, &bucket_bandwidth_rollup.Inline, &bucket_bandwidth_rollup.Allocated, &bucket_bandwidth_rollup.Settled, &__continuation._value_project_id, &__continuation._value_bucket_name, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, bucket_bandwidth_rollup)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxcockroachImpl) Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	bucket_bandwidth_rollup_archive_interval_start_greater_or_equal BucketBandwidthRollupArchive_IntervalStart_Field,
	limit int, start *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*BucketBandwidthRollupArchive, next *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.product_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.interval_seconds, bucket_bandwidth_rollup_archives.action, bucket_bandwidth_rollup_archives.inline, bucket_bandwidth_rollup_archives.allocated, bucket_bandwidth_rollup_archives.settled, bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action FROM bucket_bandwidth_rollup_archives WHERE bucket_bandwidth_rollup_archives.interval_start >= ? AND (bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action) > (?, ?, ?, ?) ORDER BY bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.product_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.interval_seconds, bucket_bandwidth_rollup_archives.action, bucket_bandwidth_rollup_archives.inline, bucket_bandwidth_rollup_archives.allocated, bucket_bandwidth_rollup_archives.settled, bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action FROM bucket_bandwidth_rollup_archives WHERE bucket_bandwidth_rollup_archives.interval_start >= ? ORDER BY bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action LIMIT ?")

	var __values []any
	__values = append(__values, bucket_bandwidth_rollup_archive_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_bucket_name, start._value_project_id, start._value_interval_start, start._value_action, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*BucketBandwidthRollupArchive, next *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				bucket_bandwidth_rollup_archive := &BucketBandwidthRollupArchive{}
				err = __rows.Scan(&bucket_bandwidth_rollup_archive.BucketName, &bucket_bandwidth_rollup_archive.ProjectId, &bucket_bandwidth_rollup_archive.ProductId, &bucket_bandwidth_rollup_archive.IntervalStart, &bucket_bandwidth_rollup_archive.IntervalSeconds, &bucket_bandwidth_rollup_archive.Action, &bucket_bandwidth_rollup_archive.Inline, &bucket_bandwidth_rollup_archive.Allocated, &bucket_bandwidth_rollup_archive.Settled, &__continuation._value_bucket_name, &__continuation._value_project_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, bucket_bandwidth_rollup_archive)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxcockroachImpl) All_BucketStorageTally_OrderBy_Desc_IntervalStart(ctx context.Context) (
	rows []*BucketStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_storage_tallies.bucket_name, bucket_storage_tallies.project_id, bucket_storage_tallies.interval_start, bucket_storage_tallies.product_id, bucket_storage_tallies.total_bytes, bucket_storage_tallies.inline, bucket_storage_tallies.remote, bucket_storage_tallies.total_segments_count, bucket_storage_tallies.remote_segments_count, bucket_storage_tallies.inline_segments_count, bucket_storage_tallies.object_count, bucket_storage_tallies.metadata_size FROM bucket_storage_tallies ORDER BY bucket_storage_tallies.interval_start DESC")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_storage_tally := &BucketStorageTally{}
				err = __rows.Scan(&bucket_storage_tally.BucketName, &bucket_storage_tally.ProjectId, &bucket_storage_tally.IntervalStart, &bucket_storage_tally.ProductId, &bucket_storage_tally.TotalBytes, &bucket_storage_tally.Inline, &bucket_storage_tally.Remote, &bucket_storage_tally.TotalSegmentsCount, &bucket_storage_tally.RemoteSegmentsCount, &bucket_storage_tally.InlineSegmentsCount, &bucket_storage_tally.ObjectCount, &bucket_storage_tally.MetadataSize)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_BucketStorageTally_By_ProjectId_And_BucketName_And_IntervalStart_GreaterOrEqual_And_IntervalStart_LessOrEqual_OrderBy_Desc_IntervalStart(ctx context.Context,
	bucket_storage_tally_project_id BucketStorageTally_ProjectId_Field,
	bucket_storage_tally_bucket_name BucketStorageTally_BucketName_Field,
	bucket_storage_tally_interval_start_greater_or_equal BucketStorageTally_IntervalStart_Field,
	bucket_storage_tally_interval_start_less_or_equal BucketStorageTally_IntervalStart_Field) (
	rows []*BucketStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_storage_tallies.bucket_name, bucket_storage_tallies.project_id, bucket_storage_tallies.interval_start, bucket_storage_tallies.product_id, bucket_storage_tallies.total_bytes, bucket_storage_tallies.inline, bucket_storage_tallies.remote, bucket_storage_tallies.total_segments_count, bucket_storage_tallies.remote_segments_count, bucket_storage_tallies.inline_segments_count, bucket_storage_tallies.object_count, bucket_storage_tallies.metadata_size FROM bucket_storage_tallies WHERE bucket_storage_tallies.project_id = ? AND bucket_storage_tallies.bucket_name = ? AND bucket_storage_tallies.interval_start >= ? AND bucket_storage_tallies.interval_start <= ? ORDER BY bucket_storage_tallies.interval_start DESC")

	var __values []any
	__values = append(__values, bucket_storage_tally_project_id.value(), bucket_storage_tally_bucket_name.value(), bucket_storage_tally_interval_start_greater_or_equal.value(), bucket_storage_tally_interval_start_less_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_storage_tally := &BucketStorageTally{}
				err = __rows.Scan(&bucket_storage_tally.BucketName, &bucket_storage_tally.ProjectId, &bucket_storage_tally.IntervalStart, &bucket_storage_tally.ProductId, &bucket_storage_tally.TotalBytes, &bucket_storage_tally.Inline, &bucket_storage_tally.Remote, &bucket_storage_tally.TotalSegmentsCount, &bucket_storage_tally.RemoteSegmentsCount, &bucket_storage_tally.InlineSegmentsCount, &bucket_storage_tally.ObjectCount, &bucket_storage_tally.MetadataSize)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) First_ReverificationAudits_By_NodeId_OrderBy_Asc_StreamId_Asc_Position(ctx context.Context,
	reverification_audits_node_id ReverificationAudits_NodeId_Field) (
	reverification_audits *ReverificationAudits, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reverification_audits.node_id, reverification_audits.stream_id, reverification_audits.position, reverification_audits.piece_num, reverification_audits.inserted_at, reverification_audits.last_attempt, reverification_audits.reverify_count FROM reverification_audits WHERE reverification_audits.node_id = ? ORDER BY reverification_audits.stream_id, reverification_audits.position LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, reverification_audits_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		reverification_audits, err = func() (reverification_audits *ReverificationAudits, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			reverification_audits = &ReverificationAudits{}
			err = __rows.Scan(&reverification_audits.NodeId, &reverification_audits.StreamId, &reverification_audits.Position, &reverification_audits.PieceNum, &reverification_audits.InsertedAt, &reverification_audits.LastAttempt, &reverification_audits.ReverifyCount)
			if err != nil {
				return nil, err
			}

			return reverification_audits, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return reverification_audits, nil
	}

}

func (obj *pgxcockroachImpl) Get_StripeCustomer_PackagePlan_StripeCustomer_PurchasedPackageAt_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field) (
	row *PackagePlan_PurchasedPackageAt_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.package_plan, stripe_customers.purchased_package_at FROM stripe_customers WHERE stripe_customers.user_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &PackagePlan_PurchasedPackageAt_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.PackagePlan, &row.PurchasedPackageAt)
	if err != nil {
		return (*PackagePlan_PurchasedPackageAt_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_StripeCustomer_CustomerId_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field) (
	row *CustomerId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.customer_id FROM stripe_customers WHERE stripe_customers.user_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &CustomerId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.CustomerId)
	if err != nil {
		return (*CustomerId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_StripeCustomer_UserId_By_CustomerId(ctx context.Context,
	stripe_customer_customer_id StripeCustomer_CustomerId_Field) (
	row *UserId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.user_id FROM stripe_customers WHERE stripe_customers.customer_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_customer_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserId)
	if err != nil {
		return (*UserId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_StripeCustomer_CustomerId_StripeCustomer_BillingCustomerId_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field) (
	row *CustomerId_BillingCustomerId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.customer_id, stripe_customers.billing_customer_id FROM stripe_customers WHERE stripe_customers.user_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &CustomerId_BillingCustomerId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.CustomerId, &row.BillingCustomerId)
	if err != nil {
		return (*CustomerId_BillingCustomerId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_BillingBalance_Balance_By_UserId(ctx context.Context,
	billing_balance_user_id BillingBalance_UserId_Field) (
	row *Balance_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_balances.balance FROM billing_balances WHERE billing_balances.user_id = ?")

	var __values []any
	__values = append(__values, billing_balance_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Balance_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Balance)
	if err != nil {
		return (*Balance_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_BillingTransaction_By_Id(ctx context.Context,
	billing_transaction_id BillingTransaction_Id_Field) (
	billing_transaction *BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.id = ?")

	var __values []any
	__values = append(__values, billing_transaction_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	billing_transaction = &BillingTransaction{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
	if err != nil {
		return (*BillingTransaction)(nil), obj.makeErr(err)
	}
	return billing_transaction, nil

}

func (obj *pgxcockroachImpl) Get_BillingTransaction_Metadata_By_Id(ctx context.Context,
	billing_transaction_id BillingTransaction_Id_Field) (
	row *Metadata_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.metadata FROM billing_transactions WHERE billing_transactions.id = ?")

	var __values []any
	__values = append(__values, billing_transaction_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Metadata_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Metadata)
	if err != nil {
		return (*Metadata_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) All_BillingTransaction_By_UserId_OrderBy_Desc_TxTimestamp(ctx context.Context,
	billing_transaction_user_id BillingTransaction_UserId_Field) (
	rows []*BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.user_id = ? ORDER BY billing_transactions.tx_timestamp DESC")

	var __values []any
	__values = append(__values, billing_transaction_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BillingTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				billing_transaction := &BillingTransaction{}
				err = __rows.Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, billing_transaction)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_BillingTransaction_By_UserId_And_Source_OrderBy_Desc_TxTimestamp(ctx context.Context,
	billing_transaction_user_id BillingTransaction_UserId_Field,
	billing_transaction_source BillingTransaction_Source_Field) (
	rows []*BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.user_id = ? AND billing_transactions.source = ? ORDER BY billing_transactions.tx_timestamp DESC")

	var __values []any
	__values = append(__values, billing_transaction_user_id.value(), billing_transaction_source.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BillingTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				billing_transaction := &BillingTransaction{}
				err = __rows.Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, billing_transaction)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) First_BillingTransaction_By_Source_And_Type_OrderBy_Desc_CreatedAt(ctx context.Context,
	billing_transaction_source BillingTransaction_Source_Field,
	billing_transaction_type BillingTransaction_Type_Field) (
	billing_transaction *BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.source = ? AND billing_transactions.type = ? ORDER BY billing_transactions.created_at DESC LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, billing_transaction_source.value(), billing_transaction_type.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		billing_transaction, err = func() (billing_transaction *BillingTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			billing_transaction = &BillingTransaction{}
			err = __rows.Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, &billing_transaction.Metadata, &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
			if err != nil {
				return nil, err
			}

			return billing_transaction, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return billing_transaction, nil
	}

}

func (obj *pgxcockroachImpl) Get_StorjscanWallet_UserId_By_WalletAddress(ctx context.Context,
	storjscan_wallet_wallet_address StorjscanWallet_WalletAddress_Field) (
	row *UserId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_wallets.user_id FROM storjscan_wallets WHERE storjscan_wallets.wallet_address = ? LIMIT 2")

	var __values []any
	__values = append(__values, storjscan_wallet_wallet_address.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *UserId_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			row = &UserId_Row{}
			err = __rows.Scan(&row.UserId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("StorjscanWallet_UserId_By_WalletAddress")
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *pgxcockroachImpl) Get_StorjscanWallet_WalletAddress_By_UserId(ctx context.Context,
	storjscan_wallet_user_id StorjscanWallet_UserId_Field) (
	row *WalletAddress_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_wallets.wallet_address FROM storjscan_wallets WHERE storjscan_wallets.user_id = ? LIMIT 2")

	var __values []any
	__values = append(__values, storjscan_wallet_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *WalletAddress_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			row = &WalletAddress_Row{}
			err = __rows.Scan(&row.WalletAddress)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("StorjscanWallet_WalletAddress_By_UserId")
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *pgxcockroachImpl) All_StorjscanWallet(ctx context.Context) (
	rows []*StorjscanWallet, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_wallets.user_id, storjscan_wallets.wallet_address, storjscan_wallets.created_at FROM storjscan_wallets")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StorjscanWallet, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storjscan_wallet := &StorjscanWallet{}
				err = __rows.Scan(&storjscan_wallet.UserId, &storjscan_wallet.WalletAddress, &storjscan_wallet.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storjscan_wallet)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_CoinpaymentsTransaction_By_UserId_OrderBy_Desc_CreatedAt(ctx context.Context,
	coinpayments_transaction_user_id CoinpaymentsTransaction_UserId_Field) (
	rows []*CoinpaymentsTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT coinpayments_transactions.id, coinpayments_transactions.user_id, coinpayments_transactions.address, coinpayments_transactions.amount_numeric, coinpayments_transactions.received_numeric, coinpayments_transactions.status, coinpayments_transactions.key, coinpayments_transactions.timeout, coinpayments_transactions.created_at FROM coinpayments_transactions WHERE coinpayments_transactions.user_id = ? ORDER BY coinpayments_transactions.created_at DESC")

	var __values []any
	__values = append(__values, coinpayments_transaction_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*CoinpaymentsTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				coinpayments_transaction := &CoinpaymentsTransaction{}
				err = __rows.Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, coinpayments_transaction)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_StripecoinpaymentsInvoiceProjectRecord_By_ProjectId_And_PeriodStart_And_PeriodEnd(ctx context.Context,
	stripecoinpayments_invoice_project_record_project_id StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field,
	stripecoinpayments_invoice_project_record_period_start StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field,
	stripecoinpayments_invoice_project_record_period_end StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field) (
	stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripecoinpayments_invoice_project_records.id, stripecoinpayments_invoice_project_records.project_id, stripecoinpayments_invoice_project_records.storage, stripecoinpayments_invoice_project_records.egress, stripecoinpayments_invoice_project_records.objects, stripecoinpayments_invoice_project_records.segments, stripecoinpayments_invoice_project_records.period_start, stripecoinpayments_invoice_project_records.period_end, stripecoinpayments_invoice_project_records.state, stripecoinpayments_invoice_project_records.created_at FROM stripecoinpayments_invoice_project_records WHERE stripecoinpayments_invoice_project_records.project_id = ? AND stripecoinpayments_invoice_project_records.period_start = ? AND stripecoinpayments_invoice_project_records.period_end = ?")

	var __values []any
	__values = append(__values, stripecoinpayments_invoice_project_record_project_id.value(), stripecoinpayments_invoice_project_record_period_start.value(), stripecoinpayments_invoice_project_record_period_end.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_invoice_project_record = &StripecoinpaymentsInvoiceProjectRecord{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
	if err != nil {
		return (*StripecoinpaymentsInvoiceProjectRecord)(nil), obj.makeErr(err)
	}
	return stripecoinpayments_invoice_project_record, nil

}

func (obj *pgxcockroachImpl) Get_StripecoinpaymentsTxConversionRate_By_TxId(ctx context.Context,
	stripecoinpayments_tx_conversion_rate_tx_id StripecoinpaymentsTxConversionRate_TxId_Field) (
	stripecoinpayments_tx_conversion_rate *StripecoinpaymentsTxConversionRate, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripecoinpayments_tx_conversion_rates.tx_id, stripecoinpayments_tx_conversion_rates.rate_numeric, stripecoinpayments_tx_conversion_rates.created_at FROM stripecoinpayments_tx_conversion_rates WHERE stripecoinpayments_tx_conversion_rates.tx_id = ?")

	var __values []any
	__values = append(__values, stripecoinpayments_tx_conversion_rate_tx_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_tx_conversion_rate = &StripecoinpaymentsTxConversionRate{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_tx_conversion_rate.TxId, &stripecoinpayments_tx_conversion_rate.RateNumeric, &stripecoinpayments_tx_conversion_rate.CreatedAt)
	if err != nil {
		return (*StripecoinpaymentsTxConversionRate)(nil), obj.makeErr(err)
	}
	return stripecoinpayments_tx_conversion_rate, nil

}

func (obj *pgxcockroachImpl) All_StorjscanPayment_OrderBy_Asc_ChainId_Asc_BlockNumber_Asc_LogIndex(ctx context.Context) (
	rows []*StorjscanPayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_payments.chain_id, storjscan_payments.block_hash, storjscan_payments.block_number, storjscan_payments.transaction, storjscan_payments.log_index, storjscan_payments.from_address, storjscan_payments.to_address, storjscan_payments.token_value, storjscan_payments.usd_value, storjscan_payments.status, storjscan_payments.block_timestamp, storjscan_payments.created_at FROM storjscan_payments ORDER BY storjscan_payments.chain_id, storjscan_payments.block_number, storjscan_payments.log_index")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StorjscanPayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storjscan_payment := &StorjscanPayment{}
				err = __rows.Scan(&storjscan_payment.ChainId, &storjscan_payment.BlockHash, &storjscan_payment.BlockNumber, &storjscan_payment.Transaction, &storjscan_payment.LogIndex, &storjscan_payment.FromAddress, &storjscan_payment.ToAddress, &storjscan_payment.TokenValue, &storjscan_payment.UsdValue, &storjscan_payment.Status, &storjscan_payment.BlockTimestamp, &storjscan_payment.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storjscan_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Limited_StorjscanPayment_By_ToAddress_OrderBy_Desc_ChainId_Desc_BlockNumber_Desc_LogIndex(ctx context.Context,
	storjscan_payment_to_address StorjscanPayment_ToAddress_Field,
	limit int, offset int64) (
	rows []*StorjscanPayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_payments.chain_id, storjscan_payments.block_hash, storjscan_payments.block_number, storjscan_payments.transaction, storjscan_payments.log_index, storjscan_payments.from_address, storjscan_payments.to_address, storjscan_payments.token_value, storjscan_payments.usd_value, storjscan_payments.status, storjscan_payments.block_timestamp, storjscan_payments.created_at FROM storjscan_payments WHERE storjscan_payments.to_address = ? ORDER BY storjscan_payments.chain_id DESC, storjscan_payments.block_number DESC, storjscan_payments.log_index DESC LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, storjscan_payment_to_address.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StorjscanPayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storjscan_payment := &StorjscanPayment{}
				err = __rows.Scan(&storjscan_payment.ChainId, &storjscan_payment.BlockHash, &storjscan_payment.BlockNumber, &storjscan_payment.Transaction, &storjscan_payment.LogIndex, &storjscan_payment.FromAddress, &storjscan_payment.ToAddress, &storjscan_payment.TokenValue, &storjscan_payment.UsdValue, &storjscan_payment.Status, &storjscan_payment.BlockTimestamp, &storjscan_payment.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storjscan_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) First_StorjscanPayment_BlockNumber_By_Status_And_ChainId_OrderBy_Desc_BlockNumber_Desc_LogIndex(ctx context.Context,
	storjscan_payment_status StorjscanPayment_Status_Field,
	storjscan_payment_chain_id StorjscanPayment_ChainId_Field) (
	row *BlockNumber_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_payments.block_number FROM storjscan_payments WHERE storjscan_payments.status = ? AND storjscan_payments.chain_id = ? ORDER BY storjscan_payments.block_number DESC, storjscan_payments.log_index DESC LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, storjscan_payment_status.value(), storjscan_payment_chain_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *BlockNumber_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			row = &BlockNumber_Row{}
			err = __rows.Scan(&row.BlockNumber)
			if err != nil {
				return nil, err
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *pgxcockroachImpl) All_ChangeHistory_By_UserId_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_user_id ChangeHistory_UserId_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE change_histories.user_id = ? ORDER BY change_histories.timestamp DESC")

	var __values []any
	__values = append(__values, change_history_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_ChangeHistory_By_UserId_And_ItemType_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_user_id ChangeHistory_UserId_Field,
	change_history_item_type ChangeHistory_ItemType_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE change_histories.user_id = ? AND change_histories.item_type = ? ORDER BY change_histories.timestamp DESC")

	var __values []any
	__values = append(__values, change_history_user_id.value(), change_history_item_type.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_ChangeHistory_By_ProjectId_And_ItemType_Not_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_project_id ChangeHistory_ProjectId_Field,
	change_history_item_type_not ChangeHistory_ItemType_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "change_histories.project_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE "), __cond_0, __sqlbundle_Literal(" AND change_histories.item_type != ? ORDER BY change_histories.timestamp DESC")}}

	var __values []any
	if !change_history_project_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, change_history_project_id.value())
	}
	__values = append(__values, change_history_item_type_not.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_ChangeHistory_By_ProjectId_And_ItemType_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_project_id ChangeHistory_ProjectId_Field,
	change_history_item_type ChangeHistory_ItemType_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "change_histories.project_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE "), __cond_0, __sqlbundle_Literal(" AND change_histories.item_type = ? ORDER BY change_histories.timestamp DESC")}}

	var __values []any
	if !change_history_project_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, change_history_project_id.value())
	}
	__values = append(__values, change_history_item_type.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_ChangeHistory_By_BucketName_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_bucket_name ChangeHistory_BucketName_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "change_histories.bucket_name", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE "), __cond_0, __sqlbundle_Literal(" ORDER BY change_histories.timestamp DESC")}}

	var __values []any
	if !change_history_bucket_name.isnull() {
		__cond_0.Null = false
		__values = append(__values, change_history_bucket_name.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, &change_history.Changes, &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_Domain_By_ProjectId_And_Subdomain(ctx context.Context,
	domain_project_id Domain_ProjectId_Field,
	domain_subdomain Domain_Subdomain_Field) (
	domain *Domain, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT domains.subdomain, domains.project_id, domains.prefix, domains.access_id, domains.created_by, domains.created_at FROM domains WHERE domains.project_id = ? AND domains.subdomain = ?")

	var __values []any
	__values = append(__values, domain_project_id.value(), domain_subdomain.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	domain = &Domain{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&domain.Subdomain, &domain.ProjectId, &domain.Prefix, &domain.AccessId, &domain.CreatedBy, &domain.CreatedAt)
	if err != nil {
		return (*Domain)(nil), obj.makeErr(err)
	}
	return domain, nil

}

func (obj *pgxcockroachImpl) All_Domain_Subdomain_By_ProjectId(ctx context.Context,
	domain_project_id Domain_ProjectId_Field) (
	rows []*Subdomain_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT domains.subdomain FROM domains WHERE domains.project_id = ?")

	var __values []any
	__values = append(__values, domain_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Subdomain_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Subdomain_Row{}
				err = __rows.Scan(&row.Subdomain)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_Entitlement_By_Scope(ctx context.Context,
	entitlement_scope Entitlement_Scope_Field) (
	entitlement *Entitlement, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT entitlements.scope, entitlements.features, entitlements.updated_at, entitlements.created_at FROM entitlements WHERE entitlements.scope = ?")

	var __values []any
	__values = append(__values, entitlement_scope.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	entitlement = &Entitlement{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&entitlement.Scope, &entitlement.Features, &entitlement.UpdatedAt, &entitlement.CreatedAt)
	if err != nil {
		return (*Entitlement)(nil), obj.makeErr(err)
	}
	return entitlement, nil

}

func (obj *pgxcockroachImpl) Get_PeerIdentity_By_NodeId(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field) (
	peer_identity *PeerIdentity, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT peer_identities.node_id, peer_identities.leaf_serial_number, peer_identities.chain, peer_identities.updated_at FROM peer_identities WHERE peer_identities.node_id = ?")

	var __values []any
	__values = append(__values, peer_identity_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	peer_identity = &PeerIdentity{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&peer_identity.NodeId, &peer_identity.LeafSerialNumber, &peer_identity.Chain, &peer_identity.UpdatedAt)
	if err != nil {
		return (*PeerIdentity)(nil), obj.makeErr(err)
	}
	return peer_identity, nil

}

func (obj *pgxcockroachImpl) Get_PeerIdentity_LeafSerialNumber_By_NodeId(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field) (
	row *LeafSerialNumber_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT peer_identities.leaf_serial_number FROM peer_identities WHERE peer_identities.node_id = ?")

	var __values []any
	__values = append(__values, peer_identity_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &LeafSerialNumber_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.LeafSerialNumber)
	if err != nil {
		return (*LeafSerialNumber_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field) (
	node *Node, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features FROM nodes WHERE nodes.id = ?")

	var __values []any
	__values = append(__values, node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node.Id, &node.Address, &node.LastNet, &node.LastIpPort, &node.CountryCode, &node.Protocol, &node.Email, &node.Wallet, &node.WalletFeatures, &node.FreeDisk, &node.PieceCount, &node.Major, &node.Minor, &node.Patch, &node.CommitHash, &node.ReleaseTimestamp, &node.Release, &node.Latency90, &node.VettedAt, &node.CreatedAt, &node.UpdatedAt, &node.LastContactSuccess, &node.LastContactFailure, &node.Disqualified, &node.DisqualificationReason, &node.UnknownAuditSuspended, &node.OfflineSuspended, &node.UnderReview, &node.ExitInitiatedAt, &node.ExitLoopCompletedAt, &node.ExitFinishedAt, &node.ExitSuccess, &node.Contained, &node.LastOfflineEmail, &node.LastSoftwareUpdateEmail, &node.NoiseProto, &node.NoisePublicKey, &node.DebounceLimit, &node.Features)
	if err != nil {
		return (*Node)(nil), obj.makeErr(err)
	}
	return node, nil

}

func (obj *pgxcockroachImpl) All_Node_Id(ctx context.Context) (
	rows []*Id_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id FROM nodes")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_Row{}
				err = __rows.Scan(&row.Id)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Paged_Node(ctx context.Context,
	limit int, start *Paged_Node_Continuation) (
	rows []*Node, next *Paged_Node_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features, nodes.id FROM nodes WHERE (nodes.id) > ? ORDER BY nodes.id LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features, nodes.id FROM nodes ORDER BY nodes.id LIMIT ?")

	var __values []any

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_id, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*Node, next *Paged_Node_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_Node_Continuation
			__continuation._set = true

			for __rows.Next() {
				node := &Node{}
				err = __rows.Scan(&node.Id, &node.Address, &node.LastNet, &node.LastIpPort, &node.CountryCode, &node.Protocol, &node.Email, &node.Wallet, &node.WalletFeatures, &node.FreeDisk, &node.PieceCount, &node.Major, &node.Minor, &node.Patch, &node.CommitHash, &node.ReleaseTimestamp, &node.Release, &node.Latency90, &node.VettedAt, &node.CreatedAt, &node.UpdatedAt, &node.LastContactSuccess, &node.LastContactFailure, &node.Disqualified, &node.DisqualificationReason, &node.UnknownAuditSuspended, &node.OfflineSuspended, &node.UnderReview, &node.ExitInitiatedAt, &node.ExitLoopCompletedAt, &node.ExitFinishedAt, &node.ExitSuccess, &node.Contained, &node.LastOfflineEmail, &node.LastSoftwareUpdateEmail, &node.NoiseProto, &node.NoisePublicKey, &node.DebounceLimit, &node.Features, &__continuation._value_id)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, node)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxcockroachImpl) All_Node_Id_Node_PieceCount_By_Disqualified_Is_Null_And_ExitInitiatedAt_Is_Null_And_ExitFinishedAt_Is_Null(ctx context.Context) (
	rows []*Id_PieceCount_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.piece_count FROM nodes WHERE nodes.disqualified is NULL AND nodes.exit_initiated_at is NULL AND nodes.exit_finished_at is NULL")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_PieceCount_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_PieceCount_Row{}
				err = __rows.Scan(&row.Id, &row.PieceCount)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Has_NodeApiVersion_By_Id_And_ApiVersion_GreaterOrEqual(ctx context.Context,
	node_api_version_id NodeApiVersion_Id_Field,
	node_api_version_api_version_greater_or_equal NodeApiVersion_ApiVersion_Field) (
	has bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT EXISTS( SELECT 1 FROM node_api_versions WHERE node_api_versions.id = ? AND node_api_versions.api_version >= ? )")

	var __values []any
	__values = append(__values, node_api_version_id.value(), node_api_version_api_version_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&has)
	if err != nil {
		return false, obj.makeErr(err)
	}
	return has, nil

}

func (obj *pgxcockroachImpl) Get_NodeEvent_By_Id(ctx context.Context,
	node_event_id NodeEvent_Id_Field) (
	node_event *NodeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_events.id, node_events.email, node_events.last_ip_port, node_events.node_id, node_events.event, node_events.created_at, node_events.last_attempted, node_events.email_sent FROM node_events WHERE node_events.id = ?")

	var __values []any
	__values = append(__values, node_event_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node_event = &NodeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
	if err != nil {
		return (*NodeEvent)(nil), obj.makeErr(err)
	}
	return node_event, nil

}

func (obj *pgxcockroachImpl) First_NodeEvent_By_Email_And_Event_OrderBy_Desc_CreatedAt(ctx context.Context,
	node_event_email NodeEvent_Email_Field,
	node_event_event NodeEvent_Event_Field) (
	node_event *NodeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_events.id, node_events.email, node_events.last_ip_port, node_events.node_id, node_events.event, node_events.created_at, node_events.last_attempted, node_events.email_sent FROM node_events WHERE node_events.email = ? AND node_events.event = ? ORDER BY node_events.created_at DESC LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, node_event_email.value(), node_event_event.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		node_event, err = func() (node_event *NodeEvent, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			node_event = &NodeEvent{}
			err = __rows.Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
			if err != nil {
				return nil, err
			}

			return node_event, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return node_event, nil
	}

}

func (obj *pgxcockroachImpl) All_NodeTags_By_NodeId(ctx context.Context,
	node_tags_node_id NodeTags_NodeId_Field) (
	rows []*NodeTags, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_tags.node_id, node_tags.name, node_tags.value, node_tags.signed_at, node_tags.signer FROM node_tags WHERE node_tags.node_id = ?")

	var __values []any
	__values = append(__values, node_tags_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*NodeTags, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				node_tags := &NodeTags{}
				err = __rows.Scan(&node_tags.NodeId, &node_tags.Name, &node_tags.Value, &node_tags.SignedAt, &node_tags.Signer)
				if err != nil {
					return nil, err
				}
				rows = append(rows, node_tags)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_NodeTags(ctx context.Context) (
	rows []*NodeTags, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_tags.node_id, node_tags.name, node_tags.value, node_tags.signed_at, node_tags.signer FROM node_tags")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*NodeTags, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				node_tags := &NodeTags{}
				err = __rows.Scan(&node_tags.NodeId, &node_tags.Name, &node_tags.Value, &node_tags.SignedAt, &node_tags.Signer)
				if err != nil {
					return nil, err
				}
				rows = append(rows, node_tags)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_StoragenodePaystub_By_NodeId_And_Period(ctx context.Context,
	storagenode_paystub_node_id StoragenodePaystub_NodeId_Field,
	storagenode_paystub_period StoragenodePaystub_Period_Field) (
	storagenode_paystub *StoragenodePaystub, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_paystubs.period, storagenode_paystubs.node_id, storagenode_paystubs.created_at, storagenode_paystubs.codes, storagenode_paystubs.usage_at_rest, storagenode_paystubs.usage_get, storagenode_paystubs.usage_put, storagenode_paystubs.usage_get_repair, storagenode_paystubs.usage_put_repair, storagenode_paystubs.usage_get_audit, storagenode_paystubs.comp_at_rest, storagenode_paystubs.comp_get, storagenode_paystubs.comp_put, storagenode_paystubs.comp_get_repair, storagenode_paystubs.comp_put_repair, storagenode_paystubs.comp_get_audit, storagenode_paystubs.surge_percent, storagenode_paystubs.held, storagenode_paystubs.owed, storagenode_paystubs.disposed, storagenode_paystubs.paid, storagenode_paystubs.distributed FROM storagenode_paystubs WHERE storagenode_paystubs.node_id = ? AND storagenode_paystubs.period = ?")

	var __values []any
	__values = append(__values, storagenode_paystub_node_id.value(), storagenode_paystub_period.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	storagenode_paystub = &StoragenodePaystub{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&storagenode_paystub.Period, &storagenode_paystub.NodeId, &storagenode_paystub.CreatedAt, &storagenode_paystub.Codes, &storagenode_paystub.UsageAtRest, &storagenode_paystub.UsageGet, &storagenode_paystub.UsagePut, &storagenode_paystub.UsageGetRepair, &storagenode_paystub.UsagePutRepair, &storagenode_paystub.UsageGetAudit, &storagenode_paystub.CompAtRest, &storagenode_paystub.CompGet, &storagenode_paystub.CompPut, &storagenode_paystub.CompGetRepair, &storagenode_paystub.CompPutRepair, &storagenode_paystub.CompGetAudit, &storagenode_paystub.SurgePercent, &storagenode_paystub.Held, &storagenode_paystub.Owed, &storagenode_paystub.Disposed, &storagenode_paystub.Paid, &storagenode_paystub.Distributed)
	if err != nil {
		return (*StoragenodePaystub)(nil), obj.makeErr(err)
	}
	return storagenode_paystub, nil

}

func (obj *pgxcockroachImpl) All_StoragenodePaystub_By_NodeId(ctx context.Context,
	storagenode_paystub_node_id StoragenodePaystub_NodeId_Field) (
	rows []*StoragenodePaystub, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_paystubs.period, storagenode_paystubs.node_id, storagenode_paystubs.created_at, storagenode_paystubs.codes, storagenode_paystubs.usage_at_rest, storagenode_paystubs.usage_get, storagenode_paystubs.usage_put, storagenode_paystubs.usage_get_repair, storagenode_paystubs.usage_put_repair, storagenode_paystubs.usage_get_audit, storagenode_paystubs.comp_at_rest, storagenode_paystubs.comp_get, storagenode_paystubs.comp_put, storagenode_paystubs.comp_get_repair, storagenode_paystubs.comp_put_repair, storagenode_paystubs.comp_get_audit, storagenode_paystubs.surge_percent, storagenode_paystubs.held, storagenode_paystubs.owed, storagenode_paystubs.disposed, storagenode_paystubs.paid, storagenode_paystubs.distributed FROM storagenode_paystubs WHERE storagenode_paystubs.node_id = ?")

	var __values []any
	__values = append(__values, storagenode_paystub_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePaystub, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_paystub := &StoragenodePaystub{}
				err = __rows.Scan(&storagenode_paystub.Period, &storagenode_paystub.NodeId, &storagenode_paystub.CreatedAt, &storagenode_paystub.Codes, &storagenode_paystub.UsageAtRest, &storagenode_paystub.UsageGet, &storagenode_paystub.UsagePut, &storagenode_paystub.UsageGetRepair, &storagenode_paystub.UsagePutRepair, &storagenode_paystub.UsageGetAudit, &storagenode_paystub.CompAtRest, &storagenode_paystub.CompGet, &storagenode_paystub.CompPut, &storagenode_paystub.CompGetRepair, &storagenode_paystub.CompPutRepair, &storagenode_paystub.CompGetAudit, &storagenode_paystub.SurgePercent, &storagenode_paystub.Held, &storagenode_paystub.Owed, &storagenode_paystub.Disposed, &storagenode_paystub.Paid, &storagenode_paystub.Distributed)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_paystub)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Limited_StoragenodePayment_By_NodeId_And_Period_OrderBy_Desc_Id(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field,
	storagenode_payment_period StoragenodePayment_Period_Field,
	limit int, offset int64) (
	rows []*StoragenodePayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_payments.id, storagenode_payments.created_at, storagenode_payments.node_id, storagenode_payments.period, storagenode_payments.amount, storagenode_payments.receipt, storagenode_payments.notes FROM storagenode_payments WHERE storagenode_payments.node_id = ? AND storagenode_payments.period = ? ORDER BY storagenode_payments.id DESC LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, storagenode_payment_node_id.value(), storagenode_payment_period.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_payment := &StoragenodePayment{}
				err = __rows.Scan(&storagenode_payment.Id, &storagenode_payment.CreatedAt, &storagenode_payment.NodeId, &storagenode_payment.Period, &storagenode_payment.Amount, &storagenode_payment.Receipt, &storagenode_payment.Notes)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_StoragenodePayment_By_NodeId(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field) (
	rows []*StoragenodePayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_payments.id, storagenode_payments.created_at, storagenode_payments.node_id, storagenode_payments.period, storagenode_payments.amount, storagenode_payments.receipt, storagenode_payments.notes FROM storagenode_payments WHERE storagenode_payments.node_id = ?")

	var __values []any
	__values = append(__values, storagenode_payment_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_payment := &StoragenodePayment{}
				err = __rows.Scan(&storagenode_payment.Id, &storagenode_payment.CreatedAt, &storagenode_payment.NodeId, &storagenode_payment.Period, &storagenode_payment.Amount, &storagenode_payment.Receipt, &storagenode_payment.Notes)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_StoragenodePayment_By_NodeId_And_Period(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field,
	storagenode_payment_period StoragenodePayment_Period_Field) (
	rows []*StoragenodePayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_payments.id, storagenode_payments.created_at, storagenode_payments.node_id, storagenode_payments.period, storagenode_payments.amount, storagenode_payments.receipt, storagenode_payments.notes FROM storagenode_payments WHERE storagenode_payments.node_id = ? AND storagenode_payments.period = ?")

	var __values []any
	__values = append(__values, storagenode_payment_node_id.value(), storagenode_payment_period.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_payment := &StoragenodePayment{}
				err = __rows.Scan(&storagenode_payment.Id, &storagenode_payment.CreatedAt, &storagenode_payment.NodeId, &storagenode_payment.Period, &storagenode_payment.Amount, &storagenode_payment.Receipt, &storagenode_payment.Notes)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_Reputation_By_Id(ctx context.Context,
	reputation_id Reputation_Id_Field) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta FROM reputations WHERE reputations.id = ?")

	var __values []any
	__values = append(__values, reputation_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if err != nil {
		return (*Reputation)(nil), obj.makeErr(err)
	}
	return reputation, nil

}

func (obj *pgxcockroachImpl) Get_OauthClient_By_Id(ctx context.Context,
	oauth_client_id OauthClient_Id_Field) (
	oauth_client *OauthClient, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT oauth_clients.id, oauth_clients.encrypted_secret, oauth_clients.redirect_url, oauth_clients.user_id, oauth_clients.app_name, oauth_clients.app_logo_url FROM oauth_clients WHERE oauth_clients.id = ?")

	var __values []any
	__values = append(__values, oauth_client_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	oauth_client = &OauthClient{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&oauth_client.Id, &oauth_client.EncryptedSecret, &oauth_client.RedirectUrl, &oauth_client.UserId, &oauth_client.AppName, &oauth_client.AppLogoUrl)
	if err != nil {
		return (*OauthClient)(nil), obj.makeErr(err)
	}
	return oauth_client, nil

}

func (obj *pgxcockroachImpl) Get_OauthCode_By_Code_And_ClaimedAt_Is_Null(ctx context.Context,
	oauth_code_code OauthCode_Code_Field) (
	oauth_code *OauthCode, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT oauth_codes.client_id, oauth_codes.user_id, oauth_codes.scope, oauth_codes.redirect_url, oauth_codes.challenge, oauth_codes.challenge_method, oauth_codes.code, oauth_codes.created_at, oauth_codes.expires_at, oauth_codes.claimed_at FROM oauth_codes WHERE oauth_codes.code = ? AND oauth_codes.claimed_at is NULL")

	var __values []any
	__values = append(__values, oauth_code_code.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	oauth_code = &OauthCode{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&oauth_code.ClientId, &oauth_code.UserId, &oauth_code.Scope, &oauth_code.RedirectUrl, &oauth_code.Challenge, &oauth_code.ChallengeMethod, &oauth_code.Code, &oauth_code.CreatedAt, &oauth_code.ExpiresAt, &oauth_code.ClaimedAt)
	if err != nil {
		return (*OauthCode)(nil), obj.makeErr(err)
	}
	return oauth_code, nil

}

func (obj *pgxcockroachImpl) Get_OauthToken_By_Kind_And_Token(ctx context.Context,
	oauth_token_kind OauthToken_Kind_Field,
	oauth_token_token OauthToken_Token_Field) (
	oauth_token *OauthToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT oauth_tokens.client_id, oauth_tokens.user_id, oauth_tokens.scope, oauth_tokens.kind, oauth_tokens.token, oauth_tokens.created_at, oauth_tokens.expires_at FROM oauth_tokens WHERE oauth_tokens.kind = ? AND oauth_tokens.token = ?")

	var __values []any
	__values = append(__values, oauth_token_kind.value(), oauth_token_token.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	oauth_token = &OauthToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&oauth_token.ClientId, &oauth_token.UserId, &oauth_token.Scope, &oauth_token.Kind, &oauth_token.Token, &oauth_token.CreatedAt, &oauth_token.ExpiresAt)
	if err != nil {
		return (*OauthToken)(nil), obj.makeErr(err)
	}
	return oauth_token, nil

}

func (obj *pgxcockroachImpl) Get_Project_PassphraseEnc_Project_PassphraseEncKeyId_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *PassphraseEnc_PassphraseEncKeyId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.passphrase_enc, projects.passphrase_enc_key_id FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &PassphraseEnc_PassphraseEncKeyId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.PassphraseEnc, &row.PassphraseEncKeyId)
	if err != nil {
		return (*PassphraseEnc_PassphraseEncKeyId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_Salt_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *Salt_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.salt FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Salt_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Salt)
	if err != nil {
		return (*Salt_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_By_PublicId(ctx context.Context,
	project_public_id Project_PublicId_Field) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.public_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE "), __cond_0, __sqlbundle_Literal(" LIMIT 2")}}

	var __values []any
	if !project_public_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_public_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		project, err = func() (project *Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			project = &Project{}
			err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return project, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("Project_By_PublicId")
			}
			return nil, obj.makeErr(err)
		}
		return project, nil
	}

}

func (obj *pgxcockroachImpl) Get_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
	if err != nil {
		return (*Project)(nil), obj.makeErr(err)
	}
	return project, nil

}

func (obj *pgxcockroachImpl) Get_Project_By__Id_Or_PublicId(ctx context.Context,
	project_id Project_Id_Field,
	project_public_id Project_PublicId_Field) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.public_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE (projects.id = ? OR "), __cond_0, __sqlbundle_Literal(") LIMIT 2")}}

	var __values []any
	__values = append(__values, project_id.value())
	if !project_public_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_public_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		project, err = func() (project *Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			project = &Project{}
			err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return project, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("Project_By__Id_Or_PublicId")
			}
			return nil, obj.makeErr(err)
		}
		return project, nil
	}

}

func (obj *pgxcockroachImpl) Get_Project_UsageLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UsageLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.usage_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UsageLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UsageLimit)
	if err != nil {
		return (*UsageLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_BandwidthLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *BandwidthLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.bandwidth_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &BandwidthLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.BandwidthLimit)
	if err != nil {
		return (*BandwidthLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_UserSpecifiedUsageLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UserSpecifiedUsageLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.user_specified_usage_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserSpecifiedUsageLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserSpecifiedUsageLimit)
	if err != nil {
		return (*UserSpecifiedUsageLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_UserSpecifiedBandwidthLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UserSpecifiedBandwidthLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.user_specified_bandwidth_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserSpecifiedBandwidthLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserSpecifiedBandwidthLimit)
	if err != nil {
		return (*UserSpecifiedBandwidthLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_SegmentLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *SegmentLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.segment_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &SegmentLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.SegmentLimit)
	if err != nil {
		return (*SegmentLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_MaxBuckets_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *MaxBuckets_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.max_buckets FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &MaxBuckets_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.MaxBuckets)
	if err != nil {
		return (*MaxBuckets_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_BandwidthLimit_Project_UserSpecifiedBandwidthLimit_Project_UsageLimit_Project_UserSpecifiedUsageLimit_Project_SegmentLimit_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.bandwidth_limit, projects.user_specified_bandwidth_limit, projects.usage_limit, projects.user_specified_usage_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.BandwidthLimit, &row.UserSpecifiedBandwidthLimit, &row.UsageLimit, &row.UserSpecifiedUsageLimit, &row.SegmentLimit, &row.RateLimit, &row.BurstLimit, &row.RateLimitHead, &row.BurstLimitHead, &row.RateLimitGet, &row.BurstLimitGet, &row.RateLimitPut, &row.BurstLimitPut, &row.RateLimitList, &row.BurstLimitList, &row.RateLimitDel, &row.BurstLimitDel)
	if err != nil {
		return (*BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_DefaultVersioning_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *DefaultVersioning_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.default_versioning FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &DefaultVersioning_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.DefaultVersioning)
	if err != nil {
		return (*DefaultVersioning_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_UserAgent_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UserAgent_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.user_agent FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserAgent_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserAgent)
	if err != nil {
		return (*UserAgent_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Project_PublicId_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *PublicId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.public_id FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &PublicId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.PublicId)
	if err != nil {
		return (*PublicId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) All_Project(ctx context.Context) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_Project_By_CreatedAt_Less_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_created_at_less Project_CreatedAt_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.created_at < ? ORDER BY projects.created_at")

	var __values []any
	__values = append(__values, project_created_at_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_Project_By_OwnerId_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_owner_id Project_OwnerId_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.owner_id = ? ORDER BY projects.created_at")

	var __values []any
	__values = append(__values, project_owner_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_Project_By_OwnerId_And_Status_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_owner_id Project_OwnerId_Field,
	project_status Project_Status_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.status", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.owner_id = ? AND "), __cond_0, __sqlbundle_Literal(" ORDER BY projects.created_at")}}

	var __values []any
	__values = append(__values, project_owner_id.value())
	if !project_status.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_status.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_Project_By_ProjectMember_MemberId_OrderBy_Asc_Project_Name(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects  JOIN project_members ON projects.id = project_members.project_id WHERE project_members.member_id = ? ORDER BY projects.name")

	var __values []any
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Limited_Project_By_CreatedAt_Less_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_created_at_less Project_CreatedAt_Field,
	limit int, offset int64) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.created_at < ? ORDER BY projects.created_at LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, project_created_at_less.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Limited_Project_Id_Project_PublicId_Project_OwnerId_By_Status_And_StatusUpdatedAt_Less_OrderBy_Asc_StatusUpdatedAt(ctx context.Context,
	project_status Project_Status_Field,
	project_status_updated_at_less Project_StatusUpdatedAt_Field,
	limit int, offset int64) (
	rows []*Id_PublicId_OwnerId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.status", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.owner_id FROM projects WHERE "), __cond_0, __sqlbundle_Literal(" AND projects.status_updated_at < ? ORDER BY projects.status_updated_at LIMIT ? OFFSET ?")}}

	var __values []any
	if !project_status.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_status.value())
	}
	__values = append(__values, project_status_updated_at_less.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_PublicId_OwnerId_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_PublicId_OwnerId_Row{}
				err = __rows.Scan(&row.Id, &row.PublicId, &row.OwnerId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	project_member *ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.role, project_members.created_at FROM project_members WHERE project_members.member_id = ? AND project_members.project_id = ?")

	var __values []any
	__values = append(__values, project_member_member_id.value(), project_member_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_member = &ProjectMember{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
	if err != nil {
		return (*ProjectMember)(nil), obj.makeErr(err)
	}
	return project_member, nil

}

func (obj *pgxcockroachImpl) All_ProjectMember_By_MemberId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.role, project_members.created_at FROM project_members WHERE project_members.member_id = ?")

	var __values []any
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectMember, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_member := &ProjectMember{}
				err = __rows.Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_member)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field) (
	project_invitation *ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations WHERE project_invitations.project_id = ? AND project_invitations.email = ?")

	var __values []any
	__values = append(__values, project_invitation_project_id.value(), project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_invitation = &ProjectInvitation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
	if err != nil {
		return (*ProjectInvitation)(nil), obj.makeErr(err)
	}
	return project_invitation, nil

}

func (obj *pgxcockroachImpl) All_ProjectInvitation_By_Email(ctx context.Context,
	project_invitation_email ProjectInvitation_Email_Field) (
	rows []*ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations WHERE project_invitations.email = ?")

	var __values []any
	__values = append(__values, project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectInvitation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_invitation := &ProjectInvitation{}
				err = __rows.Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_invitation)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_ProjectInvitation_By_Project_Status_And_ProjectInvitation_Email(ctx context.Context,
	project_status Project_Status_Field,
	project_invitation_email ProjectInvitation_Email_Field) (
	rows []*ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.status", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations  JOIN projects ON project_invitations.project_id = projects.id WHERE "), __cond_0, __sqlbundle_Literal(" AND project_invitations.email = ?")}}

	var __values []any
	if !project_status.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_status.value())
	}
	__values = append(__values, project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectInvitation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_invitation := &ProjectInvitation{}
				err = __rows.Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_invitation)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_ProjectInvitation_By_ProjectId(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field) (
	rows []*ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations WHERE project_invitations.project_id = ?")

	var __values []any
	__values = append(__values, project_invitation_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectInvitation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_invitation := &ProjectInvitation{}
				err = __rows.Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_invitation)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_ApiKey_Project_PublicId_By_ApiKey_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	row *ApiKey_Project_PublicId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version, projects.public_id FROM projects  JOIN api_keys ON projects.id = api_keys.project_id WHERE api_keys.id = ?")

	var __values []any
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ApiKey_Project_PublicId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ApiKey.Id, &row.ApiKey.ProjectId, &row.ApiKey.Head, &row.ApiKey.Name, &row.ApiKey.Secret, &row.ApiKey.UserAgent, &row.ApiKey.CreatedAt, &row.ApiKey.CreatedBy, &row.ApiKey.Version, &row.Project_PublicId)
	if err != nil {
		return (*ApiKey_Project_PublicId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_By_ApiKey_Head(ctx context.Context,
	api_key_head ApiKey_Head_Field) (
	row *ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version, projects.public_id, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.segment_limit, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit FROM projects  JOIN api_keys ON projects.id = api_keys.project_id WHERE api_keys.head = ?")

	var __values []any
	__values = append(__values, api_key_head.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ApiKey.Id, &row.ApiKey.ProjectId, &row.ApiKey.Head, &row.ApiKey.Name, &row.ApiKey.Secret, &row.ApiKey.UserAgent, &row.ApiKey.CreatedAt, &row.ApiKey.CreatedBy, &row.ApiKey.Version, &row.Project_PublicId, &row.Project_RateLimit, &row.Project_BurstLimit, &row.Project_RateLimitHead, &row.Project_BurstLimitHead, &row.Project_RateLimitGet, &row.Project_BurstLimitGet, &row.Project_RateLimitPut, &row.Project_BurstLimitPut, &row.Project_RateLimitList, &row.Project_BurstLimitList, &row.Project_RateLimitDel, &row.Project_BurstLimitDel, &row.Project_SegmentLimit, &row.Project_UsageLimit, &row.Project_BandwidthLimit, &row.Project_UserSpecifiedUsageLimit, &row.Project_UserSpecifiedBandwidthLimit)
	if err != nil {
		return (*ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_ApiKey_Project_PublicId_By_ApiKey_Name_And_ApiKey_ProjectId(ctx context.Context,
	api_key_name ApiKey_Name_Field,
	api_key_project_id ApiKey_ProjectId_Field) (
	row *ApiKey_Project_PublicId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version, projects.public_id FROM projects  JOIN api_keys ON projects.id = api_keys.project_id WHERE api_keys.name = ? AND api_keys.project_id = ?")

	var __values []any
	__values = append(__values, api_key_name.value(), api_key_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ApiKey_Project_PublicId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ApiKey.Id, &row.ApiKey.ProjectId, &row.ApiKey.Head, &row.ApiKey.Name, &row.ApiKey.Secret, &row.ApiKey.UserAgent, &row.ApiKey.CreatedAt, &row.ApiKey.CreatedBy, &row.ApiKey.Version, &row.Project_PublicId)
	if err != nil {
		return (*ApiKey_Project_PublicId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_ApiKeyTail_By_Tail(ctx context.Context,
	api_key_tail_tail ApiKeyTail_Tail_Field) (
	api_key_tail *ApiKeyTail, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_key_tails.root_key_id, api_key_tails.tail, api_key_tails.parent_tail, api_key_tails.caveat, api_key_tails.last_used FROM api_key_tails WHERE api_key_tails.tail = ?")

	var __values []any
	__values = append(__values, api_key_tail_tail.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key_tail = &ApiKeyTail{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&api_key_tail.RootKeyId, &api_key_tail.Tail, &api_key_tail.ParentTail, &api_key_tail.Caveat, &api_key_tail.LastUsed)
	if err != nil {
		return (*ApiKeyTail)(nil), obj.makeErr(err)
	}
	return api_key_tail, nil

}

func (obj *pgxcockroachImpl) Get_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err != nil {
		return (*BucketMetainfo)(nil), obj.makeErr(err)
	}
	return bucket_metainfo, nil

}

func (obj *pgxcockroachImpl) Get_BucketMetainfo_Tags_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Tags_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.tags FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Tags_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Tags)
	if err != nil {
		return (*Tags_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_BucketMetainfo_CreatedBy_BucketMetainfo_CreatedAt_BucketMetainfo_Placement_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *CreatedBy_CreatedAt_Placement_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.created_by, bucket_metainfos.created_at, bucket_metainfos.placement FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &CreatedBy_CreatedAt_Placement_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.CreatedBy, &row.CreatedAt, &row.Placement)
	if err != nil {
		return (*CreatedBy_CreatedAt_Placement_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_BucketMetainfo_Placement_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Placement_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.placement FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Placement_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Placement)
	if err != nil {
		return (*Placement_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_BucketMetainfo_UserAgent_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *UserAgent_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.user_agent FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserAgent_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserAgent)
	if err != nil {
		return (*UserAgent_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_BucketMetainfo_Versioning_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Versioning_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.versioning FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Versioning_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Versioning)
	if err != nil {
		return (*Versioning_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_BucketMetainfo_ObjectLockEnabled_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *ObjectLockEnabled_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.object_lock_enabled FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ObjectLockEnabled_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ObjectLockEnabled)
	if err != nil {
		return (*ObjectLockEnabled_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_BucketMetainfo_ObjectLockEnabled_BucketMetainfo_DefaultRetentionMode_BucketMetainfo_DefaultRetentionDays_BucketMetainfo_DefaultRetentionYears_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ObjectLockEnabled, &row.DefaultRetentionMode, &row.DefaultRetentionDays, &row.DefaultRetentionYears)
	if err != nil {
		return (*ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_Bucket(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.created_by, bucket_metainfos.user_agent, bucket_metainfos.created_at, bucket_metainfos.placement, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Id, &row.CreatedBy, &row.UserAgent, &row.CreatedAt, &row.Placement, &row.Versioning, &row.ObjectLockEnabled, &row.DefaultRetentionMode, &row.DefaultRetentionDays, &row.DefaultRetentionYears)
	if err != nil {
		return (*Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Has_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	has bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT EXISTS( SELECT 1 FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? )")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&has)
	if err != nil {
		return false, obj.makeErr(err)
	}
	return has, nil

}

func (obj *pgxcockroachImpl) Limited_BucketMetainfo_By_ProjectId_And_Name_GreaterOrEqual_OrderBy_Asc_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name_greater_or_equal BucketMetainfo_Name_Field,
	limit int, offset int64) (
	rows []*BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name >= ? ORDER BY bucket_metainfos.name LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name_greater_or_equal.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMetainfo, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_metainfo := &BucketMetainfo{}
				err = __rows.Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_metainfo)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Limited_BucketMetainfo_By_ProjectId_And_Name_Greater_OrderBy_Asc_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name_greater BucketMetainfo_Name_Field,
	limit int, offset int64) (
	rows []*BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name > ? ORDER BY bucket_metainfos.name LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name_greater.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMetainfo, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_metainfo := &BucketMetainfo{}
				err = __rows.Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_metainfo)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Count_BucketMetainfo_Name_By_ProjectId(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT COUNT(*) FROM bucket_metainfos WHERE bucket_metainfos.project_id = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&count)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Count_BucketMetainfo_Name_By_ProjectId_And_ObjectLockEnabled_Equal_True(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT COUNT(*) FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.object_lock_enabled = true")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&count)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name(ctx context.Context,
	limit int, start *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation) (
	rows []*ProjectId_Name_Row, next *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.project_id, bucket_metainfos.name FROM bucket_metainfos WHERE (bucket_metainfos.project_id, bucket_metainfos.name) > (?, ?) ORDER BY bucket_metainfos.project_id, bucket_metainfos.name LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.project_id, bucket_metainfos.name FROM bucket_metainfos ORDER BY bucket_metainfos.project_id, bucket_metainfos.name LIMIT ?")

	var __values []any

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_project_id, start._value_name, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*ProjectId_Name_Row, next *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation
			__continuation._set = true

			for __rows.Next() {
				row := &ProjectId_Name_Row{}
				err = __rows.Scan(&row.ProjectId, &row.Name, &__continuation._value_project_id, &__continuation._value_name)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, row)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxcockroachImpl) Get_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field) (
	value_attribution *ValueAttribution, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT value_attributions.project_id, value_attributions.bucket_name, value_attributions.user_agent, value_attributions.placement, value_attributions.last_updated FROM value_attributions WHERE value_attributions.project_id = ? AND value_attributions.bucket_name = ?")

	var __values []any
	__values = append(__values, value_attribution_project_id.value(), value_attribution_bucket_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	value_attribution = &ValueAttribution{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
	if err != nil {
		return (*ValueAttribution)(nil), obj.makeErr(err)
	}
	return value_attribution, nil

}

func (obj *pgxcockroachImpl) Get_BucketMigration_By_Id(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field) (
	bucket_migration *BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at FROM bucket_migrations WHERE bucket_migrations.id = ?")

	var __values []any
	__values = append(__values, bucket_migration_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_migration = &BucketMigration{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
	if err != nil {
		return (*BucketMigration)(nil), obj.makeErr(err)
	}
	return bucket_migration, nil

}

func (obj *pgxcockroachImpl) All_BucketMigration_By_ProjectId_And_BucketName_OrderBy_Desc_CreatedAt(ctx context.Context,
	bucket_migration_project_id BucketMigration_ProjectId_Field,
	bucket_migration_bucket_name BucketMigration_BucketName_Field) (
	rows []*BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at FROM bucket_migrations WHERE bucket_migrations.project_id = ? AND bucket_migrations.bucket_name = ? ORDER BY bucket_migrations.created_at DESC")

	var __values []any
	__values = append(__values, bucket_migration_project_id.value(), bucket_migration_bucket_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMigration, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_migration := &BucketMigration{}
				err = __rows.Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_migration)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Limited_BucketMigration_By_State_OrderBy_Asc_CreatedAt(ctx context.Context,
	bucket_migration_state BucketMigration_State_Field,
	limit int, offset int64) (
	rows []*BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at FROM bucket_migrations WHERE bucket_migrations.state = ? ORDER BY bucket_migrations.created_at LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, bucket_migration_state.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMigration, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_migration := &BucketMigration{}
				err = __rows.Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_migration)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_RestApiKey_By_Id(ctx context.Context,
	rest_api_key_id RestApiKey_Id_Field) (
	rest_api_key *RestApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT rest_api_keys.id, rest_api_keys.user_id, rest_api_keys.token, rest_api_keys.name, rest_api_keys.expires_at, rest_api_keys.created_at FROM rest_api_keys WHERE rest_api_keys.id = ?")

	var __values []any
	__values = append(__values, rest_api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	rest_api_key = &RestApiKey{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&rest_api_key.Id, &rest_api_key.UserId, &rest_api_key.Token, &rest_api_key.Name, &rest_api_key.ExpiresAt, &rest_api_key.CreatedAt)
	if err != nil {
		return (*RestApiKey)(nil), obj.makeErr(err)
	}
	return rest_api_key, nil

}

func (obj *pgxcockroachImpl) Get_RestApiKey_By_Token(ctx context.Context,
	rest_api_key_token RestApiKey_Token_Field) (
	rest_api_key *RestApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT rest_api_keys.id, rest_api_keys.user_id, rest_api_keys.token, rest_api_keys.name, rest_api_keys.expires_at, rest_api_keys.created_at FROM rest_api_keys WHERE rest_api_keys.token = ?")

	var __values []any
	__values = append(__values, rest_api_key_token.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	rest_api_key = &RestApiKey{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&rest_api_key.Id, &rest_api_key.UserId, &rest_api_key.Token, &rest_api_key.Name, &rest_api_key.ExpiresAt, &rest_api_key.CreatedAt)
	if err != nil {
		return (*RestApiKey)(nil), obj.makeErr(err)
	}
	return rest_api_key, nil

}

func (obj *pgxcockroachImpl) All_RestApiKey_By_UserId(ctx context.Context,
	rest_api_key_user_id RestApiKey_UserId_Field) (
	rows []*RestApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT rest_api_keys.id, rest_api_keys.user_id, rest_api_keys.token, rest_api_keys.name, rest_api_keys.expires_at, rest_api_keys.created_at FROM rest_api_keys WHERE rest_api_keys.user_id = ?")

	var __values []any
	__values = append(__values, rest_api_key_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*RestApiKey, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				rest_api_key := &RestApiKey{}
				err = __rows.Scan(&rest_api_key.Id, &rest_api_key.UserId, &rest_api_key.Token, &rest_api_key.Name, &rest_api_key.ExpiresAt, &rest_api_key.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, rest_api_key)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_User(ctx context.Context) (
	rows []*User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				user := &User{}
				err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, user)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_User_By_NormalizedEmail(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field) (
	rows []*User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ?")

	var __values []any
	__values = append(__values, user_normalized_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				user := &User{}
				err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, user)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) All_User_By_NormalizedEmail_And_TenantId(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field,
	user_tenant_id User_TenantId_Field) (
	rows []*User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "users.tenant_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ? AND "), __cond_0}}

	var __values []any
	__values = append(__values, user_normalized_email.value())
	if !user_tenant_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_tenant_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				user := &User{}
				err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, user)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_User_By_NormalizedEmail_And_Status_Not_Number(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ? AND users.status != 0 LIMIT 2")

	var __values []any
	__values = append(__values, user_normalized_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		user, err = func() (user *User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			user = &User{}
			err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return user, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("User_By_NormalizedEmail_And_Status_Not_Number")
			}
			return nil, obj.makeErr(err)
		}
		return user, nil
	}

}

func (obj *pgxcockroachImpl) Get_User_By_NormalizedEmail_And_TenantId_And_Status_Not_Number(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field,
	user_tenant_id User_TenantId_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "users.tenant_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ? AND "), __cond_0, __sqlbundle_Literal(" AND users.status != 0 LIMIT 2")}}

	var __values []any
	__values = append(__values, user_normalized_email.value())
	if !user_tenant_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_tenant_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		user, err = func() (user *User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			user = &User{}
			err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return user, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("User_By_NormalizedEmail_And_TenantId_And_Status_Not_Number")
			}
			return nil, obj.makeErr(err)
		}
		return user, nil
	}

}

func (obj *pgxcockroachImpl) Get_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
	if err != nil {
		return (*User)(nil), obj.makeErr(err)
	}
	return user, nil

}

func (obj *pgxcockroachImpl) Get_User_ProjectLimit_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *ProjectLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.project_limit FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ProjectLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ProjectLimit)
	if err != nil {
		return (*ProjectLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_User_Kind_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *Kind_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.kind FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Kind_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Kind)
	if err != nil {
		return (*Kind_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_User_UpgradeTime_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *UpgradeTime_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.upgrade_time FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UpgradeTime_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UpgradeTime)
	if err != nil {
		return (*UpgradeTime_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Get_User_By_ExternalId(ctx context.Context,
	user_external_id User_ExternalId_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "users.external_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE "), __cond_0, __sqlbundle_Literal(" LIMIT 2")}}

	var __values []any
	if !user_external_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_external_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		user, err = func() (user *User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			user = &User{}
			err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return user, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("User_By_ExternalId")
			}
			return nil, obj.makeErr(err)
		}
		return user, nil
	}

}

func (obj *pgxcockroachImpl) Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event(ctx context.Context,
	user_status_not User_Status_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field,
	limit int, start *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation) (
	rows []*AccountFreezeEvent, next *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at, account_freeze_events.user_id, account_freeze_events.event FROM account_freeze_events  JOIN users ON account_freeze_events.user_id = users.id WHERE users.status != ? AND account_freeze_events.event = ? AND (account_freeze_events.user_id, account_freeze_events.event) > (?, ?) ORDER BY account_freeze_events.user_id, account_freeze_events.event LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at, account_freeze_events.user_id, account_freeze_events.event FROM account_freeze_events  JOIN users ON account_freeze_events.user_id = users.id WHERE users.status != ? AND account_freeze_events.event = ? ORDER BY account_freeze_events.user_id, account_freeze_events.event LIMIT ?")

	var __values []any
	__values = append(__values, user_status_not.value(), account_freeze_event_event.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_user_id, start._value_event, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*AccountFreezeEvent, next *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation
			__continuation._set = true

			for __rows.Next() {
				account_freeze_event := &AccountFreezeEvent{}
				err = __rows.Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt, &__continuation._value_user_id, &__continuation._value_event)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, account_freeze_event)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *pgxcockroachImpl) Get_User_ProjectStorageLimit_User_ProjectBandwidthLimit_User_ProjectSegmentLimit_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.project_storage_limit, users.project_bandwidth_limit, users.project_segment_limit FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ProjectStorageLimit, &row.ProjectBandwidthLimit, &row.ProjectSegmentLimit)
	if err != nil {
		return (*ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) Count_User_By_Status(ctx context.Context,
	user_status User_Status_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT COUNT(*) FROM users WHERE users.status = ?")

	var __values []any
	__values = append(__values, user_status.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&count)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Limited_User_Id_User_Email_User_FullName_By_Status(ctx context.Context,
	user_status User_Status_Field,
	limit int, offset int64) (
	rows []*Id_Email_FullName_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.email, users.full_name FROM users WHERE users.status = ? LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, user_status.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_Email_FullName_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_Email_FullName_Row{}
				err = __rows.Scan(&row.Id, &row.Email, &row.FullName)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_User_Status_By_Project_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *Status_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.status FROM users  JOIN projects ON users.id = projects.owner_id WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Status_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Status)
	if err != nil {
		return (*Status_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *pgxcockroachImpl) All_WebappSession_By_UserId(ctx context.Context,
	webapp_session_user_id WebappSession_UserId_Field) (
	rows []*WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at FROM webapp_sessions WHERE webapp_sessions.user_id = ?")

	var __values []any
	__values = append(__values, webapp_session_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*WebappSession, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				webapp_session := &WebappSession{}
				err = __rows.Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, webapp_session)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_WebappSession_By_Id(ctx context.Context,
	webapp_session_id WebappSession_Id_Field) (
	webapp_session *WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at FROM webapp_sessions WHERE webapp_sessions.id = ?")

	var __values []any
	__values = append(__values, webapp_session_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	webapp_session = &WebappSession{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
	if err != nil {
		return (*WebappSession)(nil), obj.makeErr(err)
	}
	return webapp_session, nil

}

func (obj *pgxcockroachImpl) Get_RegistrationToken_By_Secret(ctx context.Context,
	registration_token_secret RegistrationToken_Secret_Field) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at FROM registration_tokens WHERE registration_tokens.secret = ?")

	var __values []any
	__values = append(__values, registration_token_secret.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err != nil {
		return (*RegistrationToken)(nil), obj.makeErr(err)
	}
	return registration_token, nil

}

func (obj *pgxcockroachImpl) Get_RegistrationToken_By_OwnerId(ctx context.Context,
	registration_token_owner_id RegistrationToken_OwnerId_Field) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "registration_tokens.owner_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at FROM registration_tokens WHERE "), __cond_0}}

	var __values []any
	if !registration_token_owner_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, registration_token_owner_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err != nil {
		return (*RegistrationToken)(nil), obj.makeErr(err)
	}
	return registration_token, nil

}

func (obj *pgxcockroachImpl) Get_ResetPasswordToken_By_Secret(ctx context.Context,
	reset_password_token_secret ResetPasswordToken_Secret_Field) (
	reset_password_token *ResetPasswordToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reset_password_tokens.secret, reset_password_tokens.owner_id, reset_password_tokens.created_at FROM reset_password_tokens WHERE reset_password_tokens.secret = ?")

	var __values []any
	__values = append(__values, reset_password_token_secret.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reset_password_token = &ResetPasswordToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
	if err != nil {
		return (*ResetPasswordToken)(nil), obj.makeErr(err)
	}
	return reset_password_token, nil

}

func (obj *pgxcockroachImpl) Get_ResetPasswordToken_By_OwnerId(ctx context.Context,
	reset_password_token_owner_id ResetPasswordToken_OwnerId_Field) (
	reset_password_token *ResetPasswordToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reset_password_tokens.secret, reset_password_tokens.owner_id, reset_password_tokens.created_at FROM reset_password_tokens WHERE reset_password_tokens.owner_id = ?")

	var __values []any
	__values = append(__values, reset_password_token_owner_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reset_password_token = &ResetPasswordToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
	if err != nil {
		return (*ResetPasswordToken)(nil), obj.makeErr(err)
	}
	return reset_password_token, nil

}

func (obj *pgxcockroachImpl) Get_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field) (
	account_freeze_event *AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at FROM account_freeze_events WHERE account_freeze_events.user_id = ? AND account_freeze_events.event = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value(), account_freeze_event_event.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	account_freeze_event = &AccountFreezeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
	if err != nil {
		return (*AccountFreezeEvent)(nil), obj.makeErr(err)
	}
	return account_freeze_event, nil

}

func (obj *pgxcockroachImpl) All_AccountFreezeEvent_By_UserId(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field) (
	rows []*AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at FROM account_freeze_events WHERE account_freeze_events.user_id = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*AccountFreezeEvent, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				account_freeze_event := &AccountFreezeEvent{}
				err = __rows.Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, account_freeze_event)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *pgxcockroachImpl) Get_UserSettings_By_UserId(ctx context.Context,
	user_settings_user_id UserSettings_UserId_Field) (
	user_settings *UserSettings, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT user_settings.user_id, user_settings.session_minutes, user_settings.passphrase_prompt, user_settings.onboarding_start, user_settings.onboarding_end, user_settings.onboarding_step, user_settings.notice_dismissal FROM user_settings WHERE user_settings.user_id = ?")

	var __values []any
	__values = append(__values, user_settings_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user_settings = &UserSettings{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user_settings.UserId, &user_settings.SessionMinutes, &user_settings.PassphrasePrompt, &user_settings.OnboardingStart, &user_settings.OnboardingEnd, &user_settings.OnboardingStep, &user_settings.NoticeDismissal)
	if err != nil {
		return (*UserSettings)(nil), obj.makeErr(err)
	}
	return user_settings, nil

}

func (obj *pgxcockroachImpl) UpdateNoReturn_AccountingTimestamps_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	update AccountingTimestamps_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE accounting_timestamps SET "), __sets, __sqlbundle_Literal(" WHERE accounting_timestamps.name = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Value._set {
		__values = append(__values, update.Value.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("value = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, accounting_timestamps_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) Update_StripeCustomer_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field,
	update StripeCustomer_Update_Fields) (
	stripe_customer *StripeCustomer, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE stripe_customers SET "), __sets, __sqlbundle_Literal(" WHERE stripe_customers.user_id = ? RETURNING stripe_customers.user_id, stripe_customers.customer_id, stripe_customers.billing_customer_id, stripe_customers.package_plan, stripe_customers.purchased_package_at, stripe_customers.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.BillingCustomerId._set {
		__values = append(__values, update.BillingCustomerId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("billing_customer_id = ?"))
	}

	if update.PackagePlan._set {
		__values = append(__values, update.PackagePlan.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("package_plan = ?"))
	}

	if update.PurchasedPackageAt._set {
		__values = append(__values, update.PurchasedPackageAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("purchased_package_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, stripe_customer_user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripe_customer = &StripeCustomer{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripe_customer.UserId, &stripe_customer.CustomerId, &stripe_customer.BillingCustomerId, &stripe_customer.PackagePlan, &stripe_customer.PurchasedPackageAt, &stripe_customer.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripe_customer, nil
}

func (obj *pgxcockroachImpl) Update_BillingBalance_By_UserId_And_Balance(ctx context.Context,
	billing_balance_user_id BillingBalance_UserId_Field,
	billing_balance_balance BillingBalance_Balance_Field,
	update BillingBalance_Update_Fields) (
	billing_balance *BillingBalance, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE billing_balances SET "), __sets, __sqlbundle_Literal(" WHERE billing_balances.user_id = ? AND billing_balances.balance = ? RETURNING billing_balances.user_id, billing_balances.balance, billing_balances.last_updated")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Balance._set {
		__values = append(__values, update.Balance.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("balance = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_updated = ?"))

	__args = append(__args, billing_balance_user_id.value(), billing_balance_balance.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	billing_balance = &BillingBalance{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&billing_balance.UserId, &billing_balance.Balance, &billing_balance.LastUpdated)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return billing_balance, nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_BillingTransaction_By_Id_And_Status(ctx context.Context,
	billing_transaction_id BillingTransaction_Id_Field,
	billing_transaction_status BillingTransaction_Status_Field,
	update BillingTransaction_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE billing_transactions SET "), __sets, __sqlbundle_Literal(" WHERE billing_transactions.id = ? AND billing_transactions.status = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if update.Metadata._set {
		__values = append(__values, update.Metadata.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("metadata = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, billing_transaction_id.value(), billing_transaction_status.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) Update_CoinpaymentsTransaction_By_Id(ctx context.Context,
	coinpayments_transaction_id CoinpaymentsTransaction_Id_Field,
	update CoinpaymentsTransaction_Update_Fields) (
	coinpayments_transaction *CoinpaymentsTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE coinpayments_transactions SET "), __sets, __sqlbundle_Literal(" WHERE coinpayments_transactions.id = ? RETURNING coinpayments_transactions.id, coinpayments_transactions.user_id, coinpayments_transactions.address, coinpayments_transactions.amount_numeric, coinpayments_transactions.received_numeric, coinpayments_transactions.status, coinpayments_transactions.key, coinpayments_transactions.timeout, coinpayments_transactions.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ReceivedNumeric._set {
		__values = append(__values, update.ReceivedNumeric.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("received_numeric = ?"))
	}

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, coinpayments_transaction_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	coinpayments_transaction = &CoinpaymentsTransaction{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return coinpayments_transaction, nil
}

func (obj *pgxcockroachImpl) Update_StripecoinpaymentsInvoiceProjectRecord_By_Id(ctx context.Context,
	stripecoinpayments_invoice_project_record_id StripecoinpaymentsInvoiceProjectRecord_Id_Field,
	update StripecoinpaymentsInvoiceProjectRecord_Update_Fields) (
	stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE stripecoinpayments_invoice_project_records SET "), __sets, __sqlbundle_Literal(" WHERE stripecoinpayments_invoice_project_records.id = ? RETURNING stripecoinpayments_invoice_project_records.id, stripecoinpayments_invoice_project_records.project_id, stripecoinpayments_invoice_project_records.storage, stripecoinpayments_invoice_project_records.egress, stripecoinpayments_invoice_project_records.objects, stripecoinpayments_invoice_project_records.segments, stripecoinpayments_invoice_project_records.period_start, stripecoinpayments_invoice_project_records.period_end, stripecoinpayments_invoice_project_records.state, stripecoinpayments_invoice_project_records.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.State._set {
		__values = append(__values, update.State.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("state = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, stripecoinpayments_invoice_project_record_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_invoice_project_record = &StripecoinpaymentsInvoiceProjectRecord{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripecoinpayments_invoice_project_record, nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_PeerIdentity_By_NodeId(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field,
	update PeerIdentity_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE peer_identities SET "), __sets, __sqlbundle_Literal(" WHERE peer_identities.node_id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.LeafSerialNumber._set {
		__values = append(__values, update.LeafSerialNumber.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("leaf_serial_number = ?"))
	}

	if update.Chain._set {
		__values = append(__values, update.Chain.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("chain = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, peer_identity_node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) Update_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	node *Node, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ? RETURNING nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}

	if update.LastNet._set {
		__values = append(__values, update.LastNet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_net = ?"))
	}

	if update.LastIpPort._set {
		__values = append(__values, update.LastIpPort.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_ip_port = ?"))
	}

	if update.CountryCode._set {
		__values = append(__values, update.CountryCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("country_code = ?"))
	}

	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.Wallet._set {
		__values = append(__values, update.Wallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet = ?"))
	}

	if update.WalletFeatures._set {
		__values = append(__values, update.WalletFeatures.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet_features = ?"))
	}

	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}

	if update.PieceCount._set {
		__values = append(__values, update.PieceCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("piece_count = ?"))
	}

	if update.Major._set {
		__values = append(__values, update.Major.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("major = ?"))
	}

	if update.Minor._set {
		__values = append(__values, update.Minor.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("minor = ?"))
	}

	if update.Patch._set {
		__values = append(__values, update.Patch.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("patch = ?"))
	}

	if update.CommitHash._set {
		__values = append(__values, update.CommitHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("commit_hash = ?"))
	}

	if update.ReleaseTimestamp._set {
		__values = append(__values, update.ReleaseTimestamp.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release_timestamp = ?"))
	}

	if update.Release._set {
		__values = append(__values, update.Release.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release = ?"))
	}

	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.LastContactSuccess._set {
		__values = append(__values, update.LastContactSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_success = ?"))
	}

	if update.LastContactFailure._set {
		__values = append(__values, update.LastContactFailure.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_failure = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.ExitInitiatedAt._set {
		__values = append(__values, update.ExitInitiatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_initiated_at = ?"))
	}

	if update.ExitLoopCompletedAt._set {
		__values = append(__values, update.ExitLoopCompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_loop_completed_at = ?"))
	}

	if update.ExitFinishedAt._set {
		__values = append(__values, update.ExitFinishedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_finished_at = ?"))
	}

	if update.ExitSuccess._set {
		__values = append(__values, update.ExitSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_success = ?"))
	}

	if update.Contained._set {
		__values = append(__values, update.Contained.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("contained = ?"))
	}

	if update.LastOfflineEmail._set {
		__values = append(__values, update.LastOfflineEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_offline_email = ?"))
	}

	if update.LastSoftwareUpdateEmail._set {
		__values = append(__values, update.LastSoftwareUpdateEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_software_update_email = ?"))
	}

	if update.NoiseProto._set {
		__values = append(__values, update.NoiseProto.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_proto = ?"))
	}

	if update.NoisePublicKey._set {
		__values = append(__values, update.NoisePublicKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_public_key = ?"))
	}

	if update.DebounceLimit._set {
		__values = append(__values, update.DebounceLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("debounce_limit = ?"))
	}

	if update.Features._set {
		__values = append(__values, update.Features.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("features = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node.Id, &node.Address, &node.LastNet, &node.LastIpPort, &node.CountryCode, &node.Protocol, &node.Email, &node.Wallet, &node.WalletFeatures, &node.FreeDisk, &node.PieceCount, &node.Major, &node.Minor, &node.Patch, &node.CommitHash, &node.ReleaseTimestamp, &node.Release, &node.Latency90, &node.VettedAt, &node.CreatedAt, &node.UpdatedAt, &node.LastContactSuccess, &node.LastContactFailure, &node.Disqualified, &node.DisqualificationReason, &node.UnknownAuditSuspended, &node.OfflineSuspended, &node.UnderReview, &node.ExitInitiatedAt, &node.ExitLoopCompletedAt, &node.ExitFinishedAt, &node.ExitSuccess, &node.Contained, &node.LastOfflineEmail, &node.LastSoftwareUpdateEmail, &node.NoiseProto, &node.NoisePublicKey, &node.DebounceLimit, &node.Features)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node, nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}

	if update.LastNet._set {
		__values = append(__values, update.LastNet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_net = ?"))
	}

	if update.LastIpPort._set {
		__values = append(__values, update.LastIpPort.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_ip_port = ?"))
	}

	if update.CountryCode._set {
		__values = append(__values, update.CountryCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("country_code = ?"))
	}

	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.Wallet._set {
		__values = append(__values, update.Wallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet = ?"))
	}

	if update.WalletFeatures._set {
		__values = append(__values, update.WalletFeatures.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet_features = ?"))
	}

	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}

	if update.PieceCount._set {
		__values = append(__values, update.PieceCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("piece_count = ?"))
	}

	if update.Major._set {
		__values = append(__values, update.Major.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("major = ?"))
	}

	if update.Minor._set {
		__values = append(__values, update.Minor.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("minor = ?"))
	}

	if update.Patch._set {
		__values = append(__values, update.Patch.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("patch = ?"))
	}

	if update.CommitHash._set {
		__values = append(__values, update.CommitHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("commit_hash = ?"))
	}

	if update.ReleaseTimestamp._set {
		__values = append(__values, update.ReleaseTimestamp.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release_timestamp = ?"))
	}

	if update.Release._set {
		__values = append(__values, update.Release.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release = ?"))
	}

	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.LastContactSuccess._set {
		__values = append(__values, update.LastContactSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_success = ?"))
	}

	if update.LastContactFailure._set {
		__values = append(__values, update.LastContactFailure.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_failure = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.ExitInitiatedAt._set {
		__values = append(__values, update.ExitInitiatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_initiated_at = ?"))
	}

	if update.ExitLoopCompletedAt._set {
		__values = append(__values, update.ExitLoopCompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_loop_completed_at = ?"))
	}

	if update.ExitFinishedAt._set {
		__values = append(__values, update.ExitFinishedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_finished_at = ?"))
	}

	if update.ExitSuccess._set {
		__values = append(__values, update.ExitSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_success = ?"))
	}

	if update.Contained._set {
		__values = append(__values, update.Contained.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("contained = ?"))
	}

	if update.LastOfflineEmail._set {
		__values = append(__values, update.LastOfflineEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_offline_email = ?"))
	}

	if update.LastSoftwareUpdateEmail._set {
		__values = append(__values, update.LastSoftwareUpdateEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_software_update_email = ?"))
	}

	if update.NoiseProto._set {
		__values = append(__values, update.NoiseProto.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_proto = ?"))
	}

	if update.NoisePublicKey._set {
		__values = append(__values, update.NoisePublicKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_public_key = ?"))
	}

	if update.DebounceLimit._set {
		__values = append(__values, update.DebounceLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("debounce_limit = ?"))
	}

	if update.Features._set {
		__values = append(__values, update.Features.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("features = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_Node_By_Id_And_Disqualified_Is_Null_And_ExitFinishedAt_Is_Null(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ? AND nodes.disqualified is NULL AND nodes.exit_finished_at is NULL")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}

	if update.LastNet._set {
		__values = append(__values, update.LastNet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_net = ?"))
	}

	if update.LastIpPort._set {
		__values = append(__values, update.LastIpPort.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_ip_port = ?"))
	}

	if update.CountryCode._set {
		__values = append(__values, update.CountryCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("country_code = ?"))
	}

	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.Wallet._set {
		__values = append(__values, update.Wallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet = ?"))
	}

	if update.WalletFeatures._set {
		__values = append(__values, update.WalletFeatures.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet_features = ?"))
	}

	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}

	if update.PieceCount._set {
		__values = append(__values, update.PieceCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("piece_count = ?"))
	}

	if update.Major._set {
		__values = append(__values, update.Major.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("major = ?"))
	}

	if update.Minor._set {
		__values = append(__values, update.Minor.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("minor = ?"))
	}

	if update.Patch._set {
		__values = append(__values, update.Patch.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("patch = ?"))
	}

	if update.CommitHash._set {
		__values = append(__values, update.CommitHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("commit_hash = ?"))
	}

	if update.ReleaseTimestamp._set {
		__values = append(__values, update.ReleaseTimestamp.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release_timestamp = ?"))
	}

	if update.Release._set {
		__values = append(__values, update.Release.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release = ?"))
	}

	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.LastContactSuccess._set {
		__values = append(__values, update.LastContactSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_success = ?"))
	}

	if update.LastContactFailure._set {
		__values = append(__values, update.LastContactFailure.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_failure = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.ExitInitiatedAt._set {
		__values = append(__values, update.ExitInitiatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_initiated_at = ?"))
	}

	if update.ExitLoopCompletedAt._set {
		__values = append(__values, update.ExitLoopCompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_loop_completed_at = ?"))
	}

	if update.ExitFinishedAt._set {
		__values = append(__values, update.ExitFinishedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_finished_at = ?"))
	}

	if update.ExitSuccess._set {
		__values = append(__values, update.ExitSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_success = ?"))
	}

	if update.Contained._set {
		__values = append(__values, update.Contained.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("contained = ?"))
	}

	if update.LastOfflineEmail._set {
		__values = append(__values, update.LastOfflineEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_offline_email = ?"))
	}

	if update.LastSoftwareUpdateEmail._set {
		__values = append(__values, update.LastSoftwareUpdateEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_software_update_email = ?"))
	}

	if update.NoiseProto._set {
		__values = append(__values, update.NoiseProto.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_proto = ?"))
	}

	if update.NoisePublicKey._set {
		__values = append(__values, update.NoisePublicKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_public_key = ?"))
	}

	if update.DebounceLimit._set {
		__values = append(__values, update.DebounceLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("debounce_limit = ?"))
	}

	if update.Features._set {
		__values = append(__values, update.Features.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("features = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_NodeApiVersion_By_Id_And_ApiVersion_Less(ctx context.Context,
	node_api_version_id NodeApiVersion_Id_Field,
	node_api_version_api_version_less NodeApiVersion_ApiVersion_Field,
	update NodeApiVersion_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE node_api_versions SET "), __sets, __sqlbundle_Literal(" WHERE node_api_versions.id = ? AND node_api_versions.api_version < ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ApiVersion._set {
		__values = append(__values, update.ApiVersion.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("api_version = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_api_version_id.value(), node_api_version_api_version_less.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) Update_Reputation_By_Id(ctx context.Context,
	reputation_id Reputation_Id_Field,
	update Reputation_Update_Fields) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE reputations SET "), __sets, __sqlbundle_Literal(" WHERE reputations.id = ? RETURNING reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.OnlineScore._set {
		__values = append(__values, update.OnlineScore.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("online_score = ?"))
	}

	if update.AuditHistory._set {
		__values = append(__values, update.AuditHistory.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_history = ?"))
	}

	if update.AuditReputationAlpha._set {
		__values = append(__values, update.AuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_alpha = ?"))
	}

	if update.AuditReputationBeta._set {
		__values = append(__values, update.AuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_beta = ?"))
	}

	if update.UnknownAuditReputationAlpha._set {
		__values = append(__values, update.UnknownAuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha = ?"))
	}

	if update.UnknownAuditReputationBeta._set {
		__values = append(__values, update.UnknownAuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, reputation_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reputation, nil
}

func (obj *pgxcockroachImpl) Update_Reputation_By_Id_And_AuditHistory(ctx context.Context,
	reputation_id Reputation_Id_Field,
	reputation_audit_history Reputation_AuditHistory_Field,
	update Reputation_Update_Fields) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE reputations SET "), __sets, __sqlbundle_Literal(" WHERE reputations.id = ? AND reputations.audit_history = ? RETURNING reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.OnlineScore._set {
		__values = append(__values, update.OnlineScore.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("online_score = ?"))
	}

	if update.AuditHistory._set {
		__values = append(__values, update.AuditHistory.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_history = ?"))
	}

	if update.AuditReputationAlpha._set {
		__values = append(__values, update.AuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_alpha = ?"))
	}

	if update.AuditReputationBeta._set {
		__values = append(__values, update.AuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_beta = ?"))
	}

	if update.UnknownAuditReputationAlpha._set {
		__values = append(__values, update.UnknownAuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha = ?"))
	}

	if update.UnknownAuditReputationBeta._set {
		__values = append(__values, update.UnknownAuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, reputation_id.value(), reputation_audit_history.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reputation, nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_Reputation_By_Id(ctx context.Context,
	reputation_id Reputation_Id_Field,
	update Reputation_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE reputations SET "), __sets, __sqlbundle_Literal(" WHERE reputations.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}

	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}

	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}

	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}

	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}

	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}

	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}

	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}

	if update.OnlineScore._set {
		__values = append(__values, update.OnlineScore.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("online_score = ?"))
	}

	if update.AuditHistory._set {
		__values = append(__values, update.AuditHistory.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_history = ?"))
	}

	if update.AuditReputationAlpha._set {
		__values = append(__values, update.AuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_alpha = ?"))
	}

	if update.AuditReputationBeta._set {
		__values = append(__values, update.AuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_beta = ?"))
	}

	if update.UnknownAuditReputationAlpha._set {
		__values = append(__values, update.UnknownAuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha = ?"))
	}

	if update.UnknownAuditReputationBeta._set {
		__values = append(__values, update.UnknownAuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, reputation_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_OauthClient_By_Id(ctx context.Context,
	oauth_client_id OauthClient_Id_Field,
	update OauthClient_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE oauth_clients SET "), __sets, __sqlbundle_Literal(" WHERE oauth_clients.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.EncryptedSecret._set {
		__values = append(__values, update.EncryptedSecret.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("encrypted_secret = ?"))
	}

	if update.RedirectUrl._set {
		__values = append(__values, update.RedirectUrl.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("redirect_url = ?"))
	}

	if update.AppName._set {
		__values = append(__values, update.AppName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("app_name = ?"))
	}

	if update.AppLogoUrl._set {
		__values = append(__values, update.AppLogoUrl.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("app_logo_url = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, oauth_client_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_OauthCode_By_Code_And_ClaimedAt_Is_Null(ctx context.Context,
	oauth_code_code OauthCode_Code_Field,
	update OauthCode_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE oauth_codes SET "), __sets, __sqlbundle_Literal(" WHERE oauth_codes.code = ? AND oauth_codes.claimed_at is NULL")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ClaimedAt._set {
		__values = append(__values, update.ClaimedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("claimed_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, oauth_code_code.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_OauthToken_By_Token_And_Kind(ctx context.Context,
	oauth_token_token OauthToken_Token_Field,
	oauth_token_kind OauthToken_Kind_Field,
	update OauthToken_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE oauth_tokens SET "), __sets, __sqlbundle_Literal(" WHERE oauth_tokens.token = ? AND oauth_tokens.kind = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ExpiresAt._set {
		__values = append(__values, update.ExpiresAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("expires_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, oauth_token_token.value(), oauth_token_kind.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) Update_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field,
	update Project_Update_Fields) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE projects SET "), __sets, __sqlbundle_Literal(" WHERE projects.id = ? RETURNING projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Name._set {
		__values = append(__values, update.Name.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("name = ?"))
	}

	if update.Description._set {
		__values = append(__values, update.Description.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("description = ?"))
	}

	if update.UsageLimit._set {
		__values = append(__values, update.UsageLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("usage_limit = ?"))
	}

	if update.BandwidthLimit._set {
		__values = append(__values, update.BandwidthLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("bandwidth_limit = ?"))
	}

	if update.UserSpecifiedUsageLimit._set {
		__values = append(__values, update.UserSpecifiedUsageLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_specified_usage_limit = ?"))
	}

	if update.UserSpecifiedBandwidthLimit._set {
		__values = append(__values, update.UserSpecifiedBandwidthLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_specified_bandwidth_limit = ?"))
	}

	if update.SegmentLimit._set {
		__values = append(__values, update.SegmentLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("segment_limit = ?"))
	}

	if update.RateLimit._set {
		__values = append(__values, update.RateLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit = ?"))
	}

	if update.BurstLimit._set {
		__values = append(__values, update.BurstLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit = ?"))
	}

	if update.RateLimitHead._set {
		__values = append(__values, update.RateLimitHead.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_head = ?"))
	}

	if update.BurstLimitHead._set {
		__values = append(__values, update.BurstLimitHead.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_head = ?"))
	}

	if update.RateLimitGet._set {
		__values = append(__values, update.RateLimitGet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_get = ?"))
	}

	if update.BurstLimitGet._set {
		__values = append(__values, update.BurstLimitGet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_get = ?"))
	}

	if update.RateLimitPut._set {
		__values = append(__values, update.RateLimitPut.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_put = ?"))
	}

	if update.BurstLimitPut._set {
		__values = append(__values, update.BurstLimitPut.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_put = ?"))
	}

	if update.RateLimitList._set {
		__values = append(__values, update.RateLimitList.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_list = ?"))
	}

	if update.BurstLimitList._set {
		__values = append(__values, update.BurstLimitList.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_list = ?"))
	}

	if update.RateLimitDel._set {
		__values = append(__values, update.RateLimitDel.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_del = ?"))
	}

	if update.BurstLimitDel._set {
		__values = append(__values, update.BurstLimitDel.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_del = ?"))
	}

	if update.MaxBuckets._set {
		__values = append(__values, update.MaxBuckets.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("max_buckets = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if update.StatusUpdatedAt._set {
		__values = append(__values, update.StatusUpdatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status_updated_at = ?"))
	}

	if update.DefaultPlacement._set {
		__values = append(__values, update.DefaultPlacement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_placement = ?"))
	}

	if update.DefaultVersioning._set {
		__values = append(__values, update.DefaultVersioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_versioning = ?"))
	}

	if update.PromptedForVersioningBeta._set {
		__values = append(__values, update.PromptedForVersioningBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("prompted_for_versioning_beta = ?"))
	}

	if update.PassphraseEnc._set {
		__values = append(__values, update.PassphraseEnc.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("passphrase_enc = ?"))
	}

	if update.PassphraseEncKeyId._set {
		__values = append(__values, update.PassphraseEncKeyId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("passphrase_enc_key_id = ?"))
	}

	if update.PathEncryption._set {
		__values = append(__values, update.PathEncryption.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("path_encryption = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil
}

func (obj *pgxcockroachImpl) Update_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field,
	update ProjectMember_Update_Fields) (
	project_member *ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE project_members SET "), __sets, __sqlbundle_Literal(" WHERE project_members.member_id = ? AND project_members.project_id = ? RETURNING project_members.member_id, project_members.project_id, project_members.role, project_members.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Role._set {
		__values = append(__values, update.Role.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("role = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_member_member_id.value(), project_member_project_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_member = &ProjectMember{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_member, nil
}

func (obj *pgxcockroachImpl) Update_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field,
	update ProjectInvitation_Update_Fields) (
	project_invitation *ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE project_invitations SET "), __sets, __sqlbundle_Literal(" WHERE project_invitations.project_id = ? AND project_invitations.email = ? RETURNING project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.InviterId._set {
		__values = append(__values, update.InviterId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("inviter_id = ?"))
	}

	if update.CreatedAt._set {
		__values = append(__values, update.CreatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("created_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_invitation_project_id.value(), project_invitation_email.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_invitation = &ProjectInvitation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_invitation, nil
}

func (obj *pgxcockroachImpl) UpdateNoReturn_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	update ApiKey_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE api_keys SET "), __sets, __sqlbundle_Literal(" WHERE api_keys.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Name._set {
		__values = append(__values, update.Name.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("name = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, api_key_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *pgxcockroachImpl) Update_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	update BucketMetainfo_Update_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_metainfos SET "), __sets, __sqlbundle_Literal(" WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? RETURNING bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Tags._set {
		__values = append(__values, update.Tags.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tags = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Versioning._set {
		__values = append(__values, update.Versioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("versioning = ?"))
	}

	if update.ObjectLockEnabled._set {
		__values = append(__values, update.ObjectLockEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("object_lock_enabled = ?"))
	}

	if update.DefaultRetentionMode._set {
		__values = append(__values, update.DefaultRetentionMode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_mode = ?"))
	}

	if update.DefaultRetentionDays._set {
		__values = append(__values, update.DefaultRetentionDays.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_days = ?"))
	}

	if update.DefaultRetentionYears._set {
		__values = append(__values, update.DefaultRetentionYears.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_years = ?"))
	}

	if update.DefaultSegmentSize._set {
		__values = append(__values, update.DefaultSegmentSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_segment_size = ?"))
	}

	if update.DefaultEncryptionCipherSuite._set {
		__values = append(__values, update.DefaultEncryptionCipherSuite.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_cipher_suite = ?"))
	}

	if update.DefaultEncryptionBlockSize._set {
		__values = append(__values, update.DefaultEncryptionBlockSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_block_size = ?"))
	}

	if update.DefaultRedundancyAlgorithm._set {
		__values = append(__values, update.DefaultRedundancyAlgorithm.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_algorithm = ?"))
	}

	if update.DefaultRedundancyShareSize._set {
		__values = append(__values, update.DefaultRedundancyShareSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_share_size = ?"))
	}

	if update.DefaultRedundancyRequiredShares._set {
		__values = append(__values, update.DefaultRedundancyRequiredShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_required_shares = ?"))
	}

	if update.DefaultRedundancyRepairShares._set {
		__values = append(__values, update.DefaultRedundancyRepairShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_repair_shares = ?"))
	}

	if update.DefaultRedundancyOptimalShares._set {
		__values = append(__values, update.DefaultRedundancyOptimalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_optimal_shares = ?"))
	}

	if update.DefaultRedundancyTotalShares._set {
		__values = append(__values, update.DefaultRedundancyTotalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_total_shares = ?"))
	}

	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil
}

func (obj *pgxcockroachImpl) Update_BucketMetainfo_By_ProjectId_And_Name_And_Versioning_GreaterOrEqual(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	bucket_metainfo_versioning_greater_or_equal BucketMetainfo_Versioning_Field,
	update BucketMetainfo_Update_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_metainfos SET "), __sets, __sqlbundle_Literal(" WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? AND bucket_metainfos.versioning >= ? RETURNING bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Tags._set {
		__values = append(__values, update.Tags.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tags = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Versioning._set {
		__values = append(__values, update.Versioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("versioning = ?"))
	}

	if update.ObjectLockEnabled._set {
		__values = append(__values, update.ObjectLockEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("object_lock_enabled = ?"))
	}

	if update.DefaultRetentionMode._set {
		__values = append(__values, update.DefaultRetentionMode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_mode = ?"))
	}

	if update.DefaultRetentionDays._set {
		__values = append(__values, update.DefaultRetentionDays.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_days = ?"))
	}

	if update.DefaultRetentionYears._set {
		__values = append(__values, update.DefaultRetentionYears.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_years = ?"))
	}

	if update.DefaultSegmentSize._set {
		__values = append(__values, update.DefaultSegmentSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_segment_size = ?"))
	}

	if update.DefaultEncryptionCipherSuite._set {
		__values = append(__values, update.DefaultEncryptionCipherSuite.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_cipher_suite = ?"))
	}

	if update.DefaultEncryptionBlockSize._set {
		__values = append(__values, update.DefaultEncryptionBlockSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_block_size = ?"))
	}

	if update.DefaultRedundancyAlgorithm._set {
		__values = append(__values, update.DefaultRedundancyAlgorithm.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_algorithm = ?"))
	}

	if update.DefaultRedundancyShareSize._set {
		__values = append(__values, update.DefaultRedundancyShareSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_share_size = ?"))
	}

	if update.DefaultRedundancyRequiredShares._set {
		__values = append(__values, update.DefaultRedundancyRequiredShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_required_shares = ?"))
	}

	if update.DefaultRedundancyRepairShares._set {
		__values = append(__values, update.DefaultRedundancyRepairShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_repair_shares = ?"))
	}

	if update.DefaultRedundancyOptimalShares._set {
		__values = append(__values, update.DefaultRedundancyOptimalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_optimal_shares = ?"))
	}

	if update.DefaultRedundancyTotalShares._set {
		__values = append(__values, update.DefaultRedundancyTotalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_total_shares = ?"))
	}

	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, bucket_metainfo_project_id.value(), bucket_metainfo_name.value(), bucket_metainfo_versioning_greater_or_equal.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil
}

func (obj *pgxcockroachImpl) Update_BucketMetainfo_By_ProjectId_And_Name_And_Versioning_GreaterOrEqual_And_ObjectLockEnabled_Equal_False(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	bucket_metainfo_versioning_greater_or_equal BucketMetainfo_Versioning_Field,
	update BucketMetainfo_Update_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_metainfos SET "), __sets, __sqlbundle_Literal(" WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? AND bucket_metainfos.versioning >= ? AND bucket_metainfos.object_lock_enabled = false RETURNING bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Tags._set {
		__values = append(__values, update.Tags.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tags = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Versioning._set {
		__values = append(__values, update.Versioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("versioning = ?"))
	}

	if update.ObjectLockEnabled._set {
		__values = append(__values, update.ObjectLockEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("object_lock_enabled = ?"))
	}

	if update.DefaultRetentionMode._set {
		__values = append(__values, update.DefaultRetentionMode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_mode = ?"))
	}

	if update.DefaultRetentionDays._set {
		__values = append(__values, update.DefaultRetentionDays.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_days = ?"))
	}

	if update.DefaultRetentionYears._set {
		__values = append(__values, update.DefaultRetentionYears.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_years = ?"))
	}

	if update.DefaultSegmentSize._set {
		__values = append(__values, update.DefaultSegmentSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_segment_size = ?"))
	}

	if update.DefaultEncryptionCipherSuite._set {
		__values = append(__values, update.DefaultEncryptionCipherSuite.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_cipher_suite = ?"))
	}

	if update.DefaultEncryptionBlockSize._set {
		__values = append(__values, update.DefaultEncryptionBlockSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_block_size = ?"))
	}

	if update.DefaultRedundancyAlgorithm._set {
		__values = append(__values, update.DefaultRedundancyAlgorithm.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_algorithm = ?"))
	}

	if update.DefaultRedundancyShareSize._set {
		__values = append(__values, update.DefaultRedundancyShareSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_share_size = ?"))
	}

	if update.DefaultRedundancyRequiredShares._set {
		__values = append(__values, update.DefaultRedundancyRequiredShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_required_shares = ?"))
	}

	if update.DefaultRedundancyRepairShares._set {
		__values = append(__values, update.DefaultRedundancyRepairShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_repair_shares = ?"))
	}

	if update.DefaultRedundancyOptimalShares._set {
		__values = append(__values, update.DefaultRedundancyOptimalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_optimal_shares = ?"))
	}

	if update.DefaultRedundancyTotalShares._set {
		__values = append(__values, update.DefaultRedundancyTotalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_total_shares = ?"))
	}

	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, bucket_metainfo_project_id.value(), bucket_metainfo_name.value(), bucket_metainfo_versioning_greater_or_equal.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil
}

func (obj *pgxcockroachImpl) Update_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field,
	update ValueAttribution_Update_Fields) (
	value_attribution *ValueAttribution, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE value_attributions SET "), __sets, __sqlbundle_Literal(" WHERE value_attributions.project_id = ? AND value_attributions.bucket_name = ? RETURNING value_attributions.project_id, value_attributions.bucket_name, value_attributions.user_agent, value_attributions.placement, value_attributions.last_updated")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_updated = ?"))

	__args = append(__args, value_attribution_project_id.value(), value_attribution_bucket_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	value_attribution = &ValueAttribution{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return value_attribution, nil
}

func (obj *pgxcockroachImpl) Update_BucketMigration_By_Id(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field,
	update BucketMigration_Update_Fields) (
	bucket_migration *BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_migrations SET "), __sets, __sqlbundle_Literal(" WHERE bucket_migrations.id = ? RETURNING bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.State._set {
		__values = append(__values, update.State.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("state = ?"))
	}

	if update.BytesProcessed._set {
		__values = append(__values, update.BytesProcessed.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("bytes_processed = ?"))
	}

	if update.ErrorMessage._set {
		__values = append(__values, update.ErrorMessage.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("error_message = ?"))
	}

	if update.CompletedAt._set {
		__values = append(__values, update.CompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("completed_at = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, bucket_migration_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_migration = &BucketMigration{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_migration, nil
}

func (obj *pgxcockroachImpl) Update_User_By_Id(ctx context.Context,
	user_id User_Id_Field,
	update User_Update_Fields) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE users SET "), __sets, __sqlbundle_Literal(" WHERE users.id = ? RETURNING users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ExternalId._set {
		__values = append(__values, update.ExternalId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("external_id = ?"))
	}

	if update.TenantId._set {
		__values = append(__values, update.TenantId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tenant_id = ?"))
	}

	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}

	if update.NormalizedEmail._set {
		__values = append(__values, update.NormalizedEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("normalized_email = ?"))
	}

	if update.FullName._set {
		__values = append(__values, update.FullName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("full_name = ?"))
	}

	if update.ShortName._set {
		__values = append(__values, update.ShortName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("short_name = ?"))
	}

	if update.PasswordHash._set {
		__values = append(__values, update.PasswordHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("password_hash = ?"))
	}

	if update.NewUnverifiedEmail._set {
		__values = append(__values, update.NewUnverifiedEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("new_unverified_email = ?"))
	}

	if update.EmailChangeVerificationStep._set {
		__values = append(__values, update.EmailChangeVerificationStep.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email_change_verification_step = ?"))
	}

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if update.StatusUpdatedAt._set {
		__values = append(__values, update.StatusUpdatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status_updated_at = ?"))
	}

	if update.FinalInvoiceGenerated._set {
		__values = append(__values, update.FinalInvoiceGenerated.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("final_invoice_generated = ?"))
	}

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}

	if update.ProjectLimit._set {
		__values = append(__values, update.ProjectLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_limit = ?"))
	}

	if update.ProjectBandwidthLimit._set {
		__values = append(__values, update.ProjectBandwidthLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_bandwidth_limit = ?"))
	}

	if update.ProjectStorageLimit._set {
		__values = append(__values, update.ProjectStorageLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_storage_limit = ?"))
	}

	if update.ProjectSegmentLimit._set {
		__values = append(__values, update.ProjectSegmentLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_segment_limit = ?"))
	}

	if update.Kind._set {
		__values = append(__values, update.Kind.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("kind = ?"))
	}

	if update.Position._set {
		__values = append(__values, update.Position.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("position = ?"))
	}

	if update.CompanyName._set {
		__values = append(__values, update.CompanyName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("company_name = ?"))
	}

	if update.CompanySize._set {
		__values = append(__values, update.CompanySize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("company_size = ?"))
	}

	if update.WorkingOn._set {
		__values = append(__values, update.WorkingOn.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("working_on = ?"))
	}

	if update.IsProfessional._set {
		__values = append(__values, update.IsProfessional.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("is_professional = ?"))
	}

	if update.EmployeeCount._set {
		__values = append(__values, update.EmployeeCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("employee_count = ?"))
	}

	if update.HaveSalesContact._set {
		__values = append(__values, update.HaveSalesContact.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("have_sales_contact = ?"))
	}

	if update.MfaEnabled._set {
		__values = append(__values, update.MfaEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("mfa_enabled = ?"))
	}

	if update.MfaSecretKey._set {
		__values = append(__values, update.MfaSecretKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("mfa_secret_key = ?"))
	}

	if update.MfaRecoveryCodes._set {
		__values = append(__values, update.MfaRecoveryCodes.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("mfa_recovery_codes = ?"))
	}

	if update.SignupPromoCode._set {
		__values = append(__values, update.SignupPromoCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("signup_promo_code = ?"))
	}

	if update.VerificationReminders._set {
		__values = append(__values, update.VerificationReminders.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("verification_reminders = ?"))
	}

	if update.TrialNotifications._set {
		__values = append(__values, update.TrialNotifications.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("trial_notifications = ?"))
	}

	if update.FailedLoginCount._set {
		__values = append(__values, update.FailedLoginCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("failed_login_count = ?"))
	}

	if update.LoginLockoutExpiration._set {
		__values = append(__values, update.LoginLockoutExpiration.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("login_lockout_expiration = ?"))
	}

	if update.DefaultPlacement._set {
		__values = append(__values, update.DefaultPlacement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_placement = ?"))
	}

	if update.ActivationCode._set {
		__values = append(__values, update.ActivationCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("activation_code = ?"))
	}

	if update.SignupId._set {
		__values = append(__values, update.SignupId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("signup_id = ?"))
	}

	if update.TrialExpiration._set {
		__values = append(__values, update.TrialExpiration.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("trial_expiration = ?"))
	}

	if update.UpgradeTime._set {
		__values = append(__values, update.UpgradeTime.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("upgrade_time = ?"))
	}

	if update.HubspotObjectId._set {
		__values = append(__values, update.HubspotObjectId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("hubspot_object_id = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil
}

func (obj *pgxcockroachImpl) Update_WebappSession_By_Id(ctx context.Context,
	webapp_session_id WebappSession_Id_Field,
	update WebappSession_Update_Fields) (
	webapp_session *WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE webapp_sessions SET "), __sets, __sqlbundle_Literal(" WHERE webapp_sessions.id = ? RETURNING webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if update.ExpiresAt._set {
		__values = append(__values, update.ExpiresAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("expires_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, webapp_session_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	webapp_session = &WebappSession{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return webapp_session, nil
}

func (obj *pgxcockroachImpl) Update_RegistrationToken_By_Secret(ctx context.Context,
	registration_token_secret RegistrationToken_Secret_Field,
	update RegistrationToken_Update_Fields) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE registration_tokens SET "), __sets, __sqlbundle_Literal(" WHERE registration_tokens.secret = ? RETURNING registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.OwnerId._set {
		__values = append(__values, update.OwnerId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("owner_id = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, registration_token_secret.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return registration_token, nil
}

func (obj *pgxcockroachImpl) Update_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field,
	update AccountFreezeEvent_Update_Fields) (
	account_freeze_event *AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE account_freeze_events SET "), __sets, __sqlbundle_Literal(" WHERE account_freeze_events.user_id = ? AND account_freeze_events.event = ? RETURNING account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Limits._set {
		__values = append(__values, update.Limits.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("limits = ?"))
	}

	if update.DaysTillEscalation._set {
		__values = append(__values, update.DaysTillEscalation.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("days_till_escalation = ?"))
	}

	if update.NotificationsCount._set {
		__values = append(__values, update.NotificationsCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("notifications_count = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, account_freeze_event_user_id.value(), account_freeze_event_event.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	account_freeze_event = &AccountFreezeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, &account_freeze_event.Limits, &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return account_freeze_event, nil
}

func (obj *pgxcockroachImpl) Update_UserSettings_By_UserId(ctx context.Context,
	user_settings_user_id UserSettings_UserId_Field,
	update UserSettings_Update_Fields) (
	user_settings *UserSettings, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE user_settings SET "), __sets, __sqlbundle_Literal(" WHERE user_settings.user_id = ? RETURNING user_settings.user_id, user_settings.session_minutes, user_settings.passphrase_prompt, user_settings.onboarding_start, user_settings.onboarding_end, user_settings.onboarding_step, user_settings.notice_dismissal")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.SessionMinutes._set {
		__values = append(__values, update.SessionMinutes.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("session_minutes = ?"))
	}

	if update.PassphrasePrompt._set {
		__values = append(__values, update.PassphrasePrompt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("passphrase_prompt = ?"))
	}

	if update.OnboardingStart._set {
		__values = append(__values, update.OnboardingStart.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("onboarding_start = ?"))
	}

	if update.OnboardingEnd._set {
		__values = append(__values, update.OnboardingEnd.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("onboarding_end = ?"))
	}

	if update.OnboardingStep._set {
		__values = append(__values, update.OnboardingStep.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("onboarding_step = ?"))
	}

	if update.NoticeDismissal._set {
		__values = append(__values, update.NoticeDismissal.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("notice_dismissal = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, user_settings_user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user_settings = &UserSettings{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user_settings.UserId, &user_settings.SessionMinutes, &user_settings.PassphrasePrompt, &user_settings.OnboardingStart, &user_settings.OnboardingEnd, &user_settings.OnboardingStep, &user_settings.NoticeDismissal)
	if err == sql.ErrNoRows {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user_settings, nil
}

func (obj *pgxcockroachImpl) Delete_StoragenodeStorageTally_By_IntervalEndTime_Less(ctx context.Context,
	storagenode_storage_tally_interval_end_time_less StoragenodeStorageTally_IntervalEndTime_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM storagenode_storage_tallies WHERE storagenode_storage_tallies.interval_end_time < ?")

	var __values []any
	__values = append(__values, storagenode_storage_tally_interval_end_time_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_BucketStorageTally_By_IntervalStart_Less(ctx context.Context,
	bucket_storage_tally_interval_start_less BucketStorageTally_IntervalStart_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM bucket_storage_tallies WHERE bucket_storage_tallies.interval_start < ?")

	var __values []any
	__values = append(__values, bucket_storage_tally_interval_start_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_ReverificationAudits_By_NodeId_And_StreamId_And_Position(ctx context.Context,
	reverification_audits_node_id ReverificationAudits_NodeId_Field,
	reverification_audits_stream_id ReverificationAudits_StreamId_Field,
	reverification_audits_position ReverificationAudits_Position_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM reverification_audits WHERE reverification_audits.node_id = ? AND reverification_audits.stream_id = ? AND reverification_audits.position = ?")

	var __values []any
	__values = append(__values, reverification_audits_node_id.value(), reverification_audits_stream_id.value(), reverification_audits_position.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_StorjscanPayment_By_Status(ctx context.Context,
	storjscan_payment_status StorjscanPayment_Status_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM storjscan_payments WHERE storjscan_payments.status = ?")

	var __values []any
	__values = append(__values, storjscan_payment_status.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_Domain_By_ProjectId_And_Subdomain(ctx context.Context,
	domain_project_id Domain_ProjectId_Field,
	domain_subdomain Domain_Subdomain_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM domains WHERE domains.project_id = ? AND domains.subdomain = ?")

	var __values []any
	__values = append(__values, domain_project_id.value(), domain_subdomain.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_Domain_By_ProjectId(ctx context.Context,
	domain_project_id Domain_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM domains WHERE domains.project_id = ?")

	var __values []any
	__values = append(__values, domain_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_Entitlement_By_Scope(ctx context.Context,
	entitlement_scope Entitlement_Scope_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM entitlements WHERE entitlements.scope = ?")

	var __values []any
	__values = append(__values, entitlement_scope.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_NodeEvent_By_CreatedAt_Less(ctx context.Context,
	node_event_created_at_less NodeEvent_CreatedAt_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM node_events WHERE node_events.created_at < ?")

	var __values []any
	__values = append(__values, node_event_created_at_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_OauthClient_By_Id(ctx context.Context,
	oauth_client_id OauthClient_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM oauth_clients WHERE oauth_clients.id = ?")

	var __values []any
	__values = append(__values, oauth_client_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM project_members WHERE project_members.member_id = ? AND project_members.project_id = ?")

	var __values []any
	__values = append(__values, project_member_member_id.value(), project_member_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM project_invitations WHERE project_invitations.project_id = ? AND project_invitations.email = ?")

	var __values []any
	__values = append(__values, project_invitation_project_id.value(), project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM api_keys WHERE api_keys.id = ?")

	var __values []any
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_ApiKey_By_ProjectId(ctx context.Context,
	api_key_project_id ApiKey_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM api_keys WHERE api_keys.project_id = ?")

	var __values []any
	__values = append(__values, api_key_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM value_attributions WHERE value_attributions.project_id = ? AND value_attributions.bucket_name = ?")

	var __values []any
	__values = append(__values, value_attribution_project_id.value(), value_attribution_bucket_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_BucketMigration_By_Id(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM bucket_migrations WHERE bucket_migrations.id = ?")

	var __values []any
	__values = append(__values, bucket_migration_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_RepairQueue_By_UpdatedAt_Less(ctx context.Context,
	repair_queue_updated_at_less RepairQueue_UpdatedAt_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM repair_queue WHERE repair_queue.updated_at < ?")

	var __values []any
	__values = append(__values, repair_queue_updated_at_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_RestApiKey_By_Id(ctx context.Context,
	rest_api_key_id RestApiKey_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM rest_api_keys WHERE rest_api_keys.id = ?")

	var __values []any
	__values = append(__values, rest_api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_WebappSession_By_Id(ctx context.Context,
	webapp_session_id WebappSession_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM webapp_sessions WHERE webapp_sessions.id = ?")

	var __values []any
	__values = append(__values, webapp_session_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_WebappSession_By_UserId_And_Id_Not(ctx context.Context,
	webapp_session_user_id WebappSession_UserId_Field,
	webapp_session_id_not WebappSession_Id_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM webapp_sessions WHERE webapp_sessions.user_id = ? AND webapp_sessions.id != ?")

	var __values []any
	__values = append(__values, webapp_session_user_id.value(), webapp_session_id_not.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_WebappSession_By_UserId(ctx context.Context,
	webapp_session_user_id WebappSession_UserId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM webapp_sessions WHERE webapp_sessions.user_id = ?")

	var __values []any
	__values = append(__values, webapp_session_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_ResetPasswordToken_By_Secret(ctx context.Context,
	reset_password_token_secret ResetPasswordToken_Secret_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM reset_password_tokens WHERE reset_password_tokens.secret = ?")

	var __values []any
	__values = append(__values, reset_password_token_secret.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *pgxcockroachImpl) Delete_AccountFreezeEvent_By_UserId(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM account_freeze_events WHERE account_freeze_events.user_id = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *pgxcockroachImpl) Delete_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM account_freeze_events WHERE account_freeze_events.user_id = ? AND account_freeze_events.event = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value(), account_freeze_event_event.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (impl pgxcockroachImpl) isConstraintError(err error) (constraint string, ok bool) {
	if e, ok := err.(*pgconn.PgError); ok {
		if e.Code[:2] == "23" {
			return e.ConstraintName, true
		}
	}
	return "", false
}

func (obj *pgxcockroachImpl) deleteAll(ctx context.Context) (count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	var __res sql.Result
	var __count int64
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM api_key_tails;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripecoinpayments_apply_balance_intents;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM rest_api_keys;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM project_members;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM project_invitations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM domains;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_migrations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_metainfos;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM api_keys;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM webapp_sessions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM verification_audits;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM value_attributions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM user_settings;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM users;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripecoinpayments_tx_conversion_rates;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripecoinpayments_invoice_project_records;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripe_customers;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storjscan_wallets;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storjscan_payments;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_storage_tallies;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_paystubs;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_payments;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_bandwidth_rollup_archives;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_bandwidth_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM segment_pending_audits;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM revocations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM reverification_audits;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM reset_password_tokens;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM reputations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM repair_queue;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM registration_tokens;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM project_bandwidth_daily_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM projects;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM peer_identities;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM oauth_tokens;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM oauth_codes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM oauth_clients;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM node_tags;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM node_events;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM node_api_versions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM nodes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM entitlements;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM coinpayments_transactions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM change_histories;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_storage_tallies;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_bandwidth_rollup_archives;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_bandwidth_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM billing_transactions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM billing_balances;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM accounting_timestamps;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM accounting_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM account_freeze_events;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count

	return count, nil

}

func (obj *spannerImpl) ReplaceNoReturn_AccountingTimestamps(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	accounting_timestamps_value AccountingTimestamps_Value_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__name_val := accounting_timestamps_name.value()
	__value_val := accounting_timestamps_value.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT OR UPDATE INTO accounting_timestamps ( name, value ) VALUES ( ?, ? )")

	var __values []any
	__values = append(__values, __name_val, __value_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Create_StoragenodeBandwidthRollup(ctx context.Context,
	storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
	storagenode_bandwidth_rollup_interval_start StoragenodeBandwidthRollup_IntervalStart_Field,
	storagenode_bandwidth_rollup_interval_seconds StoragenodeBandwidthRollup_IntervalSeconds_Field,
	storagenode_bandwidth_rollup_action StoragenodeBandwidthRollup_Action_Field,
	storagenode_bandwidth_rollup_settled StoragenodeBandwidthRollup_Settled_Field,
	optional StoragenodeBandwidthRollup_Create_Fields) (
	storagenode_bandwidth_rollup *StoragenodeBandwidthRollup, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__storagenode_id_val := storagenode_bandwidth_rollup_storagenode_id.value()
	__interval_start_val := storagenode_bandwidth_rollup_interval_start.value()
	__interval_seconds_val := storagenode_bandwidth_rollup_interval_seconds.value()
	__action_val := storagenode_bandwidth_rollup_action.value()
	__settled_val := storagenode_bandwidth_rollup_settled.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("storagenode_id, interval_start, interval_seconds, action, settled")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO storagenode_bandwidth_rollups "), __clause, __sqlbundle_Literal(" THEN RETURN storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled")}}

	var __values []any
	__values = append(__values, __storagenode_id_val, __interval_start_val, __interval_seconds_val, __action_val, __settled_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Allocated._set {
		__values = append(__values, optional.Allocated.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("allocated"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("allocated"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	storagenode_bandwidth_rollup = &StoragenodeBandwidthRollup{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return storagenode_bandwidth_rollup, nil

}

func (obj *spannerImpl) Create_ReverificationAudits(ctx context.Context,
	reverification_audits_node_id ReverificationAudits_NodeId_Field,
	reverification_audits_stream_id ReverificationAudits_StreamId_Field,
	reverification_audits_position ReverificationAudits_Position_Field,
	reverification_audits_piece_num ReverificationAudits_PieceNum_Field,
	optional ReverificationAudits_Create_Fields) (
	reverification_audits *ReverificationAudits, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__node_id_val := reverification_audits_node_id.value()
	__stream_id_val := reverification_audits_stream_id.value()
	__position_val := reverification_audits_position.value()
	__piece_num_val := reverification_audits_piece_num.value()
	__last_attempt_val := optional.LastAttempt.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("node_id, stream_id, position, piece_num, last_attempt")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO reverification_audits "), __clause, __sqlbundle_Literal(" THEN RETURN reverification_audits.node_id, reverification_audits.stream_id, reverification_audits.position, reverification_audits.piece_num, reverification_audits.inserted_at, reverification_audits.last_attempt, reverification_audits.reverify_count")}}

	var __values []any
	__values = append(__values, __node_id_val, __stream_id_val, __position_val, __piece_num_val, __last_attempt_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.InsertedAt._set {
		__values = append(__values, optional.InsertedAt.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("inserted_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ReverifyCount._set {
		__values = append(__values, optional.ReverifyCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("reverify_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("inserted_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("reverify_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reverification_audits = &ReverificationAudits{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&reverification_audits.NodeId, &reverification_audits.StreamId, &reverification_audits.Position, &reverification_audits.PieceNum, &reverification_audits.InsertedAt, &reverification_audits.LastAttempt, &reverification_audits.ReverifyCount)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&reverification_audits.NodeId, &reverification_audits.StreamId, &reverification_audits.Position, &reverification_audits.PieceNum, &reverification_audits.InsertedAt, &reverification_audits.LastAttempt, &reverification_audits.ReverifyCount)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reverification_audits, nil

}

func (obj *spannerImpl) Create_StripeCustomer(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field,
	stripe_customer_customer_id StripeCustomer_CustomerId_Field,
	optional StripeCustomer_Create_Fields) (
	stripe_customer *StripeCustomer, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := stripe_customer_user_id.value()
	__customer_id_val := stripe_customer_customer_id.value()
	__billing_customer_id_val := optional.BillingCustomerId.value()
	__package_plan_val := optional.PackagePlan.value()
	__purchased_package_at_val := optional.PurchasedPackageAt.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO stripe_customers ( user_id, customer_id, billing_customer_id, package_plan, purchased_package_at, created_at ) VALUES ( ?, ?, ?, ?, ?, ? ) THEN RETURN stripe_customers.user_id, stripe_customers.customer_id, stripe_customers.billing_customer_id, stripe_customers.package_plan, stripe_customers.purchased_package_at, stripe_customers.created_at")

	var __values []any
	__values = append(__values, __user_id_val, __customer_id_val, __billing_customer_id_val, __package_plan_val, __purchased_package_at_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripe_customer = &StripeCustomer{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&stripe_customer.UserId, &stripe_customer.CustomerId, &stripe_customer.BillingCustomerId, &stripe_customer.PackagePlan, &stripe_customer.PurchasedPackageAt, &stripe_customer.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&stripe_customer.UserId, &stripe_customer.CustomerId, &stripe_customer.BillingCustomerId, &stripe_customer.PackagePlan, &stripe_customer.PurchasedPackageAt, &stripe_customer.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripe_customer, nil

}

func (obj *spannerImpl) CreateNoReturn_BillingBalance(ctx context.Context,
	billing_balance_user_id BillingBalance_UserId_Field,
	billing_balance_balance BillingBalance_Balance_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := billing_balance_user_id.value()
	__balance_val := billing_balance_balance.value()
	__last_updated_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO billing_balances ( user_id, balance, last_updated ) VALUES ( ?, ?, ? )")

	var __values []any
	__values = append(__values, __user_id_val, __balance_val, __last_updated_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Create_BillingTransaction(ctx context.Context,
	billing_transaction_user_id BillingTransaction_UserId_Field,
	billing_transaction_amount BillingTransaction_Amount_Field,
	billing_transaction_currency BillingTransaction_Currency_Field,
	billing_transaction_description BillingTransaction_Description_Field,
	billing_transaction_source BillingTransaction_Source_Field,
	billing_transaction_status BillingTransaction_Status_Field,
	billing_transaction_type BillingTransaction_Type_Field,
	billing_transaction_metadata BillingTransaction_Metadata_Field,
	billing_transaction_tx_timestamp BillingTransaction_TxTimestamp_Field) (
	billing_transaction *BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := billing_transaction_user_id.value()
	__amount_val := billing_transaction_amount.value()
	__currency_val := billing_transaction_currency.value()
	__description_val := billing_transaction_description.value()
	__source_val := billing_transaction_source.value()
	__status_val := billing_transaction_status.value()
	__type_val := billing_transaction_type.value()
	__metadata_val := spannerConvertJSON(billing_transaction_metadata.value())
	__tx_timestamp_val := billing_transaction_tx_timestamp.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO billing_transactions ( user_id, amount, currency, description, source, status, type, metadata, tx_timestamp, created_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) THEN RETURN billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at")

	var __values []any
	__values = append(__values, __user_id_val, __amount_val, __currency_val, __description_val, __source_val, __status_val, __type_val, __metadata_val, __tx_timestamp_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	billing_transaction = &BillingTransaction{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, spannerConvertJSON(&billing_transaction.Metadata), &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, spannerConvertJSON(&billing_transaction.Metadata), &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return billing_transaction, nil

}

func (obj *spannerImpl) CreateNoReturn_StorjscanWallet(ctx context.Context,
	storjscan_wallet_user_id StorjscanWallet_UserId_Field,
	storjscan_wallet_wallet_address StorjscanWallet_WalletAddress_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__user_id_val := storjscan_wallet_user_id.value()
	__wallet_address_val := storjscan_wallet_wallet_address.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO storjscan_wallets ( user_id, wallet_address, created_at ) VALUES ( ?, ?, ? )")

	var __values []any
	__values = append(__values, __user_id_val, __wallet_address_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Create_CoinpaymentsTransaction(ctx context.Context,
	coinpayments_transaction_id CoinpaymentsTransaction_Id_Field,
	coinpayments_transaction_user_id CoinpaymentsTransaction_UserId_Field,
	coinpayments_transaction_address CoinpaymentsTransaction_Address_Field,
	coinpayments_transaction_amount_numeric CoinpaymentsTransaction_AmountNumeric_Field,
	coinpayments_transaction_received_numeric CoinpaymentsTransaction_ReceivedNumeric_Field,
	coinpayments_transaction_status CoinpaymentsTransaction_Status_Field,
	coinpayments_transaction_key CoinpaymentsTransaction_Key_Field,
	coinpayments_transaction_timeout CoinpaymentsTransaction_Timeout_Field) (
	coinpayments_transaction *CoinpaymentsTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := coinpayments_transaction_id.value()
	__user_id_val := coinpayments_transaction_user_id.value()
	__address_val := coinpayments_transaction_address.value()
	__amount_numeric_val := coinpayments_transaction_amount_numeric.value()
	__received_numeric_val := coinpayments_transaction_received_numeric.value()
	__status_val := coinpayments_transaction_status.value()
	__key_val := coinpayments_transaction_key.value()
	__timeout_val := coinpayments_transaction_timeout.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO coinpayments_transactions ( id, user_id, address, amount_numeric, received_numeric, status, key, timeout, created_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ? ) THEN RETURN coinpayments_transactions.id, coinpayments_transactions.user_id, coinpayments_transactions.address, coinpayments_transactions.amount_numeric, coinpayments_transactions.received_numeric, coinpayments_transactions.status, coinpayments_transactions.key, coinpayments_transactions.timeout, coinpayments_transactions.created_at")

	var __values []any
	__values = append(__values, __id_val, __user_id_val, __address_val, __amount_numeric_val, __received_numeric_val, __status_val, __key_val, __timeout_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	coinpayments_transaction = &CoinpaymentsTransaction{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return coinpayments_transaction, nil

}

func (obj *spannerImpl) Create_StripecoinpaymentsInvoiceProjectRecord(ctx context.Context,
	stripecoinpayments_invoice_project_record_id StripecoinpaymentsInvoiceProjectRecord_Id_Field,
	stripecoinpayments_invoice_project_record_project_id StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field,
	stripecoinpayments_invoice_project_record_storage StripecoinpaymentsInvoiceProjectRecord_Storage_Field,
	stripecoinpayments_invoice_project_record_egress StripecoinpaymentsInvoiceProjectRecord_Egress_Field,
	stripecoinpayments_invoice_project_record_period_start StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field,
	stripecoinpayments_invoice_project_record_period_end StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field,
	stripecoinpayments_invoice_project_record_state StripecoinpaymentsInvoiceProjectRecord_State_Field,
	optional StripecoinpaymentsInvoiceProjectRecord_Create_Fields) (
	stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := stripecoinpayments_invoice_project_record_id.value()
	__project_id_val := stripecoinpayments_invoice_project_record_project_id.value()
	__storage_val := stripecoinpayments_invoice_project_record_storage.value()
	__egress_val := stripecoinpayments_invoice_project_record_egress.value()
	__objects_val := optional.Objects.value()
	__segments_val := optional.Segments.value()
	__period_start_val := stripecoinpayments_invoice_project_record_period_start.value()
	__period_end_val := stripecoinpayments_invoice_project_record_period_end.value()
	__state_val := stripecoinpayments_invoice_project_record_state.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO stripecoinpayments_invoice_project_records ( id, project_id, storage, egress, objects, segments, period_start, period_end, state, created_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ? ) THEN RETURN stripecoinpayments_invoice_project_records.id, stripecoinpayments_invoice_project_records.project_id, stripecoinpayments_invoice_project_records.storage, stripecoinpayments_invoice_project_records.egress, stripecoinpayments_invoice_project_records.objects, stripecoinpayments_invoice_project_records.segments, stripecoinpayments_invoice_project_records.period_start, stripecoinpayments_invoice_project_records.period_end, stripecoinpayments_invoice_project_records.state, stripecoinpayments_invoice_project_records.created_at")

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __storage_val, __egress_val, __objects_val, __segments_val, __period_start_val, __period_end_val, __state_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_invoice_project_record = &StripecoinpaymentsInvoiceProjectRecord{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripecoinpayments_invoice_project_record, nil

}

func (obj *spannerImpl) Create_StripecoinpaymentsTxConversionRate(ctx context.Context,
	stripecoinpayments_tx_conversion_rate_tx_id StripecoinpaymentsTxConversionRate_TxId_Field,
	stripecoinpayments_tx_conversion_rate_rate_numeric StripecoinpaymentsTxConversionRate_RateNumeric_Field) (
	stripecoinpayments_tx_conversion_rate *StripecoinpaymentsTxConversionRate, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__tx_id_val := stripecoinpayments_tx_conversion_rate_tx_id.value()
	__rate_numeric_val := stripecoinpayments_tx_conversion_rate_rate_numeric.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO stripecoinpayments_tx_conversion_rates ( tx_id, rate_numeric, created_at ) VALUES ( ?, ?, ? ) THEN RETURN stripecoinpayments_tx_conversion_rates.tx_id, stripecoinpayments_tx_conversion_rates.rate_numeric, stripecoinpayments_tx_conversion_rates.created_at")

	var __values []any
	__values = append(__values, __tx_id_val, __rate_numeric_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_tx_conversion_rate = &StripecoinpaymentsTxConversionRate{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_tx_conversion_rate.TxId, &stripecoinpayments_tx_conversion_rate.RateNumeric, &stripecoinpayments_tx_conversion_rate.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_tx_conversion_rate.TxId, &stripecoinpayments_tx_conversion_rate.RateNumeric, &stripecoinpayments_tx_conversion_rate.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripecoinpayments_tx_conversion_rate, nil

}

func (obj *spannerImpl) CreateNoReturn_StorjscanPayment(ctx context.Context,
	storjscan_payment_block_hash StorjscanPayment_BlockHash_Field,
	storjscan_payment_block_number StorjscanPayment_BlockNumber_Field,
	storjscan_payment_transaction StorjscanPayment_Transaction_Field,
	storjscan_payment_log_index StorjscanPayment_LogIndex_Field,
	storjscan_payment_from_address StorjscanPayment_FromAddress_Field,
	storjscan_payment_to_address StorjscanPayment_ToAddress_Field,
	storjscan_payment_token_value StorjscanPayment_TokenValue_Field,
	storjscan_payment_usd_value StorjscanPayment_UsdValue_Field,
	storjscan_payment_status StorjscanPayment_Status_Field,
	storjscan_payment_block_timestamp StorjscanPayment_BlockTimestamp_Field,
	optional StorjscanPayment_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__block_hash_val := storjscan_payment_block_hash.value()
	__block_number_val := storjscan_payment_block_number.value()
	__transaction_val := storjscan_payment_transaction.value()
	__log_index_val := storjscan_payment_log_index.value()
	__from_address_val := storjscan_payment_from_address.value()
	__to_address_val := storjscan_payment_to_address.value()
	__token_value_val := storjscan_payment_token_value.value()
	__usd_value_val := storjscan_payment_usd_value.value()
	__status_val := storjscan_payment_status.value()
	__block_timestamp_val := storjscan_payment_block_timestamp.value()
	__created_at_val := __now

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("block_hash, block_number, transaction, log_index, from_address, to_address, token_value, usd_value, status, block_timestamp, created_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO storjscan_payments "), __clause}}

	var __values []any
	__values = append(__values, __block_hash_val, __block_number_val, __transaction_val, __log_index_val, __from_address_val, __to_address_val, __token_value_val, __usd_value_val, __status_val, __block_timestamp_val, __created_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.ChainId._set {
		__values = append(__values, optional.ChainId.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("chain_id"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("chain_id"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Create_ChangeHistory(ctx context.Context,
	change_history_id ChangeHistory_Id_Field,
	change_history_admin_email ChangeHistory_AdminEmail_Field,
	change_history_user_id ChangeHistory_UserId_Field,
	change_history_item_type ChangeHistory_ItemType_Field,
	change_history_operation ChangeHistory_Operation_Field,
	change_history_reason ChangeHistory_Reason_Field,
	change_history_changes ChangeHistory_Changes_Field,
	optional ChangeHistory_Create_Fields) (
	change_history *ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := change_history_id.value()
	__admin_email_val := change_history_admin_email.value()
	__user_id_val := change_history_user_id.value()
	__project_id_val := optional.ProjectId.value()
	__bucket_name_val := optional.BucketName.value()
	__item_type_val := change_history_item_type.value()
	__operation_val := change_history_operation.value()
	__reason_val := change_history_reason.value()
	__changes_val := spannerConvertJSON(change_history_changes.value())

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, admin_email, user_id, project_id, bucket_name, item_type, operation, reason, changes")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO change_histories "), __clause, __sqlbundle_Literal(" THEN RETURN change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp")}}

	var __values []any
	__values = append(__values, __id_val, __admin_email_val, __user_id_val, __project_id_val, __bucket_name_val, __item_type_val, __operation_val, __reason_val, __changes_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Timestamp._set {
		__values = append(__values, optional.Timestamp.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("timestamp"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("timestamp"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	change_history = &ChangeHistory{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, spannerConvertJSON(&change_history.Changes), &change_history.Timestamp)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, spannerConvertJSON(&change_history.Changes), &change_history.Timestamp)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return change_history, nil

}

func (obj *spannerImpl) Create_Domain(ctx context.Context,
	domain_subdomain Domain_Subdomain_Field,
	domain_project_id Domain_ProjectId_Field,
	domain_prefix Domain_Prefix_Field,
	domain_access_id Domain_AccessId_Field,
	domain_created_by Domain_CreatedBy_Field) (
	domain *Domain, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__subdomain_val := domain_subdomain.value()
	__project_id_val := domain_project_id.value()
	__prefix_val := domain_prefix.value()
	__access_id_val := domain_access_id.value()
	__created_by_val := domain_created_by.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO domains ( subdomain, project_id, prefix, access_id, created_by, created_at ) VALUES ( ?, ?, ?, ?, ?, ? ) THEN RETURN domains.subdomain, domains.project_id, domains.prefix, domains.access_id, domains.created_by, domains.created_at")

	var __values []any
	__values = append(__values, __subdomain_val, __project_id_val, __prefix_val, __access_id_val, __created_by_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	domain = &Domain{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&domain.Subdomain, &domain.ProjectId, &domain.Prefix, &domain.AccessId, &domain.CreatedBy, &domain.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&domain.Subdomain, &domain.ProjectId, &domain.Prefix, &domain.AccessId, &domain.CreatedBy, &domain.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return domain, nil

}

func (obj *spannerImpl) Replace_Entitlement(ctx context.Context,
	entitlement_scope Entitlement_Scope_Field,
	entitlement_updated_at Entitlement_UpdatedAt_Field,
	optional Entitlement_Create_Fields) (
	entitlement *Entitlement, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__scope_val := entitlement_scope.value()
	__updated_at_val := entitlement_updated_at.value()
	__created_at_val := __now

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("scope, updated_at, created_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT OR UPDATE INTO entitlements "), __clause, __sqlbundle_Literal(" THEN RETURN entitlements.scope, entitlements.features, entitlements.updated_at, entitlements.created_at")}}

	var __values []any
	__values = append(__values, __scope_val, __updated_at_val, __created_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Features._set {
		__values = append(__values, spannerConvertJSON(optional.Features.value()))
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("features"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("features"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	entitlement = &Entitlement{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&entitlement.Scope, spannerConvertJSON(&entitlement.Features), &entitlement.UpdatedAt, &entitlement.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&entitlement.Scope, spannerConvertJSON(&entitlement.Features), &entitlement.UpdatedAt, &entitlement.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return entitlement, nil

}

func (obj *spannerImpl) CreateNoReturn_PeerIdentity(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field,
	peer_identity_leaf_serial_number PeerIdentity_LeafSerialNumber_Field,
	peer_identity_chain PeerIdentity_Chain_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__node_id_val := peer_identity_node_id.value()
	__leaf_serial_number_val := peer_identity_leaf_serial_number.value()
	__chain_val := peer_identity_chain.value()
	__updated_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO peer_identities ( node_id, leaf_serial_number, chain, updated_at ) VALUES ( ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __node_id_val, __leaf_serial_number_val, __chain_val, __updated_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) CreateNoReturn_Revocation(ctx context.Context,
	revocation_revoked Revocation_Revoked_Field,
	revocation_api_key_id Revocation_ApiKeyId_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__revoked_val := revocation_revoked.value()
	__api_key_id_val := revocation_api_key_id.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO revocations ( revoked, api_key_id ) VALUES ( ?, ? )")

	var __values []any
	__values = append(__values, __revoked_val, __api_key_id_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) ReplaceNoReturn_NodeApiVersion(ctx context.Context,
	node_api_version_id NodeApiVersion_Id_Field,
	node_api_version_api_version NodeApiVersion_ApiVersion_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := node_api_version_id.value()
	__api_version_val := node_api_version_api_version.value()
	__created_at_val := __now
	__updated_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT OR UPDATE INTO node_api_versions ( id, api_version, created_at, updated_at ) VALUES ( ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __id_val, __api_version_val, __created_at_val, __updated_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Create_NodeEvent(ctx context.Context,
	node_event_id NodeEvent_Id_Field,
	node_event_email NodeEvent_Email_Field,
	node_event_node_id NodeEvent_NodeId_Field,
	node_event_event NodeEvent_Event_Field,
	optional NodeEvent_Create_Fields) (
	node_event *NodeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := node_event_id.value()
	__email_val := node_event_email.value()
	__last_ip_port_val := optional.LastIpPort.value()
	__node_id_val := node_event_node_id.value()
	__event_val := node_event_event.value()
	__last_attempted_val := optional.LastAttempted.value()
	__email_sent_val := optional.EmailSent.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, email, last_ip_port, node_id, event, last_attempted, email_sent")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO node_events "), __clause, __sqlbundle_Literal(" THEN RETURN node_events.id, node_events.email, node_events.last_ip_port, node_events.node_id, node_events.event, node_events.created_at, node_events.last_attempted, node_events.email_sent")}}

	var __values []any
	__values = append(__values, __id_val, __email_val, __last_ip_port_val, __node_id_val, __event_val, __last_attempted_val, __email_sent_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.CreatedAt._set {
		__values = append(__values, optional.CreatedAt.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("created_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("created_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node_event = &NodeEvent{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node_event, nil

}

func (obj *spannerImpl) ReplaceNoReturn_NodeTags(ctx context.Context,
	node_tags_node_id NodeTags_NodeId_Field,
	node_tags_name NodeTags_Name_Field,
	node_tags_value NodeTags_Value_Field,
	node_tags_signed_at NodeTags_SignedAt_Field,
	node_tags_signer NodeTags_Signer_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__node_id_val := node_tags_node_id.value()
	__name_val := node_tags_name.value()
	__value_val := node_tags_value.value()
	__signed_at_val := node_tags_signed_at.value()
	__signer_val := node_tags_signer.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT OR UPDATE INTO node_tags ( node_id, name, value, signed_at, signer ) VALUES ( ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __node_id_val, __name_val, __value_val, __signed_at_val, __signer_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) ReplaceNoReturn_StoragenodePaystub(ctx context.Context,
	storagenode_paystub_period StoragenodePaystub_Period_Field,
	storagenode_paystub_node_id StoragenodePaystub_NodeId_Field,
	storagenode_paystub_codes StoragenodePaystub_Codes_Field,
	storagenode_paystub_usage_at_rest StoragenodePaystub_UsageAtRest_Field,
	storagenode_paystub_usage_get StoragenodePaystub_UsageGet_Field,
	storagenode_paystub_usage_put StoragenodePaystub_UsagePut_Field,
	storagenode_paystub_usage_get_repair StoragenodePaystub_UsageGetRepair_Field,
	storagenode_paystub_usage_put_repair StoragenodePaystub_UsagePutRepair_Field,
	storagenode_paystub_usage_get_audit StoragenodePaystub_UsageGetAudit_Field,
	storagenode_paystub_comp_at_rest StoragenodePaystub_CompAtRest_Field,
	storagenode_paystub_comp_get StoragenodePaystub_CompGet_Field,
	storagenode_paystub_comp_put StoragenodePaystub_CompPut_Field,
	storagenode_paystub_comp_get_repair StoragenodePaystub_CompGetRepair_Field,
	storagenode_paystub_comp_put_repair StoragenodePaystub_CompPutRepair_Field,
	storagenode_paystub_comp_get_audit StoragenodePaystub_CompGetAudit_Field,
	storagenode_paystub_surge_percent StoragenodePaystub_SurgePercent_Field,
	storagenode_paystub_held StoragenodePaystub_Held_Field,
	storagenode_paystub_owed StoragenodePaystub_Owed_Field,
	storagenode_paystub_disposed StoragenodePaystub_Disposed_Field,
	storagenode_paystub_paid StoragenodePaystub_Paid_Field,
	storagenode_paystub_distributed StoragenodePaystub_Distributed_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__period_val := storagenode_paystub_period.value()
	__node_id_val := storagenode_paystub_node_id.value()
	__created_at_val := __now
	__codes_val := storagenode_paystub_codes.value()
	__usage_at_rest_val := storagenode_paystub_usage_at_rest.value()
	__usage_get_val := storagenode_paystub_usage_get.value()
	__usage_put_val := storagenode_paystub_usage_put.value()
	__usage_get_repair_val := storagenode_paystub_usage_get_repair.value()
	__usage_put_repair_val := storagenode_paystub_usage_put_repair.value()
	__usage_get_audit_val := storagenode_paystub_usage_get_audit.value()
	__comp_at_rest_val := storagenode_paystub_comp_at_rest.value()
	__comp_get_val := storagenode_paystub_comp_get.value()
	__comp_put_val := storagenode_paystub_comp_put.value()
	__comp_get_repair_val := storagenode_paystub_comp_get_repair.value()
	__comp_put_repair_val := storagenode_paystub_comp_put_repair.value()
	__comp_get_audit_val := storagenode_paystub_comp_get_audit.value()
	__surge_percent_val := storagenode_paystub_surge_percent.value()
	__held_val := storagenode_paystub_held.value()
	__owed_val := storagenode_paystub_owed.value()
	__disposed_val := storagenode_paystub_disposed.value()
	__paid_val := storagenode_paystub_paid.value()
	__distributed_val := storagenode_paystub_distributed.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT OR UPDATE INTO storagenode_paystubs ( period, node_id, created_at, codes, usage_at_rest, usage_get, usage_put, usage_get_repair, usage_put_repair, usage_get_audit, comp_at_rest, comp_get, comp_put, comp_get_repair, comp_put_repair, comp_get_audit, surge_percent, held, owed, disposed, paid, distributed ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __period_val, __node_id_val, __created_at_val, __codes_val, __usage_at_rest_val, __usage_get_val, __usage_put_val, __usage_get_repair_val, __usage_put_repair_val, __usage_get_audit_val, __comp_at_rest_val, __comp_get_val, __comp_put_val, __comp_get_repair_val, __comp_put_repair_val, __comp_get_audit_val, __surge_percent_val, __held_val, __owed_val, __disposed_val, __paid_val, __distributed_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) CreateNoReturn_StoragenodePayment(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field,
	storagenode_payment_period StoragenodePayment_Period_Field,
	storagenode_payment_amount StoragenodePayment_Amount_Field,
	optional StoragenodePayment_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__created_at_val := __now
	__node_id_val := storagenode_payment_node_id.value()
	__period_val := storagenode_payment_period.value()
	__amount_val := storagenode_payment_amount.value()
	__receipt_val := optional.Receipt.value()
	__notes_val := optional.Notes.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO storagenode_payments ( created_at, node_id, period, amount, receipt, notes ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __created_at_val, __node_id_val, __period_val, __amount_val, __receipt_val, __notes_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Create_Reputation(ctx context.Context,
	reputation_id Reputation_Id_Field,
	reputation_audit_history Reputation_AuditHistory_Field,
	optional Reputation_Create_Fields) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := reputation_id.value()
	__vetted_at_val := optional.VettedAt.value()
	__disqualified_val := optional.Disqualified.value()
	__disqualification_reason_val := optional.DisqualificationReason.value()
	__unknown_audit_suspended_val := optional.UnknownAuditSuspended.value()
	__offline_suspended_val := optional.OfflineSuspended.value()
	__under_review_val := optional.UnderReview.value()
	__audit_history_val := reputation_audit_history.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, vetted_at, disqualified, disqualification_reason, unknown_audit_suspended, offline_suspended, under_review, audit_history")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO reputations "), __clause, __sqlbundle_Literal(" THEN RETURN reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta")}}

	var __values []any
	__values = append(__values, __id_val, __vetted_at_val, __disqualified_val, __disqualification_reason_val, __unknown_audit_suspended_val, __offline_suspended_val, __under_review_val, __audit_history_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.AuditSuccessCount._set {
		__values = append(__values, optional.AuditSuccessCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_success_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.TotalAuditCount._set {
		__values = append(__values, optional.TotalAuditCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("total_audit_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.OnlineScore._set {
		__values = append(__values, optional.OnlineScore.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("online_score"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.AuditReputationAlpha._set {
		__values = append(__values, optional.AuditReputationAlpha.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_reputation_alpha"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.AuditReputationBeta._set {
		__values = append(__values, optional.AuditReputationBeta.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_reputation_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.UnknownAuditReputationAlpha._set {
		__values = append(__values, optional.UnknownAuditReputationAlpha.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.UnknownAuditReputationBeta._set {
		__values = append(__values, optional.UnknownAuditReputationBeta.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_success_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("total_audit_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("online_score"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_reputation_alpha"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("audit_reputation_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reputation, nil

}

func (obj *spannerImpl) CreateNoReturn_OauthClient(ctx context.Context,
	oauth_client_id OauthClient_Id_Field,
	oauth_client_encrypted_secret OauthClient_EncryptedSecret_Field,
	oauth_client_redirect_url OauthClient_RedirectUrl_Field,
	oauth_client_user_id OauthClient_UserId_Field,
	oauth_client_app_name OauthClient_AppName_Field,
	oauth_client_app_logo_url OauthClient_AppLogoUrl_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := oauth_client_id.value()
	__encrypted_secret_val := oauth_client_encrypted_secret.value()
	__redirect_url_val := oauth_client_redirect_url.value()
	__user_id_val := oauth_client_user_id.value()
	__app_name_val := oauth_client_app_name.value()
	__app_logo_url_val := oauth_client_app_logo_url.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO oauth_clients ( id, encrypted_secret, redirect_url, user_id, app_name, app_logo_url ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __id_val, __encrypted_secret_val, __redirect_url_val, __user_id_val, __app_name_val, __app_logo_url_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) CreateNoReturn_OauthCode(ctx context.Context,
	oauth_code_client_id OauthCode_ClientId_Field,
	oauth_code_user_id OauthCode_UserId_Field,
	oauth_code_scope OauthCode_Scope_Field,
	oauth_code_redirect_url OauthCode_RedirectUrl_Field,
	oauth_code_challenge OauthCode_Challenge_Field,
	oauth_code_challenge_method OauthCode_ChallengeMethod_Field,
	oauth_code_code OauthCode_Code_Field,
	oauth_code_created_at OauthCode_CreatedAt_Field,
	oauth_code_expires_at OauthCode_ExpiresAt_Field,
	optional OauthCode_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__client_id_val := oauth_code_client_id.value()
	__user_id_val := oauth_code_user_id.value()
	__scope_val := oauth_code_scope.value()
	__redirect_url_val := oauth_code_redirect_url.value()
	__challenge_val := oauth_code_challenge.value()
	__challenge_method_val := oauth_code_challenge_method.value()
	__code_val := oauth_code_code.value()
	__created_at_val := oauth_code_created_at.value()
	__expires_at_val := oauth_code_expires_at.value()
	__claimed_at_val := optional.ClaimedAt.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO oauth_codes ( client_id, user_id, scope, redirect_url, challenge, challenge_method, code, created_at, expires_at, claimed_at ) VALUES ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __client_id_val, __user_id_val, __scope_val, __redirect_url_val, __challenge_val, __challenge_method_val, __code_val, __created_at_val, __expires_at_val, __claimed_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) CreateNoReturn_OauthToken(ctx context.Context,
	oauth_token_client_id OauthToken_ClientId_Field,
	oauth_token_user_id OauthToken_UserId_Field,
	oauth_token_scope OauthToken_Scope_Field,
	oauth_token_kind OauthToken_Kind_Field,
	oauth_token_token OauthToken_Token_Field,
	oauth_token_created_at OauthToken_CreatedAt_Field,
	oauth_token_expires_at OauthToken_ExpiresAt_Field) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__client_id_val := oauth_token_client_id.value()
	__user_id_val := oauth_token_user_id.value()
	__scope_val := oauth_token_scope.value()
	__kind_val := oauth_token_kind.value()
	__token_val := oauth_token_token.value()
	__created_at_val := oauth_token_created_at.value()
	__expires_at_val := oauth_token_expires_at.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO oauth_tokens ( client_id, user_id, scope, kind, token, created_at, expires_at ) VALUES ( ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __client_id_val, __user_id_val, __scope_val, __kind_val, __token_val, __created_at_val, __expires_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Create_Project(ctx context.Context,
	project_id Project_Id_Field,
	project_name Project_Name_Field,
	project_description Project_Description_Field,
	project_owner_id Project_OwnerId_Field,
	optional Project_Create_Fields) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := project_id.value()
	__public_id_val := optional.PublicId.value()
	__name_val := project_name.value()
	__description_val := project_description.value()
	__usage_limit_val := optional.UsageLimit.value()
	__bandwidth_limit_val := optional.BandwidthLimit.value()
	__user_specified_usage_limit_val := optional.UserSpecifiedUsageLimit.value()
	__user_specified_bandwidth_limit_val := optional.UserSpecifiedBandwidthLimit.value()
	__rate_limit_val := optional.RateLimit.value()
	__burst_limit_val := optional.BurstLimit.value()
	__rate_limit_head_val := optional.RateLimitHead.value()
	__burst_limit_head_val := optional.BurstLimitHead.value()
	__rate_limit_get_val := optional.RateLimitGet.value()
	__burst_limit_get_val := optional.BurstLimitGet.value()
	__rate_limit_put_val := optional.RateLimitPut.value()
	__burst_limit_put_val := optional.BurstLimitPut.value()
	__rate_limit_list_val := optional.RateLimitList.value()
	__burst_limit_list_val := optional.BurstLimitList.value()
	__rate_limit_del_val := optional.RateLimitDel.value()
	__burst_limit_del_val := optional.BurstLimitDel.value()
	__max_buckets_val := optional.MaxBuckets.value()
	__user_agent_val := optional.UserAgent.value()
	__owner_id_val := project_owner_id.value()
	__salt_val := optional.Salt.value()
	__status_updated_at_val := optional.StatusUpdatedAt.value()
	__created_at_val := __now
	__default_placement_val := optional.DefaultPlacement.value()
	__passphrase_enc_val := optional.PassphraseEnc.value()
	__passphrase_enc_key_id_val := optional.PassphraseEncKeyId.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, public_id, name, description, usage_limit, bandwidth_limit, user_specified_usage_limit, user_specified_bandwidth_limit, rate_limit, burst_limit, rate_limit_head, burst_limit_head, rate_limit_get, burst_limit_get, rate_limit_put, burst_limit_put, rate_limit_list, burst_limit_list, rate_limit_del, burst_limit_del, max_buckets, user_agent, owner_id, salt, status_updated_at, created_at, default_placement, passphrase_enc, passphrase_enc_key_id")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO projects "), __clause, __sqlbundle_Literal(" THEN RETURN projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption")}}

	var __values []any
	__values = append(__values, __id_val, __public_id_val, __name_val, __description_val, __usage_limit_val, __bandwidth_limit_val, __user_specified_usage_limit_val, __user_specified_bandwidth_limit_val, __rate_limit_val, __burst_limit_val, __rate_limit_head_val, __burst_limit_head_val, __rate_limit_get_val, __burst_limit_get_val, __rate_limit_put_val, __burst_limit_put_val, __rate_limit_list_val, __burst_limit_list_val, __rate_limit_del_val, __burst_limit_del_val, __max_buckets_val, __user_agent_val, __owner_id_val, __salt_val, __status_updated_at_val, __created_at_val, __default_placement_val, __passphrase_enc_val, __passphrase_enc_key_id_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.SegmentLimit._set {
		__values = append(__values, optional.SegmentLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("segment_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.Status._set {
		__values = append(__values, optional.Status.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("status"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.DefaultVersioning._set {
		__values = append(__values, optional.DefaultVersioning.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("default_versioning"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.PromptedForVersioningBeta._set {
		__values = append(__values, optional.PromptedForVersioningBeta.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("prompted_for_versioning_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.PathEncryption._set {
		__values = append(__values, optional.PathEncryption.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("path_encryption"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("segment_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("status"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("default_versioning"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("prompted_for_versioning_beta"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("path_encryption"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil

}

func (obj *spannerImpl) Create_ProjectMember(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field,
	optional ProjectMember_Create_Fields) (
	project_member *ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__member_id_val := project_member_member_id.value()
	__project_id_val := project_member_project_id.value()
	__created_at_val := __now

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("member_id, project_id, created_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO project_members "), __clause, __sqlbundle_Literal(" THEN RETURN project_members.member_id, project_members.project_id, project_members.role, project_members.created_at")}}

	var __values []any
	__values = append(__values, __member_id_val, __project_id_val, __created_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Role._set {
		__values = append(__values, optional.Role.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("role"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("role"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_member = &ProjectMember{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_member, nil

}

func (obj *spannerImpl) Replace_ProjectInvitation(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field,
	optional ProjectInvitation_Create_Fields) (
	project_invitation *ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__project_id_val := project_invitation_project_id.value()
	__email_val := project_invitation_email.value()
	__inviter_id_val := optional.InviterId.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT OR UPDATE INTO project_invitations ( project_id, email, inviter_id, created_at ) VALUES ( ?, ?, ?, ? ) THEN RETURN project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at")

	var __values []any
	__values = append(__values, __project_id_val, __email_val, __inviter_id_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_invitation = &ProjectInvitation{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_invitation, nil

}

func (obj *spannerImpl) Create_ApiKey(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	api_key_project_id ApiKey_ProjectId_Field,
	api_key_head ApiKey_Head_Field,
	api_key_name ApiKey_Name_Field,
	api_key_secret ApiKey_Secret_Field,
	optional ApiKey_Create_Fields) (
	api_key *ApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := api_key_id.value()
	__project_id_val := api_key_project_id.value()
	__head_val := api_key_head.value()
	__name_val := api_key_name.value()
	__secret_val := api_key_secret.value()
	__user_agent_val := optional.UserAgent.value()
	__created_at_val := __now
	__created_by_val := optional.CreatedBy.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, project_id, head, name, secret, user_agent, created_at, created_by")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO api_keys "), __clause, __sqlbundle_Literal(" THEN RETURN api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version")}}

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __head_val, __name_val, __secret_val, __user_agent_val, __created_at_val, __created_by_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Version._set {
		__values = append(__values, optional.Version.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("version"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("version"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key = &ApiKey{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Head, &api_key.Name, &api_key.Secret, &api_key.UserAgent, &api_key.CreatedAt, &api_key.CreatedBy, &api_key.Version)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&api_key.Id, &api_key.ProjectId, &api_key.Head, &api_key.Name, &api_key.Secret, &api_key.UserAgent, &api_key.CreatedAt, &api_key.CreatedBy, &api_key.Version)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key, nil

}

func (obj *spannerImpl) Replace_ApiKeyTail(ctx context.Context,
	api_key_tail_tail ApiKeyTail_Tail_Field,
	api_key_tail_parent_tail ApiKeyTail_ParentTail_Field,
	api_key_tail_caveat ApiKeyTail_Caveat_Field,
	api_key_tail_last_used ApiKeyTail_LastUsed_Field,
	optional ApiKeyTail_Create_Fields) (
	api_key_tail *ApiKeyTail, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__root_key_id_val := optional.RootKeyId.value()
	__tail_val := api_key_tail_tail.value()
	__parent_tail_val := api_key_tail_parent_tail.value()
	__caveat_val := api_key_tail_caveat.value()
	__last_used_val := api_key_tail_last_used.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT OR UPDATE INTO api_key_tails ( root_key_id, tail, parent_tail, caveat, last_used ) VALUES ( ?, ?, ?, ?, ? ) THEN RETURN api_key_tails.root_key_id, api_key_tails.tail, api_key_tails.parent_tail, api_key_tails.caveat, api_key_tails.last_used")

	var __values []any
	__values = append(__values, __root_key_id_val, __tail_val, __parent_tail_val, __caveat_val, __last_used_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key_tail = &ApiKeyTail{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&api_key_tail.RootKeyId, &api_key_tail.Tail, &api_key_tail.ParentTail, &api_key_tail.Caveat, &api_key_tail.LastUsed)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&api_key_tail.RootKeyId, &api_key_tail.Tail, &api_key_tail.ParentTail, &api_key_tail.Caveat, &api_key_tail.LastUsed)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return api_key_tail, nil

}

func (obj *spannerImpl) Create_BucketMetainfo(ctx context.Context,
	bucket_metainfo_id BucketMetainfo_Id_Field,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	bucket_metainfo_path_cipher BucketMetainfo_PathCipher_Field,
	bucket_metainfo_default_segment_size BucketMetainfo_DefaultSegmentSize_Field,
	bucket_metainfo_default_encryption_cipher_suite BucketMetainfo_DefaultEncryptionCipherSuite_Field,
	bucket_metainfo_default_encryption_block_size BucketMetainfo_DefaultEncryptionBlockSize_Field,
	bucket_metainfo_default_redundancy_algorithm BucketMetainfo_DefaultRedundancyAlgorithm_Field,
	bucket_metainfo_default_redundancy_share_size BucketMetainfo_DefaultRedundancyShareSize_Field,
	bucket_metainfo_default_redundancy_required_shares BucketMetainfo_DefaultRedundancyRequiredShares_Field,
	bucket_metainfo_default_redundancy_repair_shares BucketMetainfo_DefaultRedundancyRepairShares_Field,
	bucket_metainfo_default_redundancy_optimal_shares BucketMetainfo_DefaultRedundancyOptimalShares_Field,
	bucket_metainfo_default_redundancy_total_shares BucketMetainfo_DefaultRedundancyTotalShares_Field,
	optional BucketMetainfo_Create_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := bucket_metainfo_id.value()
	__project_id_val := bucket_metainfo_project_id.value()
	__name_val := bucket_metainfo_name.value()
	__tags_val := optional.Tags.value()
	__user_agent_val := optional.UserAgent.value()
	__default_retention_mode_val := optional.DefaultRetentionMode.value()
	__default_retention_days_val := optional.DefaultRetentionDays.value()
	__default_retention_years_val := optional.DefaultRetentionYears.value()
	__path_cipher_val := bucket_metainfo_path_cipher.value()
	__created_at_val := __now
	__default_segment_size_val := bucket_metainfo_default_segment_size.value()
	__default_encryption_cipher_suite_val := bucket_metainfo_default_encryption_cipher_suite.value()
	__default_encryption_block_size_val := bucket_metainfo_default_encryption_block_size.value()
	__default_redundancy_algorithm_val := bucket_metainfo_default_redundancy_algorithm.value()
	__default_redundancy_share_size_val := bucket_metainfo_default_redundancy_share_size.value()
	__default_redundancy_required_shares_val := bucket_metainfo_default_redundancy_required_shares.value()
	__default_redundancy_repair_shares_val := bucket_metainfo_default_redundancy_repair_shares.value()
	__default_redundancy_optimal_shares_val := bucket_metainfo_default_redundancy_optimal_shares.value()
	__default_redundancy_total_shares_val := bucket_metainfo_default_redundancy_total_shares.value()
	__placement_val := optional.Placement.value()
	__created_by_val := optional.CreatedBy.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, project_id, name, tags, user_agent, default_retention_mode, default_retention_days, default_retention_years, path_cipher, created_at, default_segment_size, default_encryption_cipher_suite, default_encryption_block_size, default_redundancy_algorithm, default_redundancy_share_size, default_redundancy_required_shares, default_redundancy_repair_shares, default_redundancy_optimal_shares, default_redundancy_total_shares, placement, created_by")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO bucket_metainfos "), __clause, __sqlbundle_Literal(" THEN RETURN bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __name_val, __tags_val, __user_agent_val, __default_retention_mode_val, __default_retention_days_val, __default_retention_years_val, __path_cipher_val, __created_at_val, __default_segment_size_val, __default_encryption_cipher_suite_val, __default_encryption_block_size_val, __default_redundancy_algorithm_val, __default_redundancy_share_size_val, __default_redundancy_required_shares_val, __default_redundancy_repair_shares_val, __default_redundancy_optimal_shares_val, __default_redundancy_total_shares_val, __placement_val, __created_by_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.Versioning._set {
		__values = append(__values, optional.Versioning.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("versioning"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ObjectLockEnabled._set {
		__values = append(__values, optional.ObjectLockEnabled.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("object_lock_enabled"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("versioning"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("object_lock_enabled"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil

}

func (obj *spannerImpl) Create_ValueAttribution(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field,
	optional ValueAttribution_Create_Fields) (
	value_attribution *ValueAttribution, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__project_id_val := value_attribution_project_id.value()
	__bucket_name_val := value_attribution_bucket_name.value()
	__user_agent_val := optional.UserAgent.value()
	__placement_val := optional.Placement.value()
	__last_updated_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO value_attributions ( project_id, bucket_name, user_agent, placement, last_updated ) VALUES ( ?, ?, ?, ?, ? ) THEN RETURN value_attributions.project_id, value_attributions.bucket_name, value_attributions.user_agent, value_attributions.placement, value_attributions.last_updated")

	var __values []any
	__values = append(__values, __project_id_val, __bucket_name_val, __user_agent_val, __placement_val, __last_updated_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	value_attribution = &ValueAttribution{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return value_attribution, nil

}

func (obj *spannerImpl) Create_BucketMigration(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field,
	bucket_migration_project_id BucketMigration_ProjectId_Field,
	bucket_migration_bucket_name BucketMigration_BucketName_Field,
	bucket_migration_from_placement BucketMigration_FromPlacement_Field,
	bucket_migration_to_placement BucketMigration_ToPlacement_Field,
	bucket_migration_migration_type BucketMigration_MigrationType_Field,
	bucket_migration_state BucketMigration_State_Field,
	optional BucketMigration_Create_Fields) (
	bucket_migration *BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := bucket_migration_id.value()
	__project_id_val := bucket_migration_project_id.value()
	__bucket_name_val := bucket_migration_bucket_name.value()
	__from_placement_val := bucket_migration_from_placement.value()
	__to_placement_val := bucket_migration_to_placement.value()
	__migration_type_val := bucket_migration_migration_type.value()
	__state_val := bucket_migration_state.value()
	__error_message_val := optional.ErrorMessage.value()
	__created_at_val := __now
	__updated_at_val := __now
	__completed_at_val := optional.CompletedAt.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, project_id, bucket_name, from_placement, to_placement, migration_type, state, error_message, created_at, updated_at, completed_at")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO bucket_migrations "), __clause, __sqlbundle_Literal(" THEN RETURN bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at")}}

	var __values []any
	__values = append(__values, __id_val, __project_id_val, __bucket_name_val, __from_placement_val, __to_placement_val, __migration_type_val, __state_val, __error_message_val, __created_at_val, __updated_at_val, __completed_at_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.BytesProcessed._set {
		__values = append(__values, optional.BytesProcessed.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("bytes_processed"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("bytes_processed"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_migration = &BucketMigration{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_migration, nil

}

func (obj *spannerImpl) CreateNoReturn_RestApiKey(ctx context.Context,
	rest_api_key_id RestApiKey_Id_Field,
	rest_api_key_user_id RestApiKey_UserId_Field,
	rest_api_key_token RestApiKey_Token_Field,
	rest_api_key_name RestApiKey_Name_Field,
	optional RestApiKey_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := rest_api_key_id.value()
	__user_id_val := rest_api_key_user_id.value()
	__token_val := rest_api_key_token.value()
	__name_val := rest_api_key_name.value()
	__expires_at_val := optional.ExpiresAt.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO rest_api_keys ( id, user_id, token, name, expires_at, created_at ) VALUES ( ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __id_val, __user_id_val, __token_val, __name_val, __expires_at_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Create_User(ctx context.Context,
	user_id User_Id_Field,
	user_email User_Email_Field,
	user_normalized_email User_NormalizedEmail_Field,
	user_full_name User_FullName_Field,
	user_password_hash User_PasswordHash_Field,
	optional User_Create_Fields) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__id_val := user_id.value()
	__external_id_val := optional.ExternalId.value()
	__tenant_id_val := optional.TenantId.value()
	__email_val := user_email.value()
	__normalized_email_val := user_normalized_email.value()
	__full_name_val := user_full_name.value()
	__short_name_val := optional.ShortName.value()
	__password_hash_val := user_password_hash.value()
	__new_unverified_email_val := optional.NewUnverifiedEmail.value()
	__status_val := int(0)
	__status_updated_at_val := optional.StatusUpdatedAt.value()
	__user_agent_val := optional.UserAgent.value()
	__created_at_val := __now
	__position_val := optional.Position.value()
	__company_name_val := optional.CompanyName.value()
	__company_size_val := optional.CompanySize.value()
	__working_on_val := optional.WorkingOn.value()
	__employee_count_val := optional.EmployeeCount.value()
	__mfa_secret_key_val := optional.MfaSecretKey.value()
	__mfa_recovery_codes_val := optional.MfaRecoveryCodes.value()
	__signup_promo_code_val := optional.SignupPromoCode.value()
	__failed_login_count_val := optional.FailedLoginCount.value()
	__login_lockout_expiration_val := optional.LoginLockoutExpiration.value()
	__signup_captcha_val := optional.SignupCaptcha.value()
	__default_placement_val := optional.DefaultPlacement.value()
	__activation_code_val := optional.ActivationCode.value()
	__signup_id_val := optional.SignupId.value()
	__trial_expiration_val := optional.TrialExpiration.value()
	__upgrade_time_val := optional.UpgradeTime.value()
	__hubspot_object_id_val := optional.HubspotObjectId.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("id, external_id, tenant_id, email, normalized_email, full_name, short_name, password_hash, new_unverified_email, status, status_updated_at, user_agent, created_at, position, company_name, company_size, working_on, employee_count, mfa_secret_key, mfa_recovery_codes, signup_promo_code, failed_login_count, login_lockout_expiration, signup_captcha, default_placement, activation_code, signup_id, trial_expiration, upgrade_time, hubspot_object_id")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO users "), __clause, __sqlbundle_Literal(" THEN RETURN users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id")}}

	var __values []any
	__values = append(__values, __id_val, __external_id_val, __tenant_id_val, __email_val, __normalized_email_val, __full_name_val, __short_name_val, __password_hash_val, __new_unverified_email_val, __status_val, __status_updated_at_val, __user_agent_val, __created_at_val, __position_val, __company_name_val, __company_size_val, __working_on_val, __employee_count_val, __mfa_secret_key_val, __mfa_recovery_codes_val, __signup_promo_code_val, __failed_login_count_val, __login_lockout_expiration_val, __signup_captcha_val, __default_placement_val, __activation_code_val, __signup_id_val, __trial_expiration_val, __upgrade_time_val, __hubspot_object_id_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.EmailChangeVerificationStep._set {
		__values = append(__values, optional.EmailChangeVerificationStep.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("email_change_verification_step"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.FinalInvoiceGenerated._set {
		__values = append(__values, optional.FinalInvoiceGenerated.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("final_invoice_generated"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectLimit._set {
		__values = append(__values, optional.ProjectLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectBandwidthLimit._set {
		__values = append(__values, optional.ProjectBandwidthLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_bandwidth_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectStorageLimit._set {
		__values = append(__values, optional.ProjectStorageLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_storage_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.ProjectSegmentLimit._set {
		__values = append(__values, optional.ProjectSegmentLimit.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_segment_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.Kind._set {
		__values = append(__values, optional.Kind.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("kind"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.IsProfessional._set {
		__values = append(__values, optional.IsProfessional.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("is_professional"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.HaveSalesContact._set {
		__values = append(__values, optional.HaveSalesContact.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("have_sales_contact"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.MfaEnabled._set {
		__values = append(__values, optional.MfaEnabled.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("mfa_enabled"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.VerificationReminders._set {
		__values = append(__values, optional.VerificationReminders.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("verification_reminders"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.TrialNotifications._set {
		__values = append(__values, optional.TrialNotifications.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("trial_notifications"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("email_change_verification_step"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("final_invoice_generated"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_bandwidth_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_storage_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("project_segment_limit"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("kind"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("is_professional"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("have_sales_contact"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("mfa_enabled"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("verification_reminders"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("trial_notifications"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil

}

func (obj *spannerImpl) Create_WebappSession(ctx context.Context,
	webapp_session_id WebappSession_Id_Field,
	webapp_session_user_id WebappSession_UserId_Field,
	webapp_session_ip_address WebappSession_IpAddress_Field,
	webapp_session_user_agent WebappSession_UserAgent_Field,
	webapp_session_expires_at WebappSession_ExpiresAt_Field) (
	webapp_session *WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__id_val := webapp_session_id.value()
	__user_id_val := webapp_session_user_id.value()
	__ip_address_val := webapp_session_ip_address.value()
	__user_agent_val := webapp_session_user_agent.value()
	__status_val := int(0)
	__expires_at_val := webapp_session_expires_at.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO webapp_sessions ( id, user_id, ip_address, user_agent, status, expires_at ) VALUES ( ?, ?, ?, ?, ?, ? ) THEN RETURN webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at")

	var __values []any
	__values = append(__values, __id_val, __user_id_val, __ip_address_val, __user_agent_val, __status_val, __expires_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	webapp_session = &WebappSession{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return webapp_session, nil

}

func (obj *spannerImpl) Create_RegistrationToken(ctx context.Context,
	registration_token_secret RegistrationToken_Secret_Field,
	registration_token_project_limit RegistrationToken_ProjectLimit_Field,
	optional RegistrationToken_Create_Fields) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__secret_val := registration_token_secret.value()
	__owner_id_val := optional.OwnerId.value()
	__project_limit_val := registration_token_project_limit.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO registration_tokens ( secret, owner_id, project_limit, created_at ) VALUES ( ?, ?, ?, ? ) THEN RETURN registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at")

	var __values []any
	__values = append(__values, __secret_val, __owner_id_val, __project_limit_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return registration_token, nil

}

func (obj *spannerImpl) Create_ResetPasswordToken(ctx context.Context,
	reset_password_token_secret ResetPasswordToken_Secret_Field,
	reset_password_token_owner_id ResetPasswordToken_OwnerId_Field) (
	reset_password_token *ResetPasswordToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	__now := obj.db.Hooks.Now().UTC()
	__secret_val := reset_password_token_secret.value()
	__owner_id_val := reset_password_token_owner_id.value()
	__created_at_val := __now

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO reset_password_tokens ( secret, owner_id, created_at ) VALUES ( ?, ?, ? ) THEN RETURN reset_password_tokens.secret, reset_password_tokens.owner_id, reset_password_tokens.created_at")

	var __values []any
	__values = append(__values, __secret_val, __owner_id_val, __created_at_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reset_password_token = &ResetPasswordToken{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reset_password_token, nil

}

func (obj *spannerImpl) Replace_AccountFreezeEvent(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field,
	optional AccountFreezeEvent_Create_Fields) (
	account_freeze_event *AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__user_id_val := account_freeze_event_user_id.value()
	__event_val := account_freeze_event_event.value()
	__limits_val := spannerConvertJSON(optional.Limits.value())
	__days_till_escalation_val := optional.DaysTillEscalation.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("user_id, event, limits, days_till_escalation")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT OR UPDATE INTO account_freeze_events "), __clause, __sqlbundle_Literal(" THEN RETURN account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at")}}

	var __values []any
	__values = append(__values, __user_id_val, __event_val, __limits_val, __days_till_escalation_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.NotificationsCount._set {
		__values = append(__values, optional.NotificationsCount.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("notifications_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.CreatedAt._set {
		__values = append(__values, optional.CreatedAt.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("created_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("notifications_count"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("created_at"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	account_freeze_event = &AccountFreezeEvent{}
	if !obj.txn {
		err = obj.withTx(ctx, func(tx tagsql.Tx) error {
			return tx.QueryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, spannerConvertJSON(&account_freeze_event.Limits), &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
		})
	} else {
		err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, spannerConvertJSON(&account_freeze_event.Limits), &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return account_freeze_event, nil

}

func (obj *spannerImpl) CreateNoReturn_UserSettings(ctx context.Context,
	user_settings_user_id UserSettings_UserId_Field,
	optional UserSettings_Create_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	__user_id_val := user_settings_user_id.value()
	__session_minutes_val := optional.SessionMinutes.value()
	__passphrase_prompt_val := optional.PassphrasePrompt.value()
	__onboarding_step_val := optional.OnboardingStep.value()

	var __columns = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("user_id, session_minutes, passphrase_prompt, onboarding_step")}
	var __placeholders = &__sqlbundle_Hole{SQL: __sqlbundle_Literal("?, ?, ?, ?")}
	var __clause = &__sqlbundle_Hole{SQL: __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("("), __columns, __sqlbundle_Literal(") VALUES ("), __placeholders, __sqlbundle_Literal(")")}}}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("INSERT INTO user_settings "), __clause}}

	var __values []any
	__values = append(__values, __user_id_val, __session_minutes_val, __passphrase_prompt_val, __onboarding_step_val)

	__optional_columns := __sqlbundle_Literals{Join: ", "}
	__optional_placeholders := __sqlbundle_Literals{Join: ", "}

	if optional.OnboardingStart._set {
		__values = append(__values, optional.OnboardingStart.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("onboarding_start"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.OnboardingEnd._set {
		__values = append(__values, optional.OnboardingEnd.value())
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("onboarding_end"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if optional.NoticeDismissal._set {
		__values = append(__values, spannerConvertJSON(optional.NoticeDismissal.value()))
		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("notice_dismissal"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("?"))
	}

	if len(__optional_columns.SQLs) == 0 && __columns.SQL == nil {

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("onboarding_start"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("onboarding_end"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

		__optional_columns.SQLs = append(__optional_columns.SQLs, __sqlbundle_Literal("notice_dismissal"))
		__optional_placeholders.SQLs = append(__optional_placeholders.SQLs, __sqlbundle_Literal("DEFAULT"))

	}

	if len(__optional_columns.SQLs) > 0 {
		__columns.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__columns.SQL, __optional_columns}}
		__placeholders.SQL = __sqlbundle_Literals{Join: ", ", SQLs: []__sqlbundle_SQL{__placeholders.SQL, __optional_placeholders}}
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Find_AccountingTimestamps_Value_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field) (
	row *Value_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT accounting_timestamps.value FROM accounting_timestamps WHERE accounting_timestamps.name = ?")

	var __values []any
	__values = append(__values, accounting_timestamps_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Value_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Value)
	if errors.Is(err, sql.ErrNoRows) {
		return (*Value_Row)(nil), nil
	}
	if err != nil {
		return (*Value_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) All_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart(ctx context.Context,
	storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
	storagenode_bandwidth_rollup_interval_start StoragenodeBandwidthRollup_IntervalStart_Field) (
	rows []*StoragenodeBandwidthRollup, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.storagenode_id = ? AND storagenode_bandwidth_rollups.interval_start = ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_storagenode_id.value(), storagenode_bandwidth_rollup_interval_start.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodeBandwidthRollup, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_bandwidth_rollup := &StoragenodeBandwidthRollup{}
				err = __rows.Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	storagenode_bandwidth_rollup_interval_start_greater_or_equal StoragenodeBandwidthRollup_IntervalStart_Field,
	limit int, start *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.interval_start >= ? AND (storagenode_bandwidth_rollups.storagenode_id > ? OR (storagenode_bandwidth_rollups.storagenode_id = ? AND (storagenode_bandwidth_rollups.interval_start > ? OR (storagenode_bandwidth_rollups.interval_start = ? AND storagenode_bandwidth_rollups.action > ?)))) ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.interval_start >= ? ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values,
			start._value_storagenode_id, start._value_storagenode_id, start._value_interval_start, start._value_interval_start, start._value_action,
			limit,
		)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				storagenode_bandwidth_rollup := &StoragenodeBandwidthRollup{}
				err = __rows.Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled, &__continuation._value_storagenode_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *spannerImpl) Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual(ctx context.Context,
	storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
	storagenode_bandwidth_rollup_interval_start_greater_or_equal StoragenodeBandwidthRollup_IntervalStart_Field,
	limit int, start *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.storagenode_id = ? AND storagenode_bandwidth_rollups.interval_start >= ? AND (storagenode_bandwidth_rollups.storagenode_id > ? OR (storagenode_bandwidth_rollups.storagenode_id = ? AND (storagenode_bandwidth_rollups.interval_start > ? OR (storagenode_bandwidth_rollups.interval_start = ? AND storagenode_bandwidth_rollups.action > ?)))) ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.interval_seconds, storagenode_bandwidth_rollups.action, storagenode_bandwidth_rollups.allocated, storagenode_bandwidth_rollups.settled, storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action FROM storagenode_bandwidth_rollups WHERE storagenode_bandwidth_rollups.storagenode_id = ? AND storagenode_bandwidth_rollups.interval_start >= ? ORDER BY storagenode_bandwidth_rollups.storagenode_id, storagenode_bandwidth_rollups.interval_start, storagenode_bandwidth_rollups.action LIMIT ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_storagenode_id.value(), storagenode_bandwidth_rollup_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values,
			start._value_storagenode_id, start._value_storagenode_id, start._value_interval_start, start._value_interval_start, start._value_action,
			limit,
		)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				storagenode_bandwidth_rollup := &StoragenodeBandwidthRollup{}
				err = __rows.Scan(&storagenode_bandwidth_rollup.StoragenodeId, &storagenode_bandwidth_rollup.IntervalStart, &storagenode_bandwidth_rollup.IntervalSeconds, &storagenode_bandwidth_rollup.Action, &storagenode_bandwidth_rollup.Allocated, &storagenode_bandwidth_rollup.Settled, &__continuation._value_storagenode_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *spannerImpl) Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	storagenode_bandwidth_rollup_archive_interval_start_greater_or_equal StoragenodeBandwidthRollupArchive_IntervalStart_Field,
	limit int, start *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*StoragenodeBandwidthRollupArchive, next *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.interval_seconds, storagenode_bandwidth_rollup_archives.action, storagenode_bandwidth_rollup_archives.allocated, storagenode_bandwidth_rollup_archives.settled, storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action FROM storagenode_bandwidth_rollup_archives WHERE storagenode_bandwidth_rollup_archives.interval_start >= ? AND (storagenode_bandwidth_rollup_archives.storagenode_id > ? OR (storagenode_bandwidth_rollup_archives.storagenode_id = ? AND (storagenode_bandwidth_rollup_archives.interval_start > ? OR (storagenode_bandwidth_rollup_archives.interval_start = ? AND storagenode_bandwidth_rollup_archives.action > ?)))) ORDER BY storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.interval_seconds, storagenode_bandwidth_rollup_archives.action, storagenode_bandwidth_rollup_archives.allocated, storagenode_bandwidth_rollup_archives.settled, storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action FROM storagenode_bandwidth_rollup_archives WHERE storagenode_bandwidth_rollup_archives.interval_start >= ? ORDER BY storagenode_bandwidth_rollup_archives.storagenode_id, storagenode_bandwidth_rollup_archives.interval_start, storagenode_bandwidth_rollup_archives.action LIMIT ?")

	var __values []any
	__values = append(__values, storagenode_bandwidth_rollup_archive_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values,
			start._value_storagenode_id, start._value_storagenode_id, start._value_interval_start, start._value_interval_start, start._value_action,
			limit,
		)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*StoragenodeBandwidthRollupArchive, next *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				storagenode_bandwidth_rollup_archive := &StoragenodeBandwidthRollupArchive{}
				err = __rows.Scan(&storagenode_bandwidth_rollup_archive.StoragenodeId, &storagenode_bandwidth_rollup_archive.IntervalStart, &storagenode_bandwidth_rollup_archive.IntervalSeconds, &storagenode_bandwidth_rollup_archive.Action, &storagenode_bandwidth_rollup_archive.Allocated, &storagenode_bandwidth_rollup_archive.Settled, &__continuation._value_storagenode_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, storagenode_bandwidth_rollup_archive)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *spannerImpl) All_StoragenodeStorageTally(ctx context.Context) (
	rows []*StoragenodeStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_storage_tallies.node_id, storagenode_storage_tallies.interval_end_time, storagenode_storage_tallies.data_total FROM storagenode_storage_tallies")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodeStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_storage_tally := &StoragenodeStorageTally{}
				err = __rows.Scan(&storagenode_storage_tally.NodeId, &storagenode_storage_tally.IntervalEndTime, &storagenode_storage_tally.DataTotal)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_StoragenodeStorageTally_By_IntervalEndTime_GreaterOrEqual(ctx context.Context,
	storagenode_storage_tally_interval_end_time_greater_or_equal StoragenodeStorageTally_IntervalEndTime_Field) (
	rows []*StoragenodeStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_storage_tallies.node_id, storagenode_storage_tallies.interval_end_time, storagenode_storage_tallies.data_total FROM storagenode_storage_tallies WHERE storagenode_storage_tallies.interval_end_time >= ?")

	var __values []any
	__values = append(__values, storagenode_storage_tally_interval_end_time_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodeStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_storage_tally := &StoragenodeStorageTally{}
				err = __rows.Scan(&storagenode_storage_tally.NodeId, &storagenode_storage_tally.IntervalEndTime, &storagenode_storage_tally.DataTotal)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) First_StoragenodeStorageTally_IntervalEndTime_OrderBy_Asc_IntervalEndTime(ctx context.Context) (
	row *IntervalEndTime_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_storage_tallies.interval_end_time FROM storagenode_storage_tallies ORDER BY storagenode_storage_tallies.interval_end_time LIMIT 1 OFFSET 0")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *IntervalEndTime_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			row = &IntervalEndTime_Row{}
			err = __rows.Scan(&row.IntervalEndTime)
			if err != nil {
				return nil, err
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *spannerImpl) Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	bucket_bandwidth_rollup_interval_start_greater_or_equal BucketBandwidthRollup_IntervalStart_Field,
	limit int, start *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*BucketBandwidthRollup, next *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.interval_seconds, bucket_bandwidth_rollups.action, bucket_bandwidth_rollups.product_id, bucket_bandwidth_rollups.inline, bucket_bandwidth_rollups.allocated, bucket_bandwidth_rollups.settled, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action FROM bucket_bandwidth_rollups WHERE bucket_bandwidth_rollups.interval_start >= ? AND (bucket_bandwidth_rollups.project_id > ? OR (bucket_bandwidth_rollups.project_id = ? AND (bucket_bandwidth_rollups.bucket_name > ? OR (bucket_bandwidth_rollups.bucket_name = ? AND (bucket_bandwidth_rollups.interval_start > ? OR (bucket_bandwidth_rollups.interval_start = ? AND bucket_bandwidth_rollups.action > ?)))))) ORDER BY bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.interval_seconds, bucket_bandwidth_rollups.action, bucket_bandwidth_rollups.product_id, bucket_bandwidth_rollups.inline, bucket_bandwidth_rollups.allocated, bucket_bandwidth_rollups.settled, bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action FROM bucket_bandwidth_rollups WHERE bucket_bandwidth_rollups.interval_start >= ? ORDER BY bucket_bandwidth_rollups.project_id, bucket_bandwidth_rollups.bucket_name, bucket_bandwidth_rollups.interval_start, bucket_bandwidth_rollups.action LIMIT ?")

	var __values []any
	__values = append(__values, bucket_bandwidth_rollup_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values,
			start._value_project_id, start._value_project_id, start._value_bucket_name, start._value_bucket_name, start._value_interval_start, start._value_interval_start, start._value_action,
			limit,
		)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*BucketBandwidthRollup, next *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				bucket_bandwidth_rollup := &BucketBandwidthRollup{}
				err = __rows.Scan(&bucket_bandwidth_rollup.BucketName, &bucket_bandwidth_rollup.ProjectId, &bucket_bandwidth_rollup.IntervalStart, &bucket_bandwidth_rollup.IntervalSeconds, &bucket_bandwidth_rollup.Action, &bucket_bandwidth_rollup.ProductId, &bucket_bandwidth_rollup.Inline, &bucket_bandwidth_rollup.Allocated, &bucket_bandwidth_rollup.Settled, &__continuation._value_project_id, &__continuation._value_bucket_name, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, bucket_bandwidth_rollup)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *spannerImpl) Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual(ctx context.Context,
	bucket_bandwidth_rollup_archive_interval_start_greater_or_equal BucketBandwidthRollupArchive_IntervalStart_Field,
	limit int, start *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation) (
	rows []*BucketBandwidthRollupArchive, next *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.product_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.interval_seconds, bucket_bandwidth_rollup_archives.action, bucket_bandwidth_rollup_archives.inline, bucket_bandwidth_rollup_archives.allocated, bucket_bandwidth_rollup_archives.settled, bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action FROM bucket_bandwidth_rollup_archives WHERE bucket_bandwidth_rollup_archives.interval_start >= ? AND (bucket_bandwidth_rollup_archives.bucket_name > ? OR (bucket_bandwidth_rollup_archives.bucket_name = ? AND (bucket_bandwidth_rollup_archives.project_id > ? OR (bucket_bandwidth_rollup_archives.project_id = ? AND (bucket_bandwidth_rollup_archives.interval_start > ? OR (bucket_bandwidth_rollup_archives.interval_start = ? AND bucket_bandwidth_rollup_archives.action > ?)))))) ORDER BY bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.product_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.interval_seconds, bucket_bandwidth_rollup_archives.action, bucket_bandwidth_rollup_archives.inline, bucket_bandwidth_rollup_archives.allocated, bucket_bandwidth_rollup_archives.settled, bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action FROM bucket_bandwidth_rollup_archives WHERE bucket_bandwidth_rollup_archives.interval_start >= ? ORDER BY bucket_bandwidth_rollup_archives.bucket_name, bucket_bandwidth_rollup_archives.project_id, bucket_bandwidth_rollup_archives.interval_start, bucket_bandwidth_rollup_archives.action LIMIT ?")

	var __values []any
	__values = append(__values, bucket_bandwidth_rollup_archive_interval_start_greater_or_equal.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values,
			start._value_bucket_name, start._value_bucket_name, start._value_project_id, start._value_project_id, start._value_interval_start, start._value_interval_start, start._value_action,
			limit,
		)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*BucketBandwidthRollupArchive, next *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation
			__continuation._set = true

			for __rows.Next() {
				bucket_bandwidth_rollup_archive := &BucketBandwidthRollupArchive{}
				err = __rows.Scan(&bucket_bandwidth_rollup_archive.BucketName, &bucket_bandwidth_rollup_archive.ProjectId, &bucket_bandwidth_rollup_archive.ProductId, &bucket_bandwidth_rollup_archive.IntervalStart, &bucket_bandwidth_rollup_archive.IntervalSeconds, &bucket_bandwidth_rollup_archive.Action, &bucket_bandwidth_rollup_archive.Inline, &bucket_bandwidth_rollup_archive.Allocated, &bucket_bandwidth_rollup_archive.Settled, &__continuation._value_bucket_name, &__continuation._value_project_id, &__continuation._value_interval_start, &__continuation._value_action)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, bucket_bandwidth_rollup_archive)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *spannerImpl) All_BucketStorageTally_OrderBy_Desc_IntervalStart(ctx context.Context) (
	rows []*BucketStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_storage_tallies.bucket_name, bucket_storage_tallies.project_id, bucket_storage_tallies.interval_start, bucket_storage_tallies.product_id, bucket_storage_tallies.total_bytes, bucket_storage_tallies.inline, bucket_storage_tallies.remote, bucket_storage_tallies.total_segments_count, bucket_storage_tallies.remote_segments_count, bucket_storage_tallies.inline_segments_count, bucket_storage_tallies.object_count, bucket_storage_tallies.metadata_size FROM bucket_storage_tallies ORDER BY bucket_storage_tallies.interval_start DESC")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_storage_tally := &BucketStorageTally{}
				err = __rows.Scan(&bucket_storage_tally.BucketName, &bucket_storage_tally.ProjectId, &bucket_storage_tally.IntervalStart, &bucket_storage_tally.ProductId, &bucket_storage_tally.TotalBytes, &bucket_storage_tally.Inline, &bucket_storage_tally.Remote, &bucket_storage_tally.TotalSegmentsCount, &bucket_storage_tally.RemoteSegmentsCount, &bucket_storage_tally.InlineSegmentsCount, &bucket_storage_tally.ObjectCount, &bucket_storage_tally.MetadataSize)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_BucketStorageTally_By_ProjectId_And_BucketName_And_IntervalStart_GreaterOrEqual_And_IntervalStart_LessOrEqual_OrderBy_Desc_IntervalStart(ctx context.Context,
	bucket_storage_tally_project_id BucketStorageTally_ProjectId_Field,
	bucket_storage_tally_bucket_name BucketStorageTally_BucketName_Field,
	bucket_storage_tally_interval_start_greater_or_equal BucketStorageTally_IntervalStart_Field,
	bucket_storage_tally_interval_start_less_or_equal BucketStorageTally_IntervalStart_Field) (
	rows []*BucketStorageTally, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_storage_tallies.bucket_name, bucket_storage_tallies.project_id, bucket_storage_tallies.interval_start, bucket_storage_tallies.product_id, bucket_storage_tallies.total_bytes, bucket_storage_tallies.inline, bucket_storage_tallies.remote, bucket_storage_tallies.total_segments_count, bucket_storage_tallies.remote_segments_count, bucket_storage_tallies.inline_segments_count, bucket_storage_tallies.object_count, bucket_storage_tallies.metadata_size FROM bucket_storage_tallies WHERE bucket_storage_tallies.project_id = ? AND bucket_storage_tallies.bucket_name = ? AND bucket_storage_tallies.interval_start >= ? AND bucket_storage_tallies.interval_start <= ? ORDER BY bucket_storage_tallies.interval_start DESC")

	var __values []any
	__values = append(__values, bucket_storage_tally_project_id.value(), bucket_storage_tally_bucket_name.value(), bucket_storage_tally_interval_start_greater_or_equal.value(), bucket_storage_tally_interval_start_less_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketStorageTally, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_storage_tally := &BucketStorageTally{}
				err = __rows.Scan(&bucket_storage_tally.BucketName, &bucket_storage_tally.ProjectId, &bucket_storage_tally.IntervalStart, &bucket_storage_tally.ProductId, &bucket_storage_tally.TotalBytes, &bucket_storage_tally.Inline, &bucket_storage_tally.Remote, &bucket_storage_tally.TotalSegmentsCount, &bucket_storage_tally.RemoteSegmentsCount, &bucket_storage_tally.InlineSegmentsCount, &bucket_storage_tally.ObjectCount, &bucket_storage_tally.MetadataSize)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_storage_tally)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) First_ReverificationAudits_By_NodeId_OrderBy_Asc_StreamId_Asc_Position(ctx context.Context,
	reverification_audits_node_id ReverificationAudits_NodeId_Field) (
	reverification_audits *ReverificationAudits, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reverification_audits.node_id, reverification_audits.stream_id, reverification_audits.position, reverification_audits.piece_num, reverification_audits.inserted_at, reverification_audits.last_attempt, reverification_audits.reverify_count FROM reverification_audits WHERE reverification_audits.node_id = ? ORDER BY reverification_audits.stream_id, reverification_audits.position LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, reverification_audits_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		reverification_audits, err = func() (reverification_audits *ReverificationAudits, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			reverification_audits = &ReverificationAudits{}
			err = __rows.Scan(&reverification_audits.NodeId, &reverification_audits.StreamId, &reverification_audits.Position, &reverification_audits.PieceNum, &reverification_audits.InsertedAt, &reverification_audits.LastAttempt, &reverification_audits.ReverifyCount)
			if err != nil {
				return nil, err
			}

			return reverification_audits, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return reverification_audits, nil
	}

}

func (obj *spannerImpl) Get_StripeCustomer_PackagePlan_StripeCustomer_PurchasedPackageAt_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field) (
	row *PackagePlan_PurchasedPackageAt_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.package_plan, stripe_customers.purchased_package_at FROM stripe_customers WHERE stripe_customers.user_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &PackagePlan_PurchasedPackageAt_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.PackagePlan, &row.PurchasedPackageAt)
	if err != nil {
		return (*PackagePlan_PurchasedPackageAt_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_StripeCustomer_CustomerId_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field) (
	row *CustomerId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.customer_id FROM stripe_customers WHERE stripe_customers.user_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &CustomerId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.CustomerId)
	if err != nil {
		return (*CustomerId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_StripeCustomer_UserId_By_CustomerId(ctx context.Context,
	stripe_customer_customer_id StripeCustomer_CustomerId_Field) (
	row *UserId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.user_id FROM stripe_customers WHERE stripe_customers.customer_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_customer_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserId)
	if err != nil {
		return (*UserId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_StripeCustomer_CustomerId_StripeCustomer_BillingCustomerId_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field) (
	row *CustomerId_BillingCustomerId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripe_customers.customer_id, stripe_customers.billing_customer_id FROM stripe_customers WHERE stripe_customers.user_id = ?")

	var __values []any
	__values = append(__values, stripe_customer_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &CustomerId_BillingCustomerId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.CustomerId, &row.BillingCustomerId)
	if err != nil {
		return (*CustomerId_BillingCustomerId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_BillingBalance_Balance_By_UserId(ctx context.Context,
	billing_balance_user_id BillingBalance_UserId_Field) (
	row *Balance_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_balances.balance FROM billing_balances WHERE billing_balances.user_id = ?")

	var __values []any
	__values = append(__values, billing_balance_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Balance_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Balance)
	if err != nil {
		return (*Balance_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_BillingTransaction_By_Id(ctx context.Context,
	billing_transaction_id BillingTransaction_Id_Field) (
	billing_transaction *BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.id = ?")

	var __values []any
	__values = append(__values, billing_transaction_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	billing_transaction = &BillingTransaction{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, spannerConvertJSON(&billing_transaction.Metadata), &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
	if err != nil {
		return (*BillingTransaction)(nil), obj.makeErr(err)
	}
	return billing_transaction, nil

}

func (obj *spannerImpl) Get_BillingTransaction_Metadata_By_Id(ctx context.Context,
	billing_transaction_id BillingTransaction_Id_Field) (
	row *Metadata_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.metadata FROM billing_transactions WHERE billing_transactions.id = ?")

	var __values []any
	__values = append(__values, billing_transaction_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Metadata_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(spannerConvertJSON(&row.Metadata))
	if err != nil {
		return (*Metadata_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) All_BillingTransaction_By_UserId_OrderBy_Desc_TxTimestamp(ctx context.Context,
	billing_transaction_user_id BillingTransaction_UserId_Field) (
	rows []*BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.user_id = ? ORDER BY billing_transactions.tx_timestamp DESC")

	var __values []any
	__values = append(__values, billing_transaction_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BillingTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				billing_transaction := &BillingTransaction{}
				err = __rows.Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, spannerConvertJSON(&billing_transaction.Metadata), &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, billing_transaction)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_BillingTransaction_By_UserId_And_Source_OrderBy_Desc_TxTimestamp(ctx context.Context,
	billing_transaction_user_id BillingTransaction_UserId_Field,
	billing_transaction_source BillingTransaction_Source_Field) (
	rows []*BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.user_id = ? AND billing_transactions.source = ? ORDER BY billing_transactions.tx_timestamp DESC")

	var __values []any
	__values = append(__values, billing_transaction_user_id.value(), billing_transaction_source.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BillingTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				billing_transaction := &BillingTransaction{}
				err = __rows.Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, spannerConvertJSON(&billing_transaction.Metadata), &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, billing_transaction)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) First_BillingTransaction_By_Source_And_Type_OrderBy_Desc_CreatedAt(ctx context.Context,
	billing_transaction_source BillingTransaction_Source_Field,
	billing_transaction_type BillingTransaction_Type_Field) (
	billing_transaction *BillingTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT billing_transactions.id, billing_transactions.user_id, billing_transactions.amount, billing_transactions.currency, billing_transactions.description, billing_transactions.source, billing_transactions.status, billing_transactions.type, billing_transactions.metadata, billing_transactions.tx_timestamp, billing_transactions.created_at FROM billing_transactions WHERE billing_transactions.source = ? AND billing_transactions.type = ? ORDER BY billing_transactions.created_at DESC LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, billing_transaction_source.value(), billing_transaction_type.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		billing_transaction, err = func() (billing_transaction *BillingTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			billing_transaction = &BillingTransaction{}
			err = __rows.Scan(&billing_transaction.Id, &billing_transaction.UserId, &billing_transaction.Amount, &billing_transaction.Currency, &billing_transaction.Description, &billing_transaction.Source, &billing_transaction.Status, &billing_transaction.Type, spannerConvertJSON(&billing_transaction.Metadata), &billing_transaction.TxTimestamp, &billing_transaction.CreatedAt)
			if err != nil {
				return nil, err
			}

			return billing_transaction, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return billing_transaction, nil
	}

}

func (obj *spannerImpl) Get_StorjscanWallet_UserId_By_WalletAddress(ctx context.Context,
	storjscan_wallet_wallet_address StorjscanWallet_WalletAddress_Field) (
	row *UserId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_wallets.user_id FROM storjscan_wallets WHERE storjscan_wallets.wallet_address = ? LIMIT 2")

	var __values []any
	__values = append(__values, storjscan_wallet_wallet_address.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *UserId_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			row = &UserId_Row{}
			err = __rows.Scan(&row.UserId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("StorjscanWallet_UserId_By_WalletAddress")
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *spannerImpl) Get_StorjscanWallet_WalletAddress_By_UserId(ctx context.Context,
	storjscan_wallet_user_id StorjscanWallet_UserId_Field) (
	row *WalletAddress_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_wallets.wallet_address FROM storjscan_wallets WHERE storjscan_wallets.user_id = ? LIMIT 2")

	var __values []any
	__values = append(__values, storjscan_wallet_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *WalletAddress_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			row = &WalletAddress_Row{}
			err = __rows.Scan(&row.WalletAddress)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("StorjscanWallet_WalletAddress_By_UserId")
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *spannerImpl) All_StorjscanWallet(ctx context.Context) (
	rows []*StorjscanWallet, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_wallets.user_id, storjscan_wallets.wallet_address, storjscan_wallets.created_at FROM storjscan_wallets")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StorjscanWallet, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storjscan_wallet := &StorjscanWallet{}
				err = __rows.Scan(&storjscan_wallet.UserId, &storjscan_wallet.WalletAddress, &storjscan_wallet.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storjscan_wallet)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_CoinpaymentsTransaction_By_UserId_OrderBy_Desc_CreatedAt(ctx context.Context,
	coinpayments_transaction_user_id CoinpaymentsTransaction_UserId_Field) (
	rows []*CoinpaymentsTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT coinpayments_transactions.id, coinpayments_transactions.user_id, coinpayments_transactions.address, coinpayments_transactions.amount_numeric, coinpayments_transactions.received_numeric, coinpayments_transactions.status, coinpayments_transactions.key, coinpayments_transactions.timeout, coinpayments_transactions.created_at FROM coinpayments_transactions WHERE coinpayments_transactions.user_id = ? ORDER BY coinpayments_transactions.created_at DESC")

	var __values []any
	__values = append(__values, coinpayments_transaction_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*CoinpaymentsTransaction, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				coinpayments_transaction := &CoinpaymentsTransaction{}
				err = __rows.Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, coinpayments_transaction)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_StripecoinpaymentsInvoiceProjectRecord_By_ProjectId_And_PeriodStart_And_PeriodEnd(ctx context.Context,
	stripecoinpayments_invoice_project_record_project_id StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field,
	stripecoinpayments_invoice_project_record_period_start StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field,
	stripecoinpayments_invoice_project_record_period_end StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field) (
	stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripecoinpayments_invoice_project_records.id, stripecoinpayments_invoice_project_records.project_id, stripecoinpayments_invoice_project_records.storage, stripecoinpayments_invoice_project_records.egress, stripecoinpayments_invoice_project_records.objects, stripecoinpayments_invoice_project_records.segments, stripecoinpayments_invoice_project_records.period_start, stripecoinpayments_invoice_project_records.period_end, stripecoinpayments_invoice_project_records.state, stripecoinpayments_invoice_project_records.created_at FROM stripecoinpayments_invoice_project_records WHERE stripecoinpayments_invoice_project_records.project_id = ? AND stripecoinpayments_invoice_project_records.period_start = ? AND stripecoinpayments_invoice_project_records.period_end = ?")

	var __values []any
	__values = append(__values, stripecoinpayments_invoice_project_record_project_id.value(), stripecoinpayments_invoice_project_record_period_start.value(), stripecoinpayments_invoice_project_record_period_end.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_invoice_project_record = &StripecoinpaymentsInvoiceProjectRecord{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
	if err != nil {
		return (*StripecoinpaymentsInvoiceProjectRecord)(nil), obj.makeErr(err)
	}
	return stripecoinpayments_invoice_project_record, nil

}

func (obj *spannerImpl) Get_StripecoinpaymentsTxConversionRate_By_TxId(ctx context.Context,
	stripecoinpayments_tx_conversion_rate_tx_id StripecoinpaymentsTxConversionRate_TxId_Field) (
	stripecoinpayments_tx_conversion_rate *StripecoinpaymentsTxConversionRate, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT stripecoinpayments_tx_conversion_rates.tx_id, stripecoinpayments_tx_conversion_rates.rate_numeric, stripecoinpayments_tx_conversion_rates.created_at FROM stripecoinpayments_tx_conversion_rates WHERE stripecoinpayments_tx_conversion_rates.tx_id = ?")

	var __values []any
	__values = append(__values, stripecoinpayments_tx_conversion_rate_tx_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_tx_conversion_rate = &StripecoinpaymentsTxConversionRate{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_tx_conversion_rate.TxId, &stripecoinpayments_tx_conversion_rate.RateNumeric, &stripecoinpayments_tx_conversion_rate.CreatedAt)
	if err != nil {
		return (*StripecoinpaymentsTxConversionRate)(nil), obj.makeErr(err)
	}
	return stripecoinpayments_tx_conversion_rate, nil

}

func (obj *spannerImpl) All_StorjscanPayment_OrderBy_Asc_ChainId_Asc_BlockNumber_Asc_LogIndex(ctx context.Context) (
	rows []*StorjscanPayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_payments.chain_id, storjscan_payments.block_hash, storjscan_payments.block_number, storjscan_payments.transaction, storjscan_payments.log_index, storjscan_payments.from_address, storjscan_payments.to_address, storjscan_payments.token_value, storjscan_payments.usd_value, storjscan_payments.status, storjscan_payments.block_timestamp, storjscan_payments.created_at FROM storjscan_payments ORDER BY storjscan_payments.chain_id, storjscan_payments.block_number, storjscan_payments.log_index")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StorjscanPayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storjscan_payment := &StorjscanPayment{}
				err = __rows.Scan(&storjscan_payment.ChainId, &storjscan_payment.BlockHash, &storjscan_payment.BlockNumber, &storjscan_payment.Transaction, &storjscan_payment.LogIndex, &storjscan_payment.FromAddress, &storjscan_payment.ToAddress, &storjscan_payment.TokenValue, &storjscan_payment.UsdValue, &storjscan_payment.Status, &storjscan_payment.BlockTimestamp, &storjscan_payment.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storjscan_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Limited_StorjscanPayment_By_ToAddress_OrderBy_Desc_ChainId_Desc_BlockNumber_Desc_LogIndex(ctx context.Context,
	storjscan_payment_to_address StorjscanPayment_ToAddress_Field,
	limit int, offset int64) (
	rows []*StorjscanPayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_payments.chain_id, storjscan_payments.block_hash, storjscan_payments.block_number, storjscan_payments.transaction, storjscan_payments.log_index, storjscan_payments.from_address, storjscan_payments.to_address, storjscan_payments.token_value, storjscan_payments.usd_value, storjscan_payments.status, storjscan_payments.block_timestamp, storjscan_payments.created_at FROM storjscan_payments WHERE storjscan_payments.to_address = ? ORDER BY storjscan_payments.chain_id DESC, storjscan_payments.block_number DESC, storjscan_payments.log_index DESC LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, storjscan_payment_to_address.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StorjscanPayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storjscan_payment := &StorjscanPayment{}
				err = __rows.Scan(&storjscan_payment.ChainId, &storjscan_payment.BlockHash, &storjscan_payment.BlockNumber, &storjscan_payment.Transaction, &storjscan_payment.LogIndex, &storjscan_payment.FromAddress, &storjscan_payment.ToAddress, &storjscan_payment.TokenValue, &storjscan_payment.UsdValue, &storjscan_payment.Status, &storjscan_payment.BlockTimestamp, &storjscan_payment.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storjscan_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) First_StorjscanPayment_BlockNumber_By_Status_And_ChainId_OrderBy_Desc_BlockNumber_Desc_LogIndex(ctx context.Context,
	storjscan_payment_status StorjscanPayment_Status_Field,
	storjscan_payment_chain_id StorjscanPayment_ChainId_Field) (
	row *BlockNumber_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storjscan_payments.block_number FROM storjscan_payments WHERE storjscan_payments.status = ? AND storjscan_payments.chain_id = ? ORDER BY storjscan_payments.block_number DESC, storjscan_payments.log_index DESC LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, storjscan_payment_status.value(), storjscan_payment_chain_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		row, err = func() (row *BlockNumber_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			row = &BlockNumber_Row{}
			err = __rows.Scan(&row.BlockNumber)
			if err != nil {
				return nil, err
			}

			return row, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return row, nil
	}

}

func (obj *spannerImpl) All_ChangeHistory_By_UserId_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_user_id ChangeHistory_UserId_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE change_histories.user_id = ? ORDER BY change_histories.timestamp DESC")

	var __values []any
	__values = append(__values, change_history_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, spannerConvertJSON(&change_history.Changes), &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_ChangeHistory_By_UserId_And_ItemType_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_user_id ChangeHistory_UserId_Field,
	change_history_item_type ChangeHistory_ItemType_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE change_histories.user_id = ? AND change_histories.item_type = ? ORDER BY change_histories.timestamp DESC")

	var __values []any
	__values = append(__values, change_history_user_id.value(), change_history_item_type.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, spannerConvertJSON(&change_history.Changes), &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_ChangeHistory_By_ProjectId_And_ItemType_Not_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_project_id ChangeHistory_ProjectId_Field,
	change_history_item_type_not ChangeHistory_ItemType_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "change_histories.project_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE "), __cond_0, __sqlbundle_Literal(" AND change_histories.item_type != ? ORDER BY change_histories.timestamp DESC")}}

	var __values []any
	if !change_history_project_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, change_history_project_id.value())
	}
	__values = append(__values, change_history_item_type_not.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, spannerConvertJSON(&change_history.Changes), &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_ChangeHistory_By_ProjectId_And_ItemType_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_project_id ChangeHistory_ProjectId_Field,
	change_history_item_type ChangeHistory_ItemType_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "change_histories.project_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE "), __cond_0, __sqlbundle_Literal(" AND change_histories.item_type = ? ORDER BY change_histories.timestamp DESC")}}

	var __values []any
	if !change_history_project_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, change_history_project_id.value())
	}
	__values = append(__values, change_history_item_type.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, spannerConvertJSON(&change_history.Changes), &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_ChangeHistory_By_BucketName_OrderBy_Desc_Timestamp(ctx context.Context,
	change_history_bucket_name ChangeHistory_BucketName_Field) (
	rows []*ChangeHistory, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "change_histories.bucket_name", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT change_histories.id, change_histories.admin_email, change_histories.user_id, change_histories.project_id, change_histories.bucket_name, change_histories.item_type, change_histories.operation, change_histories.reason, change_histories.changes, change_histories.timestamp FROM change_histories WHERE "), __cond_0, __sqlbundle_Literal(" ORDER BY change_histories.timestamp DESC")}}

	var __values []any
	if !change_history_bucket_name.isnull() {
		__cond_0.Null = false
		__values = append(__values, change_history_bucket_name.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ChangeHistory, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				change_history := &ChangeHistory{}
				err = __rows.Scan(&change_history.Id, &change_history.AdminEmail, &change_history.UserId, &change_history.ProjectId, &change_history.BucketName, &change_history.ItemType, &change_history.Operation, &change_history.Reason, spannerConvertJSON(&change_history.Changes), &change_history.Timestamp)
				if err != nil {
					return nil, err
				}
				rows = append(rows, change_history)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_Domain_By_ProjectId_And_Subdomain(ctx context.Context,
	domain_project_id Domain_ProjectId_Field,
	domain_subdomain Domain_Subdomain_Field) (
	domain *Domain, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT domains.subdomain, domains.project_id, domains.prefix, domains.access_id, domains.created_by, domains.created_at FROM domains WHERE domains.project_id = ? AND domains.subdomain = ?")

	var __values []any
	__values = append(__values, domain_project_id.value(), domain_subdomain.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	domain = &Domain{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&domain.Subdomain, &domain.ProjectId, &domain.Prefix, &domain.AccessId, &domain.CreatedBy, &domain.CreatedAt)
	if err != nil {
		return (*Domain)(nil), obj.makeErr(err)
	}
	return domain, nil

}

func (obj *spannerImpl) All_Domain_Subdomain_By_ProjectId(ctx context.Context,
	domain_project_id Domain_ProjectId_Field) (
	rows []*Subdomain_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT domains.subdomain FROM domains WHERE domains.project_id = ?")

	var __values []any
	__values = append(__values, domain_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Subdomain_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Subdomain_Row{}
				err = __rows.Scan(&row.Subdomain)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_Entitlement_By_Scope(ctx context.Context,
	entitlement_scope Entitlement_Scope_Field) (
	entitlement *Entitlement, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT entitlements.scope, entitlements.features, entitlements.updated_at, entitlements.created_at FROM entitlements WHERE entitlements.scope = ?")

	var __values []any
	__values = append(__values, entitlement_scope.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	entitlement = &Entitlement{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&entitlement.Scope, spannerConvertJSON(&entitlement.Features), &entitlement.UpdatedAt, &entitlement.CreatedAt)
	if err != nil {
		return (*Entitlement)(nil), obj.makeErr(err)
	}
	return entitlement, nil

}

func (obj *spannerImpl) Get_PeerIdentity_By_NodeId(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field) (
	peer_identity *PeerIdentity, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT peer_identities.node_id, peer_identities.leaf_serial_number, peer_identities.chain, peer_identities.updated_at FROM peer_identities WHERE peer_identities.node_id = ?")

	var __values []any
	__values = append(__values, peer_identity_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	peer_identity = &PeerIdentity{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&peer_identity.NodeId, &peer_identity.LeafSerialNumber, &peer_identity.Chain, &peer_identity.UpdatedAt)
	if err != nil {
		return (*PeerIdentity)(nil), obj.makeErr(err)
	}
	return peer_identity, nil

}

func (obj *spannerImpl) Get_PeerIdentity_LeafSerialNumber_By_NodeId(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field) (
	row *LeafSerialNumber_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT peer_identities.leaf_serial_number FROM peer_identities WHERE peer_identities.node_id = ?")

	var __values []any
	__values = append(__values, peer_identity_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &LeafSerialNumber_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.LeafSerialNumber)
	if err != nil {
		return (*LeafSerialNumber_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field) (
	node *Node, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features FROM nodes WHERE nodes.id = ?")

	var __values []any
	__values = append(__values, node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node.Id, &node.Address, &node.LastNet, &node.LastIpPort, &node.CountryCode, &node.Protocol, &node.Email, &node.Wallet, &node.WalletFeatures, &node.FreeDisk, &node.PieceCount, &node.Major, &node.Minor, &node.Patch, &node.CommitHash, &node.ReleaseTimestamp, &node.Release, &node.Latency90, &node.VettedAt, &node.CreatedAt, &node.UpdatedAt, &node.LastContactSuccess, &node.LastContactFailure, &node.Disqualified, &node.DisqualificationReason, &node.UnknownAuditSuspended, &node.OfflineSuspended, &node.UnderReview, &node.ExitInitiatedAt, &node.ExitLoopCompletedAt, &node.ExitFinishedAt, &node.ExitSuccess, &node.Contained, &node.LastOfflineEmail, &node.LastSoftwareUpdateEmail, &node.NoiseProto, &node.NoisePublicKey, &node.DebounceLimit, &node.Features)
	if err != nil {
		return (*Node)(nil), obj.makeErr(err)
	}
	return node, nil

}

func (obj *spannerImpl) All_Node_Id(ctx context.Context) (
	rows []*Id_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id FROM nodes")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_Row{}
				err = __rows.Scan(&row.Id)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Paged_Node(ctx context.Context,
	limit int, start *Paged_Node_Continuation) (
	rows []*Node, next *Paged_Node_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features, nodes.id FROM nodes WHERE nodes.id > ? ORDER BY nodes.id LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features, nodes.id FROM nodes ORDER BY nodes.id LIMIT ?")

	var __values []any

	var __stmt string
	if start != nil && start._set {
		__values = append(__values,
			start._value_id,
			limit,
		)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*Node, next *Paged_Node_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_Node_Continuation
			__continuation._set = true

			for __rows.Next() {
				node := &Node{}
				err = __rows.Scan(&node.Id, &node.Address, &node.LastNet, &node.LastIpPort, &node.CountryCode, &node.Protocol, &node.Email, &node.Wallet, &node.WalletFeatures, &node.FreeDisk, &node.PieceCount, &node.Major, &node.Minor, &node.Patch, &node.CommitHash, &node.ReleaseTimestamp, &node.Release, &node.Latency90, &node.VettedAt, &node.CreatedAt, &node.UpdatedAt, &node.LastContactSuccess, &node.LastContactFailure, &node.Disqualified, &node.DisqualificationReason, &node.UnknownAuditSuspended, &node.OfflineSuspended, &node.UnderReview, &node.ExitInitiatedAt, &node.ExitLoopCompletedAt, &node.ExitFinishedAt, &node.ExitSuccess, &node.Contained, &node.LastOfflineEmail, &node.LastSoftwareUpdateEmail, &node.NoiseProto, &node.NoisePublicKey, &node.DebounceLimit, &node.Features, &__continuation._value_id)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, node)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *spannerImpl) All_Node_Id_Node_PieceCount_By_Disqualified_Is_Null_And_ExitInitiatedAt_Is_Null_And_ExitFinishedAt_Is_Null(ctx context.Context) (
	rows []*Id_PieceCount_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT nodes.id, nodes.piece_count FROM nodes WHERE nodes.disqualified is NULL AND nodes.exit_initiated_at is NULL AND nodes.exit_finished_at is NULL")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_PieceCount_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_PieceCount_Row{}
				err = __rows.Scan(&row.Id, &row.PieceCount)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Has_NodeApiVersion_By_Id_And_ApiVersion_GreaterOrEqual(ctx context.Context,
	node_api_version_id NodeApiVersion_Id_Field,
	node_api_version_api_version_greater_or_equal NodeApiVersion_ApiVersion_Field) (
	has bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT EXISTS( SELECT 1 FROM node_api_versions WHERE node_api_versions.id = ? AND node_api_versions.api_version >= ? )")

	var __values []any
	__values = append(__values, node_api_version_id.value(), node_api_version_api_version_greater_or_equal.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&has)
	if err != nil {
		return false, obj.makeErr(err)
	}
	return has, nil

}

func (obj *spannerImpl) Get_NodeEvent_By_Id(ctx context.Context,
	node_event_id NodeEvent_Id_Field) (
	node_event *NodeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_events.id, node_events.email, node_events.last_ip_port, node_events.node_id, node_events.event, node_events.created_at, node_events.last_attempted, node_events.email_sent FROM node_events WHERE node_events.id = ?")

	var __values []any
	__values = append(__values, node_event_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node_event = &NodeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
	if err != nil {
		return (*NodeEvent)(nil), obj.makeErr(err)
	}
	return node_event, nil

}

func (obj *spannerImpl) First_NodeEvent_By_Email_And_Event_OrderBy_Desc_CreatedAt(ctx context.Context,
	node_event_email NodeEvent_Email_Field,
	node_event_event NodeEvent_Event_Field) (
	node_event *NodeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_events.id, node_events.email, node_events.last_ip_port, node_events.node_id, node_events.event, node_events.created_at, node_events.last_attempted, node_events.email_sent FROM node_events WHERE node_events.email = ? AND node_events.event = ? ORDER BY node_events.created_at DESC LIMIT 1 OFFSET 0")

	var __values []any
	__values = append(__values, node_event_email.value(), node_event_event.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		node_event, err = func() (node_event *NodeEvent, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, nil
			}

			node_event = &NodeEvent{}
			err = __rows.Scan(&node_event.Id, &node_event.Email, &node_event.LastIpPort, &node_event.NodeId, &node_event.Event, &node_event.CreatedAt, &node_event.LastAttempted, &node_event.EmailSent)
			if err != nil {
				return nil, err
			}

			return node_event, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return node_event, nil
	}

}

func (obj *spannerImpl) All_NodeTags_By_NodeId(ctx context.Context,
	node_tags_node_id NodeTags_NodeId_Field) (
	rows []*NodeTags, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_tags.node_id, node_tags.name, node_tags.value, node_tags.signed_at, node_tags.signer FROM node_tags WHERE node_tags.node_id = ?")

	var __values []any
	__values = append(__values, node_tags_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*NodeTags, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				node_tags := &NodeTags{}
				err = __rows.Scan(&node_tags.NodeId, &node_tags.Name, &node_tags.Value, &node_tags.SignedAt, &node_tags.Signer)
				if err != nil {
					return nil, err
				}
				rows = append(rows, node_tags)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_NodeTags(ctx context.Context) (
	rows []*NodeTags, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT node_tags.node_id, node_tags.name, node_tags.value, node_tags.signed_at, node_tags.signer FROM node_tags")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*NodeTags, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				node_tags := &NodeTags{}
				err = __rows.Scan(&node_tags.NodeId, &node_tags.Name, &node_tags.Value, &node_tags.SignedAt, &node_tags.Signer)
				if err != nil {
					return nil, err
				}
				rows = append(rows, node_tags)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_StoragenodePaystub_By_NodeId_And_Period(ctx context.Context,
	storagenode_paystub_node_id StoragenodePaystub_NodeId_Field,
	storagenode_paystub_period StoragenodePaystub_Period_Field) (
	storagenode_paystub *StoragenodePaystub, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_paystubs.period, storagenode_paystubs.node_id, storagenode_paystubs.created_at, storagenode_paystubs.codes, storagenode_paystubs.usage_at_rest, storagenode_paystubs.usage_get, storagenode_paystubs.usage_put, storagenode_paystubs.usage_get_repair, storagenode_paystubs.usage_put_repair, storagenode_paystubs.usage_get_audit, storagenode_paystubs.comp_at_rest, storagenode_paystubs.comp_get, storagenode_paystubs.comp_put, storagenode_paystubs.comp_get_repair, storagenode_paystubs.comp_put_repair, storagenode_paystubs.comp_get_audit, storagenode_paystubs.surge_percent, storagenode_paystubs.held, storagenode_paystubs.owed, storagenode_paystubs.disposed, storagenode_paystubs.paid, storagenode_paystubs.distributed FROM storagenode_paystubs WHERE storagenode_paystubs.node_id = ? AND storagenode_paystubs.period = ?")

	var __values []any
	__values = append(__values, storagenode_paystub_node_id.value(), storagenode_paystub_period.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	storagenode_paystub = &StoragenodePaystub{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&storagenode_paystub.Period, &storagenode_paystub.NodeId, &storagenode_paystub.CreatedAt, &storagenode_paystub.Codes, &storagenode_paystub.UsageAtRest, &storagenode_paystub.UsageGet, &storagenode_paystub.UsagePut, &storagenode_paystub.UsageGetRepair, &storagenode_paystub.UsagePutRepair, &storagenode_paystub.UsageGetAudit, &storagenode_paystub.CompAtRest, &storagenode_paystub.CompGet, &storagenode_paystub.CompPut, &storagenode_paystub.CompGetRepair, &storagenode_paystub.CompPutRepair, &storagenode_paystub.CompGetAudit, &storagenode_paystub.SurgePercent, &storagenode_paystub.Held, &storagenode_paystub.Owed, &storagenode_paystub.Disposed, &storagenode_paystub.Paid, &storagenode_paystub.Distributed)
	if err != nil {
		return (*StoragenodePaystub)(nil), obj.makeErr(err)
	}
	return storagenode_paystub, nil

}

func (obj *spannerImpl) All_StoragenodePaystub_By_NodeId(ctx context.Context,
	storagenode_paystub_node_id StoragenodePaystub_NodeId_Field) (
	rows []*StoragenodePaystub, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_paystubs.period, storagenode_paystubs.node_id, storagenode_paystubs.created_at, storagenode_paystubs.codes, storagenode_paystubs.usage_at_rest, storagenode_paystubs.usage_get, storagenode_paystubs.usage_put, storagenode_paystubs.usage_get_repair, storagenode_paystubs.usage_put_repair, storagenode_paystubs.usage_get_audit, storagenode_paystubs.comp_at_rest, storagenode_paystubs.comp_get, storagenode_paystubs.comp_put, storagenode_paystubs.comp_get_repair, storagenode_paystubs.comp_put_repair, storagenode_paystubs.comp_get_audit, storagenode_paystubs.surge_percent, storagenode_paystubs.held, storagenode_paystubs.owed, storagenode_paystubs.disposed, storagenode_paystubs.paid, storagenode_paystubs.distributed FROM storagenode_paystubs WHERE storagenode_paystubs.node_id = ?")

	var __values []any
	__values = append(__values, storagenode_paystub_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePaystub, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_paystub := &StoragenodePaystub{}
				err = __rows.Scan(&storagenode_paystub.Period, &storagenode_paystub.NodeId, &storagenode_paystub.CreatedAt, &storagenode_paystub.Codes, &storagenode_paystub.UsageAtRest, &storagenode_paystub.UsageGet, &storagenode_paystub.UsagePut, &storagenode_paystub.UsageGetRepair, &storagenode_paystub.UsagePutRepair, &storagenode_paystub.UsageGetAudit, &storagenode_paystub.CompAtRest, &storagenode_paystub.CompGet, &storagenode_paystub.CompPut, &storagenode_paystub.CompGetRepair, &storagenode_paystub.CompPutRepair, &storagenode_paystub.CompGetAudit, &storagenode_paystub.SurgePercent, &storagenode_paystub.Held, &storagenode_paystub.Owed, &storagenode_paystub.Disposed, &storagenode_paystub.Paid, &storagenode_paystub.Distributed)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_paystub)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Limited_StoragenodePayment_By_NodeId_And_Period_OrderBy_Desc_Id(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field,
	storagenode_payment_period StoragenodePayment_Period_Field,
	limit int, offset int64) (
	rows []*StoragenodePayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_payments.id, storagenode_payments.created_at, storagenode_payments.node_id, storagenode_payments.period, storagenode_payments.amount, storagenode_payments.receipt, storagenode_payments.notes FROM storagenode_payments WHERE storagenode_payments.node_id = ? AND storagenode_payments.period = ? ORDER BY storagenode_payments.id DESC LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, storagenode_payment_node_id.value(), storagenode_payment_period.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_payment := &StoragenodePayment{}
				err = __rows.Scan(&storagenode_payment.Id, &storagenode_payment.CreatedAt, &storagenode_payment.NodeId, &storagenode_payment.Period, &storagenode_payment.Amount, &storagenode_payment.Receipt, &storagenode_payment.Notes)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_StoragenodePayment_By_NodeId(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field) (
	rows []*StoragenodePayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_payments.id, storagenode_payments.created_at, storagenode_payments.node_id, storagenode_payments.period, storagenode_payments.amount, storagenode_payments.receipt, storagenode_payments.notes FROM storagenode_payments WHERE storagenode_payments.node_id = ?")

	var __values []any
	__values = append(__values, storagenode_payment_node_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_payment := &StoragenodePayment{}
				err = __rows.Scan(&storagenode_payment.Id, &storagenode_payment.CreatedAt, &storagenode_payment.NodeId, &storagenode_payment.Period, &storagenode_payment.Amount, &storagenode_payment.Receipt, &storagenode_payment.Notes)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_StoragenodePayment_By_NodeId_And_Period(ctx context.Context,
	storagenode_payment_node_id StoragenodePayment_NodeId_Field,
	storagenode_payment_period StoragenodePayment_Period_Field) (
	rows []*StoragenodePayment, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT storagenode_payments.id, storagenode_payments.created_at, storagenode_payments.node_id, storagenode_payments.period, storagenode_payments.amount, storagenode_payments.receipt, storagenode_payments.notes FROM storagenode_payments WHERE storagenode_payments.node_id = ? AND storagenode_payments.period = ?")

	var __values []any
	__values = append(__values, storagenode_payment_node_id.value(), storagenode_payment_period.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*StoragenodePayment, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				storagenode_payment := &StoragenodePayment{}
				err = __rows.Scan(&storagenode_payment.Id, &storagenode_payment.CreatedAt, &storagenode_payment.NodeId, &storagenode_payment.Period, &storagenode_payment.Amount, &storagenode_payment.Receipt, &storagenode_payment.Notes)
				if err != nil {
					return nil, err
				}
				rows = append(rows, storagenode_payment)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_Reputation_By_Id(ctx context.Context,
	reputation_id Reputation_Id_Field) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta FROM reputations WHERE reputations.id = ?")

	var __values []any
	__values = append(__values, reputation_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if err != nil {
		return (*Reputation)(nil), obj.makeErr(err)
	}
	return reputation, nil

}

func (obj *spannerImpl) Get_OauthClient_By_Id(ctx context.Context,
	oauth_client_id OauthClient_Id_Field) (
	oauth_client *OauthClient, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT oauth_clients.id, oauth_clients.encrypted_secret, oauth_clients.redirect_url, oauth_clients.user_id, oauth_clients.app_name, oauth_clients.app_logo_url FROM oauth_clients WHERE oauth_clients.id = ?")

	var __values []any
	__values = append(__values, oauth_client_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	oauth_client = &OauthClient{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&oauth_client.Id, &oauth_client.EncryptedSecret, &oauth_client.RedirectUrl, &oauth_client.UserId, &oauth_client.AppName, &oauth_client.AppLogoUrl)
	if err != nil {
		return (*OauthClient)(nil), obj.makeErr(err)
	}
	return oauth_client, nil

}

func (obj *spannerImpl) Get_OauthCode_By_Code_And_ClaimedAt_Is_Null(ctx context.Context,
	oauth_code_code OauthCode_Code_Field) (
	oauth_code *OauthCode, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT oauth_codes.client_id, oauth_codes.user_id, oauth_codes.scope, oauth_codes.redirect_url, oauth_codes.challenge, oauth_codes.challenge_method, oauth_codes.code, oauth_codes.created_at, oauth_codes.expires_at, oauth_codes.claimed_at FROM oauth_codes WHERE oauth_codes.code = ? AND oauth_codes.claimed_at is NULL")

	var __values []any
	__values = append(__values, oauth_code_code.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	oauth_code = &OauthCode{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&oauth_code.ClientId, &oauth_code.UserId, &oauth_code.Scope, &oauth_code.RedirectUrl, &oauth_code.Challenge, &oauth_code.ChallengeMethod, &oauth_code.Code, &oauth_code.CreatedAt, &oauth_code.ExpiresAt, &oauth_code.ClaimedAt)
	if err != nil {
		return (*OauthCode)(nil), obj.makeErr(err)
	}
	return oauth_code, nil

}

func (obj *spannerImpl) Get_OauthToken_By_Kind_And_Token(ctx context.Context,
	oauth_token_kind OauthToken_Kind_Field,
	oauth_token_token OauthToken_Token_Field) (
	oauth_token *OauthToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT oauth_tokens.client_id, oauth_tokens.user_id, oauth_tokens.scope, oauth_tokens.kind, oauth_tokens.token, oauth_tokens.created_at, oauth_tokens.expires_at FROM oauth_tokens WHERE oauth_tokens.kind = ? AND oauth_tokens.token = ?")

	var __values []any
	__values = append(__values, oauth_token_kind.value(), oauth_token_token.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	oauth_token = &OauthToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&oauth_token.ClientId, &oauth_token.UserId, &oauth_token.Scope, &oauth_token.Kind, &oauth_token.Token, &oauth_token.CreatedAt, &oauth_token.ExpiresAt)
	if err != nil {
		return (*OauthToken)(nil), obj.makeErr(err)
	}
	return oauth_token, nil

}

func (obj *spannerImpl) Get_Project_PassphraseEnc_Project_PassphraseEncKeyId_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *PassphraseEnc_PassphraseEncKeyId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.passphrase_enc, projects.passphrase_enc_key_id FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &PassphraseEnc_PassphraseEncKeyId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.PassphraseEnc, &row.PassphraseEncKeyId)
	if err != nil {
		return (*PassphraseEnc_PassphraseEncKeyId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_Salt_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *Salt_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.salt FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Salt_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Salt)
	if err != nil {
		return (*Salt_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_By_PublicId(ctx context.Context,
	project_public_id Project_PublicId_Field) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.public_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE "), __cond_0, __sqlbundle_Literal(" LIMIT 2")}}

	var __values []any
	if !project_public_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_public_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		project, err = func() (project *Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			project = &Project{}
			err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return project, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("Project_By_PublicId")
			}
			return nil, obj.makeErr(err)
		}
		return project, nil
	}

}

func (obj *spannerImpl) Get_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
	if err != nil {
		return (*Project)(nil), obj.makeErr(err)
	}
	return project, nil

}

func (obj *spannerImpl) Get_Project_By__Id_Or_PublicId(ctx context.Context,
	project_id Project_Id_Field,
	project_public_id Project_PublicId_Field) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.public_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE (projects.id = ? OR "), __cond_0, __sqlbundle_Literal(") LIMIT 2")}}

	var __values []any
	__values = append(__values, project_id.value())
	if !project_public_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_public_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		project, err = func() (project *Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			project = &Project{}
			err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return project, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("Project_By__Id_Or_PublicId")
			}
			return nil, obj.makeErr(err)
		}
		return project, nil
	}

}

func (obj *spannerImpl) Get_Project_UsageLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UsageLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.usage_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UsageLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UsageLimit)
	if err != nil {
		return (*UsageLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_BandwidthLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *BandwidthLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.bandwidth_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &BandwidthLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.BandwidthLimit)
	if err != nil {
		return (*BandwidthLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_UserSpecifiedUsageLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UserSpecifiedUsageLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.user_specified_usage_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserSpecifiedUsageLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserSpecifiedUsageLimit)
	if err != nil {
		return (*UserSpecifiedUsageLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_UserSpecifiedBandwidthLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UserSpecifiedBandwidthLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.user_specified_bandwidth_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserSpecifiedBandwidthLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserSpecifiedBandwidthLimit)
	if err != nil {
		return (*UserSpecifiedBandwidthLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_SegmentLimit_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *SegmentLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.segment_limit FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &SegmentLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.SegmentLimit)
	if err != nil {
		return (*SegmentLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_MaxBuckets_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *MaxBuckets_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.max_buckets FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &MaxBuckets_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.MaxBuckets)
	if err != nil {
		return (*MaxBuckets_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_BandwidthLimit_Project_UserSpecifiedBandwidthLimit_Project_UsageLimit_Project_UserSpecifiedUsageLimit_Project_SegmentLimit_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.bandwidth_limit, projects.user_specified_bandwidth_limit, projects.usage_limit, projects.user_specified_usage_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.BandwidthLimit, &row.UserSpecifiedBandwidthLimit, &row.UsageLimit, &row.UserSpecifiedUsageLimit, &row.SegmentLimit, &row.RateLimit, &row.BurstLimit, &row.RateLimitHead, &row.BurstLimitHead, &row.RateLimitGet, &row.BurstLimitGet, &row.RateLimitPut, &row.BurstLimitPut, &row.RateLimitList, &row.BurstLimitList, &row.RateLimitDel, &row.BurstLimitDel)
	if err != nil {
		return (*BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_DefaultVersioning_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *DefaultVersioning_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.default_versioning FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &DefaultVersioning_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.DefaultVersioning)
	if err != nil {
		return (*DefaultVersioning_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_UserAgent_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *UserAgent_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.user_agent FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserAgent_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserAgent)
	if err != nil {
		return (*UserAgent_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Project_PublicId_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *PublicId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.public_id FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &PublicId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.PublicId)
	if err != nil {
		return (*PublicId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) All_Project(ctx context.Context) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_Project_By_CreatedAt_Less_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_created_at_less Project_CreatedAt_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.created_at < ? ORDER BY projects.created_at")

	var __values []any
	__values = append(__values, project_created_at_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_Project_By_OwnerId_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_owner_id Project_OwnerId_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.owner_id = ? ORDER BY projects.created_at")

	var __values []any
	__values = append(__values, project_owner_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_Project_By_OwnerId_And_Status_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_owner_id Project_OwnerId_Field,
	project_status Project_Status_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.status", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.owner_id = ? AND "), __cond_0, __sqlbundle_Literal(" ORDER BY projects.created_at")}}

	var __values []any
	__values = append(__values, project_owner_id.value())
	if !project_status.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_status.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_Project_By_ProjectMember_MemberId_OrderBy_Asc_Project_Name(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects  JOIN project_members ON projects.id = project_members.project_id WHERE project_members.member_id = ? ORDER BY projects.name")

	var __values []any
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Limited_Project_By_CreatedAt_Less_OrderBy_Asc_CreatedAt(ctx context.Context,
	project_created_at_less Project_CreatedAt_Field,
	limit int, offset int64) (
	rows []*Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption FROM projects WHERE projects.created_at < ? ORDER BY projects.created_at LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, project_created_at_less.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Project, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project := &Project{}
				err = __rows.Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Limited_Project_Id_Project_PublicId_Project_OwnerId_By_Status_And_StatusUpdatedAt_Less_OrderBy_Asc_StatusUpdatedAt(ctx context.Context,
	project_status Project_Status_Field,
	project_status_updated_at_less Project_StatusUpdatedAt_Field,
	limit int, offset int64) (
	rows []*Id_PublicId_OwnerId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.status", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT projects.id, projects.public_id, projects.owner_id FROM projects WHERE "), __cond_0, __sqlbundle_Literal(" AND projects.status_updated_at < ? ORDER BY projects.status_updated_at LIMIT ? OFFSET ?")}}

	var __values []any
	if !project_status.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_status.value())
	}
	__values = append(__values, project_status_updated_at_less.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_PublicId_OwnerId_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_PublicId_OwnerId_Row{}
				err = __rows.Scan(&row.Id, &row.PublicId, &row.OwnerId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	project_member *ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.role, project_members.created_at FROM project_members WHERE project_members.member_id = ? AND project_members.project_id = ?")

	var __values []any
	__values = append(__values, project_member_member_id.value(), project_member_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_member = &ProjectMember{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
	if err != nil {
		return (*ProjectMember)(nil), obj.makeErr(err)
	}
	return project_member, nil

}

func (obj *spannerImpl) All_ProjectMember_By_MemberId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field) (
	rows []*ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_members.member_id, project_members.project_id, project_members.role, project_members.created_at FROM project_members WHERE project_members.member_id = ?")

	var __values []any
	__values = append(__values, project_member_member_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectMember, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_member := &ProjectMember{}
				err = __rows.Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_member)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field) (
	project_invitation *ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations WHERE project_invitations.project_id = ? AND project_invitations.email = ?")

	var __values []any
	__values = append(__values, project_invitation_project_id.value(), project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_invitation = &ProjectInvitation{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
	if err != nil {
		return (*ProjectInvitation)(nil), obj.makeErr(err)
	}
	return project_invitation, nil

}

func (obj *spannerImpl) All_ProjectInvitation_By_Email(ctx context.Context,
	project_invitation_email ProjectInvitation_Email_Field) (
	rows []*ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations WHERE project_invitations.email = ?")

	var __values []any
	__values = append(__values, project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectInvitation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_invitation := &ProjectInvitation{}
				err = __rows.Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_invitation)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_ProjectInvitation_By_Project_Status_And_ProjectInvitation_Email(ctx context.Context,
	project_status Project_Status_Field,
	project_invitation_email ProjectInvitation_Email_Field) (
	rows []*ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "projects.status", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations  JOIN projects ON project_invitations.project_id = projects.id WHERE "), __cond_0, __sqlbundle_Literal(" AND project_invitations.email = ?")}}

	var __values []any
	if !project_status.isnull() {
		__cond_0.Null = false
		__values = append(__values, project_status.value())
	}
	__values = append(__values, project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectInvitation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_invitation := &ProjectInvitation{}
				err = __rows.Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_invitation)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_ProjectInvitation_By_ProjectId(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field) (
	rows []*ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at FROM project_invitations WHERE project_invitations.project_id = ?")

	var __values []any
	__values = append(__values, project_invitation_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*ProjectInvitation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				project_invitation := &ProjectInvitation{}
				err = __rows.Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, project_invitation)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_ApiKey_Project_PublicId_By_ApiKey_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	row *ApiKey_Project_PublicId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version, projects.public_id FROM projects  JOIN api_keys ON projects.id = api_keys.project_id WHERE api_keys.id = ?")

	var __values []any
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ApiKey_Project_PublicId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ApiKey.Id, &row.ApiKey.ProjectId, &row.ApiKey.Head, &row.ApiKey.Name, &row.ApiKey.Secret, &row.ApiKey.UserAgent, &row.ApiKey.CreatedAt, &row.ApiKey.CreatedBy, &row.ApiKey.Version, &row.Project_PublicId)
	if err != nil {
		return (*ApiKey_Project_PublicId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_By_ApiKey_Head(ctx context.Context,
	api_key_head ApiKey_Head_Field) (
	row *ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version, projects.public_id, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.segment_limit, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit FROM projects  JOIN api_keys ON projects.id = api_keys.project_id WHERE api_keys.head = ?")

	var __values []any
	__values = append(__values, api_key_head.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ApiKey.Id, &row.ApiKey.ProjectId, &row.ApiKey.Head, &row.ApiKey.Name, &row.ApiKey.Secret, &row.ApiKey.UserAgent, &row.ApiKey.CreatedAt, &row.ApiKey.CreatedBy, &row.ApiKey.Version, &row.Project_PublicId, &row.Project_RateLimit, &row.Project_BurstLimit, &row.Project_RateLimitHead, &row.Project_BurstLimitHead, &row.Project_RateLimitGet, &row.Project_BurstLimitGet, &row.Project_RateLimitPut, &row.Project_BurstLimitPut, &row.Project_RateLimitList, &row.Project_BurstLimitList, &row.Project_RateLimitDel, &row.Project_BurstLimitDel, &row.Project_SegmentLimit, &row.Project_UsageLimit, &row.Project_BandwidthLimit, &row.Project_UserSpecifiedUsageLimit, &row.Project_UserSpecifiedBandwidthLimit)
	if err != nil {
		return (*ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_ApiKey_Project_PublicId_By_ApiKey_Name_And_ApiKey_ProjectId(ctx context.Context,
	api_key_name ApiKey_Name_Field,
	api_key_project_id ApiKey_ProjectId_Field) (
	row *ApiKey_Project_PublicId_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_keys.id, api_keys.project_id, api_keys.head, api_keys.name, api_keys.secret, api_keys.user_agent, api_keys.created_at, api_keys.created_by, api_keys.version, projects.public_id FROM projects  JOIN api_keys ON projects.id = api_keys.project_id WHERE api_keys.name = ? AND api_keys.project_id = ?")

	var __values []any
	__values = append(__values, api_key_name.value(), api_key_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ApiKey_Project_PublicId_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ApiKey.Id, &row.ApiKey.ProjectId, &row.ApiKey.Head, &row.ApiKey.Name, &row.ApiKey.Secret, &row.ApiKey.UserAgent, &row.ApiKey.CreatedAt, &row.ApiKey.CreatedBy, &row.ApiKey.Version, &row.Project_PublicId)
	if err != nil {
		return (*ApiKey_Project_PublicId_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_ApiKeyTail_By_Tail(ctx context.Context,
	api_key_tail_tail ApiKeyTail_Tail_Field) (
	api_key_tail *ApiKeyTail, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT api_key_tails.root_key_id, api_key_tails.tail, api_key_tails.parent_tail, api_key_tails.caveat, api_key_tails.last_used FROM api_key_tails WHERE api_key_tails.tail = ?")

	var __values []any
	__values = append(__values, api_key_tail_tail.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	api_key_tail = &ApiKeyTail{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&api_key_tail.RootKeyId, &api_key_tail.Tail, &api_key_tail.ParentTail, &api_key_tail.Caveat, &api_key_tail.LastUsed)
	if err != nil {
		return (*ApiKeyTail)(nil), obj.makeErr(err)
	}
	return api_key_tail, nil

}

func (obj *spannerImpl) Get_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if err != nil {
		return (*BucketMetainfo)(nil), obj.makeErr(err)
	}
	return bucket_metainfo, nil

}

func (obj *spannerImpl) Get_BucketMetainfo_Tags_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Tags_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.tags FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Tags_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Tags)
	if err != nil {
		return (*Tags_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_BucketMetainfo_CreatedBy_BucketMetainfo_CreatedAt_BucketMetainfo_Placement_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *CreatedBy_CreatedAt_Placement_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.created_by, bucket_metainfos.created_at, bucket_metainfos.placement FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &CreatedBy_CreatedAt_Placement_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.CreatedBy, &row.CreatedAt, &row.Placement)
	if err != nil {
		return (*CreatedBy_CreatedAt_Placement_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_BucketMetainfo_Placement_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Placement_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.placement FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Placement_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Placement)
	if err != nil {
		return (*Placement_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_BucketMetainfo_UserAgent_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *UserAgent_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.user_agent FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UserAgent_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UserAgent)
	if err != nil {
		return (*UserAgent_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_BucketMetainfo_Versioning_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Versioning_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.versioning FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Versioning_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Versioning)
	if err != nil {
		return (*Versioning_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_BucketMetainfo_ObjectLockEnabled_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *ObjectLockEnabled_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.object_lock_enabled FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ObjectLockEnabled_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ObjectLockEnabled)
	if err != nil {
		return (*ObjectLockEnabled_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_BucketMetainfo_ObjectLockEnabled_BucketMetainfo_DefaultRetentionMode_BucketMetainfo_DefaultRetentionDays_BucketMetainfo_DefaultRetentionYears_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ObjectLockEnabled, &row.DefaultRetentionMode, &row.DefaultRetentionDays, &row.DefaultRetentionYears)
	if err != nil {
		return (*ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_Bucket(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	row *Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.created_by, bucket_metainfos.user_agent, bucket_metainfos.created_at, bucket_metainfos.placement, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Id, &row.CreatedBy, &row.UserAgent, &row.CreatedAt, &row.Placement, &row.Versioning, &row.ObjectLockEnabled, &row.DefaultRetentionMode, &row.DefaultRetentionDays, &row.DefaultRetentionYears)
	if err != nil {
		return (*Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Has_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	has bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT EXISTS( SELECT 1 FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? )")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&has)
	if err != nil {
		return false, obj.makeErr(err)
	}
	return has, nil

}

func (obj *spannerImpl) Limited_BucketMetainfo_By_ProjectId_And_Name_GreaterOrEqual_OrderBy_Asc_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name_greater_or_equal BucketMetainfo_Name_Field,
	limit int, offset int64) (
	rows []*BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name >= ? ORDER BY bucket_metainfos.name LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name_greater_or_equal.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMetainfo, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_metainfo := &BucketMetainfo{}
				err = __rows.Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_metainfo)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Limited_BucketMetainfo_By_ProjectId_And_Name_Greater_OrderBy_Asc_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name_greater BucketMetainfo_Name_Field,
	limit int, offset int64) (
	rows []*BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name > ? ORDER BY bucket_metainfos.name LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name_greater.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMetainfo, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_metainfo := &BucketMetainfo{}
				err = __rows.Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_metainfo)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Count_BucketMetainfo_Name_By_ProjectId(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT COUNT(*) FROM bucket_metainfos WHERE bucket_metainfos.project_id = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&count)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Count_BucketMetainfo_Name_By_ProjectId_And_ObjectLockEnabled_Equal_True(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT COUNT(*) FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.object_lock_enabled = true")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&count)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name(ctx context.Context,
	limit int, start *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation) (
	rows []*ProjectId_Name_Row, next *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.project_id, bucket_metainfos.name FROM bucket_metainfos WHERE (bucket_metainfos.project_id > ? OR (bucket_metainfos.project_id = ? AND bucket_metainfos.name > ?)) ORDER BY bucket_metainfos.project_id, bucket_metainfos.name LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.project_id, bucket_metainfos.name FROM bucket_metainfos ORDER BY bucket_metainfos.project_id, bucket_metainfos.name LIMIT ?")

	var __values []any

	var __stmt string
	if start != nil && start._set {
		__values = append(__values,
			start._value_project_id, start._value_project_id, start._value_name,
			limit,
		)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*ProjectId_Name_Row, next *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation
			__continuation._set = true

			for __rows.Next() {
				row := &ProjectId_Name_Row{}
				err = __rows.Scan(&row.ProjectId, &row.Name, &__continuation._value_project_id, &__continuation._value_name)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, row)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *spannerImpl) Get_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field) (
	value_attribution *ValueAttribution, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT value_attributions.project_id, value_attributions.bucket_name, value_attributions.user_agent, value_attributions.placement, value_attributions.last_updated FROM value_attributions WHERE value_attributions.project_id = ? AND value_attributions.bucket_name = ?")

	var __values []any
	__values = append(__values, value_attribution_project_id.value(), value_attribution_bucket_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	value_attribution = &ValueAttribution{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
	if err != nil {
		return (*ValueAttribution)(nil), obj.makeErr(err)
	}
	return value_attribution, nil

}

func (obj *spannerImpl) Get_BucketMigration_By_Id(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field) (
	bucket_migration *BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at FROM bucket_migrations WHERE bucket_migrations.id = ?")

	var __values []any
	__values = append(__values, bucket_migration_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_migration = &BucketMigration{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
	if err != nil {
		return (*BucketMigration)(nil), obj.makeErr(err)
	}
	return bucket_migration, nil

}

func (obj *spannerImpl) All_BucketMigration_By_ProjectId_And_BucketName_OrderBy_Desc_CreatedAt(ctx context.Context,
	bucket_migration_project_id BucketMigration_ProjectId_Field,
	bucket_migration_bucket_name BucketMigration_BucketName_Field) (
	rows []*BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at FROM bucket_migrations WHERE bucket_migrations.project_id = ? AND bucket_migrations.bucket_name = ? ORDER BY bucket_migrations.created_at DESC")

	var __values []any
	__values = append(__values, bucket_migration_project_id.value(), bucket_migration_bucket_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMigration, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_migration := &BucketMigration{}
				err = __rows.Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_migration)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Limited_BucketMigration_By_State_OrderBy_Asc_CreatedAt(ctx context.Context,
	bucket_migration_state BucketMigration_State_Field,
	limit int, offset int64) (
	rows []*BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at FROM bucket_migrations WHERE bucket_migrations.state = ? ORDER BY bucket_migrations.created_at LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, bucket_migration_state.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*BucketMigration, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				bucket_migration := &BucketMigration{}
				err = __rows.Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, bucket_migration)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_RestApiKey_By_Id(ctx context.Context,
	rest_api_key_id RestApiKey_Id_Field) (
	rest_api_key *RestApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT rest_api_keys.id, rest_api_keys.user_id, rest_api_keys.token, rest_api_keys.name, rest_api_keys.expires_at, rest_api_keys.created_at FROM rest_api_keys WHERE rest_api_keys.id = ?")

	var __values []any
	__values = append(__values, rest_api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	rest_api_key = &RestApiKey{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&rest_api_key.Id, &rest_api_key.UserId, &rest_api_key.Token, &rest_api_key.Name, &rest_api_key.ExpiresAt, &rest_api_key.CreatedAt)
	if err != nil {
		return (*RestApiKey)(nil), obj.makeErr(err)
	}
	return rest_api_key, nil

}

func (obj *spannerImpl) Get_RestApiKey_By_Token(ctx context.Context,
	rest_api_key_token RestApiKey_Token_Field) (
	rest_api_key *RestApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT rest_api_keys.id, rest_api_keys.user_id, rest_api_keys.token, rest_api_keys.name, rest_api_keys.expires_at, rest_api_keys.created_at FROM rest_api_keys WHERE rest_api_keys.token = ?")

	var __values []any
	__values = append(__values, rest_api_key_token.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	rest_api_key = &RestApiKey{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&rest_api_key.Id, &rest_api_key.UserId, &rest_api_key.Token, &rest_api_key.Name, &rest_api_key.ExpiresAt, &rest_api_key.CreatedAt)
	if err != nil {
		return (*RestApiKey)(nil), obj.makeErr(err)
	}
	return rest_api_key, nil

}

func (obj *spannerImpl) All_RestApiKey_By_UserId(ctx context.Context,
	rest_api_key_user_id RestApiKey_UserId_Field) (
	rows []*RestApiKey, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT rest_api_keys.id, rest_api_keys.user_id, rest_api_keys.token, rest_api_keys.name, rest_api_keys.expires_at, rest_api_keys.created_at FROM rest_api_keys WHERE rest_api_keys.user_id = ?")

	var __values []any
	__values = append(__values, rest_api_key_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*RestApiKey, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				rest_api_key := &RestApiKey{}
				err = __rows.Scan(&rest_api_key.Id, &rest_api_key.UserId, &rest_api_key.Token, &rest_api_key.Name, &rest_api_key.ExpiresAt, &rest_api_key.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, rest_api_key)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_User(ctx context.Context) (
	rows []*User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users")

	var __values []any

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				user := &User{}
				err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, user)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_User_By_NormalizedEmail(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field) (
	rows []*User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ?")

	var __values []any
	__values = append(__values, user_normalized_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				user := &User{}
				err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, user)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) All_User_By_NormalizedEmail_And_TenantId(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field,
	user_tenant_id User_TenantId_Field) (
	rows []*User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "users.tenant_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ? AND "), __cond_0}}

	var __values []any
	__values = append(__values, user_normalized_email.value())
	if !user_tenant_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_tenant_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				user := &User{}
				err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
				if err != nil {
					return nil, err
				}
				rows = append(rows, user)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_User_By_NormalizedEmail_And_Status_Not_Number(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ? AND users.status != 0 LIMIT 2")

	var __values []any
	__values = append(__values, user_normalized_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		user, err = func() (user *User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			user = &User{}
			err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return user, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("User_By_NormalizedEmail_And_Status_Not_Number")
			}
			return nil, obj.makeErr(err)
		}
		return user, nil
	}

}

func (obj *spannerImpl) Get_User_By_NormalizedEmail_And_TenantId_And_Status_Not_Number(ctx context.Context,
	user_normalized_email User_NormalizedEmail_Field,
	user_tenant_id User_TenantId_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "users.tenant_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.normalized_email = ? AND "), __cond_0, __sqlbundle_Literal(" AND users.status != 0 LIMIT 2")}}

	var __values []any
	__values = append(__values, user_normalized_email.value())
	if !user_tenant_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_tenant_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		user, err = func() (user *User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			user = &User{}
			err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return user, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("User_By_NormalizedEmail_And_TenantId_And_Status_Not_Number")
			}
			return nil, obj.makeErr(err)
		}
		return user, nil
	}

}

func (obj *spannerImpl) Get_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
	if err != nil {
		return (*User)(nil), obj.makeErr(err)
	}
	return user, nil

}

func (obj *spannerImpl) Get_User_ProjectLimit_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *ProjectLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.project_limit FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ProjectLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ProjectLimit)
	if err != nil {
		return (*ProjectLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_User_Kind_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *Kind_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.kind FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Kind_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Kind)
	if err != nil {
		return (*Kind_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_User_UpgradeTime_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *UpgradeTime_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.upgrade_time FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &UpgradeTime_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.UpgradeTime)
	if err != nil {
		return (*UpgradeTime_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Get_User_By_ExternalId(ctx context.Context,
	user_external_id User_ExternalId_Field) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "users.external_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id FROM users WHERE "), __cond_0, __sqlbundle_Literal(" LIMIT 2")}}

	var __values []any
	if !user_external_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, user_external_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		user, err = func() (user *User, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			if !__rows.Next() {
				return nil, sql.ErrNoRows
			}

			user = &User{}
			err = __rows.Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
			if err != nil {
				return nil, err
			}

			if __rows.Next() {
				return nil, errTooManyRows
			}

			return user, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			if errors.Is(err, errTooManyRows) {
				return nil, tooManyRows("User_By_ExternalId")
			}
			return nil, obj.makeErr(err)
		}
		return user, nil
	}

}

func (obj *spannerImpl) Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event(ctx context.Context,
	user_status_not User_Status_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field,
	limit int, start *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation) (
	rows []*AccountFreezeEvent, next *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at, account_freeze_events.user_id, account_freeze_events.event FROM account_freeze_events  JOIN users ON account_freeze_events.user_id = users.id WHERE users.status != ? AND account_freeze_events.event = ? AND (account_freeze_events.user_id > ? OR (account_freeze_events.user_id = ? AND account_freeze_events.event > ?)) ORDER BY account_freeze_events.user_id, account_freeze_events.event LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at, account_freeze_events.user_id, account_freeze_events.event FROM account_freeze_events  JOIN users ON account_freeze_events.user_id = users.id WHERE users.status != ? AND account_freeze_events.event = ? ORDER BY account_freeze_events.user_id, account_freeze_events.event LIMIT ?")

	var __values []any
	__values = append(__values, user_status_not.value(), account_freeze_event_event.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values,
			start._value_user_id, start._value_user_id, start._value_event,
			limit,
		)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*AccountFreezeEvent, next *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer closeRows(__rows, &err)

			var __continuation Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation
			__continuation._set = true

			for __rows.Next() {
				account_freeze_event := &AccountFreezeEvent{}
				err = __rows.Scan(&account_freeze_event.UserId, &account_freeze_event.Event, spannerConvertJSON(&account_freeze_event.Limits), &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt, &__continuation._value_user_id, &__continuation._value_event)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, account_freeze_event)
				next = &__continuation
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (obj *spannerImpl) Get_User_ProjectStorageLimit_User_ProjectBandwidthLimit_User_ProjectSegmentLimit_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	row *ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.project_storage_limit, users.project_bandwidth_limit, users.project_segment_limit FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.ProjectStorageLimit, &row.ProjectBandwidthLimit, &row.ProjectSegmentLimit)
	if err != nil {
		return (*ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) Count_User_By_Status(ctx context.Context,
	user_status User_Status_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT COUNT(*) FROM users WHERE users.status = ?")

	var __values []any
	__values = append(__values, user_status.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&count)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Limited_User_Id_User_Email_User_FullName_By_Status(ctx context.Context,
	user_status User_Status_Field,
	limit int, offset int64) (
	rows []*Id_Email_FullName_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.id, users.email, users.full_name FROM users WHERE users.status = ? LIMIT ? OFFSET ?")

	var __values []any
	__values = append(__values, user_status.value())

	__values = append(__values, limit, offset)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*Id_Email_FullName_Row, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				row := &Id_Email_FullName_Row{}
				err = __rows.Scan(&row.Id, &row.Email, &row.FullName)
				if err != nil {
					return nil, err
				}
				rows = append(rows, row)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_User_Status_By_Project_Id(ctx context.Context,
	project_id Project_Id_Field) (
	row *Status_Row, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT users.status FROM users  JOIN projects ON users.id = projects.owner_id WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	row = &Status_Row{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&row.Status)
	if err != nil {
		return (*Status_Row)(nil), obj.makeErr(err)
	}
	return row, nil

}

func (obj *spannerImpl) All_WebappSession_By_UserId(ctx context.Context,
	webapp_session_user_id WebappSession_UserId_Field) (
	rows []*WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at FROM webapp_sessions WHERE webapp_sessions.user_id = ?")

	var __values []any
	__values = append(__values, webapp_session_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*WebappSession, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				webapp_session := &WebappSession{}
				err = __rows.Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, webapp_session)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_WebappSession_By_Id(ctx context.Context,
	webapp_session_id WebappSession_Id_Field) (
	webapp_session *WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at FROM webapp_sessions WHERE webapp_sessions.id = ?")

	var __values []any
	__values = append(__values, webapp_session_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	webapp_session = &WebappSession{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
	if err != nil {
		return (*WebappSession)(nil), obj.makeErr(err)
	}
	return webapp_session, nil

}

func (obj *spannerImpl) Get_RegistrationToken_By_Secret(ctx context.Context,
	registration_token_secret RegistrationToken_Secret_Field) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at FROM registration_tokens WHERE registration_tokens.secret = ?")

	var __values []any
	__values = append(__values, registration_token_secret.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err != nil {
		return (*RegistrationToken)(nil), obj.makeErr(err)
	}
	return registration_token, nil

}

func (obj *spannerImpl) Get_RegistrationToken_By_OwnerId(ctx context.Context,
	registration_token_owner_id RegistrationToken_OwnerId_Field) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __cond_0 = &__sqlbundle_Condition{Left: "registration_tokens.owner_id", Equal: true, Right: "?", Null: true}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("SELECT registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at FROM registration_tokens WHERE "), __cond_0}}

	var __values []any
	if !registration_token_owner_id.isnull() {
		__cond_0.Null = false
		__values = append(__values, registration_token_owner_id.value())
	}

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if err != nil {
		return (*RegistrationToken)(nil), obj.makeErr(err)
	}
	return registration_token, nil

}

func (obj *spannerImpl) Get_ResetPasswordToken_By_Secret(ctx context.Context,
	reset_password_token_secret ResetPasswordToken_Secret_Field) (
	reset_password_token *ResetPasswordToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reset_password_tokens.secret, reset_password_tokens.owner_id, reset_password_tokens.created_at FROM reset_password_tokens WHERE reset_password_tokens.secret = ?")

	var __values []any
	__values = append(__values, reset_password_token_secret.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reset_password_token = &ResetPasswordToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
	if err != nil {
		return (*ResetPasswordToken)(nil), obj.makeErr(err)
	}
	return reset_password_token, nil

}

func (obj *spannerImpl) Get_ResetPasswordToken_By_OwnerId(ctx context.Context,
	reset_password_token_owner_id ResetPasswordToken_OwnerId_Field) (
	reset_password_token *ResetPasswordToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT reset_password_tokens.secret, reset_password_tokens.owner_id, reset_password_tokens.created_at FROM reset_password_tokens WHERE reset_password_tokens.owner_id = ?")

	var __values []any
	__values = append(__values, reset_password_token_owner_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reset_password_token = &ResetPasswordToken{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&reset_password_token.Secret, &reset_password_token.OwnerId, &reset_password_token.CreatedAt)
	if err != nil {
		return (*ResetPasswordToken)(nil), obj.makeErr(err)
	}
	return reset_password_token, nil

}

func (obj *spannerImpl) Get_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field) (
	account_freeze_event *AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at FROM account_freeze_events WHERE account_freeze_events.user_id = ? AND account_freeze_events.event = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value(), account_freeze_event_event.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	account_freeze_event = &AccountFreezeEvent{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, spannerConvertJSON(&account_freeze_event.Limits), &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
	if err != nil {
		return (*AccountFreezeEvent)(nil), obj.makeErr(err)
	}
	return account_freeze_event, nil

}

func (obj *spannerImpl) All_AccountFreezeEvent_By_UserId(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field) (
	rows []*AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at FROM account_freeze_events WHERE account_freeze_events.user_id = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	for {
		rows, err = func() (rows []*AccountFreezeEvent, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, err
			}
			defer closeRows(__rows, &err)

			for __rows.Next() {
				account_freeze_event := &AccountFreezeEvent{}
				err = __rows.Scan(&account_freeze_event.UserId, &account_freeze_event.Event, spannerConvertJSON(&account_freeze_event.Limits), &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
				if err != nil {
					return nil, err
				}
				rows = append(rows, account_freeze_event)
			}
			return rows, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, obj.makeErr(err)
		}
		return rows, nil
	}

}

func (obj *spannerImpl) Get_UserSettings_By_UserId(ctx context.Context,
	user_settings_user_id UserSettings_UserId_Field) (
	user_settings *UserSettings, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("SELECT user_settings.user_id, user_settings.session_minutes, user_settings.passphrase_prompt, user_settings.onboarding_start, user_settings.onboarding_end, user_settings.onboarding_step, user_settings.notice_dismissal FROM user_settings WHERE user_settings.user_id = ?")

	var __values []any
	__values = append(__values, user_settings_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user_settings = &UserSettings{}
	err = obj.queryRowContext(ctx, __stmt, __values...).Scan(&user_settings.UserId, &user_settings.SessionMinutes, &user_settings.PassphrasePrompt, &user_settings.OnboardingStart, &user_settings.OnboardingEnd, &user_settings.OnboardingStep, spannerConvertJSON(&user_settings.NoticeDismissal))
	if err != nil {
		return (*UserSettings)(nil), obj.makeErr(err)
	}
	return user_settings, nil

}

func (obj *spannerImpl) UpdateNoReturn_AccountingTimestamps_By_Name(ctx context.Context,
	accounting_timestamps_name AccountingTimestamps_Name_Field,
	update AccountingTimestamps_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE accounting_timestamps SET "), __sets, __sqlbundle_Literal(" WHERE accounting_timestamps.name = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Value._set {
		__values = append(__values, update.Value.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("value = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, accounting_timestamps_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) Update_StripeCustomer_By_UserId(ctx context.Context,
	stripe_customer_user_id StripeCustomer_UserId_Field,
	update StripeCustomer_Update_Fields) (
	stripe_customer *StripeCustomer, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE stripe_customers SET "), __sets, __sqlbundle_Literal(" WHERE stripe_customers.user_id = ? THEN RETURN stripe_customers.user_id, stripe_customers.customer_id, stripe_customers.billing_customer_id, stripe_customers.package_plan, stripe_customers.purchased_package_at, stripe_customers.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.BillingCustomerId._set {
		__values = append(__values, update.BillingCustomerId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("billing_customer_id = ?"))
	}
	if update.PackagePlan._set {
		__values = append(__values, update.PackagePlan.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("package_plan = ?"))
	}
	if update.PurchasedPackageAt._set {
		__values = append(__values, update.PurchasedPackageAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("purchased_package_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, stripe_customer_user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripe_customer = &StripeCustomer{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&stripe_customer.UserId, &stripe_customer.CustomerId, &stripe_customer.BillingCustomerId, &stripe_customer.PackagePlan, &stripe_customer.PurchasedPackageAt, &stripe_customer.CreatedAt)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripe_customer, nil
}

func (obj *spannerImpl) Update_BillingBalance_By_UserId_And_Balance(ctx context.Context,
	billing_balance_user_id BillingBalance_UserId_Field,
	billing_balance_balance BillingBalance_Balance_Field,
	update BillingBalance_Update_Fields) (
	billing_balance *BillingBalance, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE billing_balances SET "), __sets, __sqlbundle_Literal(" WHERE billing_balances.user_id = ? AND billing_balances.balance = ? THEN RETURN billing_balances.user_id, billing_balances.balance, billing_balances.last_updated")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Balance._set {
		__values = append(__values, update.Balance.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("balance = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_updated = ?"))

	__args = append(__args, billing_balance_user_id.value(), billing_balance_balance.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	billing_balance = &BillingBalance{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&billing_balance.UserId, &billing_balance.Balance, &billing_balance.LastUpdated)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return billing_balance, nil
}

func (obj *spannerImpl) UpdateNoReturn_BillingTransaction_By_Id_And_Status(ctx context.Context,
	billing_transaction_id BillingTransaction_Id_Field,
	billing_transaction_status BillingTransaction_Status_Field,
	update BillingTransaction_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE billing_transactions SET "), __sets, __sqlbundle_Literal(" WHERE billing_transactions.id = ? AND billing_transactions.status = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}
	if update.Metadata._set {
		__values = append(__values, spannerConvertJSON(update.Metadata.value()))
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("metadata = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, billing_transaction_id.value(), billing_transaction_status.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) Update_CoinpaymentsTransaction_By_Id(ctx context.Context,
	coinpayments_transaction_id CoinpaymentsTransaction_Id_Field,
	update CoinpaymentsTransaction_Update_Fields) (
	coinpayments_transaction *CoinpaymentsTransaction, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE coinpayments_transactions SET "), __sets, __sqlbundle_Literal(" WHERE coinpayments_transactions.id = ? THEN RETURN coinpayments_transactions.id, coinpayments_transactions.user_id, coinpayments_transactions.address, coinpayments_transactions.amount_numeric, coinpayments_transactions.received_numeric, coinpayments_transactions.status, coinpayments_transactions.key, coinpayments_transactions.timeout, coinpayments_transactions.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ReceivedNumeric._set {
		__values = append(__values, update.ReceivedNumeric.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("received_numeric = ?"))
	}
	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, coinpayments_transaction_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	coinpayments_transaction = &CoinpaymentsTransaction{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&coinpayments_transaction.Id, &coinpayments_transaction.UserId, &coinpayments_transaction.Address, &coinpayments_transaction.AmountNumeric, &coinpayments_transaction.ReceivedNumeric, &coinpayments_transaction.Status, &coinpayments_transaction.Key, &coinpayments_transaction.Timeout, &coinpayments_transaction.CreatedAt)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return coinpayments_transaction, nil
}

func (obj *spannerImpl) Update_StripecoinpaymentsInvoiceProjectRecord_By_Id(ctx context.Context,
	stripecoinpayments_invoice_project_record_id StripecoinpaymentsInvoiceProjectRecord_Id_Field,
	update StripecoinpaymentsInvoiceProjectRecord_Update_Fields) (
	stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE stripecoinpayments_invoice_project_records SET "), __sets, __sqlbundle_Literal(" WHERE stripecoinpayments_invoice_project_records.id = ? THEN RETURN stripecoinpayments_invoice_project_records.id, stripecoinpayments_invoice_project_records.project_id, stripecoinpayments_invoice_project_records.storage, stripecoinpayments_invoice_project_records.egress, stripecoinpayments_invoice_project_records.objects, stripecoinpayments_invoice_project_records.segments, stripecoinpayments_invoice_project_records.period_start, stripecoinpayments_invoice_project_records.period_end, stripecoinpayments_invoice_project_records.state, stripecoinpayments_invoice_project_records.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.State._set {
		__values = append(__values, update.State.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("state = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, stripecoinpayments_invoice_project_record_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	stripecoinpayments_invoice_project_record = &StripecoinpaymentsInvoiceProjectRecord{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&stripecoinpayments_invoice_project_record.Id, &stripecoinpayments_invoice_project_record.ProjectId, &stripecoinpayments_invoice_project_record.Storage, &stripecoinpayments_invoice_project_record.Egress, &stripecoinpayments_invoice_project_record.Objects, &stripecoinpayments_invoice_project_record.Segments, &stripecoinpayments_invoice_project_record.PeriodStart, &stripecoinpayments_invoice_project_record.PeriodEnd, &stripecoinpayments_invoice_project_record.State, &stripecoinpayments_invoice_project_record.CreatedAt)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return stripecoinpayments_invoice_project_record, nil
}

func (obj *spannerImpl) UpdateNoReturn_PeerIdentity_By_NodeId(ctx context.Context,
	peer_identity_node_id PeerIdentity_NodeId_Field,
	update PeerIdentity_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE peer_identities SET "), __sets, __sqlbundle_Literal(" WHERE peer_identities.node_id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.LeafSerialNumber._set {
		__values = append(__values, update.LeafSerialNumber.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("leaf_serial_number = ?"))
	}
	if update.Chain._set {
		__values = append(__values, update.Chain.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("chain = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, peer_identity_node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) Update_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	node *Node, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ? THEN RETURN nodes.id, nodes.address, nodes.last_net, nodes.last_ip_port, nodes.country_code, nodes.protocol, nodes.email, nodes.wallet, nodes.wallet_features, nodes.free_disk, nodes.piece_count, nodes.major, nodes.minor, nodes.patch, nodes.commit_hash, nodes.release_timestamp, nodes.release, nodes.latency_90, nodes.vetted_at, nodes.created_at, nodes.updated_at, nodes.last_contact_success, nodes.last_contact_failure, nodes.disqualified, nodes.disqualification_reason, nodes.unknown_audit_suspended, nodes.offline_suspended, nodes.under_review, nodes.exit_initiated_at, nodes.exit_loop_completed_at, nodes.exit_finished_at, nodes.exit_success, nodes.contained, nodes.last_offline_email, nodes.last_software_update_email, nodes.noise_proto, nodes.noise_public_key, nodes.debounce_limit, nodes.features")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}
	if update.LastNet._set {
		__values = append(__values, update.LastNet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_net = ?"))
	}
	if update.LastIpPort._set {
		__values = append(__values, update.LastIpPort.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_ip_port = ?"))
	}
	if update.CountryCode._set {
		__values = append(__values, update.CountryCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("country_code = ?"))
	}
	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}
	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}
	if update.Wallet._set {
		__values = append(__values, update.Wallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet = ?"))
	}
	if update.WalletFeatures._set {
		__values = append(__values, update.WalletFeatures.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet_features = ?"))
	}
	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}
	if update.PieceCount._set {
		__values = append(__values, update.PieceCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("piece_count = ?"))
	}
	if update.Major._set {
		__values = append(__values, update.Major.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("major = ?"))
	}
	if update.Minor._set {
		__values = append(__values, update.Minor.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("minor = ?"))
	}
	if update.Patch._set {
		__values = append(__values, update.Patch.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("patch = ?"))
	}
	if update.CommitHash._set {
		__values = append(__values, update.CommitHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("commit_hash = ?"))
	}
	if update.ReleaseTimestamp._set {
		__values = append(__values, update.ReleaseTimestamp.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release_timestamp = ?"))
	}
	if update.Release._set {
		__values = append(__values, update.Release.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release = ?"))
	}
	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}
	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}
	if update.LastContactSuccess._set {
		__values = append(__values, update.LastContactSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_success = ?"))
	}
	if update.LastContactFailure._set {
		__values = append(__values, update.LastContactFailure.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_failure = ?"))
	}
	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}
	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}
	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}
	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}
	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}
	if update.ExitInitiatedAt._set {
		__values = append(__values, update.ExitInitiatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_initiated_at = ?"))
	}
	if update.ExitLoopCompletedAt._set {
		__values = append(__values, update.ExitLoopCompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_loop_completed_at = ?"))
	}
	if update.ExitFinishedAt._set {
		__values = append(__values, update.ExitFinishedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_finished_at = ?"))
	}
	if update.ExitSuccess._set {
		__values = append(__values, update.ExitSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_success = ?"))
	}
	if update.Contained._set {
		__values = append(__values, update.Contained.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("contained = ?"))
	}
	if update.LastOfflineEmail._set {
		__values = append(__values, update.LastOfflineEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_offline_email = ?"))
	}
	if update.LastSoftwareUpdateEmail._set {
		__values = append(__values, update.LastSoftwareUpdateEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_software_update_email = ?"))
	}
	if update.NoiseProto._set {
		__values = append(__values, update.NoiseProto.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_proto = ?"))
	}
	if update.NoisePublicKey._set {
		__values = append(__values, update.NoisePublicKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_public_key = ?"))
	}
	if update.DebounceLimit._set {
		__values = append(__values, update.DebounceLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("debounce_limit = ?"))
	}
	if update.Features._set {
		__values = append(__values, update.Features.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("features = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	node = &Node{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&node.Id, &node.Address, &node.LastNet, &node.LastIpPort, &node.CountryCode, &node.Protocol, &node.Email, &node.Wallet, &node.WalletFeatures, &node.FreeDisk, &node.PieceCount, &node.Major, &node.Minor, &node.Patch, &node.CommitHash, &node.ReleaseTimestamp, &node.Release, &node.Latency90, &node.VettedAt, &node.CreatedAt, &node.UpdatedAt, &node.LastContactSuccess, &node.LastContactFailure, &node.Disqualified, &node.DisqualificationReason, &node.UnknownAuditSuspended, &node.OfflineSuspended, &node.UnderReview, &node.ExitInitiatedAt, &node.ExitLoopCompletedAt, &node.ExitFinishedAt, &node.ExitSuccess, &node.Contained, &node.LastOfflineEmail, &node.LastSoftwareUpdateEmail, &node.NoiseProto, &node.NoisePublicKey, &node.DebounceLimit, &node.Features)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return node, nil
}

func (obj *spannerImpl) UpdateNoReturn_Node_By_Id(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}
	if update.LastNet._set {
		__values = append(__values, update.LastNet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_net = ?"))
	}
	if update.LastIpPort._set {
		__values = append(__values, update.LastIpPort.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_ip_port = ?"))
	}
	if update.CountryCode._set {
		__values = append(__values, update.CountryCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("country_code = ?"))
	}
	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}
	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}
	if update.Wallet._set {
		__values = append(__values, update.Wallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet = ?"))
	}
	if update.WalletFeatures._set {
		__values = append(__values, update.WalletFeatures.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet_features = ?"))
	}
	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}
	if update.PieceCount._set {
		__values = append(__values, update.PieceCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("piece_count = ?"))
	}
	if update.Major._set {
		__values = append(__values, update.Major.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("major = ?"))
	}
	if update.Minor._set {
		__values = append(__values, update.Minor.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("minor = ?"))
	}
	if update.Patch._set {
		__values = append(__values, update.Patch.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("patch = ?"))
	}
	if update.CommitHash._set {
		__values = append(__values, update.CommitHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("commit_hash = ?"))
	}
	if update.ReleaseTimestamp._set {
		__values = append(__values, update.ReleaseTimestamp.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release_timestamp = ?"))
	}
	if update.Release._set {
		__values = append(__values, update.Release.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release = ?"))
	}
	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}
	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}
	if update.LastContactSuccess._set {
		__values = append(__values, update.LastContactSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_success = ?"))
	}
	if update.LastContactFailure._set {
		__values = append(__values, update.LastContactFailure.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_failure = ?"))
	}
	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}
	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}
	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}
	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}
	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}
	if update.ExitInitiatedAt._set {
		__values = append(__values, update.ExitInitiatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_initiated_at = ?"))
	}
	if update.ExitLoopCompletedAt._set {
		__values = append(__values, update.ExitLoopCompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_loop_completed_at = ?"))
	}
	if update.ExitFinishedAt._set {
		__values = append(__values, update.ExitFinishedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_finished_at = ?"))
	}
	if update.ExitSuccess._set {
		__values = append(__values, update.ExitSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_success = ?"))
	}
	if update.Contained._set {
		__values = append(__values, update.Contained.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("contained = ?"))
	}
	if update.LastOfflineEmail._set {
		__values = append(__values, update.LastOfflineEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_offline_email = ?"))
	}
	if update.LastSoftwareUpdateEmail._set {
		__values = append(__values, update.LastSoftwareUpdateEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_software_update_email = ?"))
	}
	if update.NoiseProto._set {
		__values = append(__values, update.NoiseProto.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_proto = ?"))
	}
	if update.NoisePublicKey._set {
		__values = append(__values, update.NoisePublicKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_public_key = ?"))
	}
	if update.DebounceLimit._set {
		__values = append(__values, update.DebounceLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("debounce_limit = ?"))
	}
	if update.Features._set {
		__values = append(__values, update.Features.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("features = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) UpdateNoReturn_Node_By_Id_And_Disqualified_Is_Null_And_ExitFinishedAt_Is_Null(ctx context.Context,
	node_id Node_Id_Field,
	update Node_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE nodes SET "), __sets, __sqlbundle_Literal(" WHERE nodes.id = ? AND nodes.disqualified is NULL AND nodes.exit_finished_at is NULL")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Address._set {
		__values = append(__values, update.Address.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("address = ?"))
	}
	if update.LastNet._set {
		__values = append(__values, update.LastNet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_net = ?"))
	}
	if update.LastIpPort._set {
		__values = append(__values, update.LastIpPort.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_ip_port = ?"))
	}
	if update.CountryCode._set {
		__values = append(__values, update.CountryCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("country_code = ?"))
	}
	if update.Protocol._set {
		__values = append(__values, update.Protocol.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("protocol = ?"))
	}
	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}
	if update.Wallet._set {
		__values = append(__values, update.Wallet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet = ?"))
	}
	if update.WalletFeatures._set {
		__values = append(__values, update.WalletFeatures.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("wallet_features = ?"))
	}
	if update.FreeDisk._set {
		__values = append(__values, update.FreeDisk.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("free_disk = ?"))
	}
	if update.PieceCount._set {
		__values = append(__values, update.PieceCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("piece_count = ?"))
	}
	if update.Major._set {
		__values = append(__values, update.Major.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("major = ?"))
	}
	if update.Minor._set {
		__values = append(__values, update.Minor.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("minor = ?"))
	}
	if update.Patch._set {
		__values = append(__values, update.Patch.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("patch = ?"))
	}
	if update.CommitHash._set {
		__values = append(__values, update.CommitHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("commit_hash = ?"))
	}
	if update.ReleaseTimestamp._set {
		__values = append(__values, update.ReleaseTimestamp.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release_timestamp = ?"))
	}
	if update.Release._set {
		__values = append(__values, update.Release.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("release = ?"))
	}
	if update.Latency90._set {
		__values = append(__values, update.Latency90.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("latency_90 = ?"))
	}
	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}
	if update.LastContactSuccess._set {
		__values = append(__values, update.LastContactSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_success = ?"))
	}
	if update.LastContactFailure._set {
		__values = append(__values, update.LastContactFailure.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_contact_failure = ?"))
	}
	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}
	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}
	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}
	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}
	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}
	if update.ExitInitiatedAt._set {
		__values = append(__values, update.ExitInitiatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_initiated_at = ?"))
	}
	if update.ExitLoopCompletedAt._set {
		__values = append(__values, update.ExitLoopCompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_loop_completed_at = ?"))
	}
	if update.ExitFinishedAt._set {
		__values = append(__values, update.ExitFinishedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_finished_at = ?"))
	}
	if update.ExitSuccess._set {
		__values = append(__values, update.ExitSuccess.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("exit_success = ?"))
	}
	if update.Contained._set {
		__values = append(__values, update.Contained.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("contained = ?"))
	}
	if update.LastOfflineEmail._set {
		__values = append(__values, update.LastOfflineEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_offline_email = ?"))
	}
	if update.LastSoftwareUpdateEmail._set {
		__values = append(__values, update.LastSoftwareUpdateEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_software_update_email = ?"))
	}
	if update.NoiseProto._set {
		__values = append(__values, update.NoiseProto.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_proto = ?"))
	}
	if update.NoisePublicKey._set {
		__values = append(__values, update.NoisePublicKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("noise_public_key = ?"))
	}
	if update.DebounceLimit._set {
		__values = append(__values, update.DebounceLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("debounce_limit = ?"))
	}
	if update.Features._set {
		__values = append(__values, update.Features.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("features = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) UpdateNoReturn_NodeApiVersion_By_Id_And_ApiVersion_Less(ctx context.Context,
	node_api_version_id NodeApiVersion_Id_Field,
	node_api_version_api_version_less NodeApiVersion_ApiVersion_Field,
	update NodeApiVersion_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE node_api_versions SET "), __sets, __sqlbundle_Literal(" WHERE node_api_versions.id = ? AND node_api_versions.api_version < ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ApiVersion._set {
		__values = append(__values, update.ApiVersion.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("api_version = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, node_api_version_id.value(), node_api_version_api_version_less.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) Update_Reputation_By_Id(ctx context.Context,
	reputation_id Reputation_Id_Field,
	update Reputation_Update_Fields) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE reputations SET "), __sets, __sqlbundle_Literal(" WHERE reputations.id = ? THEN RETURN reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}
	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}
	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}
	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}
	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}
	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}
	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}
	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}
	if update.OnlineScore._set {
		__values = append(__values, update.OnlineScore.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("online_score = ?"))
	}
	if update.AuditHistory._set {
		__values = append(__values, update.AuditHistory.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_history = ?"))
	}
	if update.AuditReputationAlpha._set {
		__values = append(__values, update.AuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_alpha = ?"))
	}
	if update.AuditReputationBeta._set {
		__values = append(__values, update.AuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_beta = ?"))
	}
	if update.UnknownAuditReputationAlpha._set {
		__values = append(__values, update.UnknownAuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha = ?"))
	}
	if update.UnknownAuditReputationBeta._set {
		__values = append(__values, update.UnknownAuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, reputation_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reputation, nil
}

func (obj *spannerImpl) Update_Reputation_By_Id_And_AuditHistory(ctx context.Context,
	reputation_id Reputation_Id_Field,
	reputation_audit_history Reputation_AuditHistory_Field,
	update Reputation_Update_Fields) (
	reputation *Reputation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE reputations SET "), __sets, __sqlbundle_Literal(" WHERE reputations.id = ? AND reputations.audit_history = ? THEN RETURN reputations.id, reputations.audit_success_count, reputations.total_audit_count, reputations.vetted_at, reputations.created_at, reputations.updated_at, reputations.disqualified, reputations.disqualification_reason, reputations.unknown_audit_suspended, reputations.offline_suspended, reputations.under_review, reputations.online_score, reputations.audit_history, reputations.audit_reputation_alpha, reputations.audit_reputation_beta, reputations.unknown_audit_reputation_alpha, reputations.unknown_audit_reputation_beta")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}
	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}
	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}
	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}
	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}
	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}
	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}
	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}
	if update.OnlineScore._set {
		__values = append(__values, update.OnlineScore.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("online_score = ?"))
	}
	if update.AuditHistory._set {
		__values = append(__values, update.AuditHistory.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_history = ?"))
	}
	if update.AuditReputationAlpha._set {
		__values = append(__values, update.AuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_alpha = ?"))
	}
	if update.AuditReputationBeta._set {
		__values = append(__values, update.AuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_beta = ?"))
	}
	if update.UnknownAuditReputationAlpha._set {
		__values = append(__values, update.UnknownAuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha = ?"))
	}
	if update.UnknownAuditReputationBeta._set {
		__values = append(__values, update.UnknownAuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, reputation_id.value(), reputation_audit_history.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	reputation = &Reputation{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&reputation.Id, &reputation.AuditSuccessCount, &reputation.TotalAuditCount, &reputation.VettedAt, &reputation.CreatedAt, &reputation.UpdatedAt, &reputation.Disqualified, &reputation.DisqualificationReason, &reputation.UnknownAuditSuspended, &reputation.OfflineSuspended, &reputation.UnderReview, &reputation.OnlineScore, &reputation.AuditHistory, &reputation.AuditReputationAlpha, &reputation.AuditReputationBeta, &reputation.UnknownAuditReputationAlpha, &reputation.UnknownAuditReputationBeta)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return reputation, nil
}

func (obj *spannerImpl) UpdateNoReturn_Reputation_By_Id(ctx context.Context,
	reputation_id Reputation_Id_Field,
	update Reputation_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE reputations SET "), __sets, __sqlbundle_Literal(" WHERE reputations.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.AuditSuccessCount._set {
		__values = append(__values, update.AuditSuccessCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_success_count = ?"))
	}
	if update.TotalAuditCount._set {
		__values = append(__values, update.TotalAuditCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("total_audit_count = ?"))
	}
	if update.VettedAt._set {
		__values = append(__values, update.VettedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("vetted_at = ?"))
	}
	if update.Disqualified._set {
		__values = append(__values, update.Disqualified.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualified = ?"))
	}
	if update.DisqualificationReason._set {
		__values = append(__values, update.DisqualificationReason.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("disqualification_reason = ?"))
	}
	if update.UnknownAuditSuspended._set {
		__values = append(__values, update.UnknownAuditSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_suspended = ?"))
	}
	if update.OfflineSuspended._set {
		__values = append(__values, update.OfflineSuspended.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("offline_suspended = ?"))
	}
	if update.UnderReview._set {
		__values = append(__values, update.UnderReview.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("under_review = ?"))
	}
	if update.OnlineScore._set {
		__values = append(__values, update.OnlineScore.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("online_score = ?"))
	}
	if update.AuditHistory._set {
		__values = append(__values, update.AuditHistory.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_history = ?"))
	}
	if update.AuditReputationAlpha._set {
		__values = append(__values, update.AuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_alpha = ?"))
	}
	if update.AuditReputationBeta._set {
		__values = append(__values, update.AuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("audit_reputation_beta = ?"))
	}
	if update.UnknownAuditReputationAlpha._set {
		__values = append(__values, update.UnknownAuditReputationAlpha.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_alpha = ?"))
	}
	if update.UnknownAuditReputationBeta._set {
		__values = append(__values, update.UnknownAuditReputationBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("unknown_audit_reputation_beta = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, reputation_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) UpdateNoReturn_OauthClient_By_Id(ctx context.Context,
	oauth_client_id OauthClient_Id_Field,
	update OauthClient_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE oauth_clients SET "), __sets, __sqlbundle_Literal(" WHERE oauth_clients.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.EncryptedSecret._set {
		__values = append(__values, update.EncryptedSecret.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("encrypted_secret = ?"))
	}
	if update.RedirectUrl._set {
		__values = append(__values, update.RedirectUrl.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("redirect_url = ?"))
	}
	if update.AppName._set {
		__values = append(__values, update.AppName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("app_name = ?"))
	}
	if update.AppLogoUrl._set {
		__values = append(__values, update.AppLogoUrl.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("app_logo_url = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, oauth_client_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) UpdateNoReturn_OauthCode_By_Code_And_ClaimedAt_Is_Null(ctx context.Context,
	oauth_code_code OauthCode_Code_Field,
	update OauthCode_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE oauth_codes SET "), __sets, __sqlbundle_Literal(" WHERE oauth_codes.code = ? AND oauth_codes.claimed_at is NULL")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ClaimedAt._set {
		__values = append(__values, update.ClaimedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("claimed_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, oauth_code_code.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) UpdateNoReturn_OauthToken_By_Token_And_Kind(ctx context.Context,
	oauth_token_token OauthToken_Token_Field,
	oauth_token_kind OauthToken_Kind_Field,
	update OauthToken_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE oauth_tokens SET "), __sets, __sqlbundle_Literal(" WHERE oauth_tokens.token = ? AND oauth_tokens.kind = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ExpiresAt._set {
		__values = append(__values, update.ExpiresAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("expires_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, oauth_token_token.value(), oauth_token_kind.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) Update_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field,
	update Project_Update_Fields) (
	project *Project, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE projects SET "), __sets, __sqlbundle_Literal(" WHERE projects.id = ? THEN RETURN projects.id, projects.public_id, projects.name, projects.description, projects.usage_limit, projects.bandwidth_limit, projects.user_specified_usage_limit, projects.user_specified_bandwidth_limit, projects.segment_limit, projects.rate_limit, projects.burst_limit, projects.rate_limit_head, projects.burst_limit_head, projects.rate_limit_get, projects.burst_limit_get, projects.rate_limit_put, projects.burst_limit_put, projects.rate_limit_list, projects.burst_limit_list, projects.rate_limit_del, projects.burst_limit_del, projects.max_buckets, projects.user_agent, projects.owner_id, projects.salt, projects.status, projects.status_updated_at, projects.created_at, projects.default_placement, projects.default_versioning, projects.prompted_for_versioning_beta, projects.passphrase_enc, projects.passphrase_enc_key_id, projects.path_encryption")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Name._set {
		__values = append(__values, update.Name.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("name = ?"))
	}
	if update.Description._set {
		__values = append(__values, update.Description.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("description = ?"))
	}
	if update.UsageLimit._set {
		__values = append(__values, update.UsageLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("usage_limit = ?"))
	}
	if update.BandwidthLimit._set {
		__values = append(__values, update.BandwidthLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("bandwidth_limit = ?"))
	}
	if update.UserSpecifiedUsageLimit._set {
		__values = append(__values, update.UserSpecifiedUsageLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_specified_usage_limit = ?"))
	}
	if update.UserSpecifiedBandwidthLimit._set {
		__values = append(__values, update.UserSpecifiedBandwidthLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_specified_bandwidth_limit = ?"))
	}
	if update.SegmentLimit._set {
		__values = append(__values, update.SegmentLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("segment_limit = ?"))
	}
	if update.RateLimit._set {
		__values = append(__values, update.RateLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit = ?"))
	}
	if update.BurstLimit._set {
		__values = append(__values, update.BurstLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit = ?"))
	}
	if update.RateLimitHead._set {
		__values = append(__values, update.RateLimitHead.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_head = ?"))
	}
	if update.BurstLimitHead._set {
		__values = append(__values, update.BurstLimitHead.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_head = ?"))
	}
	if update.RateLimitGet._set {
		__values = append(__values, update.RateLimitGet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_get = ?"))
	}
	if update.BurstLimitGet._set {
		__values = append(__values, update.BurstLimitGet.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_get = ?"))
	}
	if update.RateLimitPut._set {
		__values = append(__values, update.RateLimitPut.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_put = ?"))
	}
	if update.BurstLimitPut._set {
		__values = append(__values, update.BurstLimitPut.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_put = ?"))
	}
	if update.RateLimitList._set {
		__values = append(__values, update.RateLimitList.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_list = ?"))
	}
	if update.BurstLimitList._set {
		__values = append(__values, update.BurstLimitList.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_list = ?"))
	}
	if update.RateLimitDel._set {
		__values = append(__values, update.RateLimitDel.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("rate_limit_del = ?"))
	}
	if update.BurstLimitDel._set {
		__values = append(__values, update.BurstLimitDel.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("burst_limit_del = ?"))
	}
	if update.MaxBuckets._set {
		__values = append(__values, update.MaxBuckets.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("max_buckets = ?"))
	}
	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}
	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}
	if update.StatusUpdatedAt._set {
		__values = append(__values, update.StatusUpdatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status_updated_at = ?"))
	}
	if update.DefaultPlacement._set {
		__values = append(__values, update.DefaultPlacement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_placement = ?"))
	}
	if update.DefaultVersioning._set {
		__values = append(__values, update.DefaultVersioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_versioning = ?"))
	}
	if update.PromptedForVersioningBeta._set {
		__values = append(__values, update.PromptedForVersioningBeta.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("prompted_for_versioning_beta = ?"))
	}
	if update.PassphraseEnc._set {
		__values = append(__values, update.PassphraseEnc.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("passphrase_enc = ?"))
	}
	if update.PassphraseEncKeyId._set {
		__values = append(__values, update.PassphraseEncKeyId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("passphrase_enc_key_id = ?"))
	}
	if update.PathEncryption._set {
		__values = append(__values, update.PathEncryption.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("path_encryption = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project = &Project{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&project.Id, &project.PublicId, &project.Name, &project.Description, &project.UsageLimit, &project.BandwidthLimit, &project.UserSpecifiedUsageLimit, &project.UserSpecifiedBandwidthLimit, &project.SegmentLimit, &project.RateLimit, &project.BurstLimit, &project.RateLimitHead, &project.BurstLimitHead, &project.RateLimitGet, &project.BurstLimitGet, &project.RateLimitPut, &project.BurstLimitPut, &project.RateLimitList, &project.BurstLimitList, &project.RateLimitDel, &project.BurstLimitDel, &project.MaxBuckets, &project.UserAgent, &project.OwnerId, &project.Salt, &project.Status, &project.StatusUpdatedAt, &project.CreatedAt, &project.DefaultPlacement, &project.DefaultVersioning, &project.PromptedForVersioningBeta, &project.PassphraseEnc, &project.PassphraseEncKeyId, &project.PathEncryption)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project, nil
}

func (obj *spannerImpl) Update_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field,
	update ProjectMember_Update_Fields) (
	project_member *ProjectMember, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE project_members SET "), __sets, __sqlbundle_Literal(" WHERE project_members.member_id = ? AND project_members.project_id = ? THEN RETURN project_members.member_id, project_members.project_id, project_members.role, project_members.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Role._set {
		__values = append(__values, update.Role.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("role = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_member_member_id.value(), project_member_project_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_member = &ProjectMember{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&project_member.MemberId, &project_member.ProjectId, &project_member.Role, &project_member.CreatedAt)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_member, nil
}

func (obj *spannerImpl) Update_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field,
	update ProjectInvitation_Update_Fields) (
	project_invitation *ProjectInvitation, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE project_invitations SET "), __sets, __sqlbundle_Literal(" WHERE project_invitations.project_id = ? AND project_invitations.email = ? THEN RETURN project_invitations.project_id, project_invitations.email, project_invitations.inviter_id, project_invitations.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.InviterId._set {
		__values = append(__values, update.InviterId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("inviter_id = ?"))
	}
	if update.CreatedAt._set {
		__values = append(__values, update.CreatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("created_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, project_invitation_project_id.value(), project_invitation_email.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	project_invitation = &ProjectInvitation{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&project_invitation.ProjectId, &project_invitation.Email, &project_invitation.InviterId, &project_invitation.CreatedAt)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return project_invitation, nil
}

func (obj *spannerImpl) UpdateNoReturn_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field,
	update ApiKey_Update_Fields) (
	err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE api_keys SET "), __sets, __sqlbundle_Literal(" WHERE api_keys.id = ?")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Name._set {
		__values = append(__values, update.Name.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("name = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return emptyUpdate()
	}

	__args = append(__args, api_key_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil
}

func (obj *spannerImpl) Update_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	update BucketMetainfo_Update_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_metainfos SET "), __sets, __sqlbundle_Literal(" WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? THEN RETURN bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Tags._set {
		__values = append(__values, update.Tags.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tags = ?"))
	}
	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}
	if update.Versioning._set {
		__values = append(__values, update.Versioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("versioning = ?"))
	}
	if update.ObjectLockEnabled._set {
		__values = append(__values, update.ObjectLockEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("object_lock_enabled = ?"))
	}
	if update.DefaultRetentionMode._set {
		__values = append(__values, update.DefaultRetentionMode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_mode = ?"))
	}
	if update.DefaultRetentionDays._set {
		__values = append(__values, update.DefaultRetentionDays.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_days = ?"))
	}
	if update.DefaultRetentionYears._set {
		__values = append(__values, update.DefaultRetentionYears.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_years = ?"))
	}
	if update.DefaultSegmentSize._set {
		__values = append(__values, update.DefaultSegmentSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_segment_size = ?"))
	}
	if update.DefaultEncryptionCipherSuite._set {
		__values = append(__values, update.DefaultEncryptionCipherSuite.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_cipher_suite = ?"))
	}
	if update.DefaultEncryptionBlockSize._set {
		__values = append(__values, update.DefaultEncryptionBlockSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_block_size = ?"))
	}
	if update.DefaultRedundancyAlgorithm._set {
		__values = append(__values, update.DefaultRedundancyAlgorithm.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_algorithm = ?"))
	}
	if update.DefaultRedundancyShareSize._set {
		__values = append(__values, update.DefaultRedundancyShareSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_share_size = ?"))
	}
	if update.DefaultRedundancyRequiredShares._set {
		__values = append(__values, update.DefaultRedundancyRequiredShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_required_shares = ?"))
	}
	if update.DefaultRedundancyRepairShares._set {
		__values = append(__values, update.DefaultRedundancyRepairShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_repair_shares = ?"))
	}
	if update.DefaultRedundancyOptimalShares._set {
		__values = append(__values, update.DefaultRedundancyOptimalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_optimal_shares = ?"))
	}
	if update.DefaultRedundancyTotalShares._set {
		__values = append(__values, update.DefaultRedundancyTotalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_total_shares = ?"))
	}
	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil
}

func (obj *spannerImpl) Update_BucketMetainfo_By_ProjectId_And_Name_And_Versioning_GreaterOrEqual(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	bucket_metainfo_versioning_greater_or_equal BucketMetainfo_Versioning_Field,
	update BucketMetainfo_Update_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_metainfos SET "), __sets, __sqlbundle_Literal(" WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? AND bucket_metainfos.versioning >= ? THEN RETURN bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Tags._set {
		__values = append(__values, update.Tags.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tags = ?"))
	}
	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}
	if update.Versioning._set {
		__values = append(__values, update.Versioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("versioning = ?"))
	}
	if update.ObjectLockEnabled._set {
		__values = append(__values, update.ObjectLockEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("object_lock_enabled = ?"))
	}
	if update.DefaultRetentionMode._set {
		__values = append(__values, update.DefaultRetentionMode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_mode = ?"))
	}
	if update.DefaultRetentionDays._set {
		__values = append(__values, update.DefaultRetentionDays.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_days = ?"))
	}
	if update.DefaultRetentionYears._set {
		__values = append(__values, update.DefaultRetentionYears.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_years = ?"))
	}
	if update.DefaultSegmentSize._set {
		__values = append(__values, update.DefaultSegmentSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_segment_size = ?"))
	}
	if update.DefaultEncryptionCipherSuite._set {
		__values = append(__values, update.DefaultEncryptionCipherSuite.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_cipher_suite = ?"))
	}
	if update.DefaultEncryptionBlockSize._set {
		__values = append(__values, update.DefaultEncryptionBlockSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_block_size = ?"))
	}
	if update.DefaultRedundancyAlgorithm._set {
		__values = append(__values, update.DefaultRedundancyAlgorithm.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_algorithm = ?"))
	}
	if update.DefaultRedundancyShareSize._set {
		__values = append(__values, update.DefaultRedundancyShareSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_share_size = ?"))
	}
	if update.DefaultRedundancyRequiredShares._set {
		__values = append(__values, update.DefaultRedundancyRequiredShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_required_shares = ?"))
	}
	if update.DefaultRedundancyRepairShares._set {
		__values = append(__values, update.DefaultRedundancyRepairShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_repair_shares = ?"))
	}
	if update.DefaultRedundancyOptimalShares._set {
		__values = append(__values, update.DefaultRedundancyOptimalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_optimal_shares = ?"))
	}
	if update.DefaultRedundancyTotalShares._set {
		__values = append(__values, update.DefaultRedundancyTotalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_total_shares = ?"))
	}
	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, bucket_metainfo_project_id.value(), bucket_metainfo_name.value(), bucket_metainfo_versioning_greater_or_equal.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil
}

func (obj *spannerImpl) Update_BucketMetainfo_By_ProjectId_And_Name_And_Versioning_GreaterOrEqual_And_ObjectLockEnabled_Equal_False(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field,
	bucket_metainfo_versioning_greater_or_equal BucketMetainfo_Versioning_Field,
	update BucketMetainfo_Update_Fields) (
	bucket_metainfo *BucketMetainfo, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_metainfos SET "), __sets, __sqlbundle_Literal(" WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ? AND bucket_metainfos.versioning >= ? AND bucket_metainfos.object_lock_enabled = false THEN RETURN bucket_metainfos.id, bucket_metainfos.project_id, bucket_metainfos.name, bucket_metainfos.tags, bucket_metainfos.user_agent, bucket_metainfos.versioning, bucket_metainfos.object_lock_enabled, bucket_metainfos.default_retention_mode, bucket_metainfos.default_retention_days, bucket_metainfos.default_retention_years, bucket_metainfos.path_cipher, bucket_metainfos.created_at, bucket_metainfos.default_segment_size, bucket_metainfos.default_encryption_cipher_suite, bucket_metainfos.default_encryption_block_size, bucket_metainfos.default_redundancy_algorithm, bucket_metainfos.default_redundancy_share_size, bucket_metainfos.default_redundancy_required_shares, bucket_metainfos.default_redundancy_repair_shares, bucket_metainfos.default_redundancy_optimal_shares, bucket_metainfos.default_redundancy_total_shares, bucket_metainfos.placement, bucket_metainfos.created_by")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Tags._set {
		__values = append(__values, update.Tags.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tags = ?"))
	}
	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}
	if update.Versioning._set {
		__values = append(__values, update.Versioning.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("versioning = ?"))
	}
	if update.ObjectLockEnabled._set {
		__values = append(__values, update.ObjectLockEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("object_lock_enabled = ?"))
	}
	if update.DefaultRetentionMode._set {
		__values = append(__values, update.DefaultRetentionMode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_mode = ?"))
	}
	if update.DefaultRetentionDays._set {
		__values = append(__values, update.DefaultRetentionDays.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_days = ?"))
	}
	if update.DefaultRetentionYears._set {
		__values = append(__values, update.DefaultRetentionYears.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_retention_years = ?"))
	}
	if update.DefaultSegmentSize._set {
		__values = append(__values, update.DefaultSegmentSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_segment_size = ?"))
	}
	if update.DefaultEncryptionCipherSuite._set {
		__values = append(__values, update.DefaultEncryptionCipherSuite.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_cipher_suite = ?"))
	}
	if update.DefaultEncryptionBlockSize._set {
		__values = append(__values, update.DefaultEncryptionBlockSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_encryption_block_size = ?"))
	}
	if update.DefaultRedundancyAlgorithm._set {
		__values = append(__values, update.DefaultRedundancyAlgorithm.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_algorithm = ?"))
	}
	if update.DefaultRedundancyShareSize._set {
		__values = append(__values, update.DefaultRedundancyShareSize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_share_size = ?"))
	}
	if update.DefaultRedundancyRequiredShares._set {
		__values = append(__values, update.DefaultRedundancyRequiredShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_required_shares = ?"))
	}
	if update.DefaultRedundancyRepairShares._set {
		__values = append(__values, update.DefaultRedundancyRepairShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_repair_shares = ?"))
	}
	if update.DefaultRedundancyOptimalShares._set {
		__values = append(__values, update.DefaultRedundancyOptimalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_optimal_shares = ?"))
	}
	if update.DefaultRedundancyTotalShares._set {
		__values = append(__values, update.DefaultRedundancyTotalShares.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_redundancy_total_shares = ?"))
	}
	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, bucket_metainfo_project_id.value(), bucket_metainfo_name.value(), bucket_metainfo_versioning_greater_or_equal.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_metainfo = &BucketMetainfo{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&bucket_metainfo.Id, &bucket_metainfo.ProjectId, &bucket_metainfo.Name, &bucket_metainfo.Tags, &bucket_metainfo.UserAgent, &bucket_metainfo.Versioning, &bucket_metainfo.ObjectLockEnabled, &bucket_metainfo.DefaultRetentionMode, &bucket_metainfo.DefaultRetentionDays, &bucket_metainfo.DefaultRetentionYears, &bucket_metainfo.PathCipher, &bucket_metainfo.CreatedAt, &bucket_metainfo.DefaultSegmentSize, &bucket_metainfo.DefaultEncryptionCipherSuite, &bucket_metainfo.DefaultEncryptionBlockSize, &bucket_metainfo.DefaultRedundancyAlgorithm, &bucket_metainfo.DefaultRedundancyShareSize, &bucket_metainfo.DefaultRedundancyRequiredShares, &bucket_metainfo.DefaultRedundancyRepairShares, &bucket_metainfo.DefaultRedundancyOptimalShares, &bucket_metainfo.DefaultRedundancyTotalShares, &bucket_metainfo.Placement, &bucket_metainfo.CreatedBy)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_metainfo, nil
}

func (obj *spannerImpl) Update_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field,
	update ValueAttribution_Update_Fields) (
	value_attribution *ValueAttribution, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE value_attributions SET "), __sets, __sqlbundle_Literal(" WHERE value_attributions.project_id = ? AND value_attributions.bucket_name = ? THEN RETURN value_attributions.project_id, value_attributions.bucket_name, value_attributions.user_agent, value_attributions.placement, value_attributions.last_updated")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}
	if update.Placement._set {
		__values = append(__values, update.Placement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("placement = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("last_updated = ?"))

	__args = append(__args, value_attribution_project_id.value(), value_attribution_bucket_name.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	value_attribution = &ValueAttribution{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&value_attribution.ProjectId, &value_attribution.BucketName, &value_attribution.UserAgent, &value_attribution.Placement, &value_attribution.LastUpdated)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return value_attribution, nil
}

func (obj *spannerImpl) Update_BucketMigration_By_Id(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field,
	update BucketMigration_Update_Fields) (
	bucket_migration *BucketMigration, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE bucket_migrations SET "), __sets, __sqlbundle_Literal(" WHERE bucket_migrations.id = ? THEN RETURN bucket_migrations.id, bucket_migrations.project_id, bucket_migrations.bucket_name, bucket_migrations.from_placement, bucket_migrations.to_placement, bucket_migrations.migration_type, bucket_migrations.state, bucket_migrations.bytes_processed, bucket_migrations.error_message, bucket_migrations.created_at, bucket_migrations.updated_at, bucket_migrations.completed_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.State._set {
		__values = append(__values, update.State.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("state = ?"))
	}
	if update.BytesProcessed._set {
		__values = append(__values, update.BytesProcessed.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("bytes_processed = ?"))
	}
	if update.ErrorMessage._set {
		__values = append(__values, update.ErrorMessage.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("error_message = ?"))
	}
	if update.CompletedAt._set {
		__values = append(__values, update.CompletedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("completed_at = ?"))
	}

	__now := obj.db.Hooks.Now().UTC()

	__values = append(__values, __now)
	__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("updated_at = ?"))

	__args = append(__args, bucket_migration_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	bucket_migration = &BucketMigration{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&bucket_migration.Id, &bucket_migration.ProjectId, &bucket_migration.BucketName, &bucket_migration.FromPlacement, &bucket_migration.ToPlacement, &bucket_migration.MigrationType, &bucket_migration.State, &bucket_migration.BytesProcessed, &bucket_migration.ErrorMessage, &bucket_migration.CreatedAt, &bucket_migration.UpdatedAt, &bucket_migration.CompletedAt)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return bucket_migration, nil
}

func (obj *spannerImpl) Update_User_By_Id(ctx context.Context,
	user_id User_Id_Field,
	update User_Update_Fields) (
	user *User, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE users SET "), __sets, __sqlbundle_Literal(" WHERE users.id = ? THEN RETURN users.id, users.external_id, users.tenant_id, users.email, users.normalized_email, users.full_name, users.short_name, users.password_hash, users.new_unverified_email, users.email_change_verification_step, users.status, users.status_updated_at, users.final_invoice_generated, users.user_agent, users.created_at, users.project_limit, users.project_bandwidth_limit, users.project_storage_limit, users.project_segment_limit, users.kind, users.position, users.company_name, users.company_size, users.working_on, users.is_professional, users.employee_count, users.have_sales_contact, users.mfa_enabled, users.mfa_secret_key, users.mfa_recovery_codes, users.signup_promo_code, users.verification_reminders, users.trial_notifications, users.failed_login_count, users.login_lockout_expiration, users.signup_captcha, users.default_placement, users.activation_code, users.signup_id, users.trial_expiration, users.upgrade_time, users.hubspot_object_id")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.ExternalId._set {
		__values = append(__values, update.ExternalId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("external_id = ?"))
	}
	if update.TenantId._set {
		__values = append(__values, update.TenantId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("tenant_id = ?"))
	}
	if update.Email._set {
		__values = append(__values, update.Email.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email = ?"))
	}
	if update.NormalizedEmail._set {
		__values = append(__values, update.NormalizedEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("normalized_email = ?"))
	}
	if update.FullName._set {
		__values = append(__values, update.FullName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("full_name = ?"))
	}
	if update.ShortName._set {
		__values = append(__values, update.ShortName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("short_name = ?"))
	}
	if update.PasswordHash._set {
		__values = append(__values, update.PasswordHash.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("password_hash = ?"))
	}
	if update.NewUnverifiedEmail._set {
		__values = append(__values, update.NewUnverifiedEmail.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("new_unverified_email = ?"))
	}
	if update.EmailChangeVerificationStep._set {
		__values = append(__values, update.EmailChangeVerificationStep.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("email_change_verification_step = ?"))
	}
	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}
	if update.StatusUpdatedAt._set {
		__values = append(__values, update.StatusUpdatedAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status_updated_at = ?"))
	}
	if update.FinalInvoiceGenerated._set {
		__values = append(__values, update.FinalInvoiceGenerated.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("final_invoice_generated = ?"))
	}
	if update.UserAgent._set {
		__values = append(__values, update.UserAgent.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("user_agent = ?"))
	}
	if update.ProjectLimit._set {
		__values = append(__values, update.ProjectLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_limit = ?"))
	}
	if update.ProjectBandwidthLimit._set {
		__values = append(__values, update.ProjectBandwidthLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_bandwidth_limit = ?"))
	}
	if update.ProjectStorageLimit._set {
		__values = append(__values, update.ProjectStorageLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_storage_limit = ?"))
	}
	if update.ProjectSegmentLimit._set {
		__values = append(__values, update.ProjectSegmentLimit.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("project_segment_limit = ?"))
	}
	if update.Kind._set {
		__values = append(__values, update.Kind.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("kind = ?"))
	}
	if update.Position._set {
		__values = append(__values, update.Position.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("position = ?"))
	}
	if update.CompanyName._set {
		__values = append(__values, update.CompanyName.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("company_name = ?"))
	}
	if update.CompanySize._set {
		__values = append(__values, update.CompanySize.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("company_size = ?"))
	}
	if update.WorkingOn._set {
		__values = append(__values, update.WorkingOn.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("working_on = ?"))
	}
	if update.IsProfessional._set {
		__values = append(__values, update.IsProfessional.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("is_professional = ?"))
	}
	if update.EmployeeCount._set {
		__values = append(__values, update.EmployeeCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("employee_count = ?"))
	}
	if update.HaveSalesContact._set {
		__values = append(__values, update.HaveSalesContact.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("have_sales_contact = ?"))
	}
	if update.MfaEnabled._set {
		__values = append(__values, update.MfaEnabled.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("mfa_enabled = ?"))
	}
	if update.MfaSecretKey._set {
		__values = append(__values, update.MfaSecretKey.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("mfa_secret_key = ?"))
	}
	if update.MfaRecoveryCodes._set {
		__values = append(__values, update.MfaRecoveryCodes.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("mfa_recovery_codes = ?"))
	}
	if update.SignupPromoCode._set {
		__values = append(__values, update.SignupPromoCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("signup_promo_code = ?"))
	}
	if update.VerificationReminders._set {
		__values = append(__values, update.VerificationReminders.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("verification_reminders = ?"))
	}
	if update.TrialNotifications._set {
		__values = append(__values, update.TrialNotifications.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("trial_notifications = ?"))
	}
	if update.FailedLoginCount._set {
		__values = append(__values, update.FailedLoginCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("failed_login_count = ?"))
	}
	if update.LoginLockoutExpiration._set {
		__values = append(__values, update.LoginLockoutExpiration.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("login_lockout_expiration = ?"))
	}
	if update.DefaultPlacement._set {
		__values = append(__values, update.DefaultPlacement.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("default_placement = ?"))
	}
	if update.ActivationCode._set {
		__values = append(__values, update.ActivationCode.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("activation_code = ?"))
	}
	if update.SignupId._set {
		__values = append(__values, update.SignupId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("signup_id = ?"))
	}
	if update.TrialExpiration._set {
		__values = append(__values, update.TrialExpiration.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("trial_expiration = ?"))
	}
	if update.UpgradeTime._set {
		__values = append(__values, update.UpgradeTime.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("upgrade_time = ?"))
	}
	if update.HubspotObjectId._set {
		__values = append(__values, update.HubspotObjectId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("hubspot_object_id = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user = &User{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&user.Id, &user.ExternalId, &user.TenantId, &user.Email, &user.NormalizedEmail, &user.FullName, &user.ShortName, &user.PasswordHash, &user.NewUnverifiedEmail, &user.EmailChangeVerificationStep, &user.Status, &user.StatusUpdatedAt, &user.FinalInvoiceGenerated, &user.UserAgent, &user.CreatedAt, &user.ProjectLimit, &user.ProjectBandwidthLimit, &user.ProjectStorageLimit, &user.ProjectSegmentLimit, &user.Kind, &user.Position, &user.CompanyName, &user.CompanySize, &user.WorkingOn, &user.IsProfessional, &user.EmployeeCount, &user.HaveSalesContact, &user.MfaEnabled, &user.MfaSecretKey, &user.MfaRecoveryCodes, &user.SignupPromoCode, &user.VerificationReminders, &user.TrialNotifications, &user.FailedLoginCount, &user.LoginLockoutExpiration, &user.SignupCaptcha, &user.DefaultPlacement, &user.ActivationCode, &user.SignupId, &user.TrialExpiration, &user.UpgradeTime, &user.HubspotObjectId)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user, nil
}

func (obj *spannerImpl) Update_WebappSession_By_Id(ctx context.Context,
	webapp_session_id WebappSession_Id_Field,
	update WebappSession_Update_Fields) (
	webapp_session *WebappSession, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE webapp_sessions SET "), __sets, __sqlbundle_Literal(" WHERE webapp_sessions.id = ? THEN RETURN webapp_sessions.id, webapp_sessions.user_id, webapp_sessions.ip_address, webapp_sessions.user_agent, webapp_sessions.status, webapp_sessions.expires_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Status._set {
		__values = append(__values, update.Status.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("status = ?"))
	}
	if update.ExpiresAt._set {
		__values = append(__values, update.ExpiresAt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("expires_at = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, webapp_session_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	webapp_session = &WebappSession{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&webapp_session.Id, &webapp_session.UserId, &webapp_session.IpAddress, &webapp_session.UserAgent, &webapp_session.Status, &webapp_session.ExpiresAt)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return webapp_session, nil
}

func (obj *spannerImpl) Update_RegistrationToken_By_Secret(ctx context.Context,
	registration_token_secret RegistrationToken_Secret_Field,
	update RegistrationToken_Update_Fields) (
	registration_token *RegistrationToken, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE registration_tokens SET "), __sets, __sqlbundle_Literal(" WHERE registration_tokens.secret = ? THEN RETURN registration_tokens.secret, registration_tokens.owner_id, registration_tokens.project_limit, registration_tokens.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.OwnerId._set {
		__values = append(__values, update.OwnerId.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("owner_id = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, registration_token_secret.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	registration_token = &RegistrationToken{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&registration_token.Secret, &registration_token.OwnerId, &registration_token.ProjectLimit, &registration_token.CreatedAt)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return registration_token, nil
}

func (obj *spannerImpl) Update_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field,
	update AccountFreezeEvent_Update_Fields) (
	account_freeze_event *AccountFreezeEvent, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE account_freeze_events SET "), __sets, __sqlbundle_Literal(" WHERE account_freeze_events.user_id = ? AND account_freeze_events.event = ? THEN RETURN account_freeze_events.user_id, account_freeze_events.event, account_freeze_events.limits, account_freeze_events.days_till_escalation, account_freeze_events.notifications_count, account_freeze_events.created_at")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.Limits._set {
		__values = append(__values, spannerConvertJSON(update.Limits.value()))
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("limits = ?"))
	}
	if update.DaysTillEscalation._set {
		__values = append(__values, update.DaysTillEscalation.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("days_till_escalation = ?"))
	}
	if update.NotificationsCount._set {
		__values = append(__values, update.NotificationsCount.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("notifications_count = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, account_freeze_event_user_id.value(), account_freeze_event_event.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	account_freeze_event = &AccountFreezeEvent{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&account_freeze_event.UserId, &account_freeze_event.Event, spannerConvertJSON(&account_freeze_event.Limits), &account_freeze_event.DaysTillEscalation, &account_freeze_event.NotificationsCount, &account_freeze_event.CreatedAt)
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return account_freeze_event, nil
}

func (obj *spannerImpl) Update_UserSettings_By_UserId(ctx context.Context,
	user_settings_user_id UserSettings_UserId_Field,
	update UserSettings_Update_Fields) (
	user_settings *UserSettings, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __sets = &__sqlbundle_Hole{}

	var __embed_stmt = __sqlbundle_Literals{Join: "", SQLs: []__sqlbundle_SQL{__sqlbundle_Literal("UPDATE user_settings SET "), __sets, __sqlbundle_Literal(" WHERE user_settings.user_id = ? THEN RETURN user_settings.user_id, user_settings.session_minutes, user_settings.passphrase_prompt, user_settings.onboarding_start, user_settings.onboarding_end, user_settings.onboarding_step, user_settings.notice_dismissal")}}

	__sets_sql := __sqlbundle_Literals{Join: ", "}
	var __values []any
	var __args []any

	if update.SessionMinutes._set {
		__values = append(__values, update.SessionMinutes.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("session_minutes = ?"))
	}
	if update.PassphrasePrompt._set {
		__values = append(__values, update.PassphrasePrompt.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("passphrase_prompt = ?"))
	}
	if update.OnboardingStart._set {
		__values = append(__values, update.OnboardingStart.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("onboarding_start = ?"))
	}
	if update.OnboardingEnd._set {
		__values = append(__values, update.OnboardingEnd.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("onboarding_end = ?"))
	}
	if update.OnboardingStep._set {
		__values = append(__values, update.OnboardingStep.value())
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("onboarding_step = ?"))
	}
	if update.NoticeDismissal._set {
		__values = append(__values, spannerConvertJSON(update.NoticeDismissal.value()))
		__sets_sql.SQLs = append(__sets_sql.SQLs, __sqlbundle_Literal("notice_dismissal = ?"))
	}

	if len(__sets_sql.SQLs) == 0 {
		return nil, emptyUpdate()
	}

	__args = append(__args, user_settings_user_id.value())

	__values = append(__values, __args...)
	__sets.SQL = __sets_sql

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	user_settings = &UserSettings{}
	err = obj.driver.QueryRowContext(ctx, __stmt, __values...).Scan(&user_settings.UserId, &user_settings.SessionMinutes, &user_settings.PassphrasePrompt, &user_settings.OnboardingStart, &user_settings.OnboardingEnd, &user_settings.OnboardingStep, spannerConvertJSON(&user_settings.NoticeDismissal))
	if errors.Is(err, sql.ErrNoRows) {
		return nil, nil
	}
	if err != nil {
		return nil, obj.makeErr(err)
	}
	return user_settings, nil
}

func (obj *spannerImpl) Delete_StoragenodeStorageTally_By_IntervalEndTime_Less(ctx context.Context,
	storagenode_storage_tally_interval_end_time_less StoragenodeStorageTally_IntervalEndTime_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM storagenode_storage_tallies WHERE storagenode_storage_tallies.interval_end_time < ?")

	var __values []any
	__values = append(__values, storagenode_storage_tally_interval_end_time_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_BucketStorageTally_By_IntervalStart_Less(ctx context.Context,
	bucket_storage_tally_interval_start_less BucketStorageTally_IntervalStart_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM bucket_storage_tallies WHERE bucket_storage_tallies.interval_start < ?")

	var __values []any
	__values = append(__values, bucket_storage_tally_interval_start_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_ReverificationAudits_By_NodeId_And_StreamId_And_Position(ctx context.Context,
	reverification_audits_node_id ReverificationAudits_NodeId_Field,
	reverification_audits_stream_id ReverificationAudits_StreamId_Field,
	reverification_audits_position ReverificationAudits_Position_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM reverification_audits WHERE reverification_audits.node_id = ? AND reverification_audits.stream_id = ? AND reverification_audits.position = ?")

	var __values []any
	__values = append(__values, reverification_audits_node_id.value(), reverification_audits_stream_id.value(), reverification_audits_position.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_StorjscanPayment_By_Status(ctx context.Context,
	storjscan_payment_status StorjscanPayment_Status_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM storjscan_payments WHERE storjscan_payments.status = ?")

	var __values []any
	__values = append(__values, storjscan_payment_status.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_Domain_By_ProjectId_And_Subdomain(ctx context.Context,
	domain_project_id Domain_ProjectId_Field,
	domain_subdomain Domain_Subdomain_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM domains WHERE domains.project_id = ? AND domains.subdomain = ?")

	var __values []any
	__values = append(__values, domain_project_id.value(), domain_subdomain.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_Domain_By_ProjectId(ctx context.Context,
	domain_project_id Domain_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM domains WHERE domains.project_id = ?")

	var __values []any
	__values = append(__values, domain_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_Entitlement_By_Scope(ctx context.Context,
	entitlement_scope Entitlement_Scope_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM entitlements WHERE entitlements.scope = ?")

	var __values []any
	__values = append(__values, entitlement_scope.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_NodeEvent_By_CreatedAt_Less(ctx context.Context,
	node_event_created_at_less NodeEvent_CreatedAt_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM node_events WHERE node_events.created_at < ?")

	var __values []any
	__values = append(__values, node_event_created_at_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_OauthClient_By_Id(ctx context.Context,
	oauth_client_id OauthClient_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM oauth_clients WHERE oauth_clients.id = ?")

	var __values []any
	__values = append(__values, oauth_client_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_Project_By_Id(ctx context.Context,
	project_id Project_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM projects WHERE projects.id = ?")

	var __values []any
	__values = append(__values, project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
	project_member_member_id ProjectMember_MemberId_Field,
	project_member_project_id ProjectMember_ProjectId_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM project_members WHERE project_members.member_id = ? AND project_members.project_id = ?")

	var __values []any
	__values = append(__values, project_member_member_id.value(), project_member_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
	project_invitation_project_id ProjectInvitation_ProjectId_Field,
	project_invitation_email ProjectInvitation_Email_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM project_invitations WHERE project_invitations.project_id = ? AND project_invitations.email = ?")

	var __values []any
	__values = append(__values, project_invitation_project_id.value(), project_invitation_email.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_ApiKey_By_Id(ctx context.Context,
	api_key_id ApiKey_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM api_keys WHERE api_keys.id = ?")

	var __values []any
	__values = append(__values, api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_ApiKey_By_ProjectId(ctx context.Context,
	api_key_project_id ApiKey_ProjectId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM api_keys WHERE api_keys.project_id = ?")

	var __values []any
	__values = append(__values, api_key_project_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
	bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
	bucket_metainfo_name BucketMetainfo_Name_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM bucket_metainfos WHERE bucket_metainfos.project_id = ? AND bucket_metainfos.name = ?")

	var __values []any
	__values = append(__values, bucket_metainfo_project_id.value(), bucket_metainfo_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
	value_attribution_project_id ValueAttribution_ProjectId_Field,
	value_attribution_bucket_name ValueAttribution_BucketName_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM value_attributions WHERE value_attributions.project_id = ? AND value_attributions.bucket_name = ?")

	var __values []any
	__values = append(__values, value_attribution_project_id.value(), value_attribution_bucket_name.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_BucketMigration_By_Id(ctx context.Context,
	bucket_migration_id BucketMigration_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM bucket_migrations WHERE bucket_migrations.id = ?")

	var __values []any
	__values = append(__values, bucket_migration_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_RepairQueue_By_UpdatedAt_Less(ctx context.Context,
	repair_queue_updated_at_less RepairQueue_UpdatedAt_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM repair_queue WHERE repair_queue.updated_at < ?")

	var __values []any
	__values = append(__values, repair_queue_updated_at_less.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_RestApiKey_By_Id(ctx context.Context,
	rest_api_key_id RestApiKey_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM rest_api_keys WHERE rest_api_keys.id = ?")

	var __values []any
	__values = append(__values, rest_api_key_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_User_By_Id(ctx context.Context,
	user_id User_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM users WHERE users.id = ?")

	var __values []any
	__values = append(__values, user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_WebappSession_By_Id(ctx context.Context,
	webapp_session_id WebappSession_Id_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM webapp_sessions WHERE webapp_sessions.id = ?")

	var __values []any
	__values = append(__values, webapp_session_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_WebappSession_By_UserId_And_Id_Not(ctx context.Context,
	webapp_session_user_id WebappSession_UserId_Field,
	webapp_session_id_not WebappSession_Id_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM webapp_sessions WHERE webapp_sessions.user_id = ? AND webapp_sessions.id != ?")

	var __values []any
	__values = append(__values, webapp_session_user_id.value(), webapp_session_id_not.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_WebappSession_By_UserId(ctx context.Context,
	webapp_session_user_id WebappSession_UserId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM webapp_sessions WHERE webapp_sessions.user_id = ?")

	var __values []any
	__values = append(__values, webapp_session_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_ResetPasswordToken_By_Secret(ctx context.Context,
	reset_password_token_secret ResetPasswordToken_Secret_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM reset_password_tokens WHERE reset_password_tokens.secret = ?")

	var __values []any
	__values = append(__values, reset_password_token_secret.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (obj *spannerImpl) Delete_AccountFreezeEvent_By_UserId(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field) (
	count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM account_freeze_events WHERE account_freeze_events.user_id = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return 0, obj.makeErr(err)
	}

	count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}

	return count, nil

}

func (obj *spannerImpl) Delete_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
	account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
	account_freeze_event_event AccountFreezeEvent_Event_Field) (
	deleted bool, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}

	var __embed_stmt = __sqlbundle_Literal("DELETE FROM account_freeze_events WHERE account_freeze_events.user_id = ? AND account_freeze_events.event = ?")

	var __values []any
	__values = append(__values, account_freeze_event_user_id.value(), account_freeze_event_event.value())

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	__res, err := obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return false, obj.makeErr(err)
	}

	__count, err := __res.RowsAffected()
	if err != nil {
		return false, obj.makeErr(err)
	}

	return __count > 0, nil

}

func (impl spannerImpl) isConstraintError(err error) (constraint string, ok bool) {
	errcode := spanner.ErrCode(err)
	return "", errcode == codes.AlreadyExists || errcode == codes.OutOfRange || errcode == codes.FailedPrecondition
}

func (obj *spannerImpl) deleteAll(ctx context.Context) (count int64, err error) {
	defer mon.Task()(&ctx)(&err)
	if !obj.txn && txutil.IsInsideTx(ctx) {
		panic("using DB when inside of a transaction")
	}
	var __res sql.Result
	var __count int64
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM api_key_tails;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripecoinpayments_apply_balance_intents;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM rest_api_keys;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM project_members;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM project_invitations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM domains;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_migrations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_metainfos;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM api_keys;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM webapp_sessions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM verification_audits;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM value_attributions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM user_settings;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM users;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripecoinpayments_tx_conversion_rates;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripecoinpayments_invoice_project_records;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM stripe_customers;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storjscan_wallets;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storjscan_payments;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_storage_tallies;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_paystubs;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_payments;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_bandwidth_rollup_archives;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM storagenode_bandwidth_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM segment_pending_audits;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM revocations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM reverification_audits;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM reset_password_tokens;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM reputations;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM repair_queue;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM registration_tokens;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM project_bandwidth_daily_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM projects;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM peer_identities;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM oauth_tokens;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM oauth_codes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM oauth_clients;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM node_tags;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM node_events;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM node_api_versions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM nodes;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM entitlements;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM coinpayments_transactions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM change_histories;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_storage_tallies;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_bandwidth_rollup_archives;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM bucket_bandwidth_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM billing_transactions;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM billing_balances;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM accounting_timestamps;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM accounting_rollups;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM account_freeze_events;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count

	return count, nil

}

type Methods interface {
	All_AccountFreezeEvent_By_UserId(ctx context.Context,
		account_freeze_event_user_id AccountFreezeEvent_UserId_Field) (
		rows []*AccountFreezeEvent, err error)

	All_BillingTransaction_By_UserId_And_Source_OrderBy_Desc_TxTimestamp(ctx context.Context,
		billing_transaction_user_id BillingTransaction_UserId_Field,
		billing_transaction_source BillingTransaction_Source_Field) (
		rows []*BillingTransaction, err error)

	All_BillingTransaction_By_UserId_OrderBy_Desc_TxTimestamp(ctx context.Context,
		billing_transaction_user_id BillingTransaction_UserId_Field) (
		rows []*BillingTransaction, err error)

	All_BucketMigration_By_ProjectId_And_BucketName_OrderBy_Desc_CreatedAt(ctx context.Context,
		bucket_migration_project_id BucketMigration_ProjectId_Field,
		bucket_migration_bucket_name BucketMigration_BucketName_Field) (
		rows []*BucketMigration, err error)

	All_BucketStorageTally_By_ProjectId_And_BucketName_And_IntervalStart_GreaterOrEqual_And_IntervalStart_LessOrEqual_OrderBy_Desc_IntervalStart(ctx context.Context,
		bucket_storage_tally_project_id BucketStorageTally_ProjectId_Field,
		bucket_storage_tally_bucket_name BucketStorageTally_BucketName_Field,
		bucket_storage_tally_interval_start_greater_or_equal BucketStorageTally_IntervalStart_Field,
		bucket_storage_tally_interval_start_less_or_equal BucketStorageTally_IntervalStart_Field) (
		rows []*BucketStorageTally, err error)

	All_BucketStorageTally_OrderBy_Desc_IntervalStart(ctx context.Context) (
		rows []*BucketStorageTally, err error)

	All_ChangeHistory_By_BucketName_OrderBy_Desc_Timestamp(ctx context.Context,
		change_history_bucket_name ChangeHistory_BucketName_Field) (
		rows []*ChangeHistory, err error)

	All_ChangeHistory_By_ProjectId_And_ItemType_Not_OrderBy_Desc_Timestamp(ctx context.Context,
		change_history_project_id ChangeHistory_ProjectId_Field,
		change_history_item_type_not ChangeHistory_ItemType_Field) (
		rows []*ChangeHistory, err error)

	All_ChangeHistory_By_ProjectId_And_ItemType_OrderBy_Desc_Timestamp(ctx context.Context,
		change_history_project_id ChangeHistory_ProjectId_Field,
		change_history_item_type ChangeHistory_ItemType_Field) (
		rows []*ChangeHistory, err error)

	All_ChangeHistory_By_UserId_And_ItemType_OrderBy_Desc_Timestamp(ctx context.Context,
		change_history_user_id ChangeHistory_UserId_Field,
		change_history_item_type ChangeHistory_ItemType_Field) (
		rows []*ChangeHistory, err error)

	All_ChangeHistory_By_UserId_OrderBy_Desc_Timestamp(ctx context.Context,
		change_history_user_id ChangeHistory_UserId_Field) (
		rows []*ChangeHistory, err error)

	All_CoinpaymentsTransaction_By_UserId_OrderBy_Desc_CreatedAt(ctx context.Context,
		coinpayments_transaction_user_id CoinpaymentsTransaction_UserId_Field) (
		rows []*CoinpaymentsTransaction, err error)

	All_Domain_Subdomain_By_ProjectId(ctx context.Context,
		domain_project_id Domain_ProjectId_Field) (
		rows []*Subdomain_Row, err error)

	All_NodeTags(ctx context.Context) (
		rows []*NodeTags, err error)

	All_NodeTags_By_NodeId(ctx context.Context,
		node_tags_node_id NodeTags_NodeId_Field) (
		rows []*NodeTags, err error)

	All_Node_Id(ctx context.Context) (
		rows []*Id_Row, err error)

	All_Node_Id_Node_PieceCount_By_Disqualified_Is_Null_And_ExitInitiatedAt_Is_Null_And_ExitFinishedAt_Is_Null(ctx context.Context) (
		rows []*Id_PieceCount_Row, err error)

	All_Project(ctx context.Context) (
		rows []*Project, err error)

	All_ProjectInvitation_By_Email(ctx context.Context,
		project_invitation_email ProjectInvitation_Email_Field) (
		rows []*ProjectInvitation, err error)

	All_ProjectInvitation_By_ProjectId(ctx context.Context,
		project_invitation_project_id ProjectInvitation_ProjectId_Field) (
		rows []*ProjectInvitation, err error)

	All_ProjectInvitation_By_Project_Status_And_ProjectInvitation_Email(ctx context.Context,
		project_status Project_Status_Field,
		project_invitation_email ProjectInvitation_Email_Field) (
		rows []*ProjectInvitation, err error)

	All_ProjectMember_By_MemberId(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field) (
		rows []*ProjectMember, err error)

	All_Project_By_CreatedAt_Less_OrderBy_Asc_CreatedAt(ctx context.Context,
		project_created_at_less Project_CreatedAt_Field) (
		rows []*Project, err error)

	All_Project_By_OwnerId_And_Status_OrderBy_Asc_CreatedAt(ctx context.Context,
		project_owner_id Project_OwnerId_Field,
		project_status Project_Status_Field) (
		rows []*Project, err error)

	All_Project_By_OwnerId_OrderBy_Asc_CreatedAt(ctx context.Context,
		project_owner_id Project_OwnerId_Field) (
		rows []*Project, err error)

	All_Project_By_ProjectMember_MemberId_OrderBy_Asc_Project_Name(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field) (
		rows []*Project, err error)

	All_RestApiKey_By_UserId(ctx context.Context,
		rest_api_key_user_id RestApiKey_UserId_Field) (
		rows []*RestApiKey, err error)

	All_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart(ctx context.Context,
		storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
		storagenode_bandwidth_rollup_interval_start StoragenodeBandwidthRollup_IntervalStart_Field) (
		rows []*StoragenodeBandwidthRollup, err error)

	All_StoragenodePayment_By_NodeId(ctx context.Context,
		storagenode_payment_node_id StoragenodePayment_NodeId_Field) (
		rows []*StoragenodePayment, err error)

	All_StoragenodePayment_By_NodeId_And_Period(ctx context.Context,
		storagenode_payment_node_id StoragenodePayment_NodeId_Field,
		storagenode_payment_period StoragenodePayment_Period_Field) (
		rows []*StoragenodePayment, err error)

	All_StoragenodePaystub_By_NodeId(ctx context.Context,
		storagenode_paystub_node_id StoragenodePaystub_NodeId_Field) (
		rows []*StoragenodePaystub, err error)

	All_StoragenodeStorageTally(ctx context.Context) (
		rows []*StoragenodeStorageTally, err error)

	All_StoragenodeStorageTally_By_IntervalEndTime_GreaterOrEqual(ctx context.Context,
		storagenode_storage_tally_interval_end_time_greater_or_equal StoragenodeStorageTally_IntervalEndTime_Field) (
		rows []*StoragenodeStorageTally, err error)

	All_StorjscanPayment_OrderBy_Asc_ChainId_Asc_BlockNumber_Asc_LogIndex(ctx context.Context) (
		rows []*StorjscanPayment, err error)

	All_StorjscanWallet(ctx context.Context) (
		rows []*StorjscanWallet, err error)

	All_User(ctx context.Context) (
		rows []*User, err error)

	All_User_By_NormalizedEmail(ctx context.Context,
		user_normalized_email User_NormalizedEmail_Field) (
		rows []*User, err error)

	All_User_By_NormalizedEmail_And_TenantId(ctx context.Context,
		user_normalized_email User_NormalizedEmail_Field,
		user_tenant_id User_TenantId_Field) (
		rows []*User, err error)

	All_WebappSession_By_UserId(ctx context.Context,
		webapp_session_user_id WebappSession_UserId_Field) (
		rows []*WebappSession, err error)

	Count_BucketMetainfo_Name_By_ProjectId(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field) (
		count int64, err error)

	Count_BucketMetainfo_Name_By_ProjectId_And_ObjectLockEnabled_Equal_True(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field) (
		count int64, err error)

	Count_User_By_Status(ctx context.Context,
		user_status User_Status_Field) (
		count int64, err error)

	CreateNoReturn_BillingBalance(ctx context.Context,
		billing_balance_user_id BillingBalance_UserId_Field,
		billing_balance_balance BillingBalance_Balance_Field) (
		err error)

	CreateNoReturn_OauthClient(ctx context.Context,
		oauth_client_id OauthClient_Id_Field,
		oauth_client_encrypted_secret OauthClient_EncryptedSecret_Field,
		oauth_client_redirect_url OauthClient_RedirectUrl_Field,
		oauth_client_user_id OauthClient_UserId_Field,
		oauth_client_app_name OauthClient_AppName_Field,
		oauth_client_app_logo_url OauthClient_AppLogoUrl_Field) (
		err error)

	CreateNoReturn_OauthCode(ctx context.Context,
		oauth_code_client_id OauthCode_ClientId_Field,
		oauth_code_user_id OauthCode_UserId_Field,
		oauth_code_scope OauthCode_Scope_Field,
		oauth_code_redirect_url OauthCode_RedirectUrl_Field,
		oauth_code_challenge OauthCode_Challenge_Field,
		oauth_code_challenge_method OauthCode_ChallengeMethod_Field,
		oauth_code_code OauthCode_Code_Field,
		oauth_code_created_at OauthCode_CreatedAt_Field,
		oauth_code_expires_at OauthCode_ExpiresAt_Field,
		optional OauthCode_Create_Fields) (
		err error)

	CreateNoReturn_OauthToken(ctx context.Context,
		oauth_token_client_id OauthToken_ClientId_Field,
		oauth_token_user_id OauthToken_UserId_Field,
		oauth_token_scope OauthToken_Scope_Field,
		oauth_token_kind OauthToken_Kind_Field,
		oauth_token_token OauthToken_Token_Field,
		oauth_token_created_at OauthToken_CreatedAt_Field,
		oauth_token_expires_at OauthToken_ExpiresAt_Field) (
		err error)

	CreateNoReturn_PeerIdentity(ctx context.Context,
		peer_identity_node_id PeerIdentity_NodeId_Field,
		peer_identity_leaf_serial_number PeerIdentity_LeafSerialNumber_Field,
		peer_identity_chain PeerIdentity_Chain_Field) (
		err error)

	CreateNoReturn_RestApiKey(ctx context.Context,
		rest_api_key_id RestApiKey_Id_Field,
		rest_api_key_user_id RestApiKey_UserId_Field,
		rest_api_key_token RestApiKey_Token_Field,
		rest_api_key_name RestApiKey_Name_Field,
		optional RestApiKey_Create_Fields) (
		err error)

	CreateNoReturn_Revocation(ctx context.Context,
		revocation_revoked Revocation_Revoked_Field,
		revocation_api_key_id Revocation_ApiKeyId_Field) (
		err error)

	CreateNoReturn_StoragenodePayment(ctx context.Context,
		storagenode_payment_node_id StoragenodePayment_NodeId_Field,
		storagenode_payment_period StoragenodePayment_Period_Field,
		storagenode_payment_amount StoragenodePayment_Amount_Field,
		optional StoragenodePayment_Create_Fields) (
		err error)

	CreateNoReturn_StorjscanPayment(ctx context.Context,
		storjscan_payment_block_hash StorjscanPayment_BlockHash_Field,
		storjscan_payment_block_number StorjscanPayment_BlockNumber_Field,
		storjscan_payment_transaction StorjscanPayment_Transaction_Field,
		storjscan_payment_log_index StorjscanPayment_LogIndex_Field,
		storjscan_payment_from_address StorjscanPayment_FromAddress_Field,
		storjscan_payment_to_address StorjscanPayment_ToAddress_Field,
		storjscan_payment_token_value StorjscanPayment_TokenValue_Field,
		storjscan_payment_usd_value StorjscanPayment_UsdValue_Field,
		storjscan_payment_status StorjscanPayment_Status_Field,
		storjscan_payment_block_timestamp StorjscanPayment_BlockTimestamp_Field,
		optional StorjscanPayment_Create_Fields) (
		err error)

	CreateNoReturn_StorjscanWallet(ctx context.Context,
		storjscan_wallet_user_id StorjscanWallet_UserId_Field,
		storjscan_wallet_wallet_address StorjscanWallet_WalletAddress_Field) (
		err error)

	CreateNoReturn_UserSettings(ctx context.Context,
		user_settings_user_id UserSettings_UserId_Field,
		optional UserSettings_Create_Fields) (
		err error)

	Create_ApiKey(ctx context.Context,
		api_key_id ApiKey_Id_Field,
		api_key_project_id ApiKey_ProjectId_Field,
		api_key_head ApiKey_Head_Field,
		api_key_name ApiKey_Name_Field,
		api_key_secret ApiKey_Secret_Field,
		optional ApiKey_Create_Fields) (
		api_key *ApiKey, err error)

	Create_BillingTransaction(ctx context.Context,
		billing_transaction_user_id BillingTransaction_UserId_Field,
		billing_transaction_amount BillingTransaction_Amount_Field,
		billing_transaction_currency BillingTransaction_Currency_Field,
		billing_transaction_description BillingTransaction_Description_Field,
		billing_transaction_source BillingTransaction_Source_Field,
		billing_transaction_status BillingTransaction_Status_Field,
		billing_transaction_type BillingTransaction_Type_Field,
		billing_transaction_metadata BillingTransaction_Metadata_Field,
		billing_transaction_tx_timestamp BillingTransaction_TxTimestamp_Field) (
		billing_transaction *BillingTransaction, err error)

	Create_BucketMetainfo(ctx context.Context,
		bucket_metainfo_id BucketMetainfo_Id_Field,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field,
		bucket_metainfo_path_cipher BucketMetainfo_PathCipher_Field,
		bucket_metainfo_default_segment_size BucketMetainfo_DefaultSegmentSize_Field,
		bucket_metainfo_default_encryption_cipher_suite BucketMetainfo_DefaultEncryptionCipherSuite_Field,
		bucket_metainfo_default_encryption_block_size BucketMetainfo_DefaultEncryptionBlockSize_Field,
		bucket_metainfo_default_redundancy_algorithm BucketMetainfo_DefaultRedundancyAlgorithm_Field,
		bucket_metainfo_default_redundancy_share_size BucketMetainfo_DefaultRedundancyShareSize_Field,
		bucket_metainfo_default_redundancy_required_shares BucketMetainfo_DefaultRedundancyRequiredShares_Field,
		bucket_metainfo_default_redundancy_repair_shares BucketMetainfo_DefaultRedundancyRepairShares_Field,
		bucket_metainfo_default_redundancy_optimal_shares BucketMetainfo_DefaultRedundancyOptimalShares_Field,
		bucket_metainfo_default_redundancy_total_shares BucketMetainfo_DefaultRedundancyTotalShares_Field,
		optional BucketMetainfo_Create_Fields) (
		bucket_metainfo *BucketMetainfo, err error)

	Create_BucketMigration(ctx context.Context,
		bucket_migration_id BucketMigration_Id_Field,
		bucket_migration_project_id BucketMigration_ProjectId_Field,
		bucket_migration_bucket_name BucketMigration_BucketName_Field,
		bucket_migration_from_placement BucketMigration_FromPlacement_Field,
		bucket_migration_to_placement BucketMigration_ToPlacement_Field,
		bucket_migration_migration_type BucketMigration_MigrationType_Field,
		bucket_migration_state BucketMigration_State_Field,
		optional BucketMigration_Create_Fields) (
		bucket_migration *BucketMigration, err error)

	Create_ChangeHistory(ctx context.Context,
		change_history_id ChangeHistory_Id_Field,
		change_history_admin_email ChangeHistory_AdminEmail_Field,
		change_history_user_id ChangeHistory_UserId_Field,
		change_history_item_type ChangeHistory_ItemType_Field,
		change_history_operation ChangeHistory_Operation_Field,
		change_history_reason ChangeHistory_Reason_Field,
		change_history_changes ChangeHistory_Changes_Field,
		optional ChangeHistory_Create_Fields) (
		change_history *ChangeHistory, err error)

	Create_CoinpaymentsTransaction(ctx context.Context,
		coinpayments_transaction_id CoinpaymentsTransaction_Id_Field,
		coinpayments_transaction_user_id CoinpaymentsTransaction_UserId_Field,
		coinpayments_transaction_address CoinpaymentsTransaction_Address_Field,
		coinpayments_transaction_amount_numeric CoinpaymentsTransaction_AmountNumeric_Field,
		coinpayments_transaction_received_numeric CoinpaymentsTransaction_ReceivedNumeric_Field,
		coinpayments_transaction_status CoinpaymentsTransaction_Status_Field,
		coinpayments_transaction_key CoinpaymentsTransaction_Key_Field,
		coinpayments_transaction_timeout CoinpaymentsTransaction_Timeout_Field) (
		coinpayments_transaction *CoinpaymentsTransaction, err error)

	Create_Domain(ctx context.Context,
		domain_subdomain Domain_Subdomain_Field,
		domain_project_id Domain_ProjectId_Field,
		domain_prefix Domain_Prefix_Field,
		domain_access_id Domain_AccessId_Field,
		domain_created_by Domain_CreatedBy_Field) (
		domain *Domain, err error)

	Create_NodeEvent(ctx context.Context,
		node_event_id NodeEvent_Id_Field,
		node_event_email NodeEvent_Email_Field,
		node_event_node_id NodeEvent_NodeId_Field,
		node_event_event NodeEvent_Event_Field,
		optional NodeEvent_Create_Fields) (
		node_event *NodeEvent, err error)

	Create_Project(ctx context.Context,
		project_id Project_Id_Field,
		project_name Project_Name_Field,
		project_description Project_Description_Field,
		project_owner_id Project_OwnerId_Field,
		optional Project_Create_Fields) (
		project *Project, err error)

	Create_ProjectMember(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field,
		project_member_project_id ProjectMember_ProjectId_Field,
		optional ProjectMember_Create_Fields) (
		project_member *ProjectMember, err error)

	Create_RegistrationToken(ctx context.Context,
		registration_token_secret RegistrationToken_Secret_Field,
		registration_token_project_limit RegistrationToken_ProjectLimit_Field,
		optional RegistrationToken_Create_Fields) (
		registration_token *RegistrationToken, err error)

	Create_Reputation(ctx context.Context,
		reputation_id Reputation_Id_Field,
		reputation_audit_history Reputation_AuditHistory_Field,
		optional Reputation_Create_Fields) (
		reputation *Reputation, err error)

	Create_ResetPasswordToken(ctx context.Context,
		reset_password_token_secret ResetPasswordToken_Secret_Field,
		reset_password_token_owner_id ResetPasswordToken_OwnerId_Field) (
		reset_password_token *ResetPasswordToken, err error)

	Create_ReverificationAudits(ctx context.Context,
		reverification_audits_node_id ReverificationAudits_NodeId_Field,
		reverification_audits_stream_id ReverificationAudits_StreamId_Field,
		reverification_audits_position ReverificationAudits_Position_Field,
		reverification_audits_piece_num ReverificationAudits_PieceNum_Field,
		optional ReverificationAudits_Create_Fields) (
		reverification_audits *ReverificationAudits, err error)

	Create_StoragenodeBandwidthRollup(ctx context.Context,
		storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
		storagenode_bandwidth_rollup_interval_start StoragenodeBandwidthRollup_IntervalStart_Field,
		storagenode_bandwidth_rollup_interval_seconds StoragenodeBandwidthRollup_IntervalSeconds_Field,
		storagenode_bandwidth_rollup_action StoragenodeBandwidthRollup_Action_Field,
		storagenode_bandwidth_rollup_settled StoragenodeBandwidthRollup_Settled_Field,
		optional StoragenodeBandwidthRollup_Create_Fields) (
		storagenode_bandwidth_rollup *StoragenodeBandwidthRollup, err error)

	Create_StripeCustomer(ctx context.Context,
		stripe_customer_user_id StripeCustomer_UserId_Field,
		stripe_customer_customer_id StripeCustomer_CustomerId_Field,
		optional StripeCustomer_Create_Fields) (
		stripe_customer *StripeCustomer, err error)

	Create_StripecoinpaymentsInvoiceProjectRecord(ctx context.Context,
		stripecoinpayments_invoice_project_record_id StripecoinpaymentsInvoiceProjectRecord_Id_Field,
		stripecoinpayments_invoice_project_record_project_id StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field,
		stripecoinpayments_invoice_project_record_storage StripecoinpaymentsInvoiceProjectRecord_Storage_Field,
		stripecoinpayments_invoice_project_record_egress StripecoinpaymentsInvoiceProjectRecord_Egress_Field,
		stripecoinpayments_invoice_project_record_period_start StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field,
		stripecoinpayments_invoice_project_record_period_end StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field,
		stripecoinpayments_invoice_project_record_state StripecoinpaymentsInvoiceProjectRecord_State_Field,
		optional StripecoinpaymentsInvoiceProjectRecord_Create_Fields) (
		stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error)

	Create_StripecoinpaymentsTxConversionRate(ctx context.Context,
		stripecoinpayments_tx_conversion_rate_tx_id StripecoinpaymentsTxConversionRate_TxId_Field,
		stripecoinpayments_tx_conversion_rate_rate_numeric StripecoinpaymentsTxConversionRate_RateNumeric_Field) (
		stripecoinpayments_tx_conversion_rate *StripecoinpaymentsTxConversionRate, err error)

	Create_User(ctx context.Context,
		user_id User_Id_Field,
		user_email User_Email_Field,
		user_normalized_email User_NormalizedEmail_Field,
		user_full_name User_FullName_Field,
		user_password_hash User_PasswordHash_Field,
		optional User_Create_Fields) (
		user *User, err error)

	Create_ValueAttribution(ctx context.Context,
		value_attribution_project_id ValueAttribution_ProjectId_Field,
		value_attribution_bucket_name ValueAttribution_BucketName_Field,
		optional ValueAttribution_Create_Fields) (
		value_attribution *ValueAttribution, err error)

	Create_WebappSession(ctx context.Context,
		webapp_session_id WebappSession_Id_Field,
		webapp_session_user_id WebappSession_UserId_Field,
		webapp_session_ip_address WebappSession_IpAddress_Field,
		webapp_session_user_agent WebappSession_UserAgent_Field,
		webapp_session_expires_at WebappSession_ExpiresAt_Field) (
		webapp_session *WebappSession, err error)

	Delete_AccountFreezeEvent_By_UserId(ctx context.Context,
		account_freeze_event_user_id AccountFreezeEvent_UserId_Field) (
		count int64, err error)

	Delete_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
		account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
		account_freeze_event_event AccountFreezeEvent_Event_Field) (
		deleted bool, err error)

	Delete_ApiKey_By_Id(ctx context.Context,
		api_key_id ApiKey_Id_Field) (
		deleted bool, err error)

	Delete_ApiKey_By_ProjectId(ctx context.Context,
		api_key_project_id ApiKey_ProjectId_Field) (
		count int64, err error)

	Delete_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		deleted bool, err error)

	Delete_BucketMigration_By_Id(ctx context.Context,
		bucket_migration_id BucketMigration_Id_Field) (
		deleted bool, err error)

	Delete_BucketStorageTally_By_IntervalStart_Less(ctx context.Context,
		bucket_storage_tally_interval_start_less BucketStorageTally_IntervalStart_Field) (
		count int64, err error)

	Delete_Domain_By_ProjectId(ctx context.Context,
		domain_project_id Domain_ProjectId_Field) (
		count int64, err error)

	Delete_Domain_By_ProjectId_And_Subdomain(ctx context.Context,
		domain_project_id Domain_ProjectId_Field,
		domain_subdomain Domain_Subdomain_Field) (
		deleted bool, err error)

	Delete_Entitlement_By_Scope(ctx context.Context,
		entitlement_scope Entitlement_Scope_Field) (
		deleted bool, err error)

	Delete_NodeEvent_By_CreatedAt_Less(ctx context.Context,
		node_event_created_at_less NodeEvent_CreatedAt_Field) (
		count int64, err error)

	Delete_OauthClient_By_Id(ctx context.Context,
		oauth_client_id OauthClient_Id_Field) (
		deleted bool, err error)

	Delete_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
		project_invitation_project_id ProjectInvitation_ProjectId_Field,
		project_invitation_email ProjectInvitation_Email_Field) (
		deleted bool, err error)

	Delete_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field,
		project_member_project_id ProjectMember_ProjectId_Field) (
		deleted bool, err error)

	Delete_Project_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		deleted bool, err error)

	Delete_RepairQueue_By_UpdatedAt_Less(ctx context.Context,
		repair_queue_updated_at_less RepairQueue_UpdatedAt_Field) (
		count int64, err error)

	Delete_ResetPasswordToken_By_Secret(ctx context.Context,
		reset_password_token_secret ResetPasswordToken_Secret_Field) (
		deleted bool, err error)

	Delete_RestApiKey_By_Id(ctx context.Context,
		rest_api_key_id RestApiKey_Id_Field) (
		deleted bool, err error)

	Delete_ReverificationAudits_By_NodeId_And_StreamId_And_Position(ctx context.Context,
		reverification_audits_node_id ReverificationAudits_NodeId_Field,
		reverification_audits_stream_id ReverificationAudits_StreamId_Field,
		reverification_audits_position ReverificationAudits_Position_Field) (
		deleted bool, err error)

	Delete_StoragenodeStorageTally_By_IntervalEndTime_Less(ctx context.Context,
		storagenode_storage_tally_interval_end_time_less StoragenodeStorageTally_IntervalEndTime_Field) (
		count int64, err error)

	Delete_StorjscanPayment_By_Status(ctx context.Context,
		storjscan_payment_status StorjscanPayment_Status_Field) (
		count int64, err error)

	Delete_User_By_Id(ctx context.Context,
		user_id User_Id_Field) (
		deleted bool, err error)

	Delete_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
		value_attribution_project_id ValueAttribution_ProjectId_Field,
		value_attribution_bucket_name ValueAttribution_BucketName_Field) (
		deleted bool, err error)

	Delete_WebappSession_By_Id(ctx context.Context,
		webapp_session_id WebappSession_Id_Field) (
		deleted bool, err error)

	Delete_WebappSession_By_UserId(ctx context.Context,
		webapp_session_user_id WebappSession_UserId_Field) (
		count int64, err error)

	Delete_WebappSession_By_UserId_And_Id_Not(ctx context.Context,
		webapp_session_user_id WebappSession_UserId_Field,
		webapp_session_id_not WebappSession_Id_Field) (
		count int64, err error)

	Find_AccountingTimestamps_Value_By_Name(ctx context.Context,
		accounting_timestamps_name AccountingTimestamps_Name_Field) (
		row *Value_Row, err error)

	First_BillingTransaction_By_Source_And_Type_OrderBy_Desc_CreatedAt(ctx context.Context,
		billing_transaction_source BillingTransaction_Source_Field,
		billing_transaction_type BillingTransaction_Type_Field) (
		billing_transaction *BillingTransaction, err error)

	First_NodeEvent_By_Email_And_Event_OrderBy_Desc_CreatedAt(ctx context.Context,
		node_event_email NodeEvent_Email_Field,
		node_event_event NodeEvent_Event_Field) (
		node_event *NodeEvent, err error)

	First_ReverificationAudits_By_NodeId_OrderBy_Asc_StreamId_Asc_Position(ctx context.Context,
		reverification_audits_node_id ReverificationAudits_NodeId_Field) (
		reverification_audits *ReverificationAudits, err error)

	First_StoragenodeStorageTally_IntervalEndTime_OrderBy_Asc_IntervalEndTime(ctx context.Context) (
		row *IntervalEndTime_Row, err error)

	First_StorjscanPayment_BlockNumber_By_Status_And_ChainId_OrderBy_Desc_BlockNumber_Desc_LogIndex(ctx context.Context,
		storjscan_payment_status StorjscanPayment_Status_Field,
		storjscan_payment_chain_id StorjscanPayment_ChainId_Field) (
		row *BlockNumber_Row, err error)

	Get_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
		account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
		account_freeze_event_event AccountFreezeEvent_Event_Field) (
		account_freeze_event *AccountFreezeEvent, err error)

	Get_ApiKeyTail_By_Tail(ctx context.Context,
		api_key_tail_tail ApiKeyTail_Tail_Field) (
		api_key_tail *ApiKeyTail, err error)

	Get_ApiKey_Project_PublicId_By_ApiKey_Id(ctx context.Context,
		api_key_id ApiKey_Id_Field) (
		row *ApiKey_Project_PublicId_Row, err error)

	Get_ApiKey_Project_PublicId_By_ApiKey_Name_And_ApiKey_ProjectId(ctx context.Context,
		api_key_name ApiKey_Name_Field,
		api_key_project_id ApiKey_ProjectId_Field) (
		row *ApiKey_Project_PublicId_Row, err error)

	Get_ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_By_ApiKey_Head(ctx context.Context,
		api_key_head ApiKey_Head_Field) (
		row *ApiKey_Project_PublicId_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_Project_SegmentLimit_Project_UsageLimit_Project_BandwidthLimit_Project_UserSpecifiedUsageLimit_Project_UserSpecifiedBandwidthLimit_Row, err error)

	Get_BillingBalance_Balance_By_UserId(ctx context.Context,
		billing_balance_user_id BillingBalance_UserId_Field) (
		row *Balance_Row, err error)

	Get_BillingTransaction_By_Id(ctx context.Context,
		billing_transaction_id BillingTransaction_Id_Field) (
		billing_transaction *BillingTransaction, err error)

	Get_BillingTransaction_Metadata_By_Id(ctx context.Context,
		billing_transaction_id BillingTransaction_Id_Field) (
		row *Metadata_Row, err error)

	Get_Bucket(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		row *Id_CreatedBy_UserAgent_CreatedAt_Placement_Versioning_ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row, err error)

	Get_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		bucket_metainfo *BucketMetainfo, err error)

	Get_BucketMetainfo_CreatedBy_BucketMetainfo_CreatedAt_BucketMetainfo_Placement_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		row *CreatedBy_CreatedAt_Placement_Row, err error)

	Get_BucketMetainfo_ObjectLockEnabled_BucketMetainfo_DefaultRetentionMode_BucketMetainfo_DefaultRetentionDays_BucketMetainfo_DefaultRetentionYears_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		row *ObjectLockEnabled_DefaultRetentionMode_DefaultRetentionDays_DefaultRetentionYears_Row, err error)

	Get_BucketMetainfo_ObjectLockEnabled_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		row *ObjectLockEnabled_Row, err error)

	Get_BucketMetainfo_Placement_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		row *Placement_Row, err error)

	Get_BucketMetainfo_Tags_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		row *Tags_Row, err error)

	Get_BucketMetainfo_UserAgent_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		row *UserAgent_Row, err error)

	Get_BucketMetainfo_Versioning_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		row *Versioning_Row, err error)

	Get_BucketMigration_By_Id(ctx context.Context,
		bucket_migration_id BucketMigration_Id_Field) (
		bucket_migration *BucketMigration, err error)

	Get_Domain_By_ProjectId_And_Subdomain(ctx context.Context,
		domain_project_id Domain_ProjectId_Field,
		domain_subdomain Domain_Subdomain_Field) (
		domain *Domain, err error)

	Get_Entitlement_By_Scope(ctx context.Context,
		entitlement_scope Entitlement_Scope_Field) (
		entitlement *Entitlement, err error)

	Get_NodeEvent_By_Id(ctx context.Context,
		node_event_id NodeEvent_Id_Field) (
		node_event *NodeEvent, err error)

	Get_Node_By_Id(ctx context.Context,
		node_id Node_Id_Field) (
		node *Node, err error)

	Get_OauthClient_By_Id(ctx context.Context,
		oauth_client_id OauthClient_Id_Field) (
		oauth_client *OauthClient, err error)

	Get_OauthCode_By_Code_And_ClaimedAt_Is_Null(ctx context.Context,
		oauth_code_code OauthCode_Code_Field) (
		oauth_code *OauthCode, err error)

	Get_OauthToken_By_Kind_And_Token(ctx context.Context,
		oauth_token_kind OauthToken_Kind_Field,
		oauth_token_token OauthToken_Token_Field) (
		oauth_token *OauthToken, err error)

	Get_PeerIdentity_By_NodeId(ctx context.Context,
		peer_identity_node_id PeerIdentity_NodeId_Field) (
		peer_identity *PeerIdentity, err error)

	Get_PeerIdentity_LeafSerialNumber_By_NodeId(ctx context.Context,
		peer_identity_node_id PeerIdentity_NodeId_Field) (
		row *LeafSerialNumber_Row, err error)

	Get_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
		project_invitation_project_id ProjectInvitation_ProjectId_Field,
		project_invitation_email ProjectInvitation_Email_Field) (
		project_invitation *ProjectInvitation, err error)

	Get_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field,
		project_member_project_id ProjectMember_ProjectId_Field) (
		project_member *ProjectMember, err error)

	Get_Project_BandwidthLimit_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *BandwidthLimit_Row, err error)

	Get_Project_BandwidthLimit_Project_UserSpecifiedBandwidthLimit_Project_UsageLimit_Project_UserSpecifiedUsageLimit_Project_SegmentLimit_Project_RateLimit_Project_BurstLimit_Project_RateLimitHead_Project_BurstLimitHead_Project_RateLimitGet_Project_BurstLimitGet_Project_RateLimitPut_Project_BurstLimitPut_Project_RateLimitList_Project_BurstLimitList_Project_RateLimitDel_Project_BurstLimitDel_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *BandwidthLimit_UserSpecifiedBandwidthLimit_UsageLimit_UserSpecifiedUsageLimit_SegmentLimit_RateLimit_BurstLimit_RateLimitHead_BurstLimitHead_RateLimitGet_BurstLimitGet_RateLimitPut_BurstLimitPut_RateLimitList_BurstLimitList_RateLimitDel_BurstLimitDel_Row, err error)

	Get_Project_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		project *Project, err error)

	Get_Project_By_PublicId(ctx context.Context,
		project_public_id Project_PublicId_Field) (
		project *Project, err error)

	Get_Project_By__Id_Or_PublicId(ctx context.Context,
		project_id Project_Id_Field,
		project_public_id Project_PublicId_Field) (
		project *Project, err error)

	Get_Project_DefaultVersioning_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *DefaultVersioning_Row, err error)

	Get_Project_MaxBuckets_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *MaxBuckets_Row, err error)

	Get_Project_PassphraseEnc_Project_PassphraseEncKeyId_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *PassphraseEnc_PassphraseEncKeyId_Row, err error)

	Get_Project_PublicId_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *PublicId_Row, err error)

	Get_Project_Salt_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *Salt_Row, err error)

	Get_Project_SegmentLimit_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *SegmentLimit_Row, err error)

	Get_Project_UsageLimit_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *UsageLimit_Row, err error)

	Get_Project_UserAgent_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *UserAgent_Row, err error)

	Get_Project_UserSpecifiedBandwidthLimit_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *UserSpecifiedBandwidthLimit_Row, err error)

	Get_Project_UserSpecifiedUsageLimit_By_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *UserSpecifiedUsageLimit_Row, err error)

	Get_RegistrationToken_By_OwnerId(ctx context.Context,
		registration_token_owner_id RegistrationToken_OwnerId_Field) (
		registration_token *RegistrationToken, err error)

	Get_RegistrationToken_By_Secret(ctx context.Context,
		registration_token_secret RegistrationToken_Secret_Field) (
		registration_token *RegistrationToken, err error)

	Get_Reputation_By_Id(ctx context.Context,
		reputation_id Reputation_Id_Field) (
		reputation *Reputation, err error)

	Get_ResetPasswordToken_By_OwnerId(ctx context.Context,
		reset_password_token_owner_id ResetPasswordToken_OwnerId_Field) (
		reset_password_token *ResetPasswordToken, err error)

	Get_ResetPasswordToken_By_Secret(ctx context.Context,
		reset_password_token_secret ResetPasswordToken_Secret_Field) (
		reset_password_token *ResetPasswordToken, err error)

	Get_RestApiKey_By_Id(ctx context.Context,
		rest_api_key_id RestApiKey_Id_Field) (
		rest_api_key *RestApiKey, err error)

	Get_RestApiKey_By_Token(ctx context.Context,
		rest_api_key_token RestApiKey_Token_Field) (
		rest_api_key *RestApiKey, err error)

	Get_StoragenodePaystub_By_NodeId_And_Period(ctx context.Context,
		storagenode_paystub_node_id StoragenodePaystub_NodeId_Field,
		storagenode_paystub_period StoragenodePaystub_Period_Field) (
		storagenode_paystub *StoragenodePaystub, err error)

	Get_StorjscanWallet_UserId_By_WalletAddress(ctx context.Context,
		storjscan_wallet_wallet_address StorjscanWallet_WalletAddress_Field) (
		row *UserId_Row, err error)

	Get_StorjscanWallet_WalletAddress_By_UserId(ctx context.Context,
		storjscan_wallet_user_id StorjscanWallet_UserId_Field) (
		row *WalletAddress_Row, err error)

	Get_StripeCustomer_CustomerId_By_UserId(ctx context.Context,
		stripe_customer_user_id StripeCustomer_UserId_Field) (
		row *CustomerId_Row, err error)

	Get_StripeCustomer_CustomerId_StripeCustomer_BillingCustomerId_By_UserId(ctx context.Context,
		stripe_customer_user_id StripeCustomer_UserId_Field) (
		row *CustomerId_BillingCustomerId_Row, err error)

	Get_StripeCustomer_PackagePlan_StripeCustomer_PurchasedPackageAt_By_UserId(ctx context.Context,
		stripe_customer_user_id StripeCustomer_UserId_Field) (
		row *PackagePlan_PurchasedPackageAt_Row, err error)

	Get_StripeCustomer_UserId_By_CustomerId(ctx context.Context,
		stripe_customer_customer_id StripeCustomer_CustomerId_Field) (
		row *UserId_Row, err error)

	Get_StripecoinpaymentsInvoiceProjectRecord_By_ProjectId_And_PeriodStart_And_PeriodEnd(ctx context.Context,
		stripecoinpayments_invoice_project_record_project_id StripecoinpaymentsInvoiceProjectRecord_ProjectId_Field,
		stripecoinpayments_invoice_project_record_period_start StripecoinpaymentsInvoiceProjectRecord_PeriodStart_Field,
		stripecoinpayments_invoice_project_record_period_end StripecoinpaymentsInvoiceProjectRecord_PeriodEnd_Field) (
		stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error)

	Get_StripecoinpaymentsTxConversionRate_By_TxId(ctx context.Context,
		stripecoinpayments_tx_conversion_rate_tx_id StripecoinpaymentsTxConversionRate_TxId_Field) (
		stripecoinpayments_tx_conversion_rate *StripecoinpaymentsTxConversionRate, err error)

	Get_UserSettings_By_UserId(ctx context.Context,
		user_settings_user_id UserSettings_UserId_Field) (
		user_settings *UserSettings, err error)

	Get_User_By_ExternalId(ctx context.Context,
		user_external_id User_ExternalId_Field) (
		user *User, err error)

	Get_User_By_Id(ctx context.Context,
		user_id User_Id_Field) (
		user *User, err error)

	Get_User_By_NormalizedEmail_And_Status_Not_Number(ctx context.Context,
		user_normalized_email User_NormalizedEmail_Field) (
		user *User, err error)

	Get_User_By_NormalizedEmail_And_TenantId_And_Status_Not_Number(ctx context.Context,
		user_normalized_email User_NormalizedEmail_Field,
		user_tenant_id User_TenantId_Field) (
		user *User, err error)

	Get_User_Kind_By_Id(ctx context.Context,
		user_id User_Id_Field) (
		row *Kind_Row, err error)

	Get_User_ProjectLimit_By_Id(ctx context.Context,
		user_id User_Id_Field) (
		row *ProjectLimit_Row, err error)

	Get_User_ProjectStorageLimit_User_ProjectBandwidthLimit_User_ProjectSegmentLimit_By_Id(ctx context.Context,
		user_id User_Id_Field) (
		row *ProjectStorageLimit_ProjectBandwidthLimit_ProjectSegmentLimit_Row, err error)

	Get_User_Status_By_Project_Id(ctx context.Context,
		project_id Project_Id_Field) (
		row *Status_Row, err error)

	Get_User_UpgradeTime_By_Id(ctx context.Context,
		user_id User_Id_Field) (
		row *UpgradeTime_Row, err error)

	Get_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
		value_attribution_project_id ValueAttribution_ProjectId_Field,
		value_attribution_bucket_name ValueAttribution_BucketName_Field) (
		value_attribution *ValueAttribution, err error)

	Get_WebappSession_By_Id(ctx context.Context,
		webapp_session_id WebappSession_Id_Field) (
		webapp_session *WebappSession, err error)

	Has_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field) (
		has bool, err error)

	Has_NodeApiVersion_By_Id_And_ApiVersion_GreaterOrEqual(ctx context.Context,
		node_api_version_id NodeApiVersion_Id_Field,
		node_api_version_api_version_greater_or_equal NodeApiVersion_ApiVersion_Field) (
		has bool, err error)

	Limited_BucketMetainfo_By_ProjectId_And_Name_GreaterOrEqual_OrderBy_Asc_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name_greater_or_equal BucketMetainfo_Name_Field,
		limit int, offset int64) (
		rows []*BucketMetainfo, err error)

	Limited_BucketMetainfo_By_ProjectId_And_Name_Greater_OrderBy_Asc_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name_greater BucketMetainfo_Name_Field,
		limit int, offset int64) (
		rows []*BucketMetainfo, err error)

	Limited_BucketMigration_By_State_OrderBy_Asc_CreatedAt(ctx context.Context,
		bucket_migration_state BucketMigration_State_Field,
		limit int, offset int64) (
		rows []*BucketMigration, err error)

	Limited_Project_By_CreatedAt_Less_OrderBy_Asc_CreatedAt(ctx context.Context,
		project_created_at_less Project_CreatedAt_Field,
		limit int, offset int64) (
		rows []*Project, err error)

	Limited_Project_Id_Project_PublicId_Project_OwnerId_By_Status_And_StatusUpdatedAt_Less_OrderBy_Asc_StatusUpdatedAt(ctx context.Context,
		project_status Project_Status_Field,
		project_status_updated_at_less Project_StatusUpdatedAt_Field,
		limit int, offset int64) (
		rows []*Id_PublicId_OwnerId_Row, err error)

	Limited_StoragenodePayment_By_NodeId_And_Period_OrderBy_Desc_Id(ctx context.Context,
		storagenode_payment_node_id StoragenodePayment_NodeId_Field,
		storagenode_payment_period StoragenodePayment_Period_Field,
		limit int, offset int64) (
		rows []*StoragenodePayment, err error)

	Limited_StorjscanPayment_By_ToAddress_OrderBy_Desc_ChainId_Desc_BlockNumber_Desc_LogIndex(ctx context.Context,
		storjscan_payment_to_address StorjscanPayment_ToAddress_Field,
		limit int, offset int64) (
		rows []*StorjscanPayment, err error)

	Limited_User_Id_User_Email_User_FullName_By_Status(ctx context.Context,
		user_status User_Status_Field,
		limit int, offset int64) (
		rows []*Id_Email_FullName_Row, err error)

	Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event(ctx context.Context,
		user_status_not User_Status_Field,
		account_freeze_event_event AccountFreezeEvent_Event_Field,
		limit int, start *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation) (
		rows []*AccountFreezeEvent, next *Paged_AccountFreezeEvent_By_User_Status_Not_And_AccountFreezeEvent_Event_Continuation, err error)

	Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual(ctx context.Context,
		bucket_bandwidth_rollup_archive_interval_start_greater_or_equal BucketBandwidthRollupArchive_IntervalStart_Field,
		limit int, start *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation) (
		rows []*BucketBandwidthRollupArchive, next *Paged_BucketBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error)

	Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual(ctx context.Context,
		bucket_bandwidth_rollup_interval_start_greater_or_equal BucketBandwidthRollup_IntervalStart_Field,
		limit int, start *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation) (
		rows []*BucketBandwidthRollup, next *Paged_BucketBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error)

	Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name(ctx context.Context,
		limit int, start *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation) (
		rows []*ProjectId_Name_Row, next *Paged_BucketMetainfo_ProjectId_BucketMetainfo_Name_Continuation, err error)

	Paged_Node(ctx context.Context,
		limit int, start *Paged_Node_Continuation) (
		rows []*Node, next *Paged_Node_Continuation, err error)

	Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual(ctx context.Context,
		storagenode_bandwidth_rollup_archive_interval_start_greater_or_equal StoragenodeBandwidthRollupArchive_IntervalStart_Field,
		limit int, start *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation) (
		rows []*StoragenodeBandwidthRollupArchive, next *Paged_StoragenodeBandwidthRollupArchive_By_IntervalStart_GreaterOrEqual_Continuation, err error)

	Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual(ctx context.Context,
		storagenode_bandwidth_rollup_interval_start_greater_or_equal StoragenodeBandwidthRollup_IntervalStart_Field,
		limit int, start *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation) (
		rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_IntervalStart_GreaterOrEqual_Continuation, err error)

	Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual(ctx context.Context,
		storagenode_bandwidth_rollup_storagenode_id StoragenodeBandwidthRollup_StoragenodeId_Field,
		storagenode_bandwidth_rollup_interval_start_greater_or_equal StoragenodeBandwidthRollup_IntervalStart_Field,
		limit int, start *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation) (
		rows []*StoragenodeBandwidthRollup, next *Paged_StoragenodeBandwidthRollup_By_StoragenodeId_And_IntervalStart_GreaterOrEqual_Continuation, err error)

	ReplaceNoReturn_AccountingTimestamps(ctx context.Context,
		accounting_timestamps_name AccountingTimestamps_Name_Field,
		accounting_timestamps_value AccountingTimestamps_Value_Field) (
		err error)

	ReplaceNoReturn_NodeApiVersion(ctx context.Context,
		node_api_version_id NodeApiVersion_Id_Field,
		node_api_version_api_version NodeApiVersion_ApiVersion_Field) (
		err error)

	ReplaceNoReturn_NodeTags(ctx context.Context,
		node_tags_node_id NodeTags_NodeId_Field,
		node_tags_name NodeTags_Name_Field,
		node_tags_value NodeTags_Value_Field,
		node_tags_signed_at NodeTags_SignedAt_Field,
		node_tags_signer NodeTags_Signer_Field) (
		err error)

	ReplaceNoReturn_StoragenodePaystub(ctx context.Context,
		storagenode_paystub_period StoragenodePaystub_Period_Field,
		storagenode_paystub_node_id StoragenodePaystub_NodeId_Field,
		storagenode_paystub_codes StoragenodePaystub_Codes_Field,
		storagenode_paystub_usage_at_rest StoragenodePaystub_UsageAtRest_Field,
		storagenode_paystub_usage_get StoragenodePaystub_UsageGet_Field,
		storagenode_paystub_usage_put StoragenodePaystub_UsagePut_Field,
		storagenode_paystub_usage_get_repair StoragenodePaystub_UsageGetRepair_Field,
		storagenode_paystub_usage_put_repair StoragenodePaystub_UsagePutRepair_Field,
		storagenode_paystub_usage_get_audit StoragenodePaystub_UsageGetAudit_Field,
		storagenode_paystub_comp_at_rest StoragenodePaystub_CompAtRest_Field,
		storagenode_paystub_comp_get StoragenodePaystub_CompGet_Field,
		storagenode_paystub_comp_put StoragenodePaystub_CompPut_Field,
		storagenode_paystub_comp_get_repair StoragenodePaystub_CompGetRepair_Field,
		storagenode_paystub_comp_put_repair StoragenodePaystub_CompPutRepair_Field,
		storagenode_paystub_comp_get_audit StoragenodePaystub_CompGetAudit_Field,
		storagenode_paystub_surge_percent StoragenodePaystub_SurgePercent_Field,
		storagenode_paystub_held StoragenodePaystub_Held_Field,
		storagenode_paystub_owed StoragenodePaystub_Owed_Field,
		storagenode_paystub_disposed StoragenodePaystub_Disposed_Field,
		storagenode_paystub_paid StoragenodePaystub_Paid_Field,
		storagenode_paystub_distributed StoragenodePaystub_Distributed_Field) (
		err error)

	Replace_AccountFreezeEvent(ctx context.Context,
		account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
		account_freeze_event_event AccountFreezeEvent_Event_Field,
		optional AccountFreezeEvent_Create_Fields) (
		account_freeze_event *AccountFreezeEvent, err error)

	Replace_ApiKeyTail(ctx context.Context,
		api_key_tail_tail ApiKeyTail_Tail_Field,
		api_key_tail_parent_tail ApiKeyTail_ParentTail_Field,
		api_key_tail_caveat ApiKeyTail_Caveat_Field,
		api_key_tail_last_used ApiKeyTail_LastUsed_Field,
		optional ApiKeyTail_Create_Fields) (
		api_key_tail *ApiKeyTail, err error)

	Replace_Entitlement(ctx context.Context,
		entitlement_scope Entitlement_Scope_Field,
		entitlement_updated_at Entitlement_UpdatedAt_Field,
		optional Entitlement_Create_Fields) (
		entitlement *Entitlement, err error)

	Replace_ProjectInvitation(ctx context.Context,
		project_invitation_project_id ProjectInvitation_ProjectId_Field,
		project_invitation_email ProjectInvitation_Email_Field,
		optional ProjectInvitation_Create_Fields) (
		project_invitation *ProjectInvitation, err error)

	UpdateNoReturn_AccountingTimestamps_By_Name(ctx context.Context,
		accounting_timestamps_name AccountingTimestamps_Name_Field,
		update AccountingTimestamps_Update_Fields) (
		err error)

	UpdateNoReturn_ApiKey_By_Id(ctx context.Context,
		api_key_id ApiKey_Id_Field,
		update ApiKey_Update_Fields) (
		err error)

	UpdateNoReturn_BillingTransaction_By_Id_And_Status(ctx context.Context,
		billing_transaction_id BillingTransaction_Id_Field,
		billing_transaction_status BillingTransaction_Status_Field,
		update BillingTransaction_Update_Fields) (
		err error)

	UpdateNoReturn_NodeApiVersion_By_Id_And_ApiVersion_Less(ctx context.Context,
		node_api_version_id NodeApiVersion_Id_Field,
		node_api_version_api_version_less NodeApiVersion_ApiVersion_Field,
		update NodeApiVersion_Update_Fields) (
		err error)

	UpdateNoReturn_Node_By_Id(ctx context.Context,
		node_id Node_Id_Field,
		update Node_Update_Fields) (
		err error)

	UpdateNoReturn_Node_By_Id_And_Disqualified_Is_Null_And_ExitFinishedAt_Is_Null(ctx context.Context,
		node_id Node_Id_Field,
		update Node_Update_Fields) (
		err error)

	UpdateNoReturn_OauthClient_By_Id(ctx context.Context,
		oauth_client_id OauthClient_Id_Field,
		update OauthClient_Update_Fields) (
		err error)

	UpdateNoReturn_OauthCode_By_Code_And_ClaimedAt_Is_Null(ctx context.Context,
		oauth_code_code OauthCode_Code_Field,
		update OauthCode_Update_Fields) (
		err error)

	UpdateNoReturn_OauthToken_By_Token_And_Kind(ctx context.Context,
		oauth_token_token OauthToken_Token_Field,
		oauth_token_kind OauthToken_Kind_Field,
		update OauthToken_Update_Fields) (
		err error)

	UpdateNoReturn_PeerIdentity_By_NodeId(ctx context.Context,
		peer_identity_node_id PeerIdentity_NodeId_Field,
		update PeerIdentity_Update_Fields) (
		err error)

	UpdateNoReturn_Reputation_By_Id(ctx context.Context,
		reputation_id Reputation_Id_Field,
		update Reputation_Update_Fields) (
		err error)

	Update_AccountFreezeEvent_By_UserId_And_Event(ctx context.Context,
		account_freeze_event_user_id AccountFreezeEvent_UserId_Field,
		account_freeze_event_event AccountFreezeEvent_Event_Field,
		update AccountFreezeEvent_Update_Fields) (
		account_freeze_event *AccountFreezeEvent, err error)

	Update_BillingBalance_By_UserId_And_Balance(ctx context.Context,
		billing_balance_user_id BillingBalance_UserId_Field,
		billing_balance_balance BillingBalance_Balance_Field,
		update BillingBalance_Update_Fields) (
		billing_balance *BillingBalance, err error)

	Update_BucketMetainfo_By_ProjectId_And_Name(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field,
		update BucketMetainfo_Update_Fields) (
		bucket_metainfo *BucketMetainfo, err error)

	Update_BucketMetainfo_By_ProjectId_And_Name_And_Versioning_GreaterOrEqual(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field,
		bucket_metainfo_versioning_greater_or_equal BucketMetainfo_Versioning_Field,
		update BucketMetainfo_Update_Fields) (
		bucket_metainfo *BucketMetainfo, err error)

	Update_BucketMetainfo_By_ProjectId_And_Name_And_Versioning_GreaterOrEqual_And_ObjectLockEnabled_Equal_False(ctx context.Context,
		bucket_metainfo_project_id BucketMetainfo_ProjectId_Field,
		bucket_metainfo_name BucketMetainfo_Name_Field,
		bucket_metainfo_versioning_greater_or_equal BucketMetainfo_Versioning_Field,
		update BucketMetainfo_Update_Fields) (
		bucket_metainfo *BucketMetainfo, err error)

	Update_BucketMigration_By_Id(ctx context.Context,
		bucket_migration_id BucketMigration_Id_Field,
		update BucketMigration_Update_Fields) (
		bucket_migration *BucketMigration, err error)

	Update_CoinpaymentsTransaction_By_Id(ctx context.Context,
		coinpayments_transaction_id CoinpaymentsTransaction_Id_Field,
		update CoinpaymentsTransaction_Update_Fields) (
		coinpayments_transaction *CoinpaymentsTransaction, err error)

	Update_Node_By_Id(ctx context.Context,
		node_id Node_Id_Field,
		update Node_Update_Fields) (
		node *Node, err error)

	Update_ProjectInvitation_By_ProjectId_And_Email(ctx context.Context,
		project_invitation_project_id ProjectInvitation_ProjectId_Field,
		project_invitation_email ProjectInvitation_Email_Field,
		update ProjectInvitation_Update_Fields) (
		project_invitation *ProjectInvitation, err error)

	Update_ProjectMember_By_MemberId_And_ProjectId(ctx context.Context,
		project_member_member_id ProjectMember_MemberId_Field,
		project_member_project_id ProjectMember_ProjectId_Field,
		update ProjectMember_Update_Fields) (
		project_member *ProjectMember, err error)

	Update_Project_By_Id(ctx context.Context,
		project_id Project_Id_Field,
		update Project_Update_Fields) (
		project *Project, err error)

	Update_RegistrationToken_By_Secret(ctx context.Context,
		registration_token_secret RegistrationToken_Secret_Field,
		update RegistrationToken_Update_Fields) (
		registration_token *RegistrationToken, err error)

	Update_Reputation_By_Id(ctx context.Context,
		reputation_id Reputation_Id_Field,
		update Reputation_Update_Fields) (
		reputation *Reputation, err error)

	Update_Reputation_By_Id_And_AuditHistory(ctx context.Context,
		reputation_id Reputation_Id_Field,
		reputation_audit_history Reputation_AuditHistory_Field,
		update Reputation_Update_Fields) (
		reputation *Reputation, err error)

	Update_StripeCustomer_By_UserId(ctx context.Context,
		stripe_customer_user_id StripeCustomer_UserId_Field,
		update StripeCustomer_Update_Fields) (
		stripe_customer *StripeCustomer, err error)

	Update_StripecoinpaymentsInvoiceProjectRecord_By_Id(ctx context.Context,
		stripecoinpayments_invoice_project_record_id StripecoinpaymentsInvoiceProjectRecord_Id_Field,
		update StripecoinpaymentsInvoiceProjectRecord_Update_Fields) (
		stripecoinpayments_invoice_project_record *StripecoinpaymentsInvoiceProjectRecord, err error)

	Update_UserSettings_By_UserId(ctx context.Context,
		user_settings_user_id UserSettings_UserId_Field,
		update UserSettings_Update_Fields) (
		user_settings *UserSettings, err error)

	Update_User_By_Id(ctx context.Context,
		user_id User_Id_Field,
		update User_Update_Fields) (
		user *User, err error)

	Update_ValueAttribution_By_ProjectId_And_BucketName(ctx context.Context,
		value_attribution_project_id ValueAttribution_ProjectId_Field,
		value_attribution_bucket_name ValueAttribution_BucketName_Field,
		update ValueAttribution_Update_Fields) (
		value_attribution *ValueAttribution, err error)

	Update_WebappSession_By_Id(ctx context.Context,
		webapp_session_id WebappSession_Id_Field,
		update WebappSession_Update_Fields) (
		webapp_session *WebappSession, err error)
}

type DialectMethods interface {
	AsOfSystemTime(time.Time) string
	AsOfSystemInterval(time.Duration) string
	Rebind(s string) string
}

type TxMethods interface {
	Methods
	DialectMethods

	Commit() error
	Rollback() error
}

type txMethods interface {
	TxMethods

	deleteAll(ctx context.Context) (int64, error)
	makeErr(err error) error
}

type DBMethods interface {
	Methods
	DialectMethods

	Schema() []string
	DropSchema() []string
}

type dbMethods interface {
	DBMethods

	wrapTx(tx tagsql.Tx) txMethods
	makeErr(err error) error
}

func openpgx(source string) (*sql.DB, error) {
	return sql.Open("pgx", source)
}

func openpgxcockroach(source string) (*sql.DB, error) {
	// try first with "cockroach" as a driver in case someone has registered
	// some special stuff. if that fails, then try again with "pgx" as
	// the driver.
	db, err := sql.Open("cockroach", source)
	if err != nil {
		db, err = sql.Open("pgx", source)
	}
	return db, err
}

func openspanner(source string) (*sql.DB, error) {
	connectorConfig, err := sqlspanner.ExtractConnectorConfig(strings.TrimPrefix(source, "spanner://"))
	if err != nil {
		return nil, err
	}

	var sessionLabels map[string]string
	if v, ok := connectorConfig.Params["sessionlabels"]; ok {
		sessionLabels = map[string]string{}
		for _, kv := range strings.Split(v, ",") {
			key, value, ok := strings.Cut(kv, "=")
			if !ok {
				return nil, fmt.Errorf("incorrect formatting of session labels in %q", v)
			}
			sessionLabels[key] = value
		}
	}

	connectorConfig.Configurator = func(config *spanner.ClientConfig, opts *[]option.ClientOption) {
		for k, v := range sessionLabels {
			config.SessionLabels[k] = v
		}
		if v, ok := connectorConfig.Params["useragent"]; ok {
			config.UserAgent = v
		}
	}

	connector, err := sqlspanner.CreateConnector(connectorConfig)
	if err != nil {
		return nil, err
	}
	return sql.OpenDB(connector), nil
}

func spannerConvertJSON(v any) any {
	if v == nil {
		return spanner.NullJSON{Value: nil, Valid: true}
	}
	if v, ok := v.([]byte); ok {
		return spanner.NullJSON{Value: v, Valid: true}
	}
	if v, ok := v.(*[]byte); ok {
		return &spannerJSON{data: v}
	}
	return v
}

type spannerJSON struct {
	data *[]byte
}

func (s *spannerJSON) Scan(input any) error {
	if input == nil {
		*s.data = nil
		return nil
	}
	if v, ok := input.(spanner.NullJSON); ok {
		if !v.Valid || v.Value == nil {
			*s.data = nil
			return nil
		}

		if str, ok := v.Value.(string); ok {
			bytesVal, err := base64.StdEncoding.DecodeString(str)
			if err != nil {
				return fmt.Errorf("expected base64 from spanner: %w", err)
			}
			*s.data = bytesVal
			return nil
		}

		// "{}" gets returned back as a map[string]interface{} for some reason, so capture any other odd value
		// that comes back and try and marshal it via json.
		bytesVal, err := json.Marshal(v.Value)
		if err != nil {
			return fmt.Errorf("failed to marshal spanner.NullJSON value with type %T to json bytes: %w", v.Value, err)
		}
		*s.data = bytesVal

		return nil
	}
	return fmt.Errorf("unable to decode %T", input)
}

func (obj *spannerImpl) withTx(ctx context.Context, fn func(tx tagsql.Tx) error) (err error) {
	for {
		err := obj.withTxOnce(ctx, fn)
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
		}
		return err
	}
}

func (obj *spannerImpl) withTxOnce(ctx context.Context, fn func(tx tagsql.Tx) error) (err error) {
	tx, err := obj.db.BeginTx(ctx, nil)
	if err != nil {
		return obj.makeErr(err)
	}
	defer func() {
		if err != nil {
			err = obj.makeErr(errors.Join(err, tx.Rollback()))
		} else {
			err = obj.makeErr(tx.Commit())
		}
	}()
	return fn(tx)
}
